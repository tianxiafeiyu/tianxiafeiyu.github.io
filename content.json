{"meta":{"title":"Dalin blog","subtitle":"","description":"","author":"Dalin","url":"http://example.com"},"pages":[{"title":"Categories","date":"2022-12-12T17:36:23.245Z","updated":"2022-12-12T17:36:23.245Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"About","date":"2022-12-12T17:36:23.245Z","updated":"2022-12-12T17:36:23.245Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""},{"title":"Tags","date":"2022-12-12T17:36:23.245Z","updated":"2022-12-12T17:36:23.245Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"开发笔记/服务缓存数据更新","date":"2022-12-12T17:36:23.245Z","updated":"2022-12-12T17:36:23.245Z","comments":true,"path":"2022/12/12/开发笔记/服务缓存数据更新/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E6%9C%8D%E5%8A%A1%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E6%9B%B4%E6%96%B0/","excerpt":"","text":"内存缓存作为最方便的提升效率的手段，很多程序都有使用到。 缓存痛点： 内存占用 缓存一致性 缓存并发 怎么解决时效性，保证缓存能够及时更新： 更新方法： 定时更新 动态更新","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"","slug":"开发笔记/进程间通信技术","date":"2022-12-12T17:36:23.245Z","updated":"2022-12-12T17:36:23.245Z","comments":true,"path":"2022/12/12/开发笔记/进程间通信技术/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/","excerpt":"","text":"转自 https://my.oschina.net/taogang/blog/4313908 最早在Unix&#x2F;Linux的编程领域，提供了进程间通信的手段，例如：管道，信号量，消息队列，套接字（Socket）等。如果你的应用是由不同语言编写的，那么这里只能选择Socket通信作为应用之间的API手段。但是Socket通信是一种非常低Level的通信手段，它以底层的数据包作为抽象和通信内容，很难维护和使用。 早期的进程间通信技术包括： DCOM （ Distributed Component Object Model ）分布式组件对象模型，这个是微软的技术，只能用于Windows平台， 通过网络实现远程对象间的通信 RMI （ Remote Method Call) Java的远程方法调用，这个是Java自己的RPC，只能用于Java应用之间的远程调用。 JNI Java的本地接口， 支持Java应用调用本地方法，这个是跨越语言障碍的，但是仅仅局限于Java应用调用其它的本地应用，不具备互操作性，是个单项通道。 CORBA1991年一种名叫CORBA （ Common Object Request Broker Architecture ） 的技术出现。 CORBA和之前提到的DCOM和RMI类似，都提供了远程的对象&#x2F;方法调用，但是CORBA是一种与语言和实现无关的技术 CORBA定了与语言解耦的系统间通信的标准。开发CORAB的过程从IDL的定义开始，用户通过IDL定义了对象，然后在Server端实现该对象的应用逻辑，在Client端调用该对象。 CORBA存在的主要问题： 对象的生命周期管理比较复杂。远程对象的发现，创建和销毁都会带来问题 整个CORAB的架构比较复杂 XML-RPC &#x2F; SOAPXML-RPC发表于1998年，由UserLand Software（UserLand Software）的Dave Winer及Microsoft共同发表。后来在新的功能不断被引入下，这个标准慢慢演变成为今日的SOAP协议。 下面是一个 XML-RPC的请求&#x2F;响应的例子： 123456789101112131415161718&lt;?xml version=&quot;1.0&quot;?&gt;&lt;methodCall&gt; &lt;methodName&gt;examples.getStateName&lt;/methodName&gt; &lt;params&gt; &lt;param&gt; &lt;value&gt;&lt;i4&gt;40&lt;/i4&gt;&lt;/value&gt; &lt;/param&gt; &lt;/params&gt;&lt;/methodCall&gt;&lt;?xml version=&quot;1.0&quot;?&gt;&lt;methodResponse&gt; &lt;params&gt; &lt;param&gt; &lt;value&gt;&lt;string&gt;South Dakota&lt;/string&gt;&lt;/value&gt; &lt;/param&gt; &lt;/params&gt;&lt;/methodResponse&gt; SOAP是 Simple Object Access Protocol 的缩写。SOAP为Web服务提供了Web服务协议栈的Messaging Protocol层。它是一个基于XML的协议，由三部分组成： 一个信封，它定义了消息结构以及如何处理它 一组用于表达应用程序定义的数据类型实例的编码规则 表示过程调用和响应的约定 SOAP具有三个主要特征： 可扩展性（安全性和WS-Addressing在开发中） 中立性（SOAP可以通过HTTP，SMTP，TCP，UDP等任何协议进行操作） 独立性（SOAP允许任何编程语言） 作为SOAP过程可以执行的操作的示例，应用程序可以将SOAP请求发送到启用了带有搜索参数的Web服务的服务器（例如，房地产价格数据库）。然后，服务器返回SOAP响应（包含结果数据的XML格式的文档），例如价格，位置，功能。由于生成的数据采用标准化的机器可解析格式，因此发出请求的应用程序可以直接将其集成。 SOAP体系结构由以下几层规范组成： 讯息格式 邮件交换模式（MEP） 底层传输协议绑定 消息处理模型 协议可扩展性 下面是一个SOAP消息的例子： 12345678910111213141516POST /InStock HTTP/1.1Host: www.example.orgContent-Type: application/soap+xml; charset=utf-8Content-Length: 299SOAPAction: &quot;http://www.w3.org/2003/05/soap-envelope&quot;&lt;?xml version=&quot;1.0&quot;?&gt;&lt;soap:Envelope xmlns:soap=&quot;http://www.w3.org/2003/05/soap-envelope&quot; xmlns:m=&quot;http://www.example.org&quot;&gt; &lt;soap:Header&gt; &lt;/soap:Header&gt; &lt;soap:Body&gt; &lt;m:GetStockPrice&gt; &lt;m:StockName&gt;T&lt;/m:StockName&gt; &lt;/m:GetStockPrice&gt; &lt;/soap:Body&gt;&lt;/soap:Envelope&gt; 相比较XML-RPC，他的功能更多，当然消息结构也更复杂。 SOAP是W3C推荐的Webservice标准，一度也是非常的流行，但是我们看到基于XML的消息比较复杂，消息本身因为XML的原因，有相当多的开销。于是后面又有了基于JSON的RPC格式。但总的来说，SOAP也已经是昨日黄花，当今的应用构建，你选它的概率应该也不大了。 RESTREST是当今最为流行的API。因为大量的Web应用采用REST作为其API的选择。REST是 Representational State Transfer 的缩写。是Roy Thomas Fielding博士于2000年在他的博士论文中提出来的一种万维网软件架构风格，目的是便于不同软件&#x2F;程序在网络（例如互联网）中互相传递信息。表现层状态转换是根基于超文本传输协议（HTTP）之上而确定的一组约束和属性，是一种设计提供万维网络服务的软件构建风格。符合或兼容于这种架构风格（简称为 REST 或 RESTful）的网络服务，允许客户端发出以统一资源标识符访问和操作网络资源的请求，而与预先定义好的无状态操作集一致化。因此表现层状态转换提供了在互联网络的计算系统之间，彼此资源可交互使用的协作性质（interoperability）。相对于其它种类的网络服务，例如SOAP服务，则是以本身所定义的操作集，来访问网络上的资源。目前在三种主流的Web服务实现方案中，因为REST模式与复杂的SOAP和XML-RPC相比更加简洁，越来越多的Web服务开始采用REST风格设计和实现。所以我么可以看到软件的发展，大体是从复杂变得简单，只有简单的东西才会变的更有生命力。 为了使任何应用程序真正实现RESTful，必须遵循六个体系结构约束： 统一接口：意味着必须向Web应用程序中的API使用者提供API接口。 客户端服务器：客户端和服务器必须彼此独立，并且客户端应仅知道资源的URI。 无状态：服务器不得存储与客户端请求相关的任何内容。 客户端负责维护应用程序的状态。 可缓存的：资源必须可缓存。 分层系统：体系结构必须是分层的，这意味着体系结构的组件可以位于多个服务器中。 按需代码：客户端必须能够获取可执行代码作为响应。 这是一个可选约束。 基于REST的Web服务被称为RESTful Web服务。 在这些应用程序中，每个组件都是一种资源，可以使用HTTP标准方法通过公共接口访问这些资源。 以下四种HTTP方法通常用于基于REST的体系结构中： GET-对资源的只读访问。 POST —创建一个新资源。 DELETE—删除资源。 PUT-更新现有资源&#x2F;创建新资源。 RESTFul风格API所有的操作都是一个动词，对应HTTP请求的一种类型。每一个操作都定义了对操作的资源的某种行为。这种抽象，特别适合相当多的Web应用，后台是一个数据库，每一个REST的端点对应了一张数据库的表，很自然的利用REST操作来实现表的增删查改。 当然RESTFul的风格也有它的不足： 不是所有的应用操作都可以用资源的增删查改来对应，在实际的开发中经常会需要把一个操作映射为一个资源这种不伦不类的行为。 REST是同步服务，如果需要可能要引入回调机制。例如Webhook。 REST只提供客户端调用服务器的选项，不支持服务器端发起请求。 GraphQLGraphQL是一个开源的API数据查询和操作语言及实现为了实现上述操作的相应运行环境。 2012年，GraphQL由Facebook内部开发，2015年公开公布。 2018年11月7日，Facebook将GraphQL项目转移到新成立的GraphQL基金会 。 GraphQL规范概述了5条设计原则，这使其成为现代前端开发的精心设计的解决方案: 查询是分层结构的，具有分层和嵌套字段，查询与响应数据一对一匹配。 查询和响应的形状像树，可以查询每个项目的其他嵌套字段。 该结构以产品为中心，着重于前端希望如何接收数据，并构建交付所需的运行时。 这样一来，就可以向后端请求一个所需的所有数据，然后让服务器根据GraphQL的规范从不同的端点获取数据。 它使用特定于应用程序的类型系统，使开发人员能够确保查询使用有效类型，并且在执行之前在语法上正确。 GraphQL查询是在客户端指定的，因此客户端确切知道它将以什么格式接收数据。 带有GraphQL的服务器结构必须是自省的，或者可由GraphQL本身查询。 这将启用功能强大的开发人员工具，例如GraphiQL或GraphQL Playground，这两种工具都将使开发人员能够准确查看哪些查询和字段可供他们在服务器中使用。 像RESTful API一样，GraphQL API旨在处理HTTP请求并提供对这些请求的响应。 但是，相似之处到此结束。 在REST API建立在请求方法和端点之间的连接上的情况下，GraphQL API设计为仅使用一个始终通过POST请求查询的端点，通常使用URL yourdomain.com&#x2F;graphql。 达到GraphQL端点后，客户端请求的负担将完全在请求主体内处理。 该请求主体必须遵守GraphQL规范，并且API必须具有适当的服务器端逻辑来处理这些请求并提供适当的响应。 与RESTful API相比，这提供了更流畅的客户端体验，后者可能要求客户端对多个数据进行多次请求，并在数据返回后进行操作。 GraphQL提供的性能优于REST API，可以为前端开发人员带来回报。 使用GraphQL规范创建服务器可能需要更多设置和编写预测性服务器端逻辑来解析和处理请求。 尽管GraphQL的安装成本可能会高于传统的REST架构，但更具可维护性的代码，强大的开发工具以及简化的客户端查询，这些都是不错的收益。 除了灵活性这个最大的优点外，GraphQL还有以下的优点： 声明性的数据获取，避免了客户端和服务器端的额外交互 优秀的开发体验，不需要版本控制，因为引入新的字段不会影响到API查询。同时客户端和服务器端的团队可以并行的独立工作。 强类型的GraphQL模式使得代码可预测，并及早发现错误。 当然，GraphQL也不是没有缺点： 使用GraphQL，如果您需要查找有关列表或记录集合的信息，则处理起来会很棘手。 例如，如果您想获取包含其地址的用户列表的详细信息，则它将执行n + 1个查询。 一个用于用户列表，然后n查询每个用户的地址。现在它会严重影响性能，因此必须非常小心地处理它。 很难缓存，缓存API响应的目的主要是为了更快地从将来的请求中获取响应。 与GraphQL不同，RESTful API可以利用HTTP规范中内置的缓存。 正如前面提到的，GraphQL查询可以请求资源的任何字段，因此缓存本质上是困难的。 gRPCgRPC是一个开源的远程过程调用框架，用于在服务之间进行高性能的通信。 这是将以不同语言编写的服务与可插拔支持（用于负载平衡，跟踪，运行状况检查和身份验证）相连接的有效方法。 默认情况下，gRPC使用Protobuf（协议缓冲区）序列化结构化数据。 通常，对于微服务体系结构，gRPC被认为是REST协议的更好替代方案。 gRPC中的” g”可以归因于最初开发该技术的Google。 gRPC是对传统RPC框架的改编。 那么，它与现有的RPC框架有何不同？ 最重要的区别是gRPC使用protobuf 协议缓冲区作为接口定义语言进行序列化和通信，而不是JSON &#x2F; XML。 协议缓冲区可以描述数据的结构，并且可以从该描述中生成代码，以生成或解析表示结构化数据的字节流。 这就是为什么gRPC首选多语言（使用不同技术实现）的Web应用程序的原因。 二进制数据格式使通信更轻松。 gRPC也可以与其他数据格式一起使用，但是首选的是protobuf。 同样，gRPC建立在HTTP &#x2F; 2之上，它支持双向通信以及传统的请求&#x2F;响应。 gRPC允许服务器和客户端之间的松散耦合。 在实践中，客户端打开与gRPC服务器的长期连接，并且将为每个RPC调用打开一个新的HTTP &#x2F; 2流。 与使用JSON（主要是JSON）的REST不同，gRPC使用Protobuf，这是编码数据的更好方法。 由于JSON是基于文本的格式，因此它比protobuf格式的压缩数据要重得多。与REST相比，gRPC的另一个显着改进是它使用HTTP 2作为其传输协议。 REST使用的HTTP 1.1基本上是一个请求-响应模型。 gRPC利用HTTP 2的双向通信功能以及传统的响应请求结构。 在HTTP 1.1中，当多个请求来自多个客户端时，它们将被一一处理。 这会降低系统速度。 HTTP 2允许多路复用，因此可以同时处理多个请求和响应。 gRPC的开发模式和之前提到的CORBA有些类似。Protobuf充当了IDL的角色，然后利用工具生成各种语言的代码，最后在生成的代码上实现服务器端和客户端的逻辑。 gRPC的优点是： 出色的性能，因为采用protobuf编码和http&#x2F;2 支持服务器端和客户端的双向通信 易用，相比REST开发，需要更少的代码 缺点： 更陡峭的学习曲线 支持的语言的种类没有REST多，当然它还在发展中 因为需要Protobuf的编译，这带来了服务器和客户端一定的耦合，因为接口变动的时候需要重新编译生成代码。REST的化，基于不同的工具链可能由不同的解决方案 因为其高性能，gRPC更适合被用于系统内部组件的通信选择。比如微服务架构中，对外的服务采用了REST或者GraphQL的API，而内部微服务之间使用的是gRPC。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"","slug":"开发笔记/数据库/mysql、redis开启远程访问","date":"2022-12-12T17:36:23.245Z","updated":"2022-12-12T17:36:23.245Z","comments":true,"path":"2022/12/12/开发笔记/数据库/mysql、redis开启远程访问/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql%E3%80%81redis%E5%BC%80%E5%90%AF%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/","excerpt":"","text":"要在本地使用云服务器中的mysql、redis服务，需要开启远程访问，阿里云还需要在控制台中开放3306、6379访问端口。 1、mysql开启远程访问默认情况下，mysql帐号不允许从远程登陆，只能在localhost登录。 在localhost登入mysql后，更改 “mysql” 数据库里的 “user” 表里的 “host” 项，将”localhost”改为”%” 12345678$ mysql -u root -p Enter password: …… mysql&gt; mysql&gt;update user set host = &#x27;%&#x27; where user = &#x27;root&#x27;; mysql&gt;select host, user from user; 2、redis开启远程访问防火墙开放6379端口： 123vim /etc/sysconfig/iptables添加字段：-A RH-Firewall-1-INPUT -m state NEW -m tcp -dport 8080 -j ACCEPT 修改redis配置文件vim &#x2F;etc&#x2F;redis.conf bind127.0.0.1 这一行注释掉 protected-mode yes 改为 protected-mode no 保存后重启：sysremctl restart redis 2020-6-1：由于鄙人暴露了mysql到公网上，不加约束、放荡不羁，如今数据库已遭到比特币勒索，血与泪的教训，以后要多加规范，防火防盗防小人","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"数据库","slug":"开发笔记/数据库","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"","slug":"开发笔记/k8s配置文件详解","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/k8s配置文件详解/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/k8s%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"k8s yaml文件yaml基础YAML是专门用来写配置文件的语言，非常简洁和强大，使用比json更方便。它实质上是一种通用的数据串行化格式。 YAML语法规则： 12345大小写敏感使用缩进表示层级关系缩进时不允许使用Tal键，只允许使用空格缩进的空格数目不重要，只要相同层级的元素左侧对齐即可”#” 表示注释，从这个字符一直到行尾，都会被解析器忽略 在Kubernetes中，只需要知道两种结构类型即可：Lists和Maps YAML Maps： Map顾名思义指的是字典，即一个Key:Value 的键值对信息。例如： 123apiVersion: v1kind: Pod 注：---为可选的分隔符 ，当需要在一个文件中定义多个结构的时候需要使用。上述内容表示有两个键apiVersion和kind，分别对应的值为v1和Pod。 Maps的value既能够对应字符串也能够对应一个Maps。例如： 123456apiVersion: v1kind: Podmetadata: name: kube100-site labels: app: web List即列表，说白了就是数组，例如： 12345args -beijing -shanghai -shenzhen -guangzhou 当然Lists的子项也可以是Maps，Maps的子项也可以是List，例如： 123456789101112131415apiVersion: v1kind: Podmetadata: name: kube100-site labels: app: webspec: containers: - name: front-end image: nginx ports: - containerPort: 80 - name: flaskapp-demo image: jcdemo/flaskapp ports: 8080 k8s yaml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172apiVersion: v1 #指定api版本，此值必须在kubectl apiversion中 kind: Pod #指定创建资源的角色/类型 metadata: #资源的元数据/属性 name: web04-pod #资源的名字，在同一个namespace中必须唯一 labels: #设定资源的标签，详情请见http://blog.csdn.net/liyingke112/article/details/77482384 k8s-app: apache version: v1 kubernetes.io/cluster-service: &quot;true&quot; annotations: #自定义注解列表 - name: String #自定义注解名字 spec:#specification of the resource content 指定该资源的内容 restartPolicy: Always #表明该容器一直运行，默认k8s的策略，在此容器退出后，会立即创建一个相同的容器 nodeSelector: #节点选择，先给主机打标签kubectl label nodes kube-node1 zone=node1 zone: node1 containers: - name: web04-pod #容器的名字 image: web:apache #容器使用的镜像地址 imagePullPolicy: Never #三个选择Always、Never、IfNotPresent，每次启动时检查和更新（从registery）images的策略， # Always，每次都检查 # Never，每次都不检查（不管本地是否有） # IfNotPresent，如果本地有就不检查，如果没有就拉取 command: [&#x27;sh&#x27;] #启动容器的运行命令，将覆盖容器中的Entrypoint,对应Dockefile中的ENTRYPOINT args: [&quot;$(str)&quot;] #启动容器的命令参数，对应Dockerfile中CMD参数 env: #指定容器中的环境变量 - name: str #变量的名字 value: &quot;/etc/run.sh&quot; #变量的值 resources: #资源管理，请求请见http://blog.csdn.net/liyingke112/article/details/77452630 requests: #容器运行时，最低资源需求，也就是说最少需要多少资源容器才能正常运行 cpu: 0.1 #CPU资源（核数），两种方式，浮点数或者是整数+m，0.1=100m，最少值为0.001核（1m） memory: 32Mi #内存使用量 limits: #资源限制 cpu: 0.5 memory: 32Mi ports: - containerPort: 80 #容器开放对外的端口 name: httpd #名称 protocol: TCP livenessProbe: #pod内容器健康检查的设置，详情请见http://blog.csdn.net/liyingke112/article/details/77531584 httpGet: #通过httpget检查健康，返回200-399之间，则认为容器正常 path: / #URI地址 port: 80 #host: 127.0.0.1 #主机地址 scheme: HTTP initialDelaySeconds: 180 #表明第一次检测在容器启动后多长时间后开始 timeoutSeconds: 5 #检测的超时时间 periodSeconds: 15 #检查间隔时间 #也可以用这种方法 #exec: 执行命令的方法进行监测，如果其退出码不为0，则认为容器正常 # command: # - cat # - /tmp/health #也可以用这种方法 #tcpSocket: //通过tcpSocket检查健康 # port: number lifecycle: #生命周期管理 postStart: #容器运行之前运行的任务 exec: command: - &#x27;sh&#x27; - &#x27;yum upgrade -y&#x27; preStop: #容器关闭之前运行的任务 exec: command: [&#x27;service httpd stop&#x27;] volumeMounts: #详情请见http://blog.csdn.net/liyingke112/article/details/76577520 - name: volume #挂载设备的名字，与volumes[*].name 需要对应 mountPath: /data #挂载到容器的某个路径下 readOnly: True volumes: #定义一组挂载设备 - name: volume #定义一个挂载设备的名字 #meptyDir: &#123;&#125; hostPath: path: /opt #挂载设备类型为hostPath，路径为宿主机下的/opt,这里设备类型支持很多种 k8s 使用过程笔记如何进入kubernetes的一个pod123456类似于docker进入docker容器 ：docker exec -ti &lt;your-container-name&gt; /bin/sh进入pod：kubectl exec -ti &lt;your-pod-name&gt; -n &lt;your-namespace&gt; -- /bin/sh 关于k8s使用镜像创建pod的坑k8s默认从远程仓库中获取镜像，可以使用镜像获取策略从本地获取： 1234containers: - name: test image: nginx:1.7.9 #必须带上tag imagePullPolicy: Never Always 总是拉取镜像 IfNotPresent 本地有则使用本地镜像,不拉取 Never 只使用本地镜像，从不拉取，即使本地没有 如果省略imagePullPolicy 镜像tag为 :latest 策略为always ，否则 策略为 IfNotPresent","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"","slug":"开发笔记/session，cookie，token学习【转】","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/session，cookie，token学习【转】/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/session%EF%BC%8Ccookie%EF%BC%8Ctoken%E5%AD%A6%E4%B9%A0%E3%80%90%E8%BD%AC%E3%80%91/","excerpt":"","text":"转载自 https://segmentfault.com/a/1190000017831088 session，cookie和token究竟是什么1. http是一个无状态协议什么是无状态呢？就是说这一次请求和上一次请求是没有任何关系的，互不认识的，没有关联的。这种无状态的的好处是快速。坏处是假如我们想要把 www.zhihu.com/login.html 和 www.zhihu.com/index.html 关联起来，必须使用某些手段和工具 2. cookie和session2.1 http请求过程 由于http的无状态性，为了使某个域名下的所有网页能够共享某些数据，session和cookie出现了。客户端访问服务器的流程如下 首先，客户端会发送一个http请求到服务器端。 服务器端接受客户端请求后，建立一个session，并发送一个http响应到客户端，这个响应头，其中就包含Set-Cookie头部。该头部包含了sessionId。Set-Cookie格式如下：Set-Cookie: value[; expires&#x3D;date][; domain&#x3D;domain][; path&#x3D;path][; secure] 在客户端发起的第二次请求，假如服务器给了set-Cookie，浏览器会自动在请求头中添加cookie 服务器接收请求，分解cookie，验证信息，核对成功后返回response给客户端 2.2 注意 cookie只是实现session的其中一种方案。虽然是最常用的，但并不是唯一的方法。禁用cookie后还有其他方法存储，比如放在url中 现在大多都是Session + Cookie的方式，但是只用session不用cookie，或是只用cookie不用session，在理论上都可以保持会话状态。可是实际中因为多种原因，一般不会单独使用 用session只需要在客户端保存一个id，实际上大量数据都是保存在服务端。如果全部用cookie，数据量大的时候客户端是没有那么多空间的。 如果只用cookie不用session，那么账户信息全部保存在客户端，一旦被劫持，全部信息都会泄露。并且客户端数据量变大，网络传输的数据量也会变大 2.3 小结 简而言之, session 有如用户信息档案表, 里面包含了用户的认证信息和登录状态等信息. 而 cookie 就是用户通行 3. token3.1 概念 token 也称作令牌，由uid+time+sign[+固定参数]token 的认证方式类似于临时的证书签名, 并且是一种服务端无状态的认证方式, 非常适合于 REST API 的场景. 所谓无状态就是服务端并不会保存身份认证相关的数据。 3.2 组成 uid: 用户唯一身份标识 time: 当前时间的时间戳 sign: 签名, 使用 hash&#x2F;encrypt 压缩成定长的十六进制字符串，以防止第三方恶意拼接 固定参数(可选): 将一些常用的固定参数加入到 token 中是为了避免重复查库 token在客户端一般存放于localStorage，cookie，或sessionStorage中。在服务器一般存于数据库中 3.3 token认证流程 token 的认证流程与cookie很相似 用户登录，成功后服务器返回Token给客户端。 客户端收到数据后保存在客户端 客户端再次访问服务器，将token放入headers中 服务器端采用filter过滤器校验。校验成功则返回请求数据，校验失败则返回错误码 4. token可以抵抗csrf，cookie+session不行假如用户正在登录银行网页，登录了攻击者的网页，并且银行网页未对csrf攻击进行防护。攻击者就可以在网页放一个表单，该表单提交src为http://www.bank.com/api/transfer，body为count=1000&amp;to=Tom。倘若是session+cookie，用户打开网页的时候就已经转给Tom1000元了.因为form 发起的 POST 请求并不受到浏览器同源策略的限制，因此可以任意地使用其他域的 Cookie 向其他域发送 POST 请求，形成 CSRF 攻击。在post请求的瞬间，cookie会被浏览器自动添加到请求头中。但token不同，token是开发者为了防范csrf而特别设计的令牌，浏览器不会自动添加到headers里，攻击者也无法访问用户的token，所以提交的表单无法通过服务器过滤，也就无法形成攻击。 5. 分布式情况下的session和token我们已经知道session时有状态的，一般存于服务器内存或硬盘中，当服务器采用分布式或集群时，session就会面对负载均衡问题。 token是无状态的，token字符串里就保存了所有的用户信息。 客户端登陆传递信息给服务端，服务端收到后把用户信息加密（token）传给客户端，客户端将token存放于localStroage等容器中。客户端每次访问都传递token，服务端解密token，就知道这个用户是谁了。通过cpu加解密，服务端就不需要存储session占用存储空间，就很好的解决负载均衡多服务器的问题了。这个方法叫做JWT(Json Web Token) 6. 总结 session存储于服务器，可以理解为一个状态列表，拥有一个唯一识别符号sessionId，通常存放于cookie中。服务器收到cookie后解析出sessionId，再去session列表中查找，才能找到相应session。依赖cookie cookie类似一个令牌，装有sessionId，存储在客户端，浏览器通常会自动添加。 token也类似一个令牌，无状态，用户信息都被加密到token中，服务器收到token后解密就可知道是哪个用户。需要开发者手动添加。 jwt只是一个跨域认证的方案 Cookie与Session的区别转载自 https://segmentfault.com/a/1190000015419746 前言本文分别对Cookie与Session做一个介绍和总结，并分别对两个知识点进行对比分析，让大家对Cookie和Session有一个更深入的了解，并对自己的开发工作中灵活运用带来启示。 cookie机制Cookies是服务器在本地机器上存储的小段文本并随每一个请求发送至同一个服务器。IETF RFC 2965 HTTP State Management Mechanism 是通用cookie规范。网络服务器用HTTP头向客户端发送cookies，在客户终端，浏览器解析这些cookies并将它们保存为一个本地文件，它会自动将同一服务器的任何请求缚上这些cookies 。 具体来说cookie机制采用的是在客户端保持状态的方案。它是在用户端的会话状态的存贮机制，他需要用户打开客户端的cookie支持。cookie的作用就是为了解决HTTP协议无状态的缺陷所作的努力。 正统的cookie分发是通过扩展HTTP协议来实现的，服务器通过在HTTP的响应头中加上一行特殊的指示以提示浏览器按照指示生成相应的cookie。然而纯粹的客户端脚本如JavaScript也可以生成cookie。而cookie的使用是由浏览器按照一定的原则在后台自动发送给服务器的。浏览器检查所有存储的cookie，如果某个cookie所声明的作用范围大于等于将要请求的资源所在的位置，则把该cookie附在请求资源的HTTP请求头上发送给服务器。 cookie的内容主要包括：名字，值，过期时间，路径和域。路径与域一起构成cookie的作用范围。若不设置过期时间，则表示这个cookie的生命期为浏览器会话期间，关闭浏览器窗口，cookie就消失。这种生命期为浏览器会话期的cookie被称为会话cookie。会话cookie一般不存储在硬盘上而是保存在内存里，当然这种行为并不是规范规定的。若设置了过期时间，浏览器就会把cookie保存到硬盘上，关闭后再次打开浏览器，这些cookie仍然有效直到超过设定的过期时间。存储在硬盘上的cookie可以在不同的浏览器进程间共享，比如两个IE窗口。而对于保存在内存里的cookie，不同的浏览器有不同的处理方式。 而session机制采用的是一种在服务器端保持状态的解决方案。同时我们也看到，由于采用服务器端保持状态的方案在客户端也需要保存一个标识，所以session机制可能需要借助于cookie机制来达到保存标识的目的。而session提供了方便管理全局变量的方式 。 session是针对每一个用户的，变量的值保存在服务器上，用一个sessionID来区分是哪个用户session变量,这个值是通过用户的浏览器在访问的时候返回给服务器，当客户禁用cookie时，这个值也可能设置为由get来返回给服务器。 就安全性来说：当你访问一个使用session 的站点，同时在自己机子上建立一个cookie，建议在服务器端的session机制更安全些，因为它不会任意读取客户存储的信息。 session机制session机制是一种服务器端的机制，服务器使用一种类似于散列表的结构（也可能就是使用散列表）来保存信息。 当程序需要为某个客户端的请求创建一个session时，服务器首先检查这个客户端的请求里是否已包含了一个session标识（称为session id），如果已包含则说明以前已经为此客户端创建过session，服务器就按照session id把这个session检索出来使用（检索不到，会新建一个），如果客户端请求不包含session id，则为此客户端创建一个session并且生成一个与此session相关联的session id，session id的值应该是一个既不会重复，又不容易被找到规律以仿造的字符串，这个session id将被在本次响应中返回给客户端保存。 保存这个session id的方式可以采用cookie，这样在交互过程中浏览器可以自动的按照规则把这个标识发挥给服务器。一般这个cookie的名字都是类似于SEEESIONID。但cookie可以被人为的禁止，则必须有其他机制以便在cookie被禁止时仍然能够把session id传递回服务器。 经常被使用的一种技术叫做URL重写，就是把session id直接附加在URL路径的后面。还有一种技术叫做表单隐藏字段。就是服务器会自动修改表单，添加一个隐藏字段，以便在表单提交时能够把session id传递回服务器。 cookie与session区别Cookie与Session都能够进行会话跟踪，但是完成的原理不太一样。普通状况下二者均能够满足需求，但有时分不能够运用Cookie，有时分不能够运用Session。下面经过比较阐明二者的特性以及适用的场所。 1. 存取方式的不同Cookie中只能保管ASCII字符串，假如需求存取Unicode字符或者二进制数据，需求先进行编码。Cookie中也不能直接存取Java对象。若要存储略微复杂的信息，运用Cookie是比较艰难的。 而Session中能够存取任何类型的数据，包括而不限于String、Integer、List、Map等。Session中也能够直接保管Java Bean乃至任何Java类，对象等，运用起来十分便当。能够把Session看做是一个Java容器类。 2. 隐私策略的不同Cookie存储在客户端阅读器中，对客户端是可见的，客户端的一些程序可能会窥探、复制以至修正Cookie中的内容。而Session存储在服务器上，对客户端是透明的，不存在敏感信息泄露的风险。 假如选用Cookie，比较好的方法是，敏感的信息如账号密码等尽量不要写到Cookie中。最好是像Google、Baidu那样将Cookie信息加密，提交到服务器后再进行解密，保证Cookie中的信息只要本人能读得懂。而假如选择Session就省事多了，反正是放在服务器上，Session里任何隐私都能够有效的保护。 3. 有效期上的不同使用过Google的人都晓得，假如登录过Google，则Google的登录信息长期有效。用户不用每次访问都重新登录，Google会持久地记载该用户的登录信息。要到达这种效果，运用Cookie会是比较好的选择。只需要设置Cookie的过期时间属性为一个很大很大的数字。 由于Session依赖于名为JSESSIONID的Cookie，而Cookie JSESSIONID的过期时间默许为–1，只需关闭了阅读器该Session就会失效，因而Session不能完成信息永世有效的效果。运用URL地址重写也不能完成。而且假如设置Session的超时时间过长，服务器累计的Session就会越多，越容易招致内存溢出。 4. 服务器压力的不同Session是保管在服务器端的，每个用户都会产生一个Session。假如并发访问的用户十分多，会产生十分多的Session，耗费大量的内存。因而像Google、Baidu、Sina这样并发访问量极高的网站，是不太可能运用Session来追踪客户会话的。 而Cookie保管在客户端，不占用服务器资源。假如并发阅读的用户十分多，Cookie是很好的选择。关于Google、Baidu、Sina来说，Cookie或许是唯一的选择。 5. 浏览器支持的不同Cookie是需要客户端浏览器支持的。假如客户端禁用了Cookie，或者不支持Cookie，则会话跟踪会失效。关于WAP上的应用，常规的Cookie就派不上用场了。 假如客户端浏览器不支持Cookie，需要运用Session以及URL地址重写。需要注意的是一切的用到Session程序的URL都要进行URL地址重写，否则Session会话跟踪还会失效。关于WAP应用来说，Session+URL地址重写或许是它唯一的选择。 假如客户端支持Cookie，则Cookie既能够设为本浏览器窗口以及子窗口内有效（把过期时间设为–1），也能够设为一切阅读器窗口内有效（把过期时间设为某个大于0的整数）。但Session只能在本阅读器窗口以及其子窗口内有效。假如两个浏览器窗口互不相干，它们将运用两个不同的Session。（IE8下不同窗口Session相干） 6、跨域支持上的不同Cookie支持跨域名访问，例如将domain属性设置为“.biaodianfu.com”，则以“.biaodianfu.com”为后缀的一切域名均能够访问该Cookie。跨域名Cookie如今被普遍用在网络中，例如Google、Baidu、Sina等。而Session则不会支持跨域名访问。Session仅在他所在的域名内有效。 仅运用Cookie或者仅运用Session可能完成不了理想的效果。这时应该尝试一下同时运用Cookie与Session。Cookie与Session的搭配运用在实践项目中会完成很多意想不到的效果。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"","slug":"开发笔记/一次完整的HTTP请求过程【转】","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/一次完整的HTTP请求过程【转】/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E4%B8%80%E6%AC%A1%E5%AE%8C%E6%95%B4%E7%9A%84HTTP%E8%AF%B7%E6%B1%82%E8%BF%87%E7%A8%8B%E3%80%90%E8%BD%AC%E3%80%91/","excerpt":"","text":"当我们在浏览器的地址栏输入 www.linux178.com ，然后回车，回车这一瞬间到看到页面到底发生了什么呢？ 域名解析 –&gt; 发起TCP的3次握手 –&gt; 建立TCP连接后发起http请求 –&gt; 服务器响应http请求，浏览器得到html代码 –&gt; 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） –&gt; 浏览器对页面进行渲染呈现给用户 以Chrome浏览器为例： 1.域名解析 首先Chrome浏览器会解析 www.linux178.com 这个域名（准确的叫法应该是主机名）对应的IP地址。怎么解析到对应的IP地址？ ① Chrome浏览器 会首先搜索浏览器自身的DNS缓存（缓存时间比较短，大概只有1分钟，且只能容纳1000条缓存），看自身的缓存中是否有www.linux178.com 对应的条目，而且没有过期，如果有且没有过期则解析到此结束。 注：我们怎么查看Chrome自身的缓存？可以使用 chrome:&#x2F;&#x2F;net-internals&#x2F;#dns 来进行查看 ② 如果浏览器自身的缓存里面没有找到对应的条目，那么Chrome会搜索操作系统自身的DNS缓存,如果找到且没有过期则停止搜索解析到此结束. 注：怎么查看操作系统自身的DNS缓存，以Windows系统为例，可以在命令行下使用 ipconfig &#x2F;displaydns 来进行查看 ③ 如果在Windows系统的DNS缓存也没有找到，那么尝试读取hosts文件（位于C:\\Windows\\System32\\drivers\\etc），看看这里面有没有该域名对应的IP地址，如果有则解析成功。 ④ 如果在hosts文件中也没有找到对应的条目，浏览器就会发起一个DNS的系统调用，就会向本地配置的首选DNS服务器（一般是电信运营商提供的，也可以使用像Google提供的DNS服务器）发起域名解析请求（通过的是UDP协议向DNS的53端口发起请求，这个请求是递归的请求，也就是运营商的DNS服务器必须得提供给我们该域名的IP地址），运营商的DNS服务器首先查找自身的缓存，找到对应的条目，且没有过期，则解析成功。如果没有找到对应的条目，则有运营商的DNS代我们的浏览器发起迭代DNS解析请求，它首先是会找根域的DNS的IP地址（这个DNS服务器都内置13台根域的DNS的IP地址），找到根域的DNS地址，就会向其发起请求（请问www.linux178.com这个域名的IP地址是多少啊？），根域发现这是一个顶级域com域的一个域名，于是就告诉运营商的DNS我不知道这个域名的IP地址，但是我知道com域的IP地址，你去找它去，于是运营商的DNS就得到了com域的IP地址，又向com域的IP地址发起了请求（请问www.linux178.com这个域名的IP地址是多少?）,com域这台服务器告诉运营商的DNS我不知道www.linux178.com这个域名的IP地址，但是我知道linux178.com这个域的DNS地址，你去找它去，于是运营商的DNS又向linux178.com这个域名的DNS地址（这个一般就是由域名注册商提供的，像万网，新网等）发起请求（请问www.linux178.com这个域名的IP地址是多少？），这个时候linux178.com域的DNS服务器一查，诶，果真在我这里，于是就把找到的结果发送给运营商的DNS服务器，这个时候运营商的DNS服务器就拿到了www.linux178.com这个域名对应的IP地址，并返回给Windows系统内核，内核又把结果返回给浏览器，终于浏览器拿到了www.linux178.com对应的IP地址，该进行一步的动作了。 注：一般情况下是不会进行以下步骤的 如果经过以上的4个步骤，还没有解析成功，那么会进行如下步骤（以下是针对Windows操作系统）： ⑤ 操作系统就会查找NetBIOS name Cache（NetBIOS名称缓存，就存在客户端电脑中的），那这个缓存有什么东西呢？凡是最近一段时间内和我成功通讯的计算机的计算机名和Ip地址，就都会存在这个缓存里面。什么情况下该步能解析成功呢？就是该名称正好是几分钟前和我成功通信过，那么这一步就可以成功解析。 ⑥ 如果第⑤步也没有成功，那会查询WINS 服务器（是NETBIOS名称和IP地址对应的服务器） ⑦ 如果第⑥步也没有查询成功，那么客户端就要进行广播查找 ⑧ 如果第⑦步也没有成功，那么客户端就读取LMHOSTS文件（和HOSTS文件同一个目录下，写法也一样） 如果第八步还没有解析成功，那么就宣告这次解析失败，那就无法跟目标计算机进行通信。只要这八步中有一步可以解析成功，那就可以成功和目标计算机进行通信。 2.发起TCP的3次握手拿到域名对应的IP地址之后，User-Agent（一般是指浏览器）会以一个随机端口（1024 &lt; 端口 &lt; 65535）向服务器的WEB程序（常用的有httpd,nginx等）80端口发起TCP的连接请求。这个连接请求（原始的http请求经过TCP&#x2F;IP4层模型的层层封包）到达服务器端后（这中间通过各种路由设备，局域网内除外），进入到网卡，然后是进入到内核的TCP&#x2F;IP协议栈（用于识别该连接请求，解封包，一层一层的剥开），还有可能要经过Netfilter防火墙（属于内核的模块）的过滤，最终到达WEB程序（本文就以Nginx为例），最终建立了TCP&#x2F;IP的连接。 1） Client首先发送一个连接试探，ACK&#x3D;0 表示确认号无效，SYN &#x3D; 1 表示这是一个连接请求或连接接受报文，同时表示这个数据报不能携带数据，seq &#x3D; x 表示Client自己的初始序号（seq &#x3D; 0 就代表这是第0号包），这时候Client进入syn_sent状态，表示客户端等待服务器的回复 2） Server监听到连接请求报文后，如同意建立连接，则向Client发送确认。TCP报文首部中的SYN 和 ACK都置1 ，ack &#x3D; x + 1表示期望收到对方下一个报文段的第一个数据字节序号是x+1，同时表明x为止的所有数据都已正确收到（ack&#x3D;1其实是ack&#x3D;0+1,也就是期望客户端的第1个包），seq &#x3D; y 表示Server 自己的初始序号（seq&#x3D;0就代表这是服务器这边发出的第0号包）。这时服务器进入syn_rcvd，表示服务器已经收到Client的连接请求，等待client的确认。 3） Client收到确认后还需再次发送确认，同时携带要发送给Server的数据。ACK 置1 表示确认号ack&#x3D; y + 1 有效（代表期望收到服务器的第1个包），Client自己的序号seq&#x3D; x + 1（表示这就是我的第1个包，相对于第0个包来说的），一旦收到Client的确认之后，这个TCP连接就进入Established状态，就可以发起http请求了。 TCP 为什么需要3次握手？ 2个计算机通信是靠协议（目前流行的TCP&#x2F;IP协议）来实现,如果2个计算机使用的协议不一样，那是不能进行通信的，所以这个3次握手就相当于试探一下对方是否遵循TCP&#x2F;IP协议，协商完成后就可以进行通信了，当然这样理解不是那么准确。 为什么HTTP协议要基于TCP来实现？ 目前在Internet中所有的传输都是通过TCP&#x2F;IP进行的，HTTP协议作为TCP&#x2F;IP模型中应用层的协议也不例外，TCP是一个端到端的可靠的面向连接的协议，所以HTTP基于传输层TCP协议不用担心数据的传输的各种问题。 3.建立TCP连接后发起http请求一个HTTP请求报文由请求行（request line）、请求头部（header）、空行和请求数据4个部分组成 1) 请求行请求行分为三个部分：请求方法、请求地址和协议版本 请求方法： HTTP&#x2F;1.1 定义的请求方法有8种：GET、POST、PUT、DELETE、PATCH、HEAD、OPTIONS、TRACE。 GET: 完整请求一个资源 （常用） HEAD: 仅请求响应首部 POST：提交表单 （常用） PUT: (webdav) 上传文件（但是浏览器不支持该方法） DELETE：(webdav) 删除 OPTIONS：返回请求的资源所支持的方法的方法 TRACE: 追求一个资源请求中间所经过的代理（该方法不能由浏览器发出） 最常的两种GET和POST，如果是RESTful接口的话一般会用到GET、POST、DELETE、PUT。 请求地址： URL:统一资源定位符，是一种资源位置的抽象唯一识别方法。 组成：&lt;协议&gt;：&#x2F;&#x2F;&lt;主机&gt;：&lt;端口&gt;&#x2F;&lt;路径&gt; 端口和路径有时可以省略（HTTP默认端口号是80），GET请求可能会带参数 什么是URL、URI、URN？URI Uniform Resource Identifier 统一资源标识符。格式： scheme:&#x2F;&#x2F;[username:password@]HOST:port&#x2F;path&#x2F;to&#x2F;source URL Uniform Resource Locator 统一资源定位符格式： http://www.magedu.com/downloads/nginx-1.5.tar.gz URN Uniform Resource Name 统一资源名称 URL和URN 都属于 URI 协议版本： 协议版本的格式为：HTTP&#x2F;主版本号.次版本号 协议有： http&#x2F;0.9: stateless http&#x2F;1.0: MIME, keep-alive (保持连接), 缓存 http&#x2F;1.1: 更多的请求方法，更精细的缓存控制，持久连接(persistent connection) 比较常用 2) 请求头部请求头部为请求报文添加了一些附加信息，如token等，由“名&#x2F;值”对组成，每行一对，名和值之间使用冒号分隔。 请求头部的最后会有一个空行，表示请求头部结束，接下来为请求数据，这一行非常重要，必不可少。 下面是Chrome发起的http请求报文头部信息： Accept 就是告诉服务器端，我接受那些MIME类型 Accept-Encoding 这个看起来是接受那些压缩方式的文件 Accept-Lanague 告诉服务器能够发送哪些语言 Connection 告诉服务器支持keep-alive特性 Cookie 每次请求时都会携带上Cookie以方便服务器端识别是否是同一个客户端 Host 用来标识请求服务器上的那个虚拟主机，比如Nginx里面可以定义很多个虚拟主机，这里就是用来标识要访问那个虚拟主机。 User-Agent 用户代理，一般情况是浏览器，也有其他类型，如：wget curl 搜索引擎的蜘蛛等 条件请求首部： If-Modified-Since 是浏览器向服务器端询问某个资源文件如果自从什么时间修改过，那么重新发给我，这样就保证服务器端资源文件更新时，浏览器再次去请求，而不是使用缓存中的文件 安全请求首部： Authorization: 客户端提供给服务器的认证信息； 什么是MIME？ MIME（Multipurpose Internet Mail Extesions 多用途互联网邮件扩展）是一个互联网标准，它扩展了电子邮件标准，使其能够支持非ASCII字符、二进制格式附件等多种格式的邮件消息，这个标准被定义在RFC 2045、RFC 2046、RFC 2047、RFC 2048、RFC 2049等RFC中。 由RFC 822转变而来的RFC 2822，规定电子邮件标准并不允许在邮件消息中使用7位ASCII字符集以外的字符。正因如此，一些非英语字符消息和二进制文件，图像，声音等非文字消息都不能在电子邮件中传输。MIME规定了用于表示各种各样的数据类型的符号化方法。 此外，在万维网中使用的HTTP协议中也使用了MIME的框架，标准被扩展为互联网媒体类型。 MIME 遵循以下格式：major&#x2F;minor 主类型&#x2F;次类型 例如： 12345image/jpgimage/giftext/htmlvideo/quicktimeappliation/x-httpd-php 3) 请求数据可选部分，比如GET请求就没有请求数据。 下面是一个POST方法的请求报文：123456789101112POST /index.php HTTP/1.1 请求行 Host: localhost User-Agent: Mozilla/5.0 (Windows NT 5.1; rv:10.0.2) Gecko/20100101 Firefox/10.0.2 请求头 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8 Accept-Language: zh-cn,zh;q=0.5 Accept-Encoding: gzip, deflate Connection: keep-alive Referer: http://localhost/ Content-Length：25 Content-Type：application/x-www-form-urlencoded 空行 username=aa&amp;password=1234 请求数据4.服务器端响应http请求，浏览器得到html代码HTTP响应报文主要由状态行、响应头部、空行以及响应数据组成。 1)状态行由3部分组成，分别为：协议版本，状态码，状态码描述。 其中协议版本与请求报文一致，状态码描述是对状态码的简单描述，所以这里就只介绍状态码。 状态码 1xx: 信息性状态码 100, 101 2xx: 成功状态码 200 OK 请求成功。一般用于GET与POST请求 201 Created 已创建。成功请求并创建了新的资源 202 Accepted 已接受。已经接受请求，但未处理完成 3xx: 重定向状态码 301: 永久重定向, Location响应首部的值仍为当前URL，因此为隐藏重定向; 302: 临时重定向，显式重定向, Location响应首部的值为新的URL 304：Not Modified 未修改，比如本地缓存的资源文件和服务器上比较时，发现并没有修改，服务器返回一个304状态码， 告诉浏览器，你不用请求该资源，直接使用本地的资源即可。 4xx: 客户端错误状态码 400：Bad Request 客户端请求的语法错误，服务器无法理解 401：Unauthorized 请求要求用户的身份认证 403：Forbidden 服务器理解请求客户端的请求，但是拒绝执行此请求 404: Not Found 请求的URL资源并不存在 5xx: 服务器端错误状态码 500: Internal Server Error 服务器内部错误 501：Not Implemented 服务器不支持请求的功能，无法完成请求 502: Bad Gateway 前面代理服务器联系不到后端的服务器时出现 504：Gateway Timeout 这个是代理能联系到后端的服务器，但是后端的服务器在规定的时间内没有给代理服务器响应 2.响应头部与请求头部类似，为响应报文添加了一些附加信息 3.响应数据用于存放需要返回给客户端的数据信息。 Connection 使用keep-alive特性 Content-Encoding 使用gzip方式对资源压缩 Content-type MIME类型为html类型，字符集是 UTF-8 Date 响应的日期 Server 使用的WEB服务器 Transfer-Encoding:chunked 分块传输编码 是http中的一种数据传输机制，允许HTTP由网页服务器发送给客户端应用（通常是网页浏览器）的数据可以分成多个部分，分块传输编码只在HTTP协议1.1版本（HTTP&#x2F;1.1）中提供 Vary 这个可以参考（http://blog.csdn.NET/tenfyguo/article/details/5939000） X-Pingback 参考（http://blog.sina.com.cn/s/blog_bb80041c0101fmfz.html） 那到底服务器端接收到http请求后是怎么样生成html文件？ 假设服务器端使用nginx+PHP(fastcgi)架构提供服务 ① nginx读取配置文件 我们在浏览器的地址栏里面输入的是 http://www.linux178.com （http:&#x2F;&#x2F;可以不用输入，浏览器会自动帮我们添加），其实完整的应该是http://www.linux178.com./ 后面还有个点（这个点代表就是根域，一般情况下我们不用输入，也不显示）,后面的&#x2F;也是不用添加，浏览器会自动帮我们添加（且看第3部那个图里面的URL），那么实际请求的URL是http://www.linux178.com/，那么好了Nginx在收到 浏览器 GET &#x2F; 请求时，会读取http请求里面的头部信息，根据Host来匹配 自己的所有的虚拟主机的配置文件的server_name,看看有没有匹配的，有匹配那么就读取该虚拟主机的配置，发现如下配置： 1root /web/echo 通过这个就知道所有网页文件的就在这个目录下 这个目录就是&#x2F; 当我们http://www.linux178.com/时就是访问这个目录下面的文件，例如访问http://www.linux178.com/index.html,那么代表/web/echo下面有个文件叫index.html 1index index.html index.htm index.php 通过这个就能得知网站的首页文件是那个文件，也就是我们在入http://www.linux178.com/ ，nginx就会自动帮我们把index.html（假设首页是index.php 当然是会尝试的去找到该文件，如果没有找到该文件就依次往下找，如果这3个文件都没有找到，那么就抛出一个404错误）加到后面，那么添加之后的URL是&#x2F;index.php,然后根据后面的配置进行处理 1234567location ~ .*\\.php(\\/.*)*$ &#123; root /web/echo; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; astcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params;&#125; 这一段配置指明凡是请求的URL中匹配（这里是启用了正则表达式进行匹配） *.php后缀的（后面跟的参数）都交给后端的fastcgi进程进行处理。 ② 把php文件交给fastcgi进程去处理于是nginx把&#x2F;index.php这个URL交给了后端的fastcgi进程处理，等待fastcgi处理完成后（结合数据库查询出数据，填充模板生成html文件）返回给nginx一个index.html文档，Nginx再把这个index.html返回给浏览器，于是乎浏览器就拿到了首页的html代码，同时nginx写一条访问日志到日志文件中去。 注1：nginx是怎么找index.php文件的？ 当nginx发现需要&#x2F;web&#x2F;echo&#x2F;index.php文件时，就会向内核发起IO系统调用(因为要跟硬件打交道，这里的硬件是指硬盘，通常需要靠内核来操作，而内核提供的这些功能是通过系统调用来实现的)，告诉内核，我需要这个文件,内核从&#x2F;开始找到web目录，再在web目录下找到echo目录，最后在echo目录下找到index.php文件，于是把这个index.php从硬盘上读取到内核自身的内存空间，然后再把这个文件复制到nginx进程所在的内存空间，于是乎nginx就得到了自己想要的文件了。 注2：寻找文件在文件系统层面是怎么操作的？ 比如nginx需要得到&#x2F;web&#x2F;echo&#x2F;index.php这个文件 每个分区（像ext3 ext3等文件系统，block块是文件存储的最小单元 默认是4096字节）都是包含元数据区和数据区，每一个文件在元数据区都有元数据条目（一般是128字节大小），每一个条目都有一个编号，我们称之为inode（index node 索引节点），这个inode里面包含 文件类型、权限、连接次数、属主和数组的ID、时间戳、这个文件占据了那些磁盘块也就是块的编号（block，每个文件可以占用多个block,并且block不一定是连续的，每个block是有编号的），如下图所示： 还有一个要点：目录其实也普通是文件，也需要占用磁盘块，目录不是一个容器。你看默认创建的目录就是4096字节，也就说只需要占用一个磁盘块，但这是不确定的。所以要找到目录也是需要到元数据区里面找到对应的条目，只有找到对应的inode就可找到目录所占用的磁盘块。 那到底目录里面存放着什么，难道不是文件或者其他目录吗？ 其实目录存着这么一张表（姑且这么理解），里面放着 目录或者文件的名称和对应的inode号（暂时称之为映射表）,如 文件名 innode号 test1.txt 100 test2.txt 101 假设 &#x2F; 在数据区占据 1、2号block ，&#x2F;其实也是一个目录 里面有3个目录 web 111 web 占据 5号block 是目录 里面有2个目录 echo data echo 占据 11号 block 是目录 里面有1个文件 index.php index.php 占据 15 16号 block 是文件 其在文件系统中分布如下图所示 那么内核究竟是怎么找到index.php这个文件的呢？ 内核拿到nginx的IO系统调用要获取&#x2F;web&#x2F;echo&#x2F;index.php这个文件请求之后 ① 内核读取元数据区 &#x2F; 的inode，从inode里面读取&#x2F;所对应的数据块的编号，然后在数据区找到其对应的块（1 2号块），读取1号块上的映射表找到web这个名称在元数据区对应的inode号 ② 内核读取web对应的inode（3号），从中得知web在数据区对应的块是5号块，于是到数据区找到5号块，从中读取映射表，知道echo对应的inode是5号，于是到元数据区找到5号inode ③ 内核读取5号inode，得到echo在数据区对应的是11号块，于是到数据区读取11号块得到映射表，得到index.php对应的inode是9号 ④ 内核到元数据区读取9号inode，得到index.php对应的是15和16号数据块，于是就到数据区域找到15 16号块，读取其中的内容，得到index.php的完整内容 5. 浏览器解析html代码，并请求html代码中的资源浏览器拿到index.html文件后，就开始解析其中的html代码，遇到js&#x2F;css&#x2F;image等静态资源时，就向服务器端去请求下载（会使用多线程下载，每个浏览器的线程数不一样），这个时候就用上keep-alive特性了，建立一次HTTP连接，可以请求多个资源，下载资源的顺序就是按照代码里的顺序，但是由于每个资源大小不一样，而浏览器又多线程请求请求资源，所以从下图看出，这里显示的顺序并不一定是代码里面的顺序。 浏览器在请求静态资源时（在未过期的情况下），向服务器端发起一个http请求（询问自从上一次修改时间到现在有没有对资源进行修改），如果服务器端返回304状态码（告诉浏览器服务器端没有修改），那么浏览器会直接读取本地的该资源的缓存文件。 详细的浏览器工作原理请看：http://kb.cnblogs.com/page/129756/ 6.浏览器对页面进行渲染呈现给用户最后，浏览器利用自己内部的工作机制，把请求到的静态资源和html代码进行渲染，渲染之后呈现给用户。 自此一次完整的HTTP事务宣告完成. 本文出自 “雷纳科斯的博客” 博客，转载自http://linux5588.blog.51cto.com/65280/1351007","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"","slug":"开发笔记/为什么bk-cmdb不用go mod管理","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/为什么bk-cmdb不用go mod管理/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E4%B8%BA%E4%BB%80%E4%B9%88bk-cmdb%E4%B8%8D%E7%94%A8go%20mod%E7%AE%A1%E7%90%86/","excerpt":"","text":"项目地址 https://github.com/Tencent/bk-cmdb 为什么不用官方推荐的 go mod 管理依赖呢？ bk-cmdb vendor下的一些依赖库都是有修改过的： vendor&#x2F;go.mongodb.org&#x2F;mongo-driver&#x2F;mongo&#x2F;session_exposer.go12345678910111213141516// CmdbPrepareCommitOrAbort set state to InProgress, so that we can commit with other// operation directly. otherwise mongodriver will do a false commitfunc CmdbPrepareCommitOrAbort(sess Session) &#123; i, ok := sess.(*sessionImpl) if !ok &#123; panic(&quot;the session is not type *sessionImpl&quot;) &#125; i.clientSession.SetState(2) i.didCommitAfterStart=false&#125;// CmdbContextWithSession set the session into context if context includes session infofunc CmdbContextWithSession(ctx context.Context, sess Session) SessionContext &#123; return contextWithSession(ctx, sess)&#125; 在mongo driver中添加了CmdbPrepareCommitOrAbort、 CmdbReloadSessio等方法 这些在官方库是没有的，如果切换 go mod,从官方源获取依赖，肯定是不行的 issue：https://github.com/Tencent/bk-cmdb/issues/4748 如果将修改后的官方库上传到github，应该可以解决go mod难切换的问题 会不会有版权问题？ 所以，尽量不要修改官方库","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"","slug":"开发笔记/各种语言版本的 Helloworld","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/各种语言版本的 Helloworld/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E5%90%84%E7%A7%8D%E8%AF%AD%E8%A8%80%E7%89%88%E6%9C%AC%E7%9A%84%20Helloworld/","excerpt":"","text":"接触过C、C++、Java、C#、Python、Go，自认为接触过的编程语言很多了，那么各种语言的经典程序 Hello World 都是什么样的呢？ C1234567#include &lt;stdio.h&gt;void main()&#123; printf(&quot;Hello,World!&quot;); return (0);&#125; C++123456#include &lt;iostream&gt;using namespace std;void main() &#123; cout &lt;&lt; &quot;Hello,World!\\n&quot;;&#125; Java12345public class Helloworld &#123; public static void main(String[] args) &#123; System.out.println(&quot;Hello,World!&quot;); &#125;&#125; C#123456789101112using System;using System.Collections.Generic;using System.Linq;using System.Text;using System.Threading.Tasks;namespace log&#123; class helloworld&#123; static void Main(string[] args)&#123; Console.WriteLine(&quot;Hello,World!&quot;); &#125; &#125;&#125; PythonPython2.x 1print &quot;Hello,World!&quot; Python3.x 1print(&quot;Hello,World!&quot;) Go12345package mainimport &quot;fmt&quot;func main()&#123; fmt.Printf(&quot;Hello,World!\\n&quot;);&#125; Javascript1console.log(&quot;Hello,World!&quot;);","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"","slug":"开发笔记/golang/学习大纲","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/golang/学习大纲/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/golang/%E5%AD%A6%E4%B9%A0%E5%A4%A7%E7%BA%B2/","excerpt":"","text":"","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"golang","slug":"开发笔记/golang","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/golang/"}],"tags":[]},{"title":"","slug":"开发笔记/java/2020 学习计划（成长之路）","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/2020 学习计划（成长之路）/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/2020%20%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92%EF%BC%88%E6%88%90%E9%95%BF%E4%B9%8B%E8%B7%AF%EF%BC%89/","excerpt":"","text":"2020 学习计划（成长之路） 领导怎么说： k8s docker 多读源码 逛逛开源社区 提高英文文档阅读能力 设计模式，工作中体现 一个优秀的软件架构师，首先一定是一个出色的程序员 eBay的架构师[RandyShoup先生]是如何总结架构师在项目中的职责的： l 具备丰富的一线大中型开发项目的整体规划、方案设计及技术队伍管理经验。 2 具备软件行业工作经验，熟悉业务领域的技术应用和发展。 3 具有项目管理理论基础，并在应用系统开发平台和项目管理上有实践经验。 4 对相关的技术标准有深刻的认识，对软件工程标准规范有良好的把握。 具备C&#x2F;S或B&#x2F;S体系结构或特定领域软件产品开发及架构和设计的经验。 5 具有面向对象分析（Object-Oriented Analysis, OOA）、设计（OOD）、开发（OOP）能力，精通UML和XML等，熟练使用Rational Rose、PowerDesigner等CASE工具进行设计开发。 6 对相关编程技术及整个解决方案有深刻的理解及熟练的应用，并且精通架构和设计模式，并在此基础上设计产品框架。 7 精通大型数据库如Oracle、Sql Server、MySQL等的开发。l 对计算机系统、网络和安全、应用系统架构等有全面的认识。 8 良好的团队意识和写作精神，有较强的内外沟通能力。 学习计划： \\1. Java 基础知识的深入理解 反射、IO、接口&#x2F;抽象类、内部类、异常、Enum、序列化、static、final、Iterator，Iterable和Comparable,Comparator 等等知识点，虽然都有学习，按实际上还差得很远，还有很多细节与需要深入学习理解。还应该尝试看 Java 源码，源码阅读理解是程序员成长中的必经之路，在源码中可以得到更多细节。最近在看《On Java 8》(事实上的 《Java 编程思想》第五版)这本书，书中讲解真的很详细，内容也非常多，需要反复深入学习。2020 年需要攻克完成这本书，不单单只是阅读浏览一遍，应该要融会贯通，对晦涩难懂的知识多思考，争取掌握。 \\2. 设计模式 设计模式很重要，支撑起代码的整个生命历程。设计模式应该被理解，被应用到项目中，而不是只是简单的概念层面上的了解，当然，也不应该生搬硬套。能够简化流程，优化项目的设计模式，才是好的设计模式。2020年希望能够掌握常用的设计模式，理解设计模式的套路，加深编程经验。完成《大话设计模式》这本书的学习理解。四人帮(GOF)的书籍《. Design Patterns》可能较之有一定的学习难度，但是经典还是需要了解。 \\3. 微服务、容器等知识 现如今，微服务非常重要，阿里系的Dubbo+Zookeeper，Spring系的SpringCloud，以及在此基础上二次开发可能更优秀的SpringCloud。主要学习SpringCloud。 Docker 是微服务中至关重要的工具，也需要学习。之前有比较简单的学习，还需要深入学习，注意在实践中多使用 Docker 技术，争取融会贯通，学以致用。 kubernetes 也需要学习理解，这是基于容器的集群管理平台，现在事实上的标准，需要掌握。主要通过网课学习。 \\4. 分布式架构 分布式缓存、分布式存储、分布式锁、幂等性、分布式事务、流量削峰、服务容错、服务降级等等，现在的分布式太火了，必须要对分布式有一定的理解和把握。计划是通过网课学习分布式架构。 \\5. 数据库等知识 常用的关系型数据库有MySQL、Oracle、DB2等，MySQL应该是使用最多的，深入学习和掌握MySQL，是高级程序员的基本要求。还又 Redis、消息中间件等也需要有一定的知识储备。 \\6. 开发工具 开发工具保证了开发效率，现在基本上离不开开发工具了，一个项目的开发到部署的过程都设计到许多的软件工具。作为使用者和潜在使用者，更应该对它们有深入的了解，就算是最熟悉的 idea, 我也不敢说完全掌握，Idea、maven、git、svn、jenkins、tomcat 等等也需要学习掌握。 \\7. 提高英语水平 如今流行的编程语言都是贴近英语语法。大家更倾向于写出来的代码是好读易懂的。能够快速的理解原作者的用词，就可以更快的读懂代码结构，这比纯粹的分析编程语法要简单且自然的多。 能够流畅的阅读英文文档，对于程序员而言，是非常重要的。这也是非常艰难的，英语也确实是我的短板，提高的英语的阅读能力，通过逼迫自己去看，去理解英文来实现，尝试去读英文的工具文档、逛外国的开发论坛，stackoverflow、github。YouTube、Reddit、ins 等也可以多逛逛。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/JTW详解","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/JTW详解/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/JTW%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"JTW详解 spring boot集成jwt实现token认证； \\1. 什么是jwt? Json web token (JWT), 是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准（(RFC 7519).定义了一种简洁的，自包含的方法用于通信双方之间以JSON对象的形式安全的传递信息。因为数字签名的存在，这些信息是可信的，JWT可以使用HMAC算法或者是RSA的公私秘钥对进行签名。 \\2. jwt的工作流程 \\1. 用户使用账号和密码发出post请求； \\2. 服务器使用私钥创建一个jwt； \\3. 服务器返回这个jwt给浏览器； \\4. 浏览器将该jwt串在请求头中向服务器发送请求； \\5. 服务器验证该jwt； \\6. 返回响应的资源给浏览器。 \\3. jwt结构 1）Header 头部：JWT的头部承载两部分信息：token类型和采用的加密算法。 2）Payload：存放有效信息的地方。 3）Signature：签证信息。 （完整见博客https://www.jianshu.com/p/e88d3f8151db）","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/JVM与Java程序","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/JVM与Java程序/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/JVM%E4%B8%8EJava%E7%A8%8B%E5%BA%8F/","excerpt":"","text":"当启动一个Java程序时，一个JVM实例也就产生。当该程序关闭退出，这个JVM实例也就随之消亡。 JVM实例负责运行一个Java程序 Java虚拟机及程序的生命周期：（1）通过java命令运行一个Java程序时，启动一个Java虚拟机进程； （2）Java虚拟机进程从启动到终止的过程，称为Java虚拟机生命周期； （3）程序生命周期和Java虚拟机生命周期是一致的，因为Java虚拟机进程从创建起的任务就是执行Java程序。 （4）每个运行中的Java程序会有独立的Java堆和非堆等物理资源，程序之间的jvm运行时状态是区分的。 类的加载，连接和初始化：Java程序要使用某个类时，Java虚拟机要确保这个类被加载，连接和运行，其中连接包括验证，准备和解析。 1、装载：查找并加载类的二进制数据 装载的最终目标是实现将编译后的class文件（class文件采用字节码，是JVM的机器语言）装入内存运行时数据区的方法区中，并在内存运行时数据区的堆区生成一个class对象，这个对象可以引用到方法区中的类定义 2、连接 （1）验证：确保加载类的正确性； （2）准备：为静态变量分配内存，并将其初始化为默认值； （3）解析：将类中的符号引用转换为直接引用。 3、初始化： 类的初始化过程是执行类的初始化语句，包括静态变量的声明语句，以及静态代码块，静态代码块的作用即是为静态变量赋初始化值。 4、卸载 只有没有任何引用指向Class对象的时候，这时候才会卸载类，结束类的生命周期。 装载验证准备解析初始化对象实例化垃圾收集对象终结卸载","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/Java 归并排序【转】","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/Java 归并排序【转】/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/Java%20%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E3%80%90%E8%BD%AC%E3%80%91/","excerpt":"","text":"归并排序1、原理归并排序是一种概念上最简单的排序算法，与快速排序一样，归并排序也是基于分治法的。归并排序将待排序的元素序列分成两个长度相等的子序列，为每一个子序列排序，然后再将他们合并成一个子序列。合并两个子序列的过程也就是两路归并。 2、复杂度归并排序是一种稳定的排序算法，归并排序的主要问题在于它需要一个与待排序数组一样大的辅助数组空间。由于归并排序每次划分时两个子序列的长度基本一样，所以归并排序最好、最差和平均时间复杂度都是nlog2n。 我们可以通过下图非常容易看懂归并排序的过程： 时间复杂度： 3、完整Java代码12345678910111213141516171819202122232425262728293031323334353637383940import org.junit.Test;public class MergeSort &#123; //两路归并算法，两个排好序的子序列合并为一个子序列 public void merge(int []a,int left,int mid,int right)&#123; int []tmp=new int[a.length];//辅助数组 int p1=left,p2=mid+1,k=left;//p1、p2是检测指针，k是存放指针 while(p1&lt;=mid &amp;&amp; p2&lt;=right)&#123; if(a[p1]&lt;=a[p2]) tmp[k++]=a[p1++]; else tmp[k++]=a[p2++]; &#125; while(p1&lt;=mid) tmp[k++]=a[p1++];//如果第一个序列未检测完，直接将后面所有元素加到合并的序列中 while(p2&lt;=right) tmp[k++]=a[p2++];//同上 //复制回原素组 for (int i = left; i &lt;=right; i++) a[i]=tmp[i]; &#125; public void mergeSort(int [] a,int start,int end)&#123; if(start&lt;end)&#123;//当子序列中只有一个元素时结束递归 int mid=(start+end)/2;//划分子序列 mergeSort(a, start, mid);//对左侧子序列进行递归排序 mergeSort(a, mid+1, end);//对右侧子序列进行递归排序 merge(a, start, mid, end);//合并 &#125; &#125; @Test public void test()&#123; int[] a = &#123; 49, 38, 65, 97, 76, 13, 27, 50 &#125;; mergeSort(a, 0, a.length-1); System.out.println(&quot;排好序的数组：&quot;); for (int e : a) System.out.print(e+&quot; &quot;); &#125;&#125; 原文链接：https://blog.csdn.net/qq_36442947/article/details/81612870","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/Java8新特性","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/Java8新特性/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/Java8%E6%96%B0%E7%89%B9%E6%80%A7/","excerpt":"","text":"Java8新特性 （转载自https://www.runoob.com/java/java8-new-features.html，具体内容见链接，非常详细实用） Java 8 (又称为 jdk 1.8) 是 Java 语言开发的一个主要版本。 Oracle 公司于 2014 年 3 月 18 日发布 Java 8 ，它支持函数式编程，新的 JavaScript 引擎，新的日期 API，新的Stream API 等。 Java8 新增了非常多的特性，我们主要讨论以下几个： Lambda 表达式 − Lambda 允许把函数作为一个方法的参数（函数作为参数传递到方法中）。 方法引用 − 方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。 默认方法 − 默认方法就是一个在接口里面有了一个实现的方法。 新工具 − 新的编译工具，如：Nashorn引擎 jjs、 类依赖分析器jdeps。 Stream API −新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。 Date Time API − 加强对日期与时间的处理。 Optional 类 − Optional 类已经成为 Java 8 类库的一部分，用来解决空指针异常。 Nashorn, JavaScript 引擎 − Java 8提供了一个新的Nashorn javascript引擎，它允许我们在JVM上运行特定的javascript应用。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/Java创建线程的4种方式","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/Java创建线程的4种方式/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/Java%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E7%9A%844%E7%A7%8D%E6%96%B9%E5%BC%8F/","excerpt":"","text":"一、概述1. 线程与进程进程（Process）是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。 线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。线程是程序中一个单一的顺序控制流程，在单个程序中同时运行多个线程完成不同的工作，称为多线程 2. 同步与异步同步（Synchronous）：同步是指一个进程在执行某个请求的时候，如果该请求需要一段时间才能返回信息，那么这个进程会一直等待下去，直到收到返回信息才继续执行下去。 异步（Asynchronous）：异步是指进程不需要一直等待下去，而是继续执行下面的操作，不管其他进程的状态，当有信息返回的时候会通知进程进行处理。 通俗地讲，也就是说，同步需要按部就班地走完一整个流程，完成一整个动作。而异步则不需要按部就班，可以在等待那个动作的时候同时做别的动作 3. 并行与并发并行：时间上是由重叠的，也就是说并行才是真正意义上的同一时刻可以有多个任务同时执行。 并发：任务在执行的时候，并发是没有时间上的重叠的，两个任务是交替执行的，由于切换的非常快，对于外界调用者来说相当于同一时刻多个任务一起执行了。 二、Java创建线程的3种方式1. 继承 Thread 类 定义 Thread 类的子类,并重写该类的 run() 方法,该 run() 方法的方法体就代表了线程需要完成的任务.因此把 run() 方法称为线程执行体。 创建 Thread 子类的实例,即创建了线程对象。 调用线程对象的 start() 方法来启动该线程。 123456789101112131415161718public class MyThread extends Thread &#123; public MyThread() &#123; &#125; public void run() &#123; for(int i=0;i&lt;10;i++) &#123; System.out.println(Thread.currentThread()+&quot;:&quot;+i); &#125; &#125; public static void main(String[] args) &#123; MyThread mThread1=new MyThread(); MyThread mThread2=new MyThread(); MyThread myThread3=new MyThread(); mThread1.start(); mThread2.start(); myThread3.start(); &#125;&#125; 2. 实现 Runnable 接口 定义 Runnable 接口的实现类,并重写该接口的 run() 方法,该 run() 方法的方法体同样是该线程的线程执行体。 创建 Runnable 实现类的实例,并以此实例作为 Thread 的target来创建 Thread 对象,该 Thread 对象才是真正的线程对象。 调用线程对象的 start() 方法来启动该线程。 12345678910111213141516171819202122public class MyThread implements Runnable&#123; public static int count=20; public void run() &#123; while(count&gt;0) &#123; try &#123; Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+&quot;-当前剩余票数:&quot;+count--); &#125; &#125; public static void main(String[] args) &#123; MyThread Thread1=new MyThread(); Thread mThread1=new Thread(Thread1,&quot;线程1&quot;); Thread mThread2=new Thread(Thread1,&quot;线程2&quot;); Thread mThread3=new Thread(Thread1,&quot;线程3&quot;); mThread1.start(); mThread2.start(); myThread3.start(); &#125;&#125; 推荐使用此方式 3. 使用 Callable 和 Future 创建 Callable 接口的实现类,并实现 call() 方法,该 call() 方法将作为线程执行体,且该 call() 方法有返回值,再创建 Callable 实现类的实例。 使用 FutureTask 类来包装 Callable 对象,该 FutureTask 对象封装了该 Callable 对象的 call() 方法的返回值。 使用 FutureTask 对象作为 Thread 对象的 target 创建并启动新线程。 调用 FutureTask 对象的 get() 方法来获得子线程执行结束后的返回值。 123456789101112131415161718192021222324252627282930import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask; public class MyThread implements Callable&lt;String&gt; &#123; private int count = 20; @Override public String call() throws Exception &#123; for (int i = count; i &gt; 0; i--) &#123; //Thread.yield(); System.out.println(Thread.currentThread().getName()+&quot;当前票数：&quot; + i); &#125; return &quot;sale out&quot;; &#125; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; Callable&lt;String&gt; callable =new MyThread(); FutureTask &lt;String&gt;futureTask=new FutureTask&lt;&gt;(callable); Thread mThread=new Thread(futureTask); Thread mThread2=new Thread(futureTask); Thread mThread3=new Thread(futureTask); //mThread.setName(&quot;hhh&quot;); mThread.start(); mThread2.start(); mThread3.start(); System.out.println(futureTask.get()); &#125;&#125; 4. 使用线程池通过 java.util.concurrent.Executors 的工具类可以创建三种类型的普通线程池： (1)SingleThreadPoolExecutor :单线程池适用于需要保证顺序执行各个任务的场景。 12345678910111213141516171819202122import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors; public class Test &#123; public static void main(String[] args) &#123; ExecutorService ex=Executors.newSingleThreadExecutor(); for(int i=0;i&lt;5;i++) &#123; ex.submit(new Runnable() &#123; @Override public void run() &#123; for(int j=0;j&lt;10;j++) &#123; System.out.println(Thread.currentThread().getName()+j); &#125; &#125; &#125;); &#125; ex.shutdown(); &#125; &#125; (2) FixThreadPool(int n); 固定大小的线程池使用于为了满足资源管理需求而需要限制当前线程数量的场合。使用于负载比较重的服务器。 12345678910111213141516171819202122import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors; public class Test &#123; public static void main(String[] args) &#123; ExecutorService ex=Executors.newFixedThreadPool(5); for(int i=0;i&lt;5;i++) &#123; ex.submit(new Runnable() &#123; @Override public void run() &#123; for(int j=0;j&lt;10;j++) &#123; System.out.println(Thread.currentThread().getName()+j); &#125; &#125; &#125;); &#125; ex.shutdown(); &#125; &#125; (5)CashedThreadPool(); 缓存线程池当提交任务速度高于线程池中任务处理速度时，缓存线程池会不断的创建线程 适用于提交短期的异步小程序，以及负载较轻的服务器 12345678910111213141516171819202122import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors; public class Test &#123; public static void main(String[] args) &#123; ExecutorService ex=Executors.newCachedThreadPool(); for(int i=0;i&lt;5;i++) &#123; ex.submit(new Runnable() &#123; @Override public void run() &#123; for(int j=0;j&lt;10;j++) &#123; System.out.println(Thread.currentThread().getName()+j); &#125; &#125; &#125;); &#125; ex.shutdown(); &#125; &#125;","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/Java序列化与反序列化","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/Java序列化与反序列化/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/Java%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/","excerpt":"","text":"1、序列化把对象转换为字节序列的过程。 2、反序列化把字节序列恢复为对象的过程。 3、对象的序列化主要有两种用途：1） 把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中； 2） 在网络上传送对象的字节序列。 4、serialVersionUID的作用对象序列化的版本号，凡是实现Serializable接口的类都有一个表示序列化版本标识符的静态变量。 如果没有显式定义serialVersionUID，那么java编译器会自动给这个class进行一个摘要算法，类似于指纹算法，只要这个文件多一个空格，得到的UID就会截然不同的，可以保证在这么多类中，这个编号是唯一的。所以class有了修改之后，已修改类的serialVersionUID和之前已经序列化的文件流中的类的的serialVersionUID是不一致的，处于安全机制考虑，程序抛出了错误，并且拒绝载入。 如果显式定义了serialVersionUID，在序列化后，在类中添加字段，或者方法，不会影响到后期的还原。可以说serialVersionUID是序列化和反序列化之间彼此认识的唯一信物。 显式地定义serialVersionUID有两种用途： 1、 在某些场合，希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有相同的serialVersionUID； 2、 在某些场合，不希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有不同的serialVersionUID。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/Java异常处理原则","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/Java异常处理原则/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/Java%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E5%8E%9F%E5%88%99/","excerpt":"","text":"Java的异常处理原则 Java异常处理中的“反例”： 丢弃异常 捕获了异常却不作任何处理，可以算得上Java编程中的杀手。调用一下printStackTrace算不上“处理异常”。既然捕获了异常，就要对它进行适当的处理。不要捕获异常之后又把它丢弃，不予理睬。 不指定具体的异常 用一个catch语句捕获所有的异常。最常见的情形就是使用catch（Exception ex）语句。在catch语句中尽可能指定具体的异常类型，必要时使用多个catch.不要试图处理所有可能出现的异常。 占用资源不释放 如果程序用到了文件、Socket、JDBC连接之类的资源，即使遇到了异常，也要正确释放占用的资源。Java提供了一个简化这类操作的关键词finally。 保证所有资源都被正确释放。充分运用finally关键词。 不说明异常的详细信息 在出现异常时，最好能够提供一些文字信息，例如当前正在执行的类、方法和其他状态信息，包括以一种更适合阅读的方式整理和组织printStackTrace提供的信息。 过于庞大的try块 一些新手常常把大量的代码放入单个try块，然后再在catch语句中声明Exception，而不是分离各个可能出现异常的段落并分别捕获其异常。这种做法为分析程序抛出异常的原因带来了困难，因为一大段代码中有太多的地方可能抛出Exception。应尽量减小try块的体积。 输出数据不完整 不完整的数据是Java程序的隐形杀手。出现异常导致输出数据不完整，应该加入提示说明。全面考虑可能出现的异常以及这些异常对执行流程的影响。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/Java构造函数细节","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/Java构造函数细节/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/Java%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E7%BB%86%E8%8A%82/","excerpt":"","text":"（1）. 当类中没有定义构造函数时，系统会指定给该类加上一个空参数的构造函数。这个是类中默认的构造函数。当类中如果自定义了构造函数，这时默认的构造函数就没有了。 注意: 有时候无参构造函数是必须的，比如用 @RequestBody 接收参数对象，如果没有无参数构造函数，无法正确接收参数，报错： 1JSON parse error: Can not construct instance of xxx: no suitable constructor found, can not deserialize from Object value （2）. 在一个类中可以定义多个构造函数，以进行不同的初始化。多个构造函数存在于类中，是以重载的形式体现的。因为构造函数的名称都相同。 构造函数与普通函数的区别： 一般函数是用于定义对象应该具备的功能。而构造函数定义的是，对象在调用功能之前，在建立时，应该具备的一些内容。也就是对象的初始化内容。 构造函数是在对象建立时由 jvm 调用, 给对象初始化。一般函数是对象建立后，当对象调用该功能时才会执行。 普通函数可以使用对象多次调用，构造函数就在创建对象时调用。 构造函数的函数名要与类名一样，而普通的函数只要符合标识符的命名规则即可。 构造函数没有返回值类型。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/Java正则表达式","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/Java正则表达式/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/Java%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"","text":"一直都有接触正则表达式，但是都是照搬过来使用的程度，没有能系统的学习，也没有留下一些笔记，下次使用还需网上查找资料。此次正好稍微做点记录，方便遗忘后重拾。 1. 什么是正则表达式正则表达式(Regular Expression)是一种文本模式，包括普通字符（例如，a 到 z 之间的字母）和特殊字符（称为”元字符”）。正则表达式使用单个字符串来描述、匹配一系列匹配某个句法规则的字符串。 2. 正则表达式知识点 一个字符串其实就是一个简单的正则表达式，例如 Hello World 正则表达式匹配 “Hello World” 字符串。 java.util.regex 包主要包括以下三个类： Pattern 类：pattern 对象是一个正则表达式的编译表示。Pattern 类没有公共构造方法。要创建一个 Pattern 对象，你必须首先调用其公共静态编译方法，它返回一个 Pattern 对象。该方法接受一个正则表达式作为它的第一个参数。 Matcher 类：Matcher 对象是对输入字符串进行解释和匹配操作的引擎。与Pattern 类一样，Matcher 也没有公共构造方法。你需要调用 Pattern 对象的 matcher 方法来获得一个 Matcher 对象。 PatternSyntaxException：PatternSyntaxException 是一个非强制异常类，它表示一个正则表达式模式中的语法错误。 以下实例中使用了正则表达式 .runoob. 用于查找字符串中是否包了 runoob 子串： 12345678910111213import java.util.regex.*; class RegexExample1&#123; public static void main(String args[])&#123; String content = &quot;I am noob &quot; + &quot;from runoob.com.&quot;; String pattern = &quot;.*runoob.*&quot;; boolean isMatch = Pattern.matches(pattern, content); System.out.println(&quot;字符串中是否包含了 &#x27;runoob&#x27; 子字符串? &quot; + isMatch); &#125;&#125; 3. Java 正则表达式语法在其他语言中，\\ 表示：我想要在正则表达式中插入一个普通的（字面上的）反斜杠，请不要给它任何特殊的意义。 在 Java 中，\\ 表示：我要插入一个正则表达式的反斜线，所以其后的字符具有特殊的意义。 所以，在其他的语言中（如Perl），一个反斜杠 \\ 就足以具有转义的作用，而在 Java 中正则表达式中则需要有两个反斜杠才能被解析为其他语言中的转义作用。也可以简单的理解在 Java 的正则表达式中，两个 \\ 代表其他语言中的一个 \\，这也就是为什么表示一位数字的正则表达式是 \\d，而表示一个普通的反斜杠是 \\\\。 字符 说明 \\ 将下一字符标记为特殊字符、文本、反向引用或八进制转义符。例如，”n”匹配字符”n”。”\\n”匹配换行符。序列”\\\\“匹配”\\“，”\\(“匹配”(“。 ^ 匹配输入字符串开始的位置。如果设置了 RegExp 对象的 Multiline 属性，^ 还会与”\\n”或”\\r”之后的位置匹配。 $ 匹配输入字符串结尾的位置。如果设置了 RegExp 对象的 Multiline 属性，$ 还会与”\\n”或”\\r”之前的位置匹配。 | 零次或多次匹配前面的字符或子表达式。例如，zo* 匹配”z”和”zoo”。* 等效于 {0,}。+ | 一次或多次匹配前面的字符或子表达式。例如，”zo+”与”zo”和”zoo”匹配，但与”z”不匹配。+ 等效于 {1,}。? | 零次或一次匹配前面的字符或子表达式。例如，”do(es)?”匹配”do”或”does”中的”do”。? 等效于 {0,1}。{n} | n 是非负整数。正好匹配 n 次。例如，”o{2}”与”Bob”中的”o”不匹配，但与”food”中的两个”o”匹配。{n,} | n 是非负整数。至少匹配 n 次。例如，”o{2,}”不匹配”Bob”中的”o”，而匹配”foooood”中的所有 o。”o{1,}”等效于”o+”。”o{0,}”等效于”o*”。{n,m} | m 和 n 是非负整数，其中 n &lt;&#x3D; m。匹配至少 n 次，至多 m 次。例如，”o{1,3}”匹配”fooooood”中的头三个 o。’o{0,1}’ 等效于 ‘o?’。注意：您不能将空格插入逗号和数字之间。? | 当此字符紧随任何其他限定符（*、+、?、{n}、{n,}、{n,m}）之后时，匹配模式是”非贪心的”。”非贪心的”模式匹配搜索到的、尽可能短的字符串，而默认的”贪心的”模式匹配搜索到的、尽可能长的字符串。例如，在字符串”oooo”中，”o+?”只匹配单个”o”，而”o+”匹配所有”o”。x|y | 匹配 x 或 y。例如，’z|food’ 匹配”z”或”food”。’(z|f)ood’ 匹配”zood”或”food”。[xyz] | 字符集。匹配包含的任一字符。例如，”[abc]”匹配”plain”中的”a”。[^xyz] | 反向字符集。匹配未包含的任何字符。例如，”[^abc]”匹配”plain”中”p”，”l”，”i”，”n”。[a-z] | 字符范围。匹配指定范围内的任何字符。例如，”[a-z]”匹配”a”到”z”范围内的任何小写字母。[^a-z] | 反向范围字符。匹配不在指定的范围内的任何字符。例如，”[^a-z]”匹配任何不在”a”到”z”范围内的任何字符。\\b | 匹配一个字边界，即字与空格间的位置。例如，”er\\b”匹配”never”中的”er”，但不匹配”verb”中的”er”。\\B | 非字边界匹配。”er\\B”匹配”verb”中的”er”，但不匹配”never”中的”er”。\\cx | 匹配 x 指示的控制字符。例如，\\cM 匹配 Control-M 或回车符。x 的值必须在 A-Z 或 a-z 之间。如果不是这样，则假定 c 就是”c”字符本身。\\d | 数字字符匹配。等效于 [0-9]。\\D | 非数字字符匹配。等效于 [^0-9]。\\f | 换页符匹配。等效于 \\x0c 和 \\cL。\\n | 换行符匹配。等效于 \\x0a 和 \\cJ。\\r | 匹配一个回车符。等效于 \\x0d 和 \\cM。\\s | 匹配任何空白字符，包括空格、制表符、换页符等。与 [ \\f\\n\\r\\t\\v] 等效。\\S | 匹配任何非空白字符。与 [^ \\f\\n\\r\\t\\v] 等效。\\t | 制表符匹配。与 \\x09 和 \\cI 等效。\\v | 垂直制表符匹配。与 \\x0b 和 \\cK 等效。\\w | 匹配任何字类字符，包括下划线。与”[A-Za-z0-9_]”等效。\\W | 与任何非单词字符匹配。与”[^A-Za-z0-9_]”等效。 4. 正则表达式应用 匹配字符串，如 手机号校验、邮箱校验 切割字符串，提取字符串信息 场景：需要从一串字符串中提取出其中的主机ip信息 123456String str = &quot;ip地址是127.0.0.1:8848，真的，不骗你&quot;Pattern pattern = Pattern.compile(&quot;(((localhost)|(\\\\d+.&#123;1&#125;\\\\d+.&#123;1&#125;\\\\d+.&#123;1&#125;\\\\d+))\\\\:&#123;1&#125;\\\\d+)&quot;);Matcher matcher = pattern.matcher(str);while (matcher.find())&#123; // 一定要先调用 find()函数！ host = matcher.group(); &#125; 详情见： 菜鸟教程：Java 正则表达式&amp;emsp;&amp;emsp; &amp;emsp; &amp;ensp;JAVA正则表达式：Pattern类与Matcher类详解","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/Java获取时间工具类","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/Java获取时间工具类/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/Java%E8%8E%B7%E5%8F%96%E6%97%B6%E9%97%B4%E5%B7%A5%E5%85%B7%E7%B1%BB/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738public class CalendarUtil &#123; /** * 获取当前时间 * @Param format：时间格式，例：yyyy-MM-dd HH:mm:ss * @return */ public static String getTimeNow(String format)&#123; Calendar calendar= Calendar.getInstance(); SimpleDateFormat dateFormat= new SimpleDateFormat(format); return dateFormat.format(calendar.getTime()); &#125; /** * 获取当前时间的前n天 * @Param format：时间格式，例：yyyy-MM-dd HH:mm:ss * @return */ public static String getTimeDayBefore(int n, String format)&#123; Calendar calendar= Calendar.getInstance(); calendar.add(Calendar.DAY_OF_MONTH, - n); SimpleDateFormat dateFormat= new SimpleDateFormat(format); return dateFormat.format(calendar.getTime()); &#125; /** * 更加自由的时间字符串获取 * @param n 当前时间之间 n 个单位 * @param step 步进单位，如 Calendar.MONTH(2) * @param format 时间格式，如：yyyy-MM-dd HH:mm:ss * @return */ public static String getTimeBefore(int n, int step, String format)&#123; Calendar calendar= Calendar.getInstance(); calendar.add(step, - n); SimpleDateFormat dateFormat= new SimpleDateFormat(format); return dateFormat.format(calendar.getTime()); &#125;&#125;","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/Jenkins遇到的坑","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/Jenkins遇到的坑/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/Jenkins%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/","excerpt":"","text":"一开始是仓库没有jar包，编译报错，上传jar后仍然报错，确认信息填写正确。 报错： 1Failure to find com.github.sanjusoftware:yamlbeans:jar:1.11 in http://nexus.apusic.net/content/groups/public was cached in the local repository, resolution will not be reattempted until the update interval of nexus has elapsed or updates are forced 由于之前编译有了缓存信息，后面再编译不会再从远程仓库拉取，需要删掉本地仓库缓存文件。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/Skywalking使用graphql查询","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/Skywalking使用graphql查询/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/Skywalking%E4%BD%BF%E7%94%A8graphql%E6%9F%A5%E8%AF%A2/","excerpt":"","text":"查询单个服务的数据信息1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&#123; &quot;query&quot;: &quot;query queryData($serviceId: ID!,$duration: Duration!) &#123; serviceApdexScore: getLinearIntValues(metric: &#123; name: \\&quot;service_apdex\\&quot; id: $serviceId &#125;, duration: $duration) &#123; values &#123;value&#125; &#125; serviceResponseTime: getLinearIntValues(metric: &#123; name: \\&quot;service_resp_time\\&quot; id: $serviceId &#125;, duration: $duration) &#123; values &#123;value&#125; &#125; serviceThroughput: getLinearIntValues(metric: &#123; name: \\&quot;service_cpm\\&quot; id: $serviceId &#125;, duration: $duration) &#123; values &#123; value &#125; &#125; serviceSLA: getLinearIntValues(metric: &#123; name: \\&quot;service_sla\\&quot; id: $serviceId &#125;, duration: $duration) &#123; values &#123; value &#125; &#125; globalPercentile: getMultipleLinearIntValues(metric: &#123; name: \\&quot;all_percentile\\&quot; &#125;, numOfLinear: 5, duration: $duration) &#123; values &#123; value &#125; &#125; servicePercentile: getMultipleLinearIntValues(metric: &#123; name: \\&quot;service_percentile\\&quot; id: $serviceId &#125;, numOfLinear: 5, duration: $duration) &#123; values &#123; value &#125; &#125; serviceSlowEndpoint: getEndpointTopN( serviceId: $serviceId duration: $duration name: \\&quot;endpoint_avg\\&quot;, topN: 10, order: DES ) &#123; key: id label: name value &#125; serviceInstanceThroughput: getServiceInstanceTopN( serviceId: $serviceId duration: $duration name: \\&quot;service_instance_cpm\\&quot;, topN: 10, order: DES ) &#123; key: id label: name value &#125;&#125;&quot;, &quot;variables&quot;:&#123; &quot;atabaseId&quot;:&quot;&quot;, &quot;duration&quot;:&#123;&quot;start&quot;: &quot;2020-05-18&quot;, &quot;end&quot;: &quot;2020-05-21&quot;, &quot;step&quot;: &quot;DAY&quot;&#125;, &quot;endpointId&quot;:&quot;4&quot;, &quot;endpointName&quot;:&quot;/api/items&quot;, &quot;instanceId&quot;:&quot;5&quot;, &quot;serviceId&quot;:&quot;4&quot; &#125;&#125;&#123;&quot;data&quot;:&#123;&quot;serviceApdexScore&quot;:&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:10000&#125;]&#125;,&quot;serviceResponseTime&quot;:&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:380&#125;]&#125;,&quot;serviceThroughput&quot;:&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;]&#125;,&quot;serviceSLA&quot;:&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:10000&#125;]&#125;,&quot;globalPercentile&quot;:[&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:370&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:410&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:410&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:1560&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:1560&#125;]&#125;],&quot;servicePercentile&quot;:[&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:370&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:380&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:380&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:380&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:380&#125;]&#125;],&quot;serviceSlowEndpoint&quot;:[&#123;&quot;key&quot;:&quot;4&quot;,&quot;label&quot;:&quot;/api/items&quot;,&quot;value&quot;:380&#125;],&quot;serviceInstanceThroughput&quot;:[&#123;&quot;key&quot;:&quot;5&quot;,&quot;label&quot;:&quot;provider-pid:4920@KFW7BT1P01V035&quot;,&quot;value&quot;:0&#125;]&#125;&#125; 2. 查询一段时间内的服务id和名称1234567891011121314151617181920212223242526272829303132&#123; &quot;query&quot;: &quot;query queryServices($duration: Duration!) &#123;services: getAllServices(duration: $duration) &#123;id, name&#125;&#125;&quot;, &quot;variables&quot;: &#123; &quot;duration&quot;: &#123; &quot;start&quot;: &quot;2020-05-21&quot;, &quot;end&quot;: &quot;2020-05-22&quot;, &quot;step&quot;: &quot;DAY&quot; &#125; &#125;&#125;&#123; &quot;data&quot;: &#123; &quot;services&quot;: [ &#123; &quot;id&quot;: &quot;3&quot;, &quot;name&quot;: &quot;consumer&quot; &#125;, &#123; &quot;id&quot;: &quot;7&quot;, &quot;name&quot;: &quot;SpringBootWithSkywalking-HelloTomcat&quot; &#125;, &#123; &quot;id&quot;: &quot;2&quot;, &quot;name&quot;: &quot;hello-world-demo&quot; &#125;, &#123; &quot;id&quot;: &quot;4&quot;, &quot;name&quot;: &quot;provider&quot; &#125; ] &#125;&#125; 获得服务的id和name，可以用来查询响应时间、可用性等指标 3. 根据服务id数组查询响应时间、服务apdex分数、slas数、吞吐量123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119&#123; &quot;query&quot;: &quot;query queryData($serviceIds: [ID!]!,$duration: Duration!) &#123; serviceResponseTime: getValues(metric: &#123; name: \\&quot;service_resp_time\\&quot; ids: $serviceIds &#125;, duration: $duration) &#123; values &#123;id, value&#125; &#125; serviceApdexScore: getValues(metric: &#123; name: \\&quot;service_apdex\\&quot; ids: $serviceIds &#125;, duration: $duration) &#123; values &#123; id,value&#125; &#125; serviceSLA: getValues(metric: &#123; name: \\&quot;service_sla\\&quot; ids: $serviceIds &#125;, duration: $duration) &#123; values &#123;id, value&#125; &#125; serviceThroughput: getValues(metric: &#123; name: \\&quot;service_cpm\\&quot; ids: $serviceIds &#125;, duration: $duration) &#123; values &#123;id, value&#125; &#125; &#125;&quot;, &quot;variables&quot;:&#123; &quot;duration&quot;:&#123;&quot;start&quot;: &quot;2020-05-21&quot;, &quot;end&quot;: &quot;2020-05-22&quot;, &quot;step&quot;: &quot;DAY&quot;&#125;, &quot;serviceIds&quot;:[&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;7&quot;] &#125;&#125;&#123; &quot;data&quot;: &#123; &quot;serviceResponseTime&quot;: &#123; &quot;values&quot;: [ &#123; &quot;id&quot;: &quot;2&quot;, &quot;value&quot;: 191 &#125;, &#123; &quot;id&quot;: &quot;3&quot;, &quot;value&quot;: 989 &#125;, &#123; &quot;id&quot;: &quot;4&quot;, &quot;value&quot;: 380 &#125;, &#123; &quot;id&quot;: &quot;7&quot;, &quot;value&quot;: 144 &#125; ] &#125;, &quot;serviceApdexScore&quot;: &#123; &quot;values&quot;: [ &#123; &quot;id&quot;: &quot;2&quot;, &quot;value&quot;: 10000 &#125;, &#123; &quot;id&quot;: &quot;3&quot;, &quot;value&quot;: 7500 &#125;, &#123; &quot;id&quot;: &quot;4&quot;, &quot;value&quot;: 10000 &#125;, &#123; &quot;id&quot;: &quot;7&quot;, &quot;value&quot;: 10000 &#125; ] &#125;, &quot;serviceSLA&quot;: &#123; &quot;values&quot;: [ &#123; &quot;id&quot;: &quot;2&quot;, &quot;value&quot;: 10000 &#125;, &#123; &quot;id&quot;: &quot;3&quot;, &quot;value&quot;: 10000 &#125;, &#123; &quot;id&quot;: &quot;4&quot;, &quot;value&quot;: 10000 &#125;, &#123; &quot;id&quot;: &quot;7&quot;, &quot;value&quot;: 10000 &#125; ] &#125;, &quot;serviceThroughput&quot;: &#123; &quot;values&quot;: [ &#123; &quot;id&quot;: &quot;2&quot;, &quot;value&quot;: 0 &#125;, &#123; &quot;id&quot;: &quot;3&quot;, &quot;value&quot;: 0 &#125;, &#123; &quot;id&quot;: &quot;4&quot;, &quot;value&quot;: 0 &#125;, &#123; &quot;id&quot;: &quot;7&quot;, &quot;value&quot;: 0 &#125; ] &#125; &#125;&#125;","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/Skywalking学习","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/Skywalking学习/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/Skywalking%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"SkyWalking 中非常重要的三个概念： 服务(Service) ：表示对请求提供相同行为的一系列或一组工作负载。在使用 Agent 或 SDK 的时候，你可以定义服务的名字。如果不定义的话，SkyWalking 将会使用你在平台（例如说 Istio）上定义的名字。 服务实例(Service Instance) ：上述的一组工作负载中的每一个工作负载称为一个实例。就像 Kubernetes 中的 pods 一样, 服务实例未必就是操作系统上的一个进程。但当你在使用 Agent 的时候, 一个服务实例实际就是操作系统上的一个真实进程。 端点(Endpoint) ：对于特定服务所接收的请求路径, 如 HTTP 的 URI 路径和 gRPC 服务的类名 + 方法签名。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/Spring boot单元测试","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/Spring boot单元测试/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/Spring%20boot%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/","excerpt":"","text":"公司职级认证有单元测试要求，花了一天时间把欠下的的补完了。。。 spring boot引入单元测试pom.xml 文件中写入： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; spring boot中单元测试目录与main同级 spring boot使用单元测试 快捷生成测试类idea 中选中要测试的类 -&gt; Ctrl+Shift+T 打开创建测试类窗口 -&gt; 选择要测试的方法，创建测试类 生成的类路径为 Test 包下的同名路径。 自己创建测试类Test 目录下自己创建类。。。 类创建完成后还需要加上注解，如下： 123456789@RunWith(SpringRunner.class)@SpringBootTestpublic class myServiceTest &#123; @Test public void test()&#123; //... &#125;&#125; 不同场景下的单元测试 对于 Controller 层单元测试，使用 @AutoConfigureMockMvc，示例代码如下： 1234567891011121314151617181920212223242526272829303132@RunWith(SpringRunner.class)@SpringBootTest@AutoConfigureMockMvcpublic class LicenseInfoResourceTest extends AbstractRestControllerTest &#123; /** * 初始化MockMvc */ @Autowired private MockMvc mvc; /** * 测试的controller */ @MockBean private LicenseInfoResource licenseInfoResource; @Before public void setUp() &#123; SecurityContextHolder.clearContext(); &#125; @Test @WithMockUser(username = &quot;admin&quot;, password = &quot;admin&quot;) public void getLicenseInfo() throws Exception &#123; MvcResult mvcResult = mvc.perform(MockMvcRequestBuilders.get(&quot;/license/get_platform_info&quot;)) .andExpect(MockMvcResultMatchers.status().isOk()) .andDo(MockMvcResultHandlers.print()) .andReturn(); System.out.println(&quot;content&quot; + mvcResult.getResponse().getContentAsString()); &#125;&#125; 对于有运行时环境的要求，当前用户记录等，需要在类或者方法上加上注册变量： 1@WithMockUser(username = &quot;admin&quot;, password = &quot;admin&quot;) 对于单点登陆应用，调用接口需要 token ,可以先获取token，然后加入到请求头中： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/* 获取token工具类 */public final class LogInUtils &#123; private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper(); private LogInUtils() &#123; &#125; public static String getTokenForLogin(String username, String password, MockMvc mockMvc) throws Exception &#123; // 设置验证码 MockHttpSession session = new MockHttpSession(); session.setAttribute(&quot;vrifyCode&quot;, &quot;123456&quot;); String code = &quot;123456&quot;; String content = mockMvc.perform(post(&quot;/api/authenticate&quot;) .contentType(MediaType.APPLICATION_JSON) .session(session) .content(&quot;&#123;\\&quot;password\\&quot;: \\&quot;&quot; + password + &quot;\\&quot;, \\&quot;username\\&quot;: \\&quot;&quot; + username + &quot;\\&quot;, \\&quot;code\\&quot;: \\&quot;&quot;+ code + &quot;\\&quot;&#125;&quot;)) .andReturn() .getResponse() .getContentAsString(); AuthenticationResponse authResponse = OBJECT_MAPPER.readValue(content, AuthenticationResponse.class); return authResponse.getIdToken(); &#125; private static class AuthenticationResponse &#123; @JsonAlias(&quot;id_token&quot;) private String idToken; public void setIdToken(String idToken) &#123; this.idToken = idToken; &#125; public String getIdToken() &#123; return idToken; &#125; &#125;&#125;/* 获取token加入到请求头 */@Testpublic void createRole() throws Exception &#123; final String token = LogInUtils.getTokenForLogin(&quot;admin&quot;, &quot;admin&quot;, mvc); String json = &quot;&#123;\\&quot;name\\&quot;:\\&quot;超级管理员2\\&quot;,\\&quot;remark\\&quot;:\\&quot;权限\\&quot;,\\&quot;permissionIds\\&quot;:\\&quot;1\\&quot;&#125;&quot;; MvcResult mvcResult = mvc.perform(MockMvcRequestBuilders.post(&quot;/role/create_role&quot;) .contentType(MediaType.APPLICATION_JSON) .content(json) .header(&quot;Authorization&quot;, &quot;Bearer &quot; + token)) .andExpect(MockMvcResultMatchers.status().isOk()) .andDo(MockMvcResultHandlers.print()) .andReturn(); System.out.println(&quot;status: &quot; + mvcResult.getResponse().getStatus());&#125; MocMvc详解转载自 https://blog.csdn.net/wo541075754/article/details/88983708 什么是Mock?模拟对象（mock object），是以可控的方式模拟真实对象行为的假对象。在编程过程中，通常通过模拟一些输入数据，来验证程序是否达到预期结果。使用模拟对象，可以模拟复杂的、真实的对象行为。如果在单元测试中无法使用真实对象，可采用模拟对象进行替代。 什么是MockMvc？MockMvc是由spring-test包提供，实现了对Http请求的模拟，能够直接使用网络的形式，转换到Controller的调用，使得测试速度快、不依赖网络环境。同时提供了一套验证的工具，结果的验证十分方便。 spring使用MocMvcspring中使用MockMvcBuilder来构造MocMvc。它有两种实现方式：StandaloneMockMvcBuilder和DefaultMockMvcBuilder，分别对应两种测试方式，即独立安装和集成Web环境测试（并不会集成真正的web环境，而是通过相应的Mock API进行模拟测试，无须启动服务器）。代码示例： 1234567891011121314151617181920//SpringBoot1.4版本之前用的是SpringJUnit4ClassRunner.class@RunWith(SpringRunner.class)//SpringBoot1.4版本之前用的是@SpringApplicationConfiguration(classes = Application.class)@SpringBootTest//测试环境使用，用来表示测试环境使用的ApplicationContext将是WebApplicationContext类型的@WebAppConfigurationpublic class HelloWorldTest &#123; private MockMvc mockMvc; @Autowired private WebApplicationContext webApplicationContext; @Before public void setup() &#123; // 实例化方式一 mockMvc = MockMvcBuilders.standaloneSetup(new HelloWorldController()).build(); // 实例化方式二// mockMvc = MockMvcBuilders.webAppContextSetup(webApplicationContext).build(); &#125; 单元测试方法： 12345678910111213141516171819202122@Testpublic void testHello() throws Exception &#123; /* * 1、mockMvc.perform执行一个请求。 * 2、MockMvcRequestBuilders.get(&quot;XXX&quot;)构造一个请求。 * 3、ResultActions.param添加请求传值 * 4、ResultActions.accept(MediaType.TEXT_HTML_VALUE))设置返回类型 * 5、ResultActions.andExpect添加执行完成后的断言。 * 6、ResultActions.andDo添加一个结果处理器，表示要对结果做点什么事情 * 比如此处使用MockMvcResultHandlers.print()输出整个响应结果信息。 * 7、ResultActions.andReturn表示执行完成后返回相应的结果。 */ mockMvc.perform(MockMvcRequestBuilders .get(&quot;/hello&quot;) // 设置返回值类型为utf-8，否则默认为ISO-8859-1 .accept(MediaType.APPLICATION_JSON_UTF8_VALUE) .param(&quot;name&quot;, &quot;Tom&quot;)) .andExpect(MockMvcResultMatchers.status().isOk()) .andExpect(MockMvcResultMatchers.content().string(&quot;Hello Tom!&quot;)) .andDo(MockMvcResultHandlers.print());&#125; 整个过程如下： 1234561、准备测试环境2、通过MockMvc执行请求3、添加验证断言4、添加结果处理器5、得到MvcResult进行自定义断言/进行下一步的异步请求6、卸载测试环境 Sping boot2.0后使用MocMvc更加方便，只需要在测试类加上@AutoConfigureMockMvc注解，就可以注入MocMvc: 123456789101112@RunWith(SpringRunner.class)@SpringBootTest@AutoConfigureMockMvcpublic class Test &#123; /** * 初始化MockMvc */ @Autowired private MockMvc mvc; //...&#125; 注意事项：如果使用DefaultMockMvcBuilder进行MockMvc实例化时需在SpringBoot启动类上添加组件扫描的package的指定，否则会出现404。如： 1@ComponentScan(basePackages = &quot;com.secbro2&quot;) 一些常用的测试 测试普通控制器 123456mockMvc.perform(get(&quot;/user/&#123;id&#125;&quot;, 1)) //执行请求 .andExpect(model().attributeExists(&quot;user&quot;)) //验证存储模型数据 .andExpect(view().name(&quot;user/view&quot;)) //验证viewName .andExpect(forwardedUrl(&quot;/WEB-INF/jsp/user/view.jsp&quot;))//验证视图渲染时forward到的jsp .andExpect(status().isOk())//验证状态码 .andDo(print()); //输出MvcResult到控制台 得到MvcResult自定义验证 123MvcResult result = mockMvc.perform(get(&quot;/user/&#123;id&#125;&quot;, 1))//执行请求 .andReturn(); //返回MvcResult Assert.assertNotNull(result.getModelAndView().getModel().get(&quot;user&quot;)); //自定义断言 验证请求参数绑定到模型数据及Flash属性 123456mockMvc.perform(post(&quot;/user&quot;).param(&quot;name&quot;, &quot;zhang&quot;)) //执行传递参数的POST请求(也可以post(&quot;/user?name=zhang&quot;)) .andExpect(handler().handlerType(UserController.class)) //验证执行的控制器类型 .andExpect(handler().methodName(&quot;create&quot;)) //验证执行的控制器方法名 .andExpect(model().hasNoErrors()) //验证页面没有错误 .andExpect(flash().attributeExists(&quot;success&quot;)) //验证存在flash属性 .andExpect(view().name(&quot;redirect:/user&quot;)); //验证视图 文件上传 1234byte[] bytes = new byte[] &#123;1, 2&#125;; mockMvc.perform(fileUpload(&quot;/user/&#123;id&#125;/icon&quot;, 1L).file(&quot;icon&quot;, bytes)) //执行文件上传 .andExpect(model().attribute(&quot;icon&quot;, bytes)) //验证属性相等性 .andExpect(view().name(&quot;success&quot;)); //验证视图 JSON请求&#x2F;响应验证 123456789101112131415String requestBody = &quot;&#123;\\&quot;id\\&quot;:1, \\&quot;name\\&quot;:\\&quot;zhang\\&quot;&#125;&quot;; mockMvc.perform(post(&quot;/user&quot;) .contentType(MediaType.APPLICATION_JSON).content(requestBody) .accept(MediaType.APPLICATION_JSON)) //执行请求 .andExpect(content().contentType(MediaType.APPLICATION_JSON)) //验证响应contentType .andExpect(jsonPath(&quot;$.id&quot;).value(1)); //使用Json path验证JSON 请参考http://goessner.net/articles/JsonPath/ String errorBody = &quot;&#123;id:1, name:zhang&#125;&quot;; MvcResult result = mockMvc.perform(post(&quot;/user&quot;) .contentType(MediaType.APPLICATION_JSON).content(errorBody) .accept(MediaType.APPLICATION_JSON)) //执行请求 .andExpect(status().isBadRequest()) //400错误请求 .andReturn(); Assert.assertTrue(HttpMessageNotReadableException.class.isAssignableFrom(result.getResolvedException().getClass()));//错误的请求内容体 异步测试 1234567891011121314151617181920//Callable MvcResult result = mockMvc.perform(get(&quot;/user/async1?id=1&amp;name=zhang&quot;)) //执行请求 .andExpect(request().asyncStarted()) .andExpect(request().asyncResult(CoreMatchers.instanceOf(User.class))) //默认会等10秒超时 .andReturn(); mockMvc.perform(asyncDispatch(result)) .andExpect(status().isOk()) .andExpect(content().contentType(MediaType.APPLICATION_JSON)) .andExpect(jsonPath(&quot;$.id&quot;).value(1)); //Callable MvcResult result = mockMvc.perform(get(&quot;/user/async1?id=1&amp;name=zhang&quot;)) //执行请求 .andExpect(request().asyncStarted()) .andExpect(request().asyncResult(CoreMatchers.instanceOf(User.class))) //默认会等10秒超时 .andReturn(); mockMvc.perform(asyncDispatch(result)) .andExpect(status().isOk()) .andExpect(content().contentType(MediaType.APPLICATION_JSON)) .andExpect(jsonPath(&quot;$.id&quot;).value(1)); 全局配置 12345678mockMvc = webAppContextSetup(wac) .defaultRequest(get(&quot;/user/1&quot;).requestAttr(&quot;default&quot;, true)) //默认请求 如果其是Mergeable类型的，会自动合并的哦mockMvc.perform中的RequestBuilder .alwaysDo(print()) //默认每次执行请求后都做的动作 .alwaysExpect(request().attribute(&quot;default&quot;, true)) //默认每次执行后进行验证的断言 .build(); mockMvc.perform(get(&quot;/user/1&quot;)) .andExpect(model().attributeExists(&quot;user&quot;));","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/Spring boot读取配置文件问题","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/Spring boot读取配置文件问题/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/Spring%20boot%E8%AF%BB%E5%8F%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E9%97%AE%E9%A2%98/","excerpt":"","text":"1. 加载自定义文件 YAML files cannot be loaded by using the @PropertySource annotation. So, in the case that you need to load values that way, you need to use a properties file.即@PropertySource不支持YAML文件。 要让@PropertySource支持Yaml文件，可以做如下配置： 继承DefaultPropertySourceFactory类并修改 12345678910111213141516171819202122public class YamlConfigFactory extends DefaultPropertySourceFactory &#123; @Override public PropertySource&lt;?&gt; createPropertySource(String name, EncodedResource resource) throws IOException &#123; String sourceName = name != null ? name : resource.getResource().getFilename(); if (!resource.getResource().exists()) &#123; return new PropertiesPropertySource(sourceName, new Properties()); &#125; else if (sourceName.endsWith(&quot;.yml&quot;) || sourceName.endsWith(&quot;.yaml&quot;)) &#123; Properties propertiesFromYaml = loadYml(resource); return new PropertiesPropertySource(sourceName, propertiesFromYaml); &#125; else &#123; return super.createPropertySource(name, resource); &#125; &#125; private Properties loadYml(EncodedResource resource) throws IOException &#123; YamlPropertiesFactoryBean factory = new YamlPropertiesFactoryBean(); factory.setResources(resource.getResource()); factory.afterPropertiesSet(); return factory.getObject(); &#125;&#125; 配置注解： 1@PropertySource(value = &#123;&quot;classpath:application-my.yml&quot;&#125;,factory = YamlConfigFactory.class) 2. spring boot中配置文件访问优先级优先级如下 第一种是在执行命令的目录下建config文件夹，然后把配置文件放到这个文件夹下。(在jar包的同一个目录下建config文件夹，执行命令需要在jar包所在目录下才行) 第二种是直接把配置文件放到jar包的同级目录 第三种在classpath下建一个config文件夹，然后把配置文件放进去。 第四种是在classpath下直接放配置文件。 springboot默认是优先读取它本身同级目录下的一个config&#x2F;application.properties文件的。在src&#x2F;main&#x2F;resource文件夹下创建的application.properties文件的优先级是最低的 所以springboot启动读取外部配置文件，只需要在外面加一层配置文件覆盖默认的即可，不用修改代码 3. 指定配置文件路径启动程序#通过 –spring.config.location指定配置文件路径 1nohup java -Xms256M -Xmx1024M -jar mailgateway-2.0.0.12.jar --spring.config.location=/usr/ums_chenly/application-prod.properties --spring.profiles.active=prod &gt; mailgateway_nohup_out_`date +%Y%m%d`.txt 2&gt;&amp;1 &amp; 说明 如果启动程序时指定配置文件路径，则程序运行时只读取指定的配置文件。指定配置文件不存在则报错，程序启动失败。 如果不指定配置文件路径，则按上述优先级加载，如果优先级高的配置文件中没有某个配置项，则会到优先级低的配置文件中找该配置项，即具有互补功能(文件名相同才会互补，比如classpath下的application-prod.properties会补jar包的同级目录下application-prod.properties的某个配置项，但是classpath下的application.properties不会补application-prod.properties的某个配置项)。如果指定配置文件路径，则不互补，只会读取指定的配置文件。 如果spring.config.location和 spring.profiles.active都不指定， 默认找application.properties文件。如果spring.profiles.active指定dev，则默认找application-dev.properties文件。如果spring.profiles.active指定prod,则会找application-prod.properties文件","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/Spring security实现权限认证","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/Spring security实现权限认证/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/Spring%20security%E5%AE%9E%E7%8E%B0%E6%9D%83%E9%99%90%E8%AE%A4%E8%AF%81/","excerpt":"","text":"配置适配器 WebSecurityConfigurerAdapter 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126/** * spring security 核心配置文件 */@Configurationpublic class BrowerSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired private AuthenticationManager authenticationManager; @Autowired //自定义的安全元 数据源 实现FilterInvocationSecurityMetadataSource private MyInvocationSecurityMetadataSourceService myInvocationSecurityMetadataSourceService; @Autowired //自定义访问决策器 private MyAccessDecisionManager myAccessDecisionManager; @Override protected void configure(HttpSecurity http) throws Exception &#123; /** * from表单登录设置 */ http.formLogin() .loginPage(&quot;&quot;) //登录页面 /login .passwordParameter(&quot;&quot;) //设置form表单中对应的name参数 默认为 password 下同 .usernameParameter(&quot;&quot;) // .defaultSuccessUrl(&quot;&quot;) //认证成功后的跳转页面 默认跳转页面 可以设置是否总是默认 不是的话可以跳转与用户的target-url .failureUrl(&quot;&quot;) .failureForwardUrl(&quot;&quot;) //登录失败 转发 的url .successForwardUrl(&quot;&quot;) //登录成功 转发 的url 与successHandler对应 即处理完后请求转发的url .failureHandler(null) //自定义的认证失败 做什么处理 .successHandler(null) //自定义认证成功 后做的处理 ----- 例如 想记录用户信息判断用户状态等 .permitAll() //对于需要所有用户都可以访问的界面 或者url进行设置 .loginProcessingUrl(&quot;&quot;) //自定义处理认证的url 默认为 /login .authenticationDetailsSource(null) //自定义身份验证的数据源 理解为查出数据库中的密码 和权限（可以不加） 然后再交给security ////修改和替换配置 已经配置好的修改 例如下面修改 安全拦截器的安全数据源 .withObjectPostProcessor(new ObjectPostProcessor&lt;FilterSecurityInterceptor&gt;() &#123; public &lt;O extends FilterSecurityInterceptor&gt; O postProcess( O fsi) &#123; fsi.setPublishAuthorizationSuccess(true); //修改成自定义的 安全元数据源 权限的源 ！！！！！ fsi.setSecurityMetadataSource(myInvocationSecurityMetadataSourceService); //修改成自定义的 访问决策器 自定义的 fsi.setAccessDecisionManager(myAccessDecisionManager); //使用系统的 fsi.setAuthenticationManager(authenticationManager); return fsi; &#125; &#125;); /** * 请求认证管理 */ http.authorizeRequests() .antMatchers(&quot;url匹配路径&quot;).permitAll() //url匹配路径 permitAll 运行 全部访问 不用认证 .accessDecisionManager(null) //访问决策器 .filterSecurityInterceptorOncePerRequest(true) //过滤每个请求一次的安全拦截器 ？？？ .anyRequest().authenticated() //其他的请求 需要认证， .antMatchers(&quot;/admin/**&quot;).hasRole(&quot;ADMIN&quot;) //url匹配路径 具有怎样的角色 .antMatchers(&quot;/admin/**&quot;).access(&quot;hasRole(&#x27;ROLE_ADMIN&#x27;)&quot;) //url匹配路径 具有怎样的角色 或者是权限 ; /** * anonymous * * 匿名访问时 存在默认 用户名 annonymousUser */ http.anonymous().disable().csrf().disable(); //禁止匿名 关闭csrf /** * 登出操作管理 */ http.logout() //登出处理 .logoutUrl(&quot;/my/logout&quot;) .logoutSuccessUrl(&quot;/my/index&quot;) .logoutSuccessHandler(null) .invalidateHttpSession(true) .addLogoutHandler(null) .deleteCookies(&quot;cookieNamesToClear&quot;) ; /** * session 会话管理 */ http.sessionManagement() //session管理 .maximumSessions(2) //最大session 数量 --用户 .maxSessionsPreventsLogin(false) //超过最大sessin数量后时候阻止登录 .expiredUrl(&quot;/&quot;) //会话失效后跳转的url .expiredSessionStrategy(null) //自定义session 过期错略 .sessionRegistry(null) //自定义的session 注册 表 ; &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; /** * 基础的配置 */ auth /** * 认证 时触发的事件 */ .authenticationEventPublisher(null) /** * 用户细节服务 * * 认证管理器数据的来源 吧 用户身份凭证信息和 权限信息 */ .userDetailsService(null) /** * 密码编辑器 对密码进行加密 */ .passwordEncoder(null) ; &#125; @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception &#123; return super.authenticationManagerBean(); &#125; @Override public void configure(WebSecurity web) throws Exception &#123; /** * 不进行拦截的mvc */ web.ignoring().mvcMatchers(); /** * 添加自定义的 安全过滤器 */ web.addSecurityFilterChainBuilder(null); &#125;&#125;","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/acmp开发记录","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/acmp开发记录/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/acmp%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/","excerpt":"","text":"1. 数据库存储创建日期是Instant格式，后台需要根据今天日期查找今天创建的记录。主要是需要得到Instant格式的今天的最小日期，用于比对。123LocalDate localDate = LocalDate.now();LocalDateTime minTime = localDate.atTime(LocalTime.MIN);Instant today = minTime.toInstant(ZoneOffset.of(&quot;+0&quot;)); 2. 物理分页查询（数据库分页）业务场景：查询数据库表联系人分页，筛选条件pid、status、name；按创建时间降序排序。 12345678910111213Specification&lt;AlarmContact&gt; specification = (Specification&lt;AlarmContact&gt;) (root, query, criteriaBuilder) -&gt; &#123; List&lt;Predicate&gt; list = new ArrayList&lt;&gt;(); list.add(criteriaBuilder.equal(root.get(&quot;projectId&quot;), projectId)); list.add(criteriaBuilder.equal(root.get(&quot;status&quot;), ResourceStatus.ENABLE)); if (name.length() != 0) &#123; // 此处为查询含有name的数据 list.add(criteriaBuilder.like(root.get(&quot;name&quot;),&quot;%&quot;+ name +&quot;%&quot; )); &#125; Predicate[] p = new Predicate[list.size()]; return criteriaBuilder.and(list.toArray(p)); &#125;;Pageable pageable = new PageRequest(page, limit, Sort.Direction.DESC, &quot;createdDate&quot;);Page&lt;AlarmContact&gt; alarmContact，Page = alarmContactRepository.findAll(specification, pageable); 3. 集合分页业务场景：拥有用户的集合，需要将这个集合进行分页返回给前端。 12345678910111213141516171819List&lt;User&gt; userList;//默认已经有List数据//根据传进来的用户名字进行模糊筛选 if(0 != name.length())&#123; List&lt;User&gt; temList = new ArrayList&lt;&gt;(); temList.addAll(userList); for(User user : temList)&#123; if(!user.getUsername().contains(name))&#123; userList.remove(user); &#125; &#125; &#125;//集合转PagePageable pageable = new PageRequest(page, limit, Sort.Direction.ASC, &quot;id&quot;);// 当前页第一条数据在List中的位置int start = (int)pageable.getOffset();// 当前页最后一条数据在List中的位置int end = (start + pageable.getPageSize()) &gt; userList.size() ? userList.size() : ( start + pageable.getPageSize());// 配置分页数据Page&lt;User&gt; userPagePage = new PageImpl&lt;&gt;(userList.subList(start, end), pageable, userList.size()); 4. 树的相关操作业务场景：在做权限控制的时候，权限是树的形式，根据前端需求需要提供不同的数据格式。 求出当前用户的所有具体权限（叶子节点） 1234567891011121314151617181920212223242526public Set&lt;Permission&gt; getEXactPermission() &#123; Set&lt;Role&gt; roles = userRoleRepository.findByUserId(userCache.getId()).stream().map(userRole -&gt; userRole.getRole()).collect(Collectors.toSet()); Set&lt;Permission&gt; permissions = roles.stream().flatMap(role -&gt; role.getPermissions().stream()).collect(Collectors.toSet()); Set&lt;Permission&gt; exactPermissions = new HashSet&lt;&gt;(); for(Permission permission : permissions)&#123; Set&lt;Permission&gt; permissions1 = new HashSet&lt;&gt;(); findTreeleafs(permission, permissions1); exactPermissions.addAll(permissions1); &#125; return exactPermissions;&#125;//递归遍历树的叶子节点，如果只有一个节点，它也是叶子public void findTreeleafs(Permission permission, Set&lt;Permission&gt; permissionSet) &#123; if(permission.getChildren().size() == 0)&#123; permissionSet.add(permission); &#125; for(Permission permission1 : permission.getChildren())&#123; if (permission.getChildren().size() == 0) &#123; permissionSet.addAll(permission.getChildren()); &#125; else &#123; findTreeleafs(permission1, permissionSet); &#125; &#125;&#125; 获取权限子树。就是用户拥有权限的完整路径 思路：获取用户的具体权限集合（叶子节点），删除完整树中没有达到集合中的路径。 5. spring boot JPA多条件查询1）Repository需要继承JpaRepository和JpaSpecificationExecutor 123public interface projectRepository extends JpaRepository&lt;Project, Long&gt;, JpaSpecificationExecutor&lt;Project&gt; &#123; &#125; 2）构建筛选器 123456789101112131415161718192021222324/** * 分页查询获取分页列表 * @param companyId * @return */ public Page&lt;Project&gt; getListByCompanyPage(PageFilter pageFilter,String companyId,Date beginDate,Date endDate,String projectName) &#123; Page&lt;Project&gt; l=projectRepository.findAll(new Specification&lt;Project&gt;() &#123; @Override public Predicate toPredicate(Root&lt;Project&gt; root, CriteriaQuery&lt;?&gt; criteriaQuery, CriteriaBuilder cBuilder) &#123; //开始，定义一个Predicate Predicat e p = cBuilder.conjunction(); /**精确查询**/ p = cBuilder.and(p, cBuilder.equal(root.get(&quot;companyId&quot;), companyId)); /**模糊查询**/ p = cBuilder.and(p, cBuilder.like(root.get(&quot;projectName&quot;), &quot;%&quot;+projectName+&quot;%&quot;)); /**时间段查询**/ //大于等于开始时间 p = cBuilder.and(p, cBuilder.greaterThanOrEqualTo(root.get(&quot;createTime&quot;), beginDate)); //小于等于结束时间 p = cBuilder.and(p, cBuilder.lessThanOrEqualTo(root.get(&quot;createTime&quot;), endDate)); return p; &#125; &#125;, pageFilter.getPageRequest()); return l; 6. jpa delete无法删除问题描述：两张表表1和表2通过一张中间表表3关联，都是一对多关系。表1的一条记录 a 已经和表2的记录 b 关联起来了。逻辑删除 a 记录，现在需要删除 b 记录，表3的关联记录还存在，要先根据 b 记录删掉表3的关联记录，但是此时用 JPA 的 deleteAllBy… 不生效，非常疑惑，自定义 sql 删除生效。 12@Modifying@Query(&quot;delete from UserRole where role.id = ?1&quot;) 解答：看到网上有说法说是 JPA 的 entity 对象生命周期问题，由于表 1 还存在记录的引用，之后会更新回来。。。 7. 分页查询结果集中某个属性等于某个值的元素排在前面业务场景：分页查询数据库，状态为 ON 的值排在前面，且根据最后修改时间排序。 分析讨论：Java分页查询的排序并不是很难，特别是使用Pagable时排序非常方便，但是一般的排序都市按照升序或者降序排序，根据某个属性的特定值排序很少看见，头疼。 问题解决： 1）偷懒办法，如果只有两种状态，仍然可以用升序降序进行排序，这时候比较的就是两种不同值的相对大小（数值、字符串类型等）； 12Sort sort =new Sort(Sort.Direction.DESC, &quot;status&quot;).and(new Sort(Sort.Direction.DESC, &quot;lastModifiedDate&quot;));Pageable pageable = new PageRequest(page, limit, sort); 2）有多种不同状态时，可以使用 sql 语句进行查询 3）查询出元素集合列表，进行排序，然后对集合进行分页。 8. 读取 jar 包中MANIFEST.MF文件信息123456789101112// 通过JarFile的getJarEntry方法读取META-INF/MANIFEST.MFjarFile = new JarFile(jarFilePath);JarEntry entry = jarFile.getJarEntry(&quot;META-INF/MANIFEST.MF&quot;);// 如果读取到MANIFEST. F文件内容，则转换为stringif (entry != null) &#123; InputStream in = jarFile.getInputStream(entry); StringBuilder sb = new StringBuilder(); BufferedReader br = new BufferedReader(new InputStreamReader(in)); String line = &quot;&quot;; while ((line = br.readLine()) != null) &#123; sb.append(line+&quot;&lt;br&gt;&quot;); &#125; 9. 编写泛型方法错误示例： 1public static Page&lt;T&gt; getPage(int page, int limit, List&lt;T&gt; data)&#123; // ... &#125; 实际使用时候会报类型无法匹配的错误。 正确写法： 123public static &lt;T extends Object&gt; Page&lt;T&gt; getPage(int page, int limit, List&lt;T&gt; data)&#123; // ...&#125; 10. Java中父类能不能强转为子类？一般来说父类是不能强转为子类对象的，因为子类中可能包含父类没有的属性或方法，父类强转子类会存在不确定性。 《java面向对象程序设计（第2版）》，一个父类类型的对象如果是用子类new出来的时候, 就不能称之为父类对象，而是一个子类的上转型对象。这两者是有区别的，区别的其中一点就是父类对象不可强制转换为子类对象，而子类的上转型对象可以强制转换回子类对象 1234567891011121314class Father&#123; &#125;class Son extends Father&#123; &#125;public class Main&#123; public static void main(String[] args)&#123; Father father1 = new Father(); Father father2 = new Son(); Son son1 = (Son) father1;//报错 Son son2 = (Son) father2;//不报错 &#125;&#125; 网上看到很搞笑的一段描述：孙子可能会装大爷，大爷永远不会装孙子。 哈哈，非常贴切生动了。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/idea+maven+git 开发环境安装","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/idea+maven+git 开发环境安装/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/idea+maven+git%20%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/","excerpt":"","text":"1. jdk安装网上下载jdk，运行安装程序 配置环境变量： 系统变量-&gt;新增-&gt;变量名：JAVA_HOME，变量值：java安装根目录 path变量-&gt;新增 -&gt;%JAVA_HOME%\\bin 控制台输入java -version验证 2. idea安装百度搜索下载安装、破解，没啥好说的 3. maven安装http://maven.apache.org/download.cgi 下载二进制安装包，直接解压到磁盘 配置环境变量： 系统变量-&gt;新增-&gt;变量名：MAVEN_HOME，变量值：maven根目录 path变量-&gt;新增 -&gt;%MAVEN_HOME%\\bin 控制台输入mvn -v验证 配置本地仓库和远程仓库：打开%MAVEN_HOME%\\conf\\settings.xml文件，编辑 本地仓库：解开localRepository标签注释，将地址改为要设置的本地仓库地址 远程仓库：在mirrors标签中添加子标签如下： 123456&lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;name&gt;nexus-aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; 4. git安装https://git-scm.com/downloads 下载安装程序，会有很多安装选项，可以一路选择默认选项，安装完成 安装过程会自动添加git环境变量，不再需要手动配置 控制台输入git --version验证 配置git 用户和邮箱: 12345git config --global user.name [github注册用户名]git config --global user.email [github邮箱]git config --global user.password [用户密码]git config --list 查看当前配置# 需要修改信息的话重新运行以上命令即可 常用命令： git init ：给项目添加仓库 git add . ：添加项目下的所有文件到仓库中，也可以指定文件 git commit -m [提交时的描述信息] ：提交时的附带信息 git remote add origin [自己的仓库url地址] ：将本地的仓库关联到github的仓库，需要先在github上创建仓库 git push -u origin master ：项目上传到github仓库中 git clone [github仓库url地址] :克隆项目到当前目录下 5. idea使用mavenFile -&gt; Settings -&gt; Build, Execution, Deployment -&gt; Build Tools -&gt; Maven : Maven home directory -&gt; 选择%MAVEN_HOME% User settings file -&gt; 选择%MAVEN_HOME%\\conf\\settings Local repository -&gt; 选择本地仓库 出现版本不兼容的bug:idea version：2019.1.1maven version：3.6.3问题描述：pom文件导入依赖包时报错No implementation for org.apache.maven.model.path.PathTranslator was bound解决办法：升级idea版本或者降低maven版本。 6. idea使用git从github仓库中下载项目到本地： settings -&gt; 配置git.exe 首页选择check out from version control，登录github，输入账号密码，就可以选择要下载的仓库了 本地项目更新到gitbub仓库中：","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/idea使用心得","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/idea使用心得/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/idea%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/","excerpt":"","text":"说是心得，其实就是一些常用到，但是容易忘记，或者有一些坑的地方的记录 全局替换查找ctrl + shift + r: 在路径中替换，指的是在选定的目录下或者类包下，查找要被替换的字符，再在第二个输入框中输入要替换的字符，点击弹出框的右下角的replace或者replaceall即可。 大小写转换 有时候需要把一大串小写的字符串常转化为大写的，或者大写的切换为小写的。idea中选中内容后，快捷键 Ctrl+Shift+u即可实现大小写的快速切换，或者 Edit -&gt; Toggle Case. 快速生成测试类 Ctrl+Shift+t","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/lombok","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/lombok/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/lombok/","excerpt":"","text":"lombok简介Lombok 是能自动接通编辑器和构建工具的一个Java库，对于简单的Java对象，通过注解的形式例如@Setter @Getter，可以替代代码中的getter和setter方法。Lombok中用到了注解，但是它并没有用到反射，而是在代码编译时期动态将注解替换为具体的代码。所以JVM实际运行的代码，和我们手动编写的包含了各种工具方法的类相同。 lombok常用注解 @Data：注解在类上，将类提供的所有属性都添加get、set方法，并添加、equals、canEquals、hashCode、toString方法 @Setter：注解在类上，为所有属性添加set方法、注解在属性上为该属性提供set方法 @Getter：注解在类上，为所有的属性添加get方法、注解在属性上为该属性提供get方法 @NotNull：在参数中使用时，如果调用时传了null值，就会抛出空指针异常 @NoArgsConstructor：创建一个无参构造函数 @toString：创建toString方法。 @UtilityClass:工具类 idea项目中使用lombok第一步： pom.xml中加入lombok依赖包 123456&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.20&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency 第二步：加入lombok插件File —&gt; Settings —&gt; Plugins：搜索lombok，点击安装install。然后会提示重启，重启。 第三步：idea配置File —&gt; Settings —&gt; Build, Execution, Deployment —&gt; Compiler —&gt; Java Compiler —&gt; User compiler：选择javacFile —&gt; Settings —&gt; Build, Execution, Deployment —&gt; Compiler —&gt; Annotation Processors -&gt; Enable annotation processors -&gt; 勾选 注意事项 1、使用 lombok.Data 注解实体类时，boolean类型的get方法，会变成is方法；若需要get方法，使用封装类Boolean。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/null==obj or obj==null ？","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/null==obj or obj==null ？/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/null==obj%20or%20obj==null%20%EF%BC%9F/","excerpt":"","text":"在比较操作中，有人提倡常量前置的写法，但是读起来就会怪怪的。 据说在 c++ 中，if(obj = null)是可以通过编译的，但是在运行时会报错，为了防止这种情况发生，所以提倡常量前置的写法。 但是在 Java 中 if(obj = null)是在编译时会报错的，所以不存在这一隐患。时候判断常量前置真的没有必要了呢？其实有两面性，有好有坏，具体要看个人和规范的要求。 好处： 可以避免if(obj = null)类似错误 类似&quot;str&quot;.equals(obj)的写法可以避免空指针错误 坏处： 影响代码可读性 使得代码存在隐患。出现了预料之外的空指针，应该积极去处理，而不是掩盖 特例Boolean 类情况： 12345678910111213141516public class Test&#123; public static void main(String[] args)&#123; Boolean obj = Boolean.FALSE; if(null = obj)&#123; // 编译器报错 //... &#125; &#125;&#125;public class Test&#123; public static void main(String[] args)&#123; Boolean obj = Boolean.FALSE; if(obj = null)&#123; // 编译器不报错，运行时报错 //... &#125; &#125;&#125; 这个算是 Java 中的特例，值得注意 反正我是喜欢常量前置的","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/spring boot + jasypt实现配置文件信息加密","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/spring boot + jasypt实现配置文件信息加密/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/spring%20boot%20+%20jasypt%E5%AE%9E%E7%8E%B0%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%BF%A1%E6%81%AF%E5%8A%A0%E5%AF%86/","excerpt":"","text":"配置文件敏感信息的加密，对于生产环境来说还是很有必要的。之前自己实现了一个粗糙的配置文件加密方案，详见spring boot中代码修改配置文件。后面有老师傅提出了有更成熟通过的方案，jasypt，本次就来使用它。 1、添加Maven依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt; &lt;artifactId&gt;jasypt-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.8&lt;/version&gt;&lt;/dependency&gt; 最新版本是2.1.1，但是只能spring-boot-2.x以上使用。因为我的程序中使用的是spring-boot-1.5.3,所以选择1.8版本。 2、编写加密脚本 下载jasypt-1.9.2.jar，添加依赖后，也可以从本地仓库中获取，如：LocalRepository\\org\\jasypt\\jasypt\\1.9.2 Windows脚本： 12345678@echo offcd /d %~dp0cd ..set /p user=请输入要加密的账户名称: java -cp lib/jasypt-1.9.2.jar org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI input=%user% password=apusic.net algorithm=PBEWithMD5AndDESset /p password=请输入要加密的密码: java -cp lib/jasypt-1.9.2.jar org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI input=%password% password=apusic.net algorithm=PBEWithMD5AndDESpause Linux脚本： 12345678910#!/bin/shBASE_DIR=$(cd `dirname $0`; pwd)/..cd $BASE_DIRread -p &quot;输入要加密的账户名称：&quot; userjava -cp $BASE_DIR/lib/jasypt-1.9.2.jar org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI input=$user password=apsuic.net algorithm=PBEWithMD5AndDESread -p &quot;输入要加密的账号密码：&quot; passwordjava -cp $BASE_DIR/lib/jasypt-1.9.2.jar org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI input=$password password=apsuic.net algorithm=PBEWithMD5AndDES 运行脚本，根据提示输入账号密码后可以获得加密串 3、使用加密字符串 程序入口（main）添加注解：@EnableConfigurationProperties 配置文件中如下格式填写加密串： 12client.user=ENC(40+Fa4B+kj2wbOQHa+JuWQ==)client.password=ENC(qX2Its/37OKPVUgxM38I7qgEhitVnuPV) 加密串用ENC()标注 填写加密key,即jasypt.encryptor.password，可以在注入到程序运行时变量中，也可以写在配置文件中，不推荐。 运行时变量方式： 1java -jar lib/exporter-aas-v9-0.0.1-SNAPSHOT.jar --spring.config.location=conf/application.properties --jasypt.encryptor.password=apusic.net 配置文件方式： 1asypt.encryptor.password=apusic.net 这样在程序运行时候jasypt就会先解析加密串，程序获取到的是解析后的账号密码。 完成","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/spring boot中代码修改配置文件","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/spring boot中代码修改配置文件/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/spring%20boot%E4%B8%AD%E4%BB%A3%E7%A0%81%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/","excerpt":"","text":"配置文件中有用户的账号密码等信息，需要为用户保护信息。 怎么做呢？暂时没有想到很好的办法，现在设想是用户第一次使用程序时候，配置文件中明文填写账号密码等信息。启用程序连接成功后加密账号密码，输出加密字符串到配置文件中，以后使用密文进行连接。其实这也只是表面功夫，因为实际的连接需要用到明文的账号密码，必须使用对称加密还原账号密码，加密key是写在程序中的，解包后就能获取到。但是怎么说呢，世界上没有攻破不了的防御，只是这个成本问题而已，增加信息被泄漏成本，加密的本质而已。 废话不多说，开始实现： 网上找到加密工具类EncryptUtil，这个加密工具类的好处是不用第三方jar包，简单方便，功能全面： 123456789101112131415161718192021222324252627282930//用账号密码长度判断是否已经加密，当然也可以加密后向配置文件中加入额外加密标识if(clientConfig.getUser().length() &gt; 30 &amp;&amp; clientConfig.getPassword().length() &gt; 30)&#123; //尝试使用解码后的账号密码进行连接 user.put(JMXConnector.CREDENTIALS, new String[] &#123;encryptUtil.AESdecode(clientConfig.getUser(), ENCRYPT_AES_KEY), encryptUtil.AESdecode(clientConfig.getPassword(), ENCRYPT_AES_KEY) &#125;); jmxc = JMXConnectorFactory.connect(url,user); mbsc = jmxc.getMBeanServerConnection(); &#125;else &#123; //尝试直接使用配置文件账号密码信息连接 user.put(JMXConnector.CREDENTIALS, new String[] &#123; clientConfig.getUser(), clientConfig.getPassword() &#125;); jmxc = JMXConnectorFactory.connect(url,user); mbsc = jmxc.getMBeanServerConnection(); try &#123; // 若是能够连接成功，加密账号密码，输出到配置文件中 Environment environment = SpringUtil.getBean(&quot;environment&quot;); String profilepath = environment.getProperty(&quot;application.file.path&quot;); LinkedProperties properties = new LinkedProperties(); FileReader fileReader = new FileReader(profilepath); properties.load(fileReader); FileWriter fileWriter = new FileWriter(profilepath); properties.setProperty(&quot;client.user&quot;, encryptUtil.AESencode(clientConfig.getUser(), ENCRYPT_AES_KEY)); properties.setProperty(&quot;client.password&quot;, encryptUtil.AESencode(clientConfig.getPassword(), ENCRYPT_AES_KEY)); properties.store(fileWriter, &quot;account and password is encrypted&quot;); fileReader.close(); fileWriter.close(); &#125; catch (IOException var2) &#123; var2.printStackTrace(); &#125; 这里我使用了自定义的 LinkedProperties ，如果使用Properties读写配置文件的话会乱序。查看Properties源码，可以看到 123class Properties extends Hashtable&lt;Object,Object&gt; &#123; //...&#125; Properties其实是一个Hashtable，所以里面的键值对会乱序。要想实现顺序也比较简单，写入我们额外使用一个LinkHashMap来保存键值对，写出时使用LinkHashMap里的数据写出即可。 12345678910111213141516171819202122232425262728public class LinkedProperties extends Properties &#123; private Map&lt;String, String&gt; linkedPropertiesMap = new LinkedHashMap&lt;&gt;(); public Map&lt;String, String&gt; getLinkedPropertiesMap()&#123; return linkedPropertiesMap; &#125; @Override public synchronized void load(Reader reader) throws IOException &#123; //... linkedPropertiesMap.put(key, value); &#125; @Override public synchronized Object setProperty(String key, String value) &#123; linkedPropertiesMap.put(key, value); return put(key, value); &#125; @Override public void store(Writer writer, String comments) throws IOException&#123; //... for(Map.Entry&lt;String, String&gt; entry : linkedPropertiesMap.entrySet())&#123;&#125; //... &#125; //...&#125; EncryptUtil工具类代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286import com.sun.org.apache.xerces.internal.impl.dv.util.Base64;import javax.crypto.Cipher;import javax.crypto.KeyGenerator;import javax.crypto.Mac;import javax.crypto.SecretKey;import javax.crypto.spec.SecretKeySpec;import java.security.MessageDigest;import java.security.SecureRandom;public class EncryptUtil &#123; public static final String MD5 = &quot;MD5&quot;; public static final String SHA1 = &quot;SHA1&quot;; public static final String HmacMD5 = &quot;HmacMD5&quot;; public static final String HmacSHA1 = &quot;HmacSHA1&quot;; public static final String DES = &quot;DES&quot;; public static final String AES = &quot;AES&quot;; /**编码格式；默认使用uft-8*/ public String charset = &quot;utf-8&quot;; /**DES*/ public int keysizeDES = 0; /**AES*/ public int keysizeAES = 128; public static EncryptUtil me; private EncryptUtil()&#123; //单例 &#125; //双重锁 public static EncryptUtil getInstance()&#123; if (me==null) &#123; synchronized (EncryptUtil.class) &#123; if(me == null)&#123; me = new EncryptUtil(); &#125; &#125; &#125; return me; &#125; /** * 使用MessageDigest进行单向加密（无密码） * @param res 被加密的文本 * @param algorithm 加密算法名称 * @return */ private String messageDigest(String res,String algorithm)&#123; try &#123; MessageDigest md = MessageDigest.getInstance(algorithm); byte[] resBytes = charset==null?res.getBytes():res.getBytes(charset); return base64(md.digest(resBytes)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; /** * 使用KeyGenerator进行单向/双向加密（可设密码） * @param res 被加密的原文 * @param algorithm 加密使用的算法名称 * @param key 加密使用的秘钥 * @return */ private String keyGeneratorMac(String res,String algorithm,String key)&#123; try &#123; SecretKey sk = null; if (key==null) &#123; KeyGenerator kg = KeyGenerator.getInstance(algorithm); sk = kg.generateKey(); &#125;else &#123; byte[] keyBytes = charset==null?key.getBytes():key.getBytes(charset); sk = new SecretKeySpec(keyBytes, algorithm); &#125; Mac mac = Mac.getInstance(algorithm); mac.init(sk); byte[] result = mac.doFinal(res.getBytes()); return base64(result); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; /** * 使用KeyGenerator双向加密，DES/AES，注意这里转化为字符串的时候是将2进制转为16进制格式的字符串，不是直接转，因为会出错 * @param res 加密的原文 * @param algorithm 加密使用的算法名称 * @param key 加密的秘钥 * @param keysize * @param isEncode * @return */ private String keyGeneratorES(String res,String algorithm,String key,int keysize,boolean isEncode)&#123; try &#123; KeyGenerator kg = KeyGenerator.getInstance(algorithm); if (keysize == 0) &#123; byte[] keyBytes = charset==null?key.getBytes():key.getBytes(charset); kg.init(new SecureRandom(keyBytes)); &#125;else if (key==null) &#123; kg.init(keysize); &#125;else &#123; byte[] keyBytes = charset==null?key.getBytes():key.getBytes(charset); kg.init(keysize, new SecureRandom(keyBytes)); &#125; SecretKey sk = kg.generateKey(); SecretKeySpec sks = new SecretKeySpec(sk.getEncoded(), algorithm); Cipher cipher = Cipher.getInstance(algorithm); if (isEncode) &#123; cipher.init(Cipher.ENCRYPT_MODE, sks); byte[] resBytes = charset==null?res.getBytes():res.getBytes(charset); return parseByte2HexStr(cipher.doFinal(resBytes)); &#125;else &#123; cipher.init(Cipher.DECRYPT_MODE, sks); return new String(cipher.doFinal(parseHexStr2Byte(res))); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; private String base64(byte[] res)&#123; return Base64.encode(res); &#125; /**将二进制转换成16进制 */ public static String parseByte2HexStr(byte buf[]) &#123; StringBuffer sb = new StringBuffer(); for (int i = 0; i &lt; buf.length; i++) &#123; String hex = Integer.toHexString(buf[i] &amp; 0xFF); if (hex.length() == 1) &#123; hex = &#x27;0&#x27; + hex; &#125; sb.append(hex.toUpperCase()); &#125; return sb.toString(); &#125; /**将16进制转换为二进制*/ public static byte[] parseHexStr2Byte(String hexStr) &#123; if (hexStr.length() &lt; 1) return null; byte[] result = new byte[hexStr.length()/2]; for (int i = 0;i&lt; hexStr.length()/2; i++) &#123; int high = Integer.parseInt(hexStr.substring(i*2, i*2+1), 16); int low = Integer.parseInt(hexStr.substring(i*2+1, i*2+2), 16); result[i] = (byte) (high * 16 + low); &#125; return result; &#125; /** * md5加密算法进行加密（不可逆） * @param res 需要加密的原文 * @return */ public String MD5(String res) &#123; return messageDigest(res, MD5); &#125; /** * md5加密算法进行加密（不可逆） * @param res 需要加密的原文 * @param key 秘钥 * @return */ public String MD5(String res, String key) &#123; return keyGeneratorMac(res, HmacMD5, key); &#125; /** * 使用SHA1加密算法进行加密（不可逆） * @param res 需要加密的原文 * @return */ public String SHA1(String res) &#123; return messageDigest(res, SHA1); &#125; /** * 使用SHA1加密算法进行加密（不可逆） * @param res 需要加密的原文 * @param key 秘钥 * @return */ public String SHA1(String res, String key) &#123; return keyGeneratorMac(res, HmacSHA1, key); &#125; /** * 使用DES加密算法进行加密（可逆） * @param res 需要加密的原文 * @param key 秘钥 * @return */ public String DESencode(String res, String key) &#123; return keyGeneratorES(res, DES, key, keysizeDES, true); &#125; /** * 对使用DES加密算法的密文进行解密（可逆） * @param res 需要解密的密文 * @param key 秘钥 * @return */ public String DESdecode(String res, String key) &#123; return keyGeneratorES(res, DES, key, keysizeDES, false); &#125; /** * 使用AES加密算法经行加密（可逆） * @param res 需要加密的密文 * @param key 秘钥 * @return */ public String AESencode(String res, String key) &#123; return keyGeneratorES(res, AES, key, keysizeAES, true); &#125; /** * 对使用AES加密算法的密文进行解密 * @param res 需要解密的密文 * @param key 秘钥 * @return */ public String AESdecode(String res, String key) &#123; return keyGeneratorES(res, AES, key, keysizeAES, false); &#125; /** * 使用异或进行加密 * @param res 需要加密的密文 * @param key 秘钥 * @return */ public String XORencode(String res, String key) &#123; byte[] bs = res.getBytes(); for (int i = 0; i &lt; bs.length; i++) &#123; bs[i] = (byte) ((bs[i]) ^ key.hashCode()); &#125; return parseByte2HexStr(bs); &#125; /** * 使用异或进行解密 * @param res 需要解密的密文 * @param key 秘钥 * @return */ public String XORdecode(String res, String key) &#123; byte[] bs = parseHexStr2Byte(res); for (int i = 0; i &lt; bs.length; i++) &#123; bs[i] = (byte) ((bs[i]) ^ key.hashCode()); &#125; return new String(bs); &#125; /** * 直接使用异或（第一调用加密，第二次调用解密） * @param res 密文 * @param key 秘钥 * @return */ public int XOR(int res, String key) &#123; return res ^ key.hashCode(); &#125; /** * 使用Base64进行加密 * @param res 密文 * @return */ public String Base64Encode(String res) &#123; return Base64.encode(res.getBytes()); &#125; /** * 使用Base64进行解密 * @param res * @return */ public String Base64Decode(String res) &#123; return new String(Base64.decode(res));&#125;","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/spring boot使用单例模式的痛","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/spring boot使用单例模式的痛/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/spring%20boot%E4%BD%BF%E7%94%A8%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E7%97%9B/","excerpt":"","text":"单例模式好处多多，是工具类中经常使用的设计模式，但是笔者在spring boot中使用单例模式中，尝到了许多痛苦的滋味。。。 Spring注解给开发带来了很多便利，要使用到这种便利，就需要使用spring的IOC注入，即类的创建需要交由spring来管理。如@Autowired，一个类如果在使用@Autowired注入了另一个类，但是当这个类被new时，@Autowired注入将会失效，出现NPE报错。 比如 1234567891011121314151617181920public class A&#123; //...&#125;public class B&#123; @Autowired A a; private static volatile B instance; private B(); public static B getInstance()&#123; if(null == instance)&#123; synchronized (B.class) &#123; instance = new B(); //B的@Autowired不生效，b.a==null &#125; &#125; return instance; &#125; //...&#125; 一些spring辅助类是必须要交由spring注入的，比如Environment，单例模式就很不方便了。 当然，办法也是有的，可以使用ApplicationContext来注入Bean： 123456789101112131415161718192021public class SpringUtil implements ApplicationContextAware &#123; private static ApplicationContext applicationContext; public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; SpringUtil.applicationContext = applicationContext; &#125; //beanName是类名，第一个字母小写 public static &lt;T&gt; T getBean(String beanName) &#123; if(applicationContext.containsBean(beanName))&#123; return (T) applicationContext.getBean(beanName); &#125;else&#123; return null; &#125; &#125; public static &lt;T&gt; Map&lt;String, T&gt; getBeansOfType(Class&lt;T&gt; baseType)&#123; return applicationContext.getBeansOfType(baseType); &#125;&#125; 要使用某一个类的时候SpringUtil.getBean(beanName)就可以的，坏处也是有的，无法使用全局变量，每个方法使用这个类时都需要注入一次。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/spring boot使用多线程","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/spring boot使用多线程/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/spring%20boot%E4%BD%BF%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"业务场景：查询数据分页，每条数据需要添加上概览信息，获取概览信息需要调用一些http接口，有一定的等待时间，单线程查询效率较慢。现在需要在查出了数据库持久化数据的基础上，使用多线程给数据添加概览信息，而且在所有异步线程都完成后，再返回分页信息给前端。 1.应用主程序添加注解 @EnableAsync 来开启 Springboot 对于异步任务的支持 1234567@SpringBootApplication@EnableAsyncpublic class SpringBootApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootApplication.class, args); &#125;&#125; 2.配置类实现接口 AsyncConfigurator，返回一个 ThreadPoolTaskExecutor 线程池对象。 12345678910111213141516171819202122232425262728293031323334@Configuration@EnableAsyncpublic class AsyncTaskConfig implements AsyncConfigurer &#123; // ThredPoolTaskExcutor的处理流程 // 当池子大小小于corePoolSize，就新建线程，并处理请求 // 当池子大小等于corePoolSize，把请求放入workQueue中，池子里的空闲线程就去workQueue中取任务并处理 // 当workQueue放不下任务时，就新建线程入池，并处理请求，如果池子大小撑到了maximumPoolSize，就用RejectedExecutionHandler来做拒绝处理 // 当池子的线程数大于corePoolSize时，多余的线程会等待keepAliveTime长时间，如果无请求可处理就自行销毁 @Override @Bean public Executor getAsyncExecutor() &#123; ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); //设置核心线程数 threadPool.setCorePoolSize(10); //设置最大线程数 threadPool.setMaxPoolSize(20); //线程池所使用的缓冲队列 threadPool.setQueueCapacity(10); // 等待时间 （默认为0，此时立即停止），并没等待xx秒后强制停止 threadPool.setAwaitTerminationSeconds(60); // 线程名称前缀 threadPool.setThreadNamePrefix(&quot;my-Async-&quot;); // 初始化线程 threadPool.initialize(); return threadPool; &#125; @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() &#123; return null; &#125;&#125; 3.异步调用的方法上添加注解@Async，表明该方法是异步方法，如果注解在类上，那表明这个类里面的所有方法都是异步的。异步方法必须是public修饰的，而且需要在另一个类中调用才会生效，否则无法实现异步。 Service层： 12345@Asyncpublic CompletableFuture&lt;Long&gt; addOverViewInfo(K8sClusterDTO k8sClusterDTO) throws ApiException &#123; // 添加概览信息 // return CompletableFuture.completedFuture(k8sClusterId);&#125; Controller层： 123456789101112131415161718// result = 查询数据库得到的分页数据List&lt;CompletableFuture&lt;Long&gt;&gt; completableFutureList = new ArrayList&lt;&gt;();// 多线程添加集群概览数据for (K8sClusterDTO k8sClusterDTO : result.getObjectList())&#123; try&#123; CompletableFuture&lt;Long&gt; completableFuture = k8sClusterService.addOverViewInfo(k8sClusterDTO); completableFutureList.add(completableFuture); &#125;catch (Exception e) &#123; e.printStackTrace(); continue; &#125;&#125;CompletableFuture&lt;Long&gt;[] completableFutureArray = new CompletableFuture[completableFutureList.size()];// 合并线程，确保子线程全部执行完CompletableFuture.allOf(completableFutureList.toArray(completableFutureArray)).join();return result; 4.至此，功能完成。查询效率确实有所提高。这算是第一次成功在实际项目中使用多线程，网上查询了很多博客，spring boot中使用多线程是很方便的，但是关键是如何等待所有子线程执行完，像这种直接使用注解来声明一个异步方法，很多网上的方案都行不通，最后看到简书上的一篇文章才有了思路。 使用了异步编程后，接口调用顺序大概是这样的： 查询数据库分页数据返回分页数据给前端第一次调用异步方法第二次调用异步方法…… 所以还没等到数据添加上概览信息，就已经返回了结果，这肯定是行不通的。 使用了CompletableFuture.allOf(…).jion() 方法后，顺序大概就是： 查询数据库分页数据第一次调用异步方法第二次调用异步方法……最后一个异步方法执行完毕返回分页数据给前端 这样才能返回正确的结果 5.CompletableFuture allOf().jion():法实现多实例的同时返回，如果allOf里面的所有线程未执行完毕，主线程会阻塞，直到allOf里面的所有线程都执行，主线程就会被唤醒，继续向下运行。总的来说就是保证了子线程之间的异步，又保证了主线程和子线程的同步。 6.参考资料： Spring Boot 创建及使用多线程。https://blog.csdn.net/asd136912/article/details/87716215 SpringBoot 多线程异步调用-提高程序执行效率。https://www.jianshu.com/p/d919f4372351","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/spring security学习【转】","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/spring security学习【转】/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/spring%20security%E5%AD%A6%E4%B9%A0%E3%80%90%E8%BD%AC%E3%80%91/","excerpt":"","text":"转载自 spring-security-4介绍 虽然现在已经到了5.x版本了，但是大同小异，知识还是不会过时的。。。 前言本教程主要分为个部分： spring security Java配置的搭建 spring security过滤器的创建与注册原理 spring security Java配置搭建中认证与授权的分析 spring security Java配置实现自定义的表单认证与授权 这篇教程主要是用来教会你以下几点： 怎么搭建spring security spring secuirty过滤器的创建与注册原理（工作的基本原理） 简单的认证与授权的原理 在明白如何实现简单的认证与授权的基础上实现自定义的认证与授权 环境说明： 版本：本教程使用的spring security版本是4.2.3.RELEASE，对应的spring版本是4.3.11.RELEASE。 工具：开发工具为eclipse，构建工具为maven 一、什么是spring security?spring security是基于spring开发的为JavaEE企业级应用提供安全服务的框架。安全服务主要是指 认证（Authentication）和 授权（Authorization）。 二、spring security的模块 搭建spring security首先我们要导入必须的jar，即maven的依赖。spring security按模块划分，一个模块对应一个jar。 spring security分为以下九个模块： 1. Core spring-security-core.jar：核心模块。包含核心的认证（authentication）和授权（authorization）的类和接口，远程支持和基础配置API。 2. Remoting spring-security-remoting.jar：提供与spring remoting整合的支持。 3. Web spring-security-web.jar：包含过滤器和相关的网络安全的代码。用于我们进行web安全验证和基于URL的访问控制。 4. Config spring-security-config.jar：包含security namepace的解析代码。 5. LDAP spring-security-ldap.jar：提供LDAP验证和配置的支持。 6. ACL spring-security-acl.jar：提供对特定domain对象的ACL（访问控制列表）实现。用来限定对特定对象的访问 7. CAS sprig-security-cas.jar：提供与spring security CAS客户端集成 8. OpenID spring-security-openid.jar：提供OpenId Web验证支持。基于一个外部OpenId服务器对用户进行验证。 9. Test spring-security-test.jar：提供spring security的测试支持。 一般情况下，Core和Config模块都是需要的，因为我们本教程只是用于Java web应用表单的验证登录，所以这里我们还需要引入Web。 说明：本篇教程的代码已上传github，地址：https://github.com/wutianqi/spring_security_create 三、工程搭建1.项目工程结构 2. 代码展示2.1 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.wuqi&lt;/groupId&gt; &lt;artifactId&gt;spring_security_create&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring_security_create Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;!-- web --&gt; &lt;jsp.version&gt;2.2&lt;/jsp.version&gt; &lt;servlet.version&gt;3.1.0&lt;/servlet.version&gt; &lt;jstl.version&gt;1.2&lt;/jstl.version&gt; &lt;!-- spring 和 spring security --&gt; &lt;spring-security.version&gt;4.2.3.RELEASE&lt;/spring-security.version&gt; &lt;spring-framework.version&gt;4.3.11.RELEASE&lt;/spring-framework.version&gt; &lt;!-- Logging --&gt; &lt;logback.version&gt;1.0.13&lt;/logback.version&gt; &lt;slf4j.version&gt;1.7.5&lt;/slf4j.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-framework.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-framework.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring security --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-config&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 其他一些依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;javax&lt;/groupId&gt; &lt;artifactId&gt;javaee-web-api&lt;/artifactId&gt; &lt;version&gt;7.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;$&#123;servlet.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;$&#123;jstl.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;$&#123;jsp.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt; &lt;artifactId&gt;jackson-dataformat-xml&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 日志 --&gt; &lt;!-- 使用SLF4J和LogBack作为日志 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--logback日志--&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--实现slf4j接口并整合--&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-access&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;spring_security_create&lt;/finalName&gt; &lt;plugins&gt; &lt;!-- 配置maven的内嵌的tomcat，通过内置的tomcat启动 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;uriEncoding&gt;utf8&lt;/uriEncoding&gt; &lt;!-- 配置启动的端口为9090 --&gt; &lt;port&gt;9090&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 该pom文件除了包括了spring security的依赖外，还包括了spring、springmvc、日志的一些依赖，除了spring security的依赖，其他的你没必要太过于纠结。直接拿过来用就可以了。日志我使用了logback，这个你也直接拿过来用就行了，直接将logback.xml放在你的类路径下就可以起作用了。而且这些知识也不是本篇教程所讨论的。 2.2 MyWebConfig 1234567891011121314151617181920212223242526272829package com.wuqi.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.EnableWebMvc;import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;import org.springframework.web.servlet.view.InternalResourceViewResolver;import org.springframework.web.servlet.view.JstlView;/** * MVC配置类 * @author wuqi * @date 2018/06/13 */@EnableWebMvc@Configuration@ComponentScan(&quot;com.wuqi&quot;)public class MyWebConfig extends WebMvcConfigurerAdapter &#123; //配置mvc视图解析器 @Bean public InternalResourceViewResolver viewResolver() &#123; InternalResourceViewResolver viewResolver = new InternalResourceViewResolver(); viewResolver.setPrefix(&quot;/WEB-INF/classes/views/&quot;); viewResolver.setSuffix(&quot;.jsp&quot;); viewResolver.setViewClass(JstlView.class); return viewResolver; &#125; &#125; MyWebConfig是SpringMvc的配置类，这里只配置了视图解析器 2.3 WebInitializer 123456789101112131415161718192021222324252627package com.wuqi.config;import org.springframework.web.servlet.support.AbstractAnnotationConfigDispatcherServletInitializer;/** * 替代web.xml的配置 * @author wuqi * @date 2018/06/13 */public class WebInitializer extends AbstractAnnotationConfigDispatcherServletInitializer &#123; @Override protected Class&lt;?&gt;[] getRootConfigClasses() &#123; return null; &#125; @Override protected Class&lt;?&gt;[] getServletConfigClasses() &#123; return new Class[] &#123;MyWebConfig.class&#125;; &#125; @Override protected String[] getServletMappings() &#123; //将DispatcherServlet映射到 / return new String[] &#123;&quot;/&quot;&#125;; &#125;&#125; WebInitializer相当于在web.xml中注册DispatcherServlet，以及配置Spring Mvc的配置文件 2.4 MySecurityConfig 12345678910111213141516171819202122232425package com.wuqi.config;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;/** * spring security配置类 * @author wuqi * @date 2018/06/13 */@EnableWebSecurity@Configurationpublic class MySecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired public void configUser(AuthenticationManagerBuilder builder) throws Exception &#123; builder .inMemoryAuthentication() //创建用户名为user，密码为password的用户 .withUser(&quot;user&quot;).password(&quot;password&quot;).roles(&quot;USER&quot;); &#125; &#125; MySecurityConfig是spring security的配置类，定制spring security的一些行为就在这里。其中@EnableWebSecurity用于创建过滤器 2.5 SecurityInitializer 1234567891011package com.wuqi.config;import org.springframework.security.web.context.AbstractSecurityWebApplicationInitializer;/** * security初始化类，用户注册过滤器 * @author wuqi * @date 2018/06/13 */public class SecurityInitializer extends AbstractSecurityWebApplicationInitializer &#123;&#125; SecurityInitializer主要就是用于注册spring secuirty的过滤器 2.6 logback.xml 1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;configuration scan=&quot;true&quot; scanPeriod=&quot;1 seconds&quot;&gt; &lt;contextListener class=&quot;ch.qos.logback.classic.jul.LevelChangePropagator&quot;&gt; &lt;resetJUL&gt;true&lt;/resetJUL&gt; &lt;/contextListener&gt; &lt;jmxConfigurator /&gt; &lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;logbak: %d&#123;HH:mm:ss.SSS&#125; %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;logger name=&quot;org.springframework.security.web&quot; level=&quot;DEBUG&quot; /&gt; &lt;logger name=&quot;org.springframework.security&quot; level=&quot;DEBUG&quot; /&gt; &lt;logger name=&quot;org.springframework.security.config&quot; level=&quot;DEBUG&quot; /&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;console&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; 该日志文件就是将web、core、config模块的日志级别调为debug模式。 3. 运行展示3.1 通过maven内置的Tomcat启动项目（不知道的网上看下，有很多资料），访问端口为9090。地址栏访问 http://localhost:9090 由此可以看到当访问我们的项目时，spring security将我们的项目保护了起来，并提供了一个默认的登录页面，让我们去登录。我们在MySecurityConfig中配置了一个用户。用户名为”user”，密码为”password”，输入这个用户名和密码，即可正常访问我们的项目。 3.2 输入用户名和密码 4. 小结到现在为止，我们已经搭建了一个基于spring(spring mvc)的spring security项目。可能你会很疑惑，为什么会产生这种效果。那个输入用户名和密码的页面，我们在项目中也没有创建，是怎么出来的呢？ 其实这一切都是经过我们上述的配置，我们创建并注册了spring security的过滤器。是这些过滤器为我们做到的。除此之外，spring security还为我们做了额外的其他的保护。总的来说，经过我们上述的配置后，spring security为我们的应用提供了以下默认功能： 访问应用中的每个URL都需要进行验证 生成一个登陆表单 允许用户使用username和password来登陆 允许用户注销 CSRF攻击拦截 Session Fixation（session固定攻击） 安全Header集成 7.1 HTTP Strict Transport Security for secure requests 7.2 X-Content-Type-Options integration 7.3 缓存控制 (can be overridden later by your application to allow caching of your static resources) 7.4 X-XSS-Protection integration 7.5 X-Frame-Options integration to help prevent Clickjacking Integrate with the following Servlet API methods 8.1 HttpServletRequest#getRemoteUser() 8.2 HttpServletRequest.html#getUserPrincipal() 8.3 HttpServletRequest.html#isUserInRole(java.lang.String) 8.4 HttpServletRequest.html#login(java.lang.String, java.lang.String) 8.5 HttpServletRequest.html#logout() 下一节，通过spring security过滤器的创建和注册源码的分析，你将会了解这一切！ 四、spring security过滤器的创建与注册原理1. Spring Security过滤器的创建原理让我们首先看下MySecurityConfig类 123456789101112@EnableWebSecurity@Configurationpublic class MySecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired public void configUser(AuthenticationManagerBuilder builder) throws Exception &#123; builder .inMemoryAuthentication() //创建用户名为user，密码为password的用户 .withUser(&quot;user&quot;).password(&quot;password&quot;).roles(&quot;USER&quot;); &#125;&#125; 可以看到MySecurityConfig上的@EnableWebSecurity注解，查看该注解的源码 123456789101112131415@Retention(value = java.lang.annotation.RetentionPolicy.RUNTIME)@Target(value = &#123; java.lang.annotation.ElementType.TYPE &#125;)@Documented@Import(&#123; WebSecurityConfiguration.class, SpringWebMvcImportSelector.class &#125;)@EnableGlobalAuthentication@Configurationpublic @interface EnableWebSecurity &#123; /** * Controls debugging support for Spring Security. Default is false. * @return if true, enables debug support with Spring Security */ boolean debug() default false;&#125; @EnableWebSecurity上的@Import注解引入了两个类WebSecurityConfiguration和SpringWebMvcImportSelector，spring security的过滤器正是由WebSecurityConfiguration创建。让我们看下WebSecurityConfiguration的部分源码 123456789101112131415161718... //查看AbstractSecurityWebApplicationInitializer的源码可以看到 //AbstractSecurityWebApplicationInitializer.DEFAULT_FILTER_NAME = &quot;springSecurityFilterChain&quot; @Bean(name = AbstractSecurityWebApplicationInitializer.DEFAULT_FILTER_NAME) public Filter springSecurityFilterChain() throws Exception &#123; boolean hasConfigurers = webSecurityConfigurers != null &amp;&amp; !webSecurityConfigurers.isEmpty(); //如果没有配置类那么就new一个WebSecurityConfigurerAdapter,也就是说我们没有配置MySecurityConfig或者说其没有被spring扫描到 if (!hasConfigurers) &#123; WebSecurityConfigurerAdapter adapter = objectObjectPostProcessor .postProcess(new WebSecurityConfigurerAdapter() &#123; &#125;); webSecurity.apply(adapter); &#125; //创建Filter return webSecurity.build(); &#125;... 从源码中可以看到通过WebSecurity.build()创建出名字为springSecurityFilterChain的Filter对象。（特别说明一下，一定要保证我们的MySecurityConfig类注解了@Configuration并可以被spring扫描到，如果没有被sping扫描到，那么spring security会认为没有配置类，就会新new 出一个WebSecurityConfigureAdapter对象，这会导致我们配置的用户名和密码失效。）那么该Filter的类型是什么呢？别着急，我们先来看下WeSecurity的继承体系。 build方法定义在AbstractSecurityBuilder中，源码如下： 12345678910...public final O build() throws Exception &#123; if (this.building.compareAndSet(false, true)) &#123; //通过doBuild方法创建 this.object = doBuild(); return this.object; &#125; throw new AlreadyBuiltException(&quot;This object has already been built&quot;);&#125;... doBuild方法定义在AbstractConfiguredSecurityBuilder中，源码如下： 123456789101112131415161718192021222324...protected final O doBuild() throws Exception &#123; synchronized (configurers) &#123; buildState = BuildState.INITIALIZING; beforeInit(); init(); buildState = BuildState.CONFIGURING; beforeConfigure(); configure(); buildState = BuildState.BUILDING; //performBuild方法创建 O result = performBuild(); buildState = BuildState.BUILT; return result; &#125; &#125;... performBuild()方法定义在WebSecurity中，源码如下 1234567891011121314151617181920212223242526272829303132333435363738...protected Filter performBuild() throws Exception &#123; Assert.state( !securityFilterChainBuilders.isEmpty(), &quot;At least one SecurityBuilder&lt;? extends SecurityFilterChain&gt; needs to be specified. Typically this done by adding a @Configuration that extends WebSecurityConfigurerAdapter. More advanced users can invoke &quot; + WebSecurity.class.getSimpleName() + &quot;.addSecurityFilterChainBuilder directly&quot;); int chainSize = ignoredRequests.size() + securityFilterChainBuilders.size(); List&lt;SecurityFilterChain&gt; securityFilterChains = new ArrayList&lt;SecurityFilterChain&gt;( chainSize); for (RequestMatcher ignoredRequest : ignoredRequests) &#123; securityFilterChains.add(new DefaultSecurityFilterChain(ignoredRequest)); &#125; for (SecurityBuilder&lt;? extends SecurityFilterChain&gt; securityFilterChainBuilder : securityFilterChainBuilders) &#123; securityFilterChains.add(securityFilterChainBuilder.build()); &#125; //创建FilterChainProxy FilterChainProxy filterChainProxy = new FilterChainProxy(securityFilterChains); if (httpFirewall != null) &#123; filterChainProxy.setFirewall(httpFirewall); &#125; filterChainProxy.afterPropertiesSet(); Filter result = filterChainProxy; if (debugEnabled) &#123; logger.warn(&quot;\\n\\n&quot; + &quot;********************************************************************\\n&quot; + &quot;********** Security debugging is enabled. *************\\n&quot; + &quot;********** This may include sensitive information. *************\\n&quot; + &quot;********** Do not use in a production system! *************\\n&quot; + &quot;********************************************************************\\n\\n&quot;); result = new DebugFilter(filterChainProxy); &#125; postBuildAction.run(); return result;&#125;... 不关心其具体实现，我们从源码中看到spring security创建的过滤器类型为FilterChainProxy。由此完成过滤器的创建。 2. Spring Security过滤器的注册原理看下我们创建的SecurityInitializer类： 123public class SecurityInitializer extends AbstractSecurityWebApplicationInitializer &#123;&#125; 这段代码虽然很简单，但却是注册过滤器所必须的。 根据Servlet3.0中，提供了ServletContainerInitializer接口，该接口提供了一个onStartup方法，用于在容器启动时动态注册Servlet,Filter,Listener等。因为我们建立的是web项目，那我们的依赖中肯定是由spring-web依赖的 根据Servlet 3.0规范，Servlet容器在启动时，会负责创建图中红色箭头所指的类，即SpringServletContainerInitializer，该类是ServletContainerInitializer的实现类。那么该类必有onStartup方法。让我们看下它的源码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package org.springframework.web;import java.lang.reflect.Modifier;import java.util.LinkedList;import java.util.List;import java.util.ServiceLoader;import java.util.Set;import javax.servlet.ServletContainerInitializer;import javax.servlet.ServletContext;import javax.servlet.ServletException;import javax.servlet.annotation.HandlesTypes;import org.springframework.core.annotation.AnnotationAwareOrderComparator;@HandlesTypes(WebApplicationInitializer.class)public class SpringServletContainerInitializer implements ServletContainerInitializer &#123; @Override public void onStartup(Set&lt;Class&lt;?&gt;&gt; webAppInitializerClasses, ServletContext servletContext) throws ServletException &#123; List&lt;WebApplicationInitializer&gt; initializers = new LinkedList&lt;WebApplicationInitializer&gt;(); if (webAppInitializerClasses != null) &#123; for (Class&lt;?&gt; waiClass : webAppInitializerClasses) &#123; //如果waiClass不为接口，抽象类，并且属于WebApplicationInitializer类型 //那么通过反射构造该接口的实例。 if (!waiClass.isInterface() &amp;&amp; !Modifier.isAbstract(waiClass.getModifiers()) &amp;&amp; WebApplicationInitializer.class.isAssignableFrom(waiClass)) &#123; try &#123; initializers.add((WebApplicationInitializer) waiClass.newInstance()); &#125; catch (Throwable ex) &#123; throw new ServletException(&quot;Failed to instantiate WebApplicationInitializer class&quot;, ex); &#125; &#125; &#125; &#125; if (initializers.isEmpty()) &#123; servletContext.log(&quot;No Spring WebApplicationInitializer types detected on classpath&quot;); return; &#125; AnnotationAwareOrderComparator.sort(initializers); servletContext.log(&quot;Spring WebApplicationInitializers detected on classpath: &quot; + initializers); for (WebApplicationInitializer initializer : initializers) &#123; //调用所有WebApplicationInitializer实例的onStartup方法 initializer.onStartup(servletContext); &#125; &#125;&#125; 请注意该类上的@HandlesTypes(WebApplicationInitializer.class)注解，根据Sevlet3.0规范，Servlet容器要负责以Set集合的方式注入指定类的子类（包括接口，抽象类）。其中AbstractSecurityWebApplicationInitializer是WebApplicationInitializer的抽象子类，我我们看下它的onStartup方法 123456789101112131415161718...public final void onStartup(ServletContext servletContext) throws ServletException &#123; beforeSpringSecurityFilterChain(servletContext); if (this.configurationClasses != null) &#123; AnnotationConfigWebApplicationContext rootAppContext = new AnnotationConfigWebApplicationContext(); rootAppContext.register(this.configurationClasses); servletContext.addListener(new ContextLoaderListener(rootAppContext)); &#125; if (enableHttpSessionEventPublisher()) &#123; servletContext.addListener( &quot;org.springframework.security.web.session.HttpSessionEventPublisher&quot;); &#125; servletContext.setSessionTrackingModes(getSessionTrackingModes()); //注册过滤器 insertSpringSecurityFilterChain(servletContext); afterSpringSecurityFilterChain(servletContext);&#125;... 该类中的insertSpringSecurityFilterChain(servletContext)就是在注册过滤器。因为在过滤器创建中所说的springSecurityFilterChain，它其实是spring中的bean，而servletContext也必定可以获取到该bean。我们接着看insertSpringSecurityFilterChain的源码 1234567891011121314151617...public static final String DEFAULT_FILTER_NAME = &quot;springSecurityFilterChain&quot;;private void insertSpringSecurityFilterChain(ServletContext servletContext) &#123; String filterName = DEFAULT_FILTER_NAME; //通过DelegatingFilterProxy代理 DelegatingFilterProxy springSecurityFilterChain = new DelegatingFilterProxy( filterName); String contextAttribute = getWebApplicationContextAttribute(); if (contextAttribute != null) &#123; springSecurityFilterChain.setContextAttribute(contextAttribute); &#125; //完成过滤器的注册 registerFilter(servletContext, true, filterName, springSecurityFilterChain);&#125;... 一开始我们就提到了调用过滤器链springSecurityFilterChain需要DelegatingFilterProxy进行代理，将其与web.xml联系起来。这段代码就是很好的证明。DelegatingFilterProxy中维护了一个类型为String，名字叫做targetBeanName的字段，targetBeanName就是DelegatingFilterProxy所代理的类的名称。最后通过registerFilter最终完成过滤器的注册。 五、spring security 认证和授权原理在上一节我们讨论了spring security过滤器的创建和注册原理。请记住springSecurityFilterChain（类型为FilterChainProxy）是实际起作用的过滤器链，DelegatingFilterProxy起到代理作用。 但是这还没有解决我们最初的所有问题，那就是虽然创建了springSecurityFilterChain过滤器链，那么过滤器链中的过滤器是如何一一创建的？这些过滤器是如何实现认证和授权的？本节我们来讨论这个问题。 注意：本节代码示例，采用的依然第二节中基于Java配置的搭建中的代码为例。 1. 过滤器的创建我们创建的MySecurityConfig继承了WebSecurityConfigurerAdapter。WebSecurityConfigurerAdapter中有个configure(HttpSecurity http)的方法： 12345678protected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() //拦截请求，创建FilterSecurityInterceptor .anyRequest().authenticated() //在创建过滤器的基础上的一些自定义配置 .and() //用and来表示配置过滤器结束，以便进行下一个过滤器的创建和配置 .formLogin().and() //设置表单登录，创建UsernamePasswordAuthenticationFilter .httpBasic(); //basic验证，创建BasicAuthenticationFilter&#125; 该方法用来实现spring security的一些自定义的配置，其中就包括Filter的创建。其中http.authorizeRequests()、http.formLogin()、http.httpBasic()分别创建了ExpressionUrlAuthorizationConfigurer，FormLoginConfigurer，HttpBasicConfigurer。在三个类从父级一直往上找，会发现它们都是SecurityConfigurer的子类。SecurityConfigurer中又有configure方法。该方法被子类实现就用于创建各个过滤器，并将过滤器添加进HttpSecurity中维护的装有Filter的List中，比如HttpBasicConfigurer中的configure方法，源码如下： 123456789101112131415161718public void configure(B http) throws Exception &#123; AuthenticationManager authenticationManager = http .getSharedObject(AuthenticationManager.class); //创建BasicAuthenticationFilter过滤器 BasicAuthenticationFilter basicAuthenticationFilter = new BasicAuthenticationFilter( authenticationManager, this.authenticationEntryPoint); if (this.authenticationDetailsSource != null) &#123; basicAuthenticationFilter .setAuthenticationDetailsSource(this.authenticationDetailsSource); &#125; RememberMeServices rememberMeServices = http.getSharedObject(RememberMeServices.class); if(rememberMeServices != null) &#123; basicAuthenticationFilter.setRememberMeServices(rememberMeServices); &#125; basicAuthenticationFilter = postProcess(basicAuthenticationFilter); //添加过滤器 http.addFilter(basicAuthenticationFilter);&#125; 另外，并非所有的过滤器都是在configure中进行创建的，比如UsernamePasswordAuthenticationFilter是在调用FormLoginConfigurer的构造方法时创建的。FormLoginConfigurer部分源码如下： 12345public FormLoginConfigurer() &#123; super(new UsernamePasswordAuthenticationFilter(), null); usernameParameter(&quot;username&quot;); passwordParameter(&quot;password&quot;);&#125; HttpSecurity的父类是AbstractConfiguredSecurityBuilder，该类中有个configure方法用来获取所有SecurityConfigurer，并调用所有SecurityConfigurer的configure方法。源码如下： 123456789private void configure() throws Exception &#123; //获取所有SecurityConfigurer类 Collection&lt;SecurityConfigurer&lt;O, B&gt;&gt; configurers = getConfigurers(); for (SecurityConfigurer&lt;O, B&gt; configurer : configurers) &#123; //调用所有SecurityConfigurer的configure方法 configurer.configure((B) this); &#125;&#125; 以上就是过滤器的创建过程。当我们的MySecurityConfig继承了WebSecurityConfigurerAdapter以后，就默认有了configure(HttpSecurity http)方法。我们也可以在MySecurityConfig中重写此方法来进行更灵活的配置。 12345678910111213141516171819202122@Override protected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() //注册FilterSecurityInterceptor .antMatchers(&quot;/index.html&quot;).permitAll()//访问index.html不要权限验证 .anyRequest().authenticated()//其他所有路径都需要权限校验 .and() .csrf().disable()//默认开启，可以显示关闭 .formLogin() //内部注册 UsernamePasswordAuthenticationFilter .loginPage(&quot;/login.html&quot;) //表单登录页面地址 .loginProcessingUrl(&quot;/login&quot;)//form表单POST请求url提交地址，默认为/login .passwordParameter(&quot;password&quot;)//form表单用户名参数名 .usernameParameter(&quot;username&quot;) //form表单密码参数名 .successForwardUrl(&quot;/success.html&quot;) //登录成功跳转地址 .failureForwardUrl(&quot;/error.html&quot;) //登录失败跳转地址 //.defaultSuccessUrl()//如果用户没有访问受保护的页面，默认跳转到页面 //.failureUrl() //.failureHandler(AuthenticationFailureHandler) //.successHandler(AuthenticationSuccessHandler) //.failureUrl(&quot;/login?error&quot;) .permitAll();//允许所有用户都有权限访问loginPage，loginProcessingUrl，failureForwardUrl &#125; 虽然我们上面仅仅看到了三种过滤器的创建，但是真正创建的远不止三种，spring secuirty会默认帮我们注册一些过滤器。比如SecurityContextPersistenceFilter，该过滤器用于在我们请求到来时，将SecurityContext从Session中取出放入SecuirtyContextHolder中供我们使用。并在请求结束时将SecuirtyContext存进Session中便于下次使用。还有DefaultLoginPageGeneratingFilter，该过滤器在我们没有自定义配置loginPage时会自动生成，用于生成我们默认的登录页面，也就是我们一开始在搭建中看到的登录页面。对于自定义配置spring security详细参考javaDoc。spring secuirty核心过滤器以及其顺序如下（并未包括所有）： 2. 认证与授权 认证(Authentication)：确定一个用户的身份的过程。授权(Authorization)：判断一个用户是否有访问某个安全对象的权限。下面讨论一下spring security中最基本的认证与授权。 首先明确一下在认证与授权中关键的三个过滤器，其他过滤器不讨论： 1. UsernamePasswordAuthenticationFilter：该过滤器用于拦截我们表单提交的请求（默认为/login），进行用户的认证过程吧。 2. ExceptionTranslationFilter：该过滤器主要用来捕获处理spring security抛出的异常，异常主要来源于FilterSecurityInterceptor。 3. FilterSecurityInterceptor：该过滤器主要用来进行授权判断。 下面根据我们访问应用的顺序并结合源码分析一下spring security的认证与授权。代码仍然是前面基于Java配置的搭建中的 我们在浏览器中输入http://localhost:9090/ 访问应用，因为我们的路径被spring secuirty保护起来了，我们是没有权限访问的，所以我们会被引导至登录页面进行登录。 此路径因为不是表单提交的路径(&#x2F;login)，该过程主要起作用的过滤器为FilterSecurityInterceptor。其部分源码如下： 1234567891011121314151617181920212223242526272829303132333435363738... public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; FilterInvocation fi = new FilterInvocation(request, response, chain); invoke(fi); &#125; public void invoke(FilterInvocation fi) throws IOException, ServletException &#123; //过滤器对每个请求只处理一次 if ((fi.getRequest() != null) &amp;&amp; (fi.getRequest().getAttribute(FILTER_APPLIED) != null) &amp;&amp; observeOncePerRequest) &#123; // filter already applied to this request and user wants us to observe // once-per-request handling, so don&#x27;t re-do security checking fi.getChain().doFilter(fi.getRequest(), fi.getResponse()); &#125; else &#123; // first time this request being called, so perform security checking if (fi.getRequest() != null) &#123; fi.getRequest().setAttribute(FILTER_APPLIED, Boolean.TRUE); &#125; //前处理 InterceptorStatusToken token = super.beforeInvocation(fi); try &#123; fi.getChain().doFilter(fi.getRequest(), fi.getResponse()); &#125; finally &#123; //使SecurityContextHolder中的Authentication保持原样，因为RunAsManager会暂时改变 //其中的Authentication super.finallyInvocation(token); &#125; //调用后的处理 super.afterInvocation(token, null); &#125; &#125;... 真正进行权限判断的为beforeInvocation，该方法定义在FilterSecurityInterceptor的父类AbstractSecurityInterceptor中，源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114... protected InterceptorStatusToken beforeInvocation(Object object) &#123; Assert.notNull(object, &quot;Object was null&quot;); final boolean debug = logger.isDebugEnabled(); //判断object是否为过滤器支持的类型，在这里是FilterInvocation(里面记录包含了请求的request,response,FilterChain) //这里可以把FilterInvocation看做是安全对象，因为通过它可以获得request,通过request可以获得请求的URI。 //而实际的安全对象就是URI if (!getSecureObjectClass().isAssignableFrom(object.getClass())) &#123; throw new IllegalArgumentException( &quot;Security invocation attempted for object &quot; + object.getClass().getName() + &quot; but AbstractSecurityInterceptor only configured to support secure objects of type: &quot; + getSecureObjectClass()); &#125; //获取安全对象所对应的ConfigAttribute，ConfigAtrribute实际就是访问安全所应该有的权限集。 Collection&lt;ConfigAttribute&gt; attributes = this.obtainSecurityMetadataSource() .getAttributes(object); //判断安全对象是否拥有权限集，没有的话说明所访问的安全对象是一个公共对象，就是任何人都可以访问的。 if (attributes == null || attributes.isEmpty()) &#123; //如果rejectPublicInvocations为true,说明不支持公共对象的访问，此时会抛出异常。 if (rejectPublicInvocations) &#123; throw new IllegalArgumentException( &quot;Secure object invocation &quot; + object + &quot; was denied as public invocations are not allowed via this interceptor. &quot; + &quot;This indicates a configuration error because the &quot; + &quot;rejectPublicInvocations property is set to &#x27;true&#x27;&quot;); &#125; if (debug) &#123; logger.debug(&quot;Public object - authentication not attempted&quot;); &#125; publishEvent(new PublicInvocationEvent(object)); return null; // no further work post-invocation &#125; if (debug) &#123; logger.debug(&quot;Secure object: &quot; + object + &quot;; Attributes: &quot; + attributes); &#125; //判断SecurityCntext中是否存在Authentication,不存在则说明访问着根本没登录 //调用下面的credentialsNotFound()方法则会抛出一个AuthenticationException， //该异常会被ExceptionTranslationFilter捕获，并做出处理。 //不过默认情况下Authentication不会为null,因为AnonymouseFilter会默认注册到 //过滤链中，如果用户没登录的话，会将其当做匿名用户(Anonymouse User)来对待。 //除非你自己将AnonymouseFilter从过滤链中去掉。 if (SecurityContextHolder.getContext().getAuthentication() == null) &#123; credentialsNotFound(messages.getMessage( &quot;AbstractSecurityInterceptor.authenticationNotFound&quot;, &quot;An Authentication object was not found in the SecurityContext&quot;), object, attributes); &#125; //Autentication存在，则说明用户已经被认证（但是不表示已登录，因为匿名用户也是相当于被认证的）， //判断用户是否需要再次被认证，如果你配置了每次访问必须重新验证，那么就会再次调用AuthenticationManager //的authenticate方法进行验证。 Authentication authenticated = authenticateIfRequired(); // Attempt authorization try &#123; //判断用户是否有访问被保护对象的权限。 //ed。默认的AccessDesicisonManager的实现类是AffirmativeBased //AffirmativeBased采取投票的形式判断用户是否有访问安全对象的权限 //票就是配置的Role。AffirmativeBased采用WebExpressionVoter进行投票 this.accessDecisionManager.decide(authenticated, object, attributes); &#125; catch (AccessDeniedException accessDeniedException) &#123; publishEvent(new AuthorizationFailureEvent(object, attributes, authenticated, accessDeniedException)); throw accessDeniedException; &#125; if (debug) &#123; logger.debug(&quot;Authorization successful&quot;); &#125; if (publishAuthorizationSuccess) &#123; publishEvent(new AuthorizedEvent(object, attributes, authenticated)); &#125; // Attempt to run as a different user Authentication runAs = this.runAsManager.buildRunAs(authenticated, object, attributes); if (runAs == null) &#123; if (debug) &#123; logger.debug(&quot;RunAsManager did not change Authentication object&quot;); &#125; // no further work post-invocation return new InterceptorStatusToken(SecurityContextHolder.getContext(), false, attributes, object); &#125; else &#123; if (debug) &#123; logger.debug(&quot;Switching to RunAs Authentication: &quot; + runAs); &#125; SecurityContext origCtx = SecurityContextHolder.getContext(); SecurityContextHolder.setContext(SecurityContextHolder.createEmptyContext()); SecurityContextHolder.getContext().setAuthentication(runAs); // need to revert to token.Authenticated post-invocation return new InterceptorStatusToken(origCtx, true, attributes, object); &#125; &#125;... 看这段代码，请明确几点: beforeInvocation(Object object)中的object为安全对象，类型为FilterInvocation。安全对象就是受spring security保护的对象。虽然按道理来说安全对象应该是我们访问的url，但是FilterInvocation中封装了request，那么url也可以获取到。 Collection attributes &#x3D; this.obtainSecurityMetadataSource().getAttributes(object) 每个安全对象都会有对应的访问权限集(Collection)，而且在容器启动后所有安全对象的所有权限集就已经被获取到并被放在安全元数据中（SecurityMetadataSource中），通过安全元数据可以获取到各个安全对象的权限集。因为我们每个安全对象都是登录才可以访问的（anyRequest().authenticated()），这里我们只需要知道此时每个对象的权限集只有一个元素，并且是authenticated。如果一个对象没有权限集，说明它是一个公共对象，不受spring security保护。 当我们没有登录时，我们会被当做匿名用户（Anonymouse）来看待。被当做匿名用户对待是AnonymouseAuthenticationFilter来拦截封装成一个Authentication对象，当用户被认证后就会被封装成一个Authentication对象。Authentication对象中封装了用户基本信息，该对象会在认证中做详细介绍。AnonymouseAuthenticationFilter也是默认被注册的。 最中进行授权判断的是AccessDecisionManager的子类AffirmativeBased的decide方法。我在来看其decide的源码： 12345678910111213141516171819202122232425262728293031323334353637...public void decide(Authentication authentication, Object object, Collection&lt;ConfigAttribute&gt; configAttributes) throws AccessDeniedException &#123; int deny = 0; for (AccessDecisionVoter voter : getDecisionVoters()) &#123; //根据用户的authenticton和权限集得出能否访问的结果 int result = voter.vote(authentication, object, configAttributes); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Voter: &quot; + voter + &quot;, returned: &quot; + result); &#125; switch (result) &#123; case AccessDecisionVoter.ACCESS_GRANTED: return; case AccessDecisionVoter.ACCESS_DENIED: deny++; break; default: break; &#125; &#125; if (deny &gt; 0) &#123; //如果deny&gt;0说明没有足够的权限去访问安全对象，此时抛出的 //AccessDeniedException会被ExceptionTranslationFilter捕获处理。 throw new AccessDeniedException(messages.getMessage( &quot;AbstractAccessDecisionManager.accessDenied&quot;, &quot;Access is denied&quot;)); &#125; // To get this far, every AccessDecisionVoter abstained checkAllowIfAllAbstainDecisions();&#125;... 因为我们首次登录，所以会抛出AccessDeniedexception。此异常会被ExceptionTranslationFilter捕获并进行处理的。其部分源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182...public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; try &#123; chain.doFilter(request, response); logger.debug(&quot;Chain processed normally&quot;); &#125; catch (IOException ex) &#123; throw ex; &#125; catch (Exception ex) &#123; // Try to extract a SpringSecurityException from the stacktrace Throwable[] causeChain = throwableAnalyzer.determineCauseChain(ex); RuntimeException ase = (AuthenticationException) throwableAnalyzer .getFirstThrowableOfType(AuthenticationException.class, causeChain); if (ase == null) &#123; ase = (AccessDeniedException) throwableAnalyzer.getFirstThrowableOfType( AccessDeniedException.class, causeChain); &#125; if (ase != null) &#123; //真正处理异常的地方 handleSpringSecurityException(request, response, chain, ase); &#125; else &#123; // Rethrow ServletExceptions and RuntimeExceptions as-is if (ex instanceof ServletException) &#123; throw (ServletException) ex; &#125; else if (ex instanceof RuntimeException) &#123; throw (RuntimeException) ex; &#125; // Wrap other Exceptions. This shouldn&#x27;t actually happen // as we&#x27;ve already covered all the possibilities for doFilter throw new RuntimeException(ex); &#125; &#125;&#125;private void handleSpringSecurityException(HttpServletRequest request, HttpServletResponse response, FilterChain chain, RuntimeException exception) throws IOException, ServletException &#123; if (exception instanceof AuthenticationException) &#123; logger.debug( &quot;Authentication exception occurred; redirecting to authentication entry point&quot;, exception); //未被认证，引导去登录 sendStartAuthentication(request, response, chain, (AuthenticationException) exception); &#125; else if (exception instanceof AccessDeniedException) &#123; Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (authenticationTrustResolver.isAnonymous(authentication) || authenticationTrustResolver.isRememberMe(authentication)) &#123; logger.debug( &quot;Access is denied (user is &quot; + (authenticationTrustResolver.isAnonymous(authentication) ? &quot;anonymous&quot; : &quot;not fully authenticated&quot;) + &quot;); redirecting to authentication entry point&quot;, exception); //如果为匿名用户说明未登录，引导去登录 sendStartAuthentication( request, response, chain, new InsufficientAuthenticationException( &quot;Full authentication is required to access this resource&quot;)); &#125; else &#123; logger.debug( &quot;Access is denied (user is not anonymous); delegating to AccessDeniedHandler&quot;, exception); //用户已登录，但是没有足够权限去访问安全对象，说明权限不足。进行 //权限不足的提醒 accessDeniedHandler.handle(request, response, (AccessDeniedException) exception); &#125; &#125;&#125;... 因为我们是以匿名用户的身份进行登录的，所以，会被引导去登录页面。登录页面的创建是由默认注册的过滤器DefaultLoginPageGeneratingFilter产生的。具体怎么产生的这里不做分析。我们只需要是谁做的就可以了。实际在使用时我们也不大可能去用默认生成的登录页面，因为太丑了。。。 2、在被引导至登录页面后，我们将输入用户名和密码，提交至应用。应用会校验用户名和密码，校验成功后，我们成功访问应用。 此时访问的路径为&#x2F;login，这是UsernamePasswordAuthenticationFilter将拦截请求进行认证。UsernamePasswordAuthenticationFilter的doFilter方法定义在其父类AbstractAuthenticationProcessingFilter中，源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; //判断请求是否需要进行验证处理。默认对/login并且是POST请求的路径进行拦截 if (!requiresAuthentication(request, response)) &#123; chain.doFilter(request, response); return; &#125; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Request is to process authentication&quot;); &#125; Authentication authResult; try &#123; //调用UsernamePasswordAuthenticationFilter的attemptAuthentication方法进行验证，并返回 //完整的被填充的Authentication对象 authResult = attemptAuthentication(request, response); if (authResult == null) &#123; // return immediately as subclass has indicated that it hasn&#x27;t completed // authentication return; &#125; //进行session固定攻击的处理 sessionStrategy.onAuthentication(authResult, request, response); &#125; catch (InternalAuthenticationServiceException failed) &#123; logger.error( &quot;An internal error occurred while trying to authenticate the user.&quot;, failed); unsuccessfulAuthentication(request, response, failed); return; &#125; catch (AuthenticationException failed) &#123; // 认证失败后的处理 unsuccessfulAuthentication(request, response, failed); return; &#125; // Authentication success if (continueChainBeforeSuccessfulAuthentication) &#123; chain.doFilter(request, response); &#125; //认证成功后的处理 successfulAuthentication(request, response, chain, authResult); &#125; 实际认证发生在UsernamePasswordAuthenticationFilter的attemptAuthentication中，如果认证失败，则会调用unsuccessfulAuthentication进行失败后的处理，一般是提示用户认证失败，要求重新输入用户名和密码，如果认证成功，那么会调用successfulAuthentication进行成功后的处理，一般是将Authentication存进SecurityContext中并跳转至之前访问的页面或者默认页面（这部分在读者读完本节后自行去看源码是怎么处理的，这里不做讨论，现在只需知道会跳到一开始我们访问的页面中）。下面我们来看认证即attemptAuthentication的源码： 123456789101112131415161718192021222324252627282930313233...public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException &#123; if (postOnly &amp;&amp; !request.getMethod().equals(&quot;POST&quot;)) &#123; throw new AuthenticationServiceException( &quot;Authentication method not supported: &quot; + request.getMethod()); &#125; String username = obtainUsername(request); String password = obtainPassword(request); if (username == null) &#123; username = &quot;&quot;; &#125; if (password == null) &#123; password = &quot;&quot;; &#125; username = username.trim(); //将用户名和密码封装在Authentication的实现UsernamePasswordAuthenticationToken //以便于AuthentictionManager进行认证 UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken( username, password); // Allow subclasses to set the &quot;details&quot; property setDetails(request, authRequest); //获得AuthenticationManager进行认证 return this.getAuthenticationManager().authenticate(authRequest);&#125;... spring security在进行认证时，会将用户名和密码封装成一个Authentication对象，在进行认证后，会将Authentication的权限等信息填充完全返回。Authentication会被存在SecurityContext中，供应用之后的授权等操作使用。此处介绍下Authentication，Authentication存储的就是访问应用的用户的一些信息。下面是Authentication源码： 12345678910111213141516171819public interface Authentication extends Principal, Serializable &#123; //用户的权限集合 Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); //用户登录的凭证，一般指的就是密码 Object getCredentials(); //用户的一些额外的详细信息，一般不用 Object getDetails(); //这里认为Principal就为登录的用户 Object getPrincipal(); //是否已经被认证了 boolean isAuthenticated(); //设置认证的状态 void setAuthenticated(boolean isAuthenticated) throws IllegalArgumentException;&#125; 讲解了Authentication后，我们回过头来再看attemptAuthentication方法，该方法会调用AuthenticationManager的authenticate方法进行认证并返回一个填充完整的Authentication对象。 在这里我们又要讲解一下认证的几个核心的类，很重要！ a). AuthenticationManager b).ProviderManager c).AuthenticationProvider d).UserDetailsService e).UserDetails 现在来说一下这几个类的作用以及关联关系。 a). AuthenticationManager是一个接口，提供了authenticate方法用于认证。 b). AuthenticationManager有一个默认的实现ProviderManager，其实现了authenticate方法。 c). ProviderManager内部维护了一个存有AuthenticationProvider的集合，ProviderManager实现的authenticate方法再调用这些AuthenticationProvider的authenticate方法去认证，表单提交默认用的AuthenticationProvider实现是DaoAuthenticationProvider。 d). AuthenticationProvider中维护了UserDetailsService，我们使用内存中的用户，默认的实现是InMemoryUserDetailsManager。UserDetailsService用来查询用户的详细信息，该详细信息就是UserDetails。UserDetails的默认实现是User。查询出来UserDetails后再对用户输入的密码进行校验。校验成功则将UserDetails中的信息填充进Authentication中返回。校验失败则提醒用户密码错误。 以上说的这些接口的实现类是由我们在MySecurityConfig中配置时生成的，即下面的代码: 1234567@Autowired public void configUser(AuthenticationManagerBuilder builder) throws Exception &#123; builder .inMemoryAuthentication() //创建用户名为user，密码为password的用户 .withUser(&quot;user&quot;).password(&quot;password&quot;).roles(&quot;USER&quot;); &#125; 这里不再讨论具体是怎么生成的，记住即可。因为我们实际在项目中一般都会用自定义的这些核心认证类。 下面我们来分析源码，先来看ProviderManager的authenticate方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788...public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; Class&lt;? extends Authentication&gt; toTest = authentication.getClass(); AuthenticationException lastException = null; Authentication result = null; boolean debug = logger.isDebugEnabled(); //获取所有AuthenticationProvider，循环进行认证 for (AuthenticationProvider provider : getProviders()) &#123; if (!provider.supports(toTest)) &#123; continue; &#125; if (debug) &#123; logger.debug(&quot;Authentication attempt using &quot; + provider.getClass().getName()); &#125; try &#123; //对authentication进行认证 result = provider.authenticate(authentication); if (result != null) &#123; //填充成完整的Authentication copyDetails(authentication, result); break; &#125; &#125; catch (AccountStatusException e) &#123; prepareException(e, authentication); // SEC-546: Avoid polling additional providers if auth failure is due to // invalid account status throw e; &#125; catch (InternalAuthenticationServiceException e) &#123; prepareException(e, authentication); throw e; &#125; catch (AuthenticationException e) &#123; lastException = e; &#125; &#125; if (result == null &amp;&amp; parent != null) &#123; // Allow the parent to try. try &#123; result = parent.authenticate(authentication); &#125; catch (ProviderNotFoundException e) &#123; // ignore as we will throw below if no other exception occurred prior to // calling parent and the parent // may throw ProviderNotFound even though a provider in the child already // handled the request &#125; catch (AuthenticationException e) &#123; lastException = e; &#125; &#125; if (result != null) &#123; if (eraseCredentialsAfterAuthentication &amp;&amp; (result instanceof CredentialsContainer)) &#123; // Authentication is complete. Remove credentials and other secret data // from authentication ((CredentialsContainer) result).eraseCredentials(); &#125; eventPublisher.publishAuthenticationSuccess(result); return result; &#125; // Parent was null, or didn&#x27;t authenticate (or throw an exception). if (lastException == null) &#123; //如果所有的AuthenticationProvider进行认证完result仍然为null //此时表示为提供AuthenticationProvider，抛出ProviderNotFoundException异常 lastException = new ProviderNotFoundException(messages.getMessage( &quot;ProviderManager.providerNotFound&quot;, new Object[] &#123; toTest.getName() &#125;, &quot;No AuthenticationProvider found for &#123;0&#125;&quot;)); &#125; prepareException(lastException, authentication); throw lastException;&#125;... ProviderManager用AuthenticationProvider对authentication进行认证。如果没有提供AuthenticationProvider，那么最终将抛出ProviderNotFoundException。 我们表单提交认证时，AuthenticationProvider默认的实现是DaoAuthenticationProvider，DaoAuthenticationProvider的authenticate方法定义在其父类AbstractUserDetailsAuthenticationProvider中，其源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879...public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; Assert.isInstanceOf(UsernamePasswordAuthenticationToken.class, authentication, messages.getMessage( &quot;AbstractUserDetailsAuthenticationProvider.onlySupports&quot;, &quot;Only UsernamePasswordAuthenticationToken is supported&quot;)); // Determine username String username = (authentication.getPrincipal() == null) ? &quot;NONE_PROVIDED&quot; : authentication.getName(); boolean cacheWasUsed = true; UserDetails user = this.userCache.getUserFromCache(username); if (user == null) &#123; cacheWasUsed = false; try &#123; //获取UserDetails，即用户详细信息 user = retrieveUser(username, (UsernamePasswordAuthenticationToken) authentication); &#125; catch (UsernameNotFoundException notFound) &#123; logger.debug(&quot;User &#x27;&quot; + username + &quot;&#x27; not found&quot;); if (hideUserNotFoundExceptions) &#123; throw new BadCredentialsException(messages.getMessage( &quot;AbstractUserDetailsAuthenticationProvider.badCredentials&quot;, &quot;Bad credentials&quot;)); &#125; else &#123; throw notFound; &#125; &#125; Assert.notNull(user, &quot;retrieveUser returned null - a violation of the interface contract&quot;); &#125; try &#123; preAuthenticationChecks.check(user); //进行密码校验 additionalAuthenticationChecks(user, (UsernamePasswordAuthenticationToken) authentication); &#125; catch (AuthenticationException exception) &#123; if (cacheWasUsed) &#123; // There was a problem, so try again after checking // we&#x27;re using latest data (i.e. not from the cache) cacheWasUsed = false; user = retrieveUser(username, (UsernamePasswordAuthenticationToken) authentication); preAuthenticationChecks.check(user); additionalAuthenticationChecks(user, (UsernamePasswordAuthenticationToken) authentication); &#125; else &#123; //认证失败抛出认证异常 throw exception; &#125; &#125; postAuthenticationChecks.check(user); if (!cacheWasUsed) &#123; this.userCache.putUserInCache(user); &#125; Object principalToReturn = user; if (forcePrincipalAsString) &#123; principalToReturn = user.getUsername(); &#125; //认证成功，返回装有用户权限等信息的authentication对象 return createSuccessAuthentication(principalToReturn, authentication, user);&#125;... retrieveUser方法定义在DaoAuthenticationProvider中，用来获取UserDetails这里不再展示源码，请读者自行去看。你会发现获取获取UserDetails正是由其中维护的UserDetailsService来完成的。获取到UserDetails后再调用其 additionalAuthenticationChecks方法进行密码的验证。如果认证失败，则抛出AuthenticationException，如果认证成功则返回装有权限等信息的Authentication对象。 3、小节到目前为止，我们结合我们创建的项目和spring security的源码分析了web应用认证和授权的原理。内容比较多，现在理一下重点。 springSecurityFilterChain中各个过滤器怎么创建的只需了解即可。不要太过关注。 重点记忆UsernamePasswordAuthenticationFilter，ExceptionTranslationFilter，FilterSecurityInterceptor这三个过滤器的作用及源码分析。 重要记忆认证中Authentication，AuthenticationManager，ProviderManager，AuthenticationProvider，UserDetailsService，UserDetails这些类的作用及源码分析。 重点记忆授权中FilterInvoction，SecurityMetadataSource，AccessDecisionManager的作用。 将这些类理解的关键是建立起关联，建立起关联的方式就是跟着本节中的案例走下去，一步步看代码如何实现的。 六、spring security Java配置实现自定义表单认证与授权前面三节讲解了spring security的搭建以及简单的表单认证与授权原理。本篇将实现我们自定义的表单登录与认证。 本篇不会再讲项目的搭建过程，因为跟第二节的搭建如出一辙。本篇也不会将项目中所有的代码全部给出，因为代码量有点大。项目的代码被放在了github上，请拉下来根据讲解去看代码，代码的注释写的也比较详细。github地址https://github.com/wutianqi/spring_security_extend.git。另外，因为项目中使用了mysql数据库，对于表结构和数据这里截图会很明白的给出。 1. 项目结构及表结构1.1 项目结构 1.2 表结构 创建名称为spring_security的数据库，创建三张表：user、role、user_role 用户表（user）： id user_name password 1 admin admin 2 test test 角色表（role）： id role_name 1 user 2 admin 用户角色表（user_role）： id user_id role_id 1 1 1 2 2 2 2. 项目功能在讲解代码之前还是要介绍一下本项目利用spring security实现的功能，便于读者分析代码。 2.1 本项目围绕着admin.jsp，user.jsp，other.jsp展开。 admin.jsp只有admin角色的用户才可以访问，ls拥有admin角色。 user.jsp有user角色或admin角色都可以访问，zs拥有user角色。 other.jsp只要用户登录就可以访问，ww什么角色都没有。为了简单起见，项目中other.jsp就代表其他任何登录后就可以访问的路径 3. 代码解读关于spring security认证与授权原理的讲解在前一篇讲的比较清楚了，这里不再详细介绍，这里只介绍一下自己认为比较重要的代码。 3.1 MySecurityConfig spring secuirty提供了一种后处理bean方式提供一个自定义配置过滤器的口子，就是下面这段代码： 这段代码对FilterSecurityInterceptor的AccessDecisionManager属性进行了自定义的配置。目的是让spring security用我们自定义的AccessDecisionManager。 3.2 MyAccessDecisionManager 在用户没有登录时，decide中的authentication参数是AnonymousAuthenticationToken，此时他会有ROLE_ANONYMOUS的角色，就是匿名角色。这是AnonymousAuthenticationFilter来做的。 这样下面这段代码就好理解了 1234if(authorityString.contains(&quot;ROLE_ANONYMOUS&quot;)) &#123; //未登录 throw new AccessDeniedException(&quot;未登录&quot;);&#125; 3.3 MyAuthenticationProvider 我们的MyAuthenticationProvider继承了AbstractUserDetailsAuthenticationProvider，我们自定义provider的真正认证过程实际发生在AbstractUserDetailsAuthenticationProvider的authenticate中。我们的MyAuthenticationProvider只是实现了retrieveUser来获取用户信息并在其中检查用户名是否存在，以及实现了additionalAuthenticationChecks检验用户输入的密码。其他一些诸如填充完整的Authentication的行为交给父类来做了。因为父类处理的很好所以我们无须自己再做。MySuccessHandler也是将认证成功后的处理都交给父类去处理了。 4. 小节本spring security系列，只是对我们web应用中常见的表单认证与登录进行了讲解。spring security还有很多安全功能。比如方法安全，域安全等。本文没有进行讲解。想了解更多，可以查看官方文档。自己以后也会再学，到时候也会再写相关博文。 项目地址 https://github.com/wutianqi/spring_security_extend.git","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/《On Java 8》读书笔记","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/《On Java 8》读书笔记/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/%E3%80%8AOn%20Java%208%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","excerpt":"","text":"《On Java 8》读书笔记1. java 8 接口可以有默认方法和静态方法增加默认方法的极具说服力的理由是它允许在不破坏已使用接口的代码的情况下，在接口中增加新的方法。默认方法有时也被称为守卫方法或虚拟扩展方法。 默认方法的最佳实践是 java 8 的 stream api。 接口使用了默认方法，继承了这个接口的类可以不用实现接口中的默认方法。如： 12345// interfaces/AnInterface.javainterface AnInterface &#123; void firstMethod(); void secondMethod();&#125; 类实现接口 12345678910111213141516// interfaces/AnImplementation.javapublic class AnImplementation implements AnInterface &#123; public void firstMethod() &#123; System.out.println(&quot;firstMethod&quot;); &#125; public void secondMethod() &#123; System.out.println(&quot;secondMethod&quot;); &#125; public static void main(String[] args) &#123; AnInterface i = new AnImplementation(); i.firstMethod(); i.secondMethod(); &#125;&#125; 如果我们在 AnInterface 中增加一个新方法 newMethod()，而在 AnImplementation 中没有实现它，编译器就会报错。如果我们使用关键字 default 为 newMethod() 方法提供默认的实现，那么所有与接口有关的代码能正常工作，不受影响，而且这些代码还可以调用新的方法 newMethod()： 123456789// interfaces/InterfaceWithDefault.javainterface InterfaceWithDefault &#123; void firstMethod(); void secondMethod(); default void newMethod() &#123; System.out.println(&quot;newMethod&quot;); &#125;&#125; 只要修改接口，不用修改实现类。 12345678910111213141516171819// interfaces/Implementation2.javapublic class Implementation2 implements InterfaceWithDefault &#123; @Override public void firstMethod() &#123; System.out.println(&quot;firstMethod&quot;); &#125; @Override public void secondMethod() &#123; System.out.println(&quot;secondMethod&quot;) &#125; public static void main(String[] args) &#123; InterfaceWithDefault i = new Implementation2(); i.firstMethod(); i.secondMethod(); i.newMethod(); &#125;&#125; 2. java 8 多继承类可以实现多个接口，由于默认方法的加入，java class 有了多继承的特性，如果一个类实现的接口中有重复的方法签名相同（方法签名包括方法名和参数类型）的默认方法，类就需要覆写冲突的方法，或者重新实现方法。 3. 数组是保存一组对象最有效的方式4. 关于集合类（Collection ）的写法12List&lt;Apple&gt; apples = new LinkedList&lt;&gt;();LinkedList&lt;Apple&gt; apples = new LinkedList&lt;&gt;(); 请注意， ArrayList 已经被向上转型为了 List接口，这是大多数情况下的写法。但是如果需要用到具体的集合类的功能特性时，就不能将它们向上转型为更通用的接口。 5. 优化是一个很棘手的问题，最好的策略就是置之不顾，直到发现必须要去担心它了（尽管去理解这些问题总是一个很好的主意）6 . 集合类中迭代器（Iterators）的理解迭代器是一个对象，它在一个序列中移动并选择该序列中的每个对象，而客户端程序员不知道或不关心该序列的底层结构。另外，迭代器通常被称为轻量级对象（lightweight object）：创建它的代价小。ava 的 Iterator 只能单向移动。这个 Iterator 只能用来： 使用 iterator() 方法要求集合返回一个 Iterator。 Iterator 将准备好返回序列中的第一个元素。 使用 next() 方法获得序列中的下一个元素。 使用 hasNext() 方法检查序列中是否还有元素。 使用 remove() 方法将迭代器最近返回的那个元素删除。 有了 Iterator ，就不必再为集合中元素的数量操心了。这是由 hasNext() 和 next() 关心的事情。也可以不用考虑到集合的确切类型。迭代器能够将遍历序列的操作与该序列的底层结构分离，统一了对集合的访问方式。 用法示例： 123456789101112131415161718192021222324252627282930313233// collections/CrossCollectionIteration.javaimport typeinfo.pets.*;import java.util.*;public class CrossCollectionIteration &#123; public static void display(Iterator&lt;Pet&gt; it) &#123; while(it.hasNext()) &#123; Pet p = it.next(); System.out.print(p.id() + &quot;:&quot; + p + &quot; &quot;); &#125; System.out.println(); &#125; public static void main(String[] args) &#123; List&lt;Pet&gt; pets = Pets.list(8); LinkedList&lt;Pet&gt; petsLL = new LinkedList&lt;&gt;(pets); HashSet&lt;Pet&gt; petsHS = new HashSet&lt;&gt;(pets); TreeSet&lt;Pet&gt; petsTS = new TreeSet&lt;&gt;(pets); display(pets.iterator()); display(petsLL.iterator()); display(petsHS.iterator()); display(petsTS.iterator()); &#125;&#125;/* Output:0:Rat 1:Manx 2:Cymric 3:Mutt 4:Pug 5:Cymric 6:Pug7:Manx0:Rat 1:Manx 2:Cymric 3:Mutt 4:Pug 5:Cymric 6:Pug7:Manx0:Rat 1:Manx 2:Cymric 3:Mutt 4:Pug 5:Cymric 6:Pug7:Manx5:Cymric 2:Cymric 7:Manx 1:Manx 3:Mutt 6:Pug 4:Pug0:Rat*/ ListIterator 是一个更强大的 Iterator 子类型，它只能由各种 List 类生成。 Iterator 只能向前移动，而 ListIterator 可以双向移动。它还可以生成相对于迭代器在列表中指向的当前位置的后一个和前一个元素的索引，并且可以使用 set() 方法替换它访问过的最近一个元素。 7. Java8 中的堆栈声明为1Deque&lt;String&gt; stack = new ArrayDeque&lt;&gt;(); 之所以是 Deque 而不是Stack，这是因为 Java 1.0 中附带了一个 Stack 类，结果设计得很糟糕（为了向后兼容，后续保留了这个类）。Java 6 添加了 ArrayDeque。 8. 队列LinkedList 实现了 Queue 接口，并且提供了一些方法以支持队列行为，因此 LinkedList 可以用作 Queue 的一种实现。 通过将 LinkedList 向上转换为 Queue 。 1Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); 9. for-in 语法糖Java 5 引入了一个名为 Iterable 的接口，该接口包含一个能够生成 Iterator 的 iterator() 方法。for-in 使用此 Iterable 接口来遍历序列。因此，如果创建了任何实现了 Iterable 的类，都可以将它用于 for-in 语句中。 1234567891011121314151617181920212223242526272829303132// collections/IterableClass.java// Anything Iterable works with for-inimport java.util.*;public class IterableClass implements Iterable&lt;String&gt; &#123; protected String[] words = (&quot;And that is how &quot; + &quot;we know the Earth to be banana-shaped.&quot; ).split(&quot; &quot;); @Override public Iterator&lt;String&gt; iterator() &#123; return new Iterator&lt;String&gt;() &#123; private int index = 0; @Override public boolean hasNext() &#123; return index &lt; words.length; &#125; @Override public String next() &#123; return words[index++]; &#125; @Override public void remove() &#123; // Not implemented throw new UnsupportedOperationException(); &#125; &#125;; &#125; public static void main(String[] args) &#123; for(String s : new IterableClass()) System.out.print(s + &quot; &quot;); &#125;&#125;/* Output:And that is how we know the Earth to be banana-shaped.*/ 10. 不要在新代码中使用遗留类 Vector ，Hashtable 和 Stack 。11. Lambda 表达式123456789101112static Body bod = h -&gt; h + &quot; No Parens!&quot;; // [1] static Body bod2 = (h) -&gt; h + &quot; More details&quot;; // [2] static Description desc = () -&gt; &quot;Short info&quot;; // [3] static Multi mult = (h, n) -&gt; h + n; // [4] static Description moreLines = () -&gt; &#123; // [5] System.out.println(&quot;moreLines()&quot;); return &quot;from moreLines()&quot;; &#125;; Lambda 表达式基本语法： 参数。 接着 -&gt;，可视为“产出”。 -&gt; 之后的内容都是方法体。 当只用一个参数，可以不需要括号 ()。 然而，这是一个特例。 正常情况使用括号 () 包裹参数。 为了保持一致性，也可以使用括号 () 包裹单个参数，虽然这种情况并不常见。 如果没有参数，则必须使用括号 () 表示空参数列表。 对于多个参数，将参数列表放在括号 () 中。 到目前为止，所有 Lambda 表达式方法体都是单行。 该表达式的结果自动成为 Lambda 表达式的返回值，在此处使用 return 关键字是非法的。 这是 Lambda 表达式缩写用于描述功能的语法的另一种方式。 如果在 Lambda 表达式中确实需要多行，则必须将这些行放在花括号中。 在这种情况下，就 需要使用 return。Lambda 表达式通常比匿名内部类产生更易读的代码，尽可能使用它们。 Fibonacci 序列改为使用递归 Lambda 表达式来实现： 123456789101112131415161718192021interface IntCall &#123; int call(int arg);&#125;public class RecursiveFibonacci &#123; IntCall fib; RecursiveFibonacci() &#123; fib = n -&gt; n == 0 ? 0 : n == 1 ? 1 : fib.call(n - 1) + fib.call(n - 2); &#125; int fibonacci(int n) &#123; return fib.call(n); &#125; public static void main(String[] args) &#123; RecursiveFibonacci rf = new RecursiveFibonacci(); for(int i = 0; i &lt;= 10; i++) System.out.println(rf.fibonacci(i)); &#125;&#125; 12. 流操作流操作的类型有三种：创建流，修改流元素（中间操作， Intermediate Operations），消费流元素（终端操作， Terminal Operations），收集流元素（通常是到集合中）。 13. 异常处理finally 子句永远会执行，即使前面有 return 语句。由于 Java 有垃圾回收机制，所以 finally 语句主要是用来恢复内存之外的资源回到初始状态，需要清理的资源包括：已经打开的文件或网络连接，在屏幕上画的图形，甚至可以是外部世界的某个开关。 14. 永恒真理你永远不能保证你的代码是正确的，你只能证明它是错的。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/java/关于线程安全","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/java/关于线程安全/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/%E5%85%B3%E4%BA%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/","excerpt":"","text":"关于线程安全（摘自https://www.cnblogs.com/nizuimeiabc1/p/4254127.html） 1）常量始终是线程安全的，因为只存在读操作。 2）每次调用方法前都新建一个实例是线程安全的，因为不会访问共享的资源。 3）局部变量是线程安全的。因为每执行一个方法，都会在独立的空间创建局部变量，它不是共享的资源。局部变量包括方法的参数变量和方法内变量。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/工具/git 笔记","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/工具/git 笔记/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E5%B7%A5%E5%85%B7/git%20%E7%AC%94%E8%AE%B0/","excerpt":"","text":"删除本地文件后从远程仓库获取问题在本地删除文件后，git pull从远程仓库获取，但是一直提示 up-to-date，无法获取被删除的文件。 原因：当前本地库处于另一个分支中，需将本分支发Head重置至master。 将本分支发Head重置至master: 12$ git checkout master $ git reset --hard 强行pull并覆盖本地文件 123$ git fetch --all $ git reset --hard origin/master $ git pull","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"工具","slug":"开发笔记/工具","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E5%B7%A5%E5%85%B7/"}],"tags":[]},{"title":"","slug":"开发笔记/数据库/es/Elasticsearch Java Rest Client","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/数据库/es/Elasticsearch Java Rest Client/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/es/Elasticsearch%20Java%20Rest%20Client/","excerpt":"","text":"基于 Elasticsearch 6.x 概述Rest client 分成两部分： Java Low Level REST Client官方低级别 es 客户端，使用 http 协议与 Elastiicsearch 集群通信，与所有 es 版本兼容。 Java High level REST Client官方高级别 es 客户端，基于低级别的客户端，它会暴露 API 特定的方法。 使用方法： 12345&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;6.3.2&lt;/version&gt;&lt;/dependency&gt; 初始化： 1234RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(&quot;localhost&quot;, 9200, &quot;http&quot;), new HttpHost(&quot;localhost&quot;, 9201, &quot;http&quot;))); 文档(Document) API单文档 API index API Get API Delete API Update API 多文档 API Bulk API Multi-Get API Index APIIndexRequest四种方式构建 IndexRequest： json 12345678910IndexRequest indexRequest = new IndexRequest( &quot;posts&quot;, // 索引 Index &quot;doc&quot;, // Type &quot;1&quot;); // 文档 Document Id String jsonString = &quot;&#123;&quot; + &quot;\\&quot;user\\&quot;:\\&quot;kimchy\\&quot;,&quot; + &quot;\\&quot;postDate\\&quot;:\\&quot;2013-01-30\\&quot;,&quot; + &quot;\\&quot;message\\&quot;:\\&quot;trying out Elasticsearch\\&quot;&quot; + &quot;&#125;&quot;;indexRequest.source(jsonString, XContentType.JSON); // 文档源格式为 json string Map 123456Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;();jsonMap.put(&quot;user&quot;, &quot;kimchy&quot;);jsonMap.put(&quot;postDate&quot;, new Date());jsonMap.put(&quot;message&quot;, &quot;trying out Elasticsearch&quot;);IndexRequest indexRequest = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .source(jsonMap); // 会自动将 Map 转换为 JSON 格式 XContentBuilder : Document Source 提供的帮助类，专门用来产生 json 格式的数据 12345678910XContentBuilder builder = XContentFactory.jsonBuilder();builder.startObject();&#123; builder.field(&quot;user&quot;, &quot;kimchy&quot;); builder.timeField(&quot;postDate&quot;, new Date()); builder.field(&quot;message&quot;, &quot;trying out Elasticsearch&quot;);&#125;builder.endObject();IndexRequest indexRequest = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .source(builder); Object 键值对 1234IndexRequest indexRequest = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .source(&quot;user&quot;, &quot;kimchy&quot;, &quot;postDate&quot;, new Date(), &quot;message&quot;, &quot;trying out Elasticsearch&quot;); 同步索引1IndexResponse indexResponse = client.index(indexRequest); 异步索引异步执行函数需要添加 listener 作为回调函数, 而对于 index 而言，这个 listener 的类型就是 ActionListener 12345678910111213ActionListener&lt;IndexResponse&gt; listener = new ActionListener&lt;IndexResponse&gt;() &#123; @Override public void onResponse(IndexResponse indexResponse) &#123; //执行成功，调用 onResponse 函数 &#125; @Override public void onFailure(Exception e) &#123; //执行失败，调用 onFailure 函数 &#125;&#125;;IndexResponse indexResponse = client.indexAsync(indexRequest, listener); IndexResponse不管是同步还是异步，如果调用成功，都会返回 IndexRespose 对象。 123456789101112131415161718tring index = indexResponse.getIndex();String type = indexResponse.getType();String id = indexResponse.getId();long version = indexResponse.getVersion();if (indexResponse.getResult() == DocWriteResponse.Result.CREATED) &#123; // 文档第一次创建 &#125; else if (indexResponse.getResult() == DocWriteResponse.Result.UPDATED) &#123; // 文档之前已存在，当前是重写&#125;ReplicationResponse.ShardInfo shardInfo = indexResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; // 成功的分片数量少于总分片数量 &#125;if (shardInfo.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); // 处理潜在的失败信息 &#125;&#125; GET APIGetRequest每个 GET 请求都必须需传入下面 3 个参数： Index Type Document id 1234GetRequest getRequest = new GetRequest( &quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;); 可选参数： 不获取源数据，默认是获取的 1getRequest.fetchSourceContext(FetchSourceContext.DO_NOT_FETCH_SOURCE); 配置返回数据中包含指定字段 12345String[] includes = new String[]&#123;&quot;message&quot;, &quot;*Date&quot;&#125;;String[] excludes = Strings.EMPTY_ARRAY;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);getRequest.fetchSourceContext(fetchSourceContext); 配置返回数据中排除指定字段 12345String[] includes = Strings.EMPTY_ARRAY;String[] excludes = new String[]&#123;&quot;message&quot;&#125;;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);getRequest.fetchSourceContext(fetchSourceContext); 实时 默认为 true 1getRequest.realtime(false); 版本 1getRequest.version(2); 版本类型 1getRequest.versionType(VersionType.EXTERNAL); 执行同步执行： 1GetResponse getResponse = client.get(getRequest); 异步执行： 12345678910111213ActionListener&lt;IndexResponse&gt; listener = new ActionListener&lt;IndexResponse&gt;() &#123; @Override public void onResponse(IndexResponse indexResponse) &#123; //执行成功，调用 onResponse 函数 &#125; @Override public void onFailure(Exception e) &#123; //执行失败，调用 onFailure 函数 &#125;&#125;;GetResponse getResponse = client.indexAsync(indexRequest, listener); GetResponse返回的 GetResponse 对象包含要请求的文档数据（包含元数据和字段） 1234567891011String index = getResponse.getIndex();String type = getResponse.getType();String id = getResponse.getId();if (getResponse.isExists()) &#123; long version = getResponse.getVersion(); String sourceAsString = getResponse.getSourceAsString(); // string 形式 Map&lt;String, Object&gt; sourceAsMap = getResponse.getSourceAsMap(); // map byte[] sourceAsBytes = getResponse.getSourceAsBytes(); // 字节形式 &#125; else &#123; // 没有发现请求的文档 &#125; Exists API如果文档存在 Exists API 返回 true, 否则返回 fasle。 GetRequest用法和 Get API 差不多，两个对象的可选参数是相同的。由于 exists() 方法只返回 true 或者 false， 应该将获取 _source 以及任何存储字段的值关闭，尽量使请求轻量级。 123456GetRequest getRequest = new GetRequest( &quot;posts&quot;, // Index &quot;doc&quot;, // Type &quot;1&quot;); // Document idgetRequest.fetchSourceContext(new FetchSourceContext(false)); // 禁用 _source 字段getRequest.storedFields(&quot;_none_&quot;); // 禁止存储任何字段 执行同步执行： 1boolean exists = client.exists(getRequest); 异步执行： 12345678910111213ActionListener&lt;Boolean&gt; listener = new ActionListener&lt;Boolean&gt;() &#123; @Override public void onResponse(Boolean exists) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;boolean exists = client.existsAsync(getRequest, listener); Delete APIDeleteRequestDeleteRequest 必须传入下面参数： Index Type Document id 1234DeleteRequest deleteRequest = new DeleteRequest( &quot;posts&quot;, // index &quot;doc&quot;, // doc &quot;1&quot;); // document id 可选参数： 超时时间 12deleteRequest.timeout(TimeValue.timeValueMinutes(2)); deleteRequest.timeout(&quot;2m&quot;); 刷新策略 12deleteRequest.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); deleteRequest.setRefreshPolicy(&quot;wait_for&quot;); 版本 1deleteRequest.version(2); 版本类型 1deleteRequest.versionType(VersionType.EXTERNAL); 执行同步执行： 1DeleteResponse deleteResponse = client.delete(deleteRequest); 异步执行 12345678910111213ActionListener&lt;DeleteResponse&gt; listener = new ActionListener&lt;DeleteResponse&gt;() &#123; @Override public void onResponse(DeleteResponse deleteResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;DeleteResponse deleteResponse = client.deleteAsync(deleteResponse, listener); DeleteResponseDeleteResponse 可以检索执行操作的信息 12345678910111213String index = deleteResponse.getIndex();String type = deleteResponse.getType();String id = deleteResponse.getId();long version = deleteResponse.getVersion();ReplicationResponse.ShardInfo shardInfo = deleteResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; // 成功分片数目小于总分片&#125;if (shardInfo.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); // 处理潜在失败 &#125;&#125; Update APIUpdateRequestUpdateRequest 必须传入下面参数： Index Type Document id 1234UpdateRequest updateRequest = new DeleteRequest( &quot;posts&quot;, // index &quot;doc&quot;, // doc &quot;1&quot;); // document id 和 index api 类似，UpdateRequest 也支持四种文档格式： json 123456UpdateRequest updateRequest = new UpdateRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;);String jsonString = &quot;&#123;&quot; + &quot;\\&quot;updated\\&quot;:\\&quot;2017-01-01\\&quot;,&quot; + &quot;\\&quot;reason\\&quot;:\\&quot;daily update\\&quot;&quot; + &quot;&#125;&quot;;request.doc(jsonString, XContentType.JSON); map 12345Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;();jsonMap.put(&quot;updated&quot;, new Date());jsonMap.put(&quot;reason&quot;, &quot;daily update&quot;);UpdateRequest updateRequest = new UpdateRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .doc(jsonMap); XContentBuilder 123456789XContentBuilder builder = XContentFactory.jsonBuilder();builder.startObject();&#123; builder.timeField(&quot;updated&quot;, new Date()); builder.field(&quot;reason&quot;, &quot;daily update&quot;);&#125;builder.endObject();UpdateRequest updateRequest = new UpdateRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .doc(builder); object 键值对 123UpdateRequest updateRequest = new UpdateRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .doc(&quot;updated&quot;, new Date(), &quot;reason&quot;, &quot;daily update&quot;); 可选参数： 超时时间 12updateRequest.timeout(TimeValue.timeValueSeconds(1)); updateRequest.timeout(&quot;1s&quot;); 刷新策略 12updateRequest.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); updateRequest.setRefreshPolicy(&quot;wait_for&quot;); 冲突后重试次数 1updateRequest.retryOnConflict(3); 获取数据源，默认是开启的 1updateRequest.fetchSource(true); 包括特定字段 123String[] includes = new String[]&#123;&quot;updated&quot;, &quot;r*&quot;&#125;;String[] excludes = Strings.EMPTY_ARRAY;updateRequest.fetchSource(new FetchSourceContext(true, includes, excludes)); 排除特定字段 123String[] includes = Strings.EMPTY_ARRAY;String[] excludes = new String[]&#123;&quot;updated&quot;&#125;;updateRequest.fetchSource(new FetchSourceContext(true, includes, excludes)); 指定版本 1updateRequest.version(2); 禁用 noop detection 1updateRequest.scriptedUpsert(true); 设置如果更新的文档不存在，就必须要创建一个 1updateRequest.docAsUpsert(true); 执行同步执行： 1UpdateResponse updateResponse = client.update(updateRequest); 异步执行： 12345678910111213ActionListener&lt;UpdateResponse&gt; listener = new ActionListener&lt;UpdateResponse&gt;() &#123; @Override public void onResponse(UpdateResponse updateResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;UpdateResponse updateResponse = client.updateAsync(request, listener); UpdateResponse12345678910111213String index = updateResponse.getIndex();String type = updateResponse.getType();String id = updateResponse.getId();long version = updateResponse.getVersion();if (updateResponse.getResult() == DocWriteResponse.Result.CREATED) &#123; // 文档已创建&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.UPDATED) &#123; // 文档已更新&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.DELETED) &#123; // 文档已删除&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.NOOP) &#123; // 文档不受更新的影响&#125; 如果在 UpdateRequest 中设置了获取源数据，响应中则包含了更新后的源文档信息： 12345678GetResult result = updateResponse.getGetResult(); if (result.isExists()) &#123; String sourceAsString = result.sourceAsString(); // 将获取的文档以 string 格式输出 Map&lt;String, Object&gt; sourceAsMap = result.sourceAsMap(); // 以 Map 格式输出 byte[] sourceAsBytes = result.source(); // 字节形式&#125; else &#123; // 默认情况下，不会返回文档源数据&#125; 检测是否分片失败： 123456789ReplicationResponse.ShardInfo shardInfo = updateResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; // 成功的分片数量小于总分片数量&#125;if (shardInfo.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); // 得到分片失败的原因 &#125;&#125; Bulk API 批量处理BulkRequest 批量请求使用 BulkRequest 可以在一次请求中执行多个索引，更新和删除的操作: 1234567BulkRequest request = new BulkRequest(); request.add(new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .source(XContentType.JSON,&quot;field&quot;, &quot;foo&quot;)); // 将第一个 IndexRequest 添加到批量请求中request.add(new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;2&quot;) .source(XContentType.JSON,&quot;field&quot;, &quot;bar&quot;)); // 第二个request.add(new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;3&quot;) .source(XContentType.JSON,&quot;field&quot;, &quot;baz&quot;)); // 第三个 在同一个 BulkRequest 也可以添加不同的操作类型: 123456BulkRequest bulkRequest = new BulkRequest();bulkRequest.add(new DeleteRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;3&quot;)); bulkRequest.add(new UpdateRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;2&quot;) .doc(XContentType.JSON,&quot;other&quot;, &quot;test&quot;));jbulkRequest.add(new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;4&quot;) .source(XContentType.JSON,&quot;field&quot;, &quot;baz&quot;)); 可选参数： 超时时间 12bulkRequest.timeout(TimeValue.timeValueMinutes(2)); bulkRequest.timeout(&quot;2m&quot;); 刷新策略 12bulkRequest.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); bulkRequest.setRefreshPolicy(&quot;wait_for&quot;); 设置在批量操作前必须有几个分片处于激活状态 1234bulkRequest.waitForActiveShards(2); bulkRequest.waitForActiveShards(ActiveShardCount.ALL); // 全部分片都处于激活状态bulkRequest.waitForActiveShards(ActiveShardCount.DEFAULT); // 默认bulkRequest.waitForActiveShards(ActiveShardCount.ONE); // 一个 执行同步请求： 1BulkResponse bulkResponse = client.bulk(request); 异步请求： 12345678910111213ActionListener&lt;BulkResponse&gt; listener = new ActionListener&lt;BulkResponse&gt;() &#123; @Override public void onResponse(BulkResponse bulkResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;BulkResponse bulkResponse = client.bulkAsync(request, listener); BulkResponseBulkResponse 中包含执行操作后的信息，并允许对每个操作结果迭代 1234567891011121314for (BulkItemResponse bulkItemResponse : bulkResponse) &#123; // 遍历所有的操作结果 DocWriteResponse itemResponse = bulkItemResponse.getResponse(); // 获取操作结果的响应，可以是 IndexResponse, UpdateResponse or DeleteResponse, 它们都可以惭怍是 DocWriteResponse 实例 if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.INDEX || bulkItemResponse.getOpType() == DocWriteRequest.OpType.CREATE) &#123; IndexResponse indexResponse = (IndexResponse) itemResponse; // index 操作后的响应结果 &#125; else if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.UPDATE) &#123; UpdateResponse updateResponse = (UpdateResponse) itemResponse; // update 操作后的响应结果 &#125; else if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.DELETE) &#123; DeleteResponse deleteResponse = (DeleteResponse) itemResponse; // delete 操作后的响应结果 &#125;&#125; 此外，批量响应还有一个非常便捷的方法来检测是否有一个或多个操作失败 12345678if (bulkResponse.hasFailures()) &#123; // 表示至少有一个操作失败 // 遍历所有的操作结果，检查是否是失败的操作，并获取对应的失败信息 for (BulkItemResponse bulkItemResponse : bulkResponse) &#123; if (bulkItemResponse.isFailed()) &#123; // 检测给定的操作是否失败 BulkItemResponse.Failure failure = bulkItemResponse.getFailure(); // 获取失败信息 &#125; &#125;&#125; BulkProcessorBulkProcessor 是为了简化 Bulk API 的操作提供的一个工具类，要执行操作，就需要下面组件: RestHighLevelClient 用来执行 BulkRequest 并获取 BulkResponse BulkProcessor.Listener 对 BulkRequest 执行前后以及失败时监听 BulkProcessor.builder 方法用来构建一个新的 BulkProcessor： 1234567891011121314151617181920ulkProcessor.Listener listener = new BulkProcessor.Listener() &#123; @Override public void beforeBulk(long executionId, BulkRequest request) &#123; // 在每个 BulkRequest 执行前调用 &#125; @Override public void afterBulk(long executionId, BulkRequest request, BulkResponse response) &#123; // 在每个 BulkRequest 执行后调用 &#125; @Override public void afterBulk(long executionId, BulkRequest request, Throwable failure) &#123; // 失败时调用 &#125;&#125;;BulkProcessor bulkProcessor = BulkProcessor.builder(client::bulkAsync, listener).build(); // 构建 BulkProcessor, RestHighLevelClient.bulkAsync() 用来执行 BulkRequest BulkProcessor.Builder 提供了多个方法来配置 BulkProcessor 如何来处理请求的执行: 1234567BulkProcessor.Builder builder = BulkProcessor.builder(client::bulkAsync, listener);builder.setBulkActions(500); // 指定多少操作时，就会刷新一次builder.setBulkSize(new ByteSizeValue(1L, ByteSizeUnit.MB)); builder.setConcurrentRequests(0); // 指定多大容量，就会刷新一次builder.setFlushInterval(TimeValue.timeValueSeconds(10L)); // 允许并发执行的数量 builder.setBackoffPolicy(BackoffPolicy .constantBackoff(TimeValue.timeValueSeconds(1L), 3)); BulkProcessor 创建后，各种请求就可以添加进去： 12345678910111213IndexRequest one = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;). source(XContentType.JSON, &quot;title&quot;, &quot;In which order are my Elasticsearch queries executed?&quot;);IndexRequest two = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;2&quot;) .source(XContentType.JSON, &quot;title&quot;, &quot;Current status and upcoming changes in Elasticsearch&quot;);IndexRequest three = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;3&quot;) .source(XContentType.JSON, &quot;title&quot;, &quot;The Future of Federated Search in Elasticsearch&quot;);bulkProcessor.add(one);bulkProcessor.add(two);bulkProcessor.add(three); BulkProcessor 执行时，会对每个 bulk request调用 BulkProcessor.Listener ， listener 提供了下面方法来访问 BulkRequest 和 BulkResponse: 123456789101112131415161718192021222324BulkProcessor.Listener listener = new BulkProcessor.Listener() &#123; @Override public void beforeBulk(long executionId, BulkRequest request) &#123; int numberOfActions = request.numberOfActions(); // 在执行前获取操作的数量 logger.debug(&quot;Executing bulk [&#123;&#125;] with &#123;&#125; requests&quot;, executionId, numberOfActions); &#125; @Override public void afterBulk(long executionId, BulkRequest request, BulkResponse response) &#123; if (response.hasFailures()) &#123; // 执行后查看响应中是否包含失败的操作 logger.warn(&quot;Bulk [&#123;&#125;] executed with failures&quot;, executionId); &#125; else &#123; logger.debug(&quot;Bulk [&#123;&#125;] completed in &#123;&#125; milliseconds&quot;, executionId, response.getTook().getMillis()); &#125; &#125; @Override public void afterBulk(long executionId, BulkRequest request, Throwable failure) &#123; logger.error(&quot;Failed to execute bulk&quot;, failure); // 请求失败时打印信息 &#125;&#125;; 请求添加到 BulkProcessor ， 它的实例可以使用下面两种方法关闭请求： awaitClose() 在请求返回后或等待一定时间关闭 1boolean terminated = bulkProcessor.awaitClose(30L, TimeUnit.SECONDS); close() 立刻关闭 1bulkProcessor.close(); 两个方法都会在关闭前对处理器中的请求进行刷新，并避免新的请求添加进去。 Multi-Get APImultiGet API 可以在单个 http 交互中并行的执行多个 get 请求。 MultiGetRequestMultiGetRequest 实例化时参数为空，实例化后可以通过添加 MultiGetRequest.Item 来配置获取的信息 123456MultiGetRequest request = new MultiGetRequest();request.add(new MultiGetRequest.Item( &quot;index&quot;, // 索引 &quot;type&quot;, // 类型 &quot;example_id&quot;)); // 文档 idjrequest.add(new MultiGetRequest.Item(&quot;index&quot;, &quot;type&quot;, &quot;another_id&quot;)); // 添加另外一个条目 可选参数： 与前面 Get API 可选参数相同 执行同步执行： 1MultiGetResponse response = client.multiGet(request); 异步执行： 12345678910111213ActionListener&lt;MultiGetResponse&gt; listener = new ActionListener&lt;MultiGetResponse&gt;() &#123; @Override public void onResponse(MultiGetResponse response) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;client.multiGetAsync(request, listener); MultiGetResponseMultiGetResponse 中getResponse 方法包含的 MultiGetItemResponse 顺序与请求时的相 MultiGetItemResponse ，如果执行成功，就会返回 GetResponse 对象，失败则返回 MultiGetResponse.Failure 12345678910111213141516MultiGetItemResponse firstItem = response.getResponses()[0];assertNull(firstItem.getFailure()); // 执行成功，则返回 null GetResponse firstGet = firstItem.getResponse(); // 返回 GetResponse 对象String index = firstItem.getIndex();String type = firstItem.getType();String id = firstItem.getId();if (firstGet.isExists()) &#123; long version = firstGet.getVersion(); String sourceAsString = firstGet.getSourceAsString(); // string 格式 Map&lt;String, Object&gt; sourceAsMap = firstGet.getSourceAsMap(); // Map byte[] sourceAsBytes = firstGet.getSourceAsBytes(); // bytes &#125; else &#123; // 没有发现文档 // 尽管响应中会返回 404 状态码，也会返回一个有效的 GetResponse // 这是可以使用 isExists 方法来判断&#125; 如果子请求中对应的 index 不存在，返回的响应中的getFailure 方法中会包含 exception: 1234567assertNull(missingIndexItem.getResponse()); // 获取的响应为空 Exception e = missingIndexItem.getFailure().getFailure(); // 获取 exceptionElasticsearchException ee = (ElasticsearchException) e; // TODO status is broken! fix in a followup// assertEquals(RestStatus.NOT_FOUND, ee.status()); assertThat(e.getMessage(), containsString(&quot;reason=no such index&quot;)); 查询（Search）APIJava High Level REST Client 支持下面的 Search API： Search API Search Scroll API Clear Scroll API Multi-Search API Ranking Evaluation API Search APISearchRequestsearchRequest 用来完成和搜索文档，聚等相关的操作同时也提供了各种方式来完成对查询结果的高亮操作。 最基本的查询操作如下: 1234SearchRequest searchRequest = new SearchRequest(); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchAllQuery()); // 添加 match_all 查询searchRequest.source(searchSourceBuilder); // 将 SearchSourceBuilder 添加到 SeachRequest 中 可选参数: 1234SearchRequest searchRequest = new SearchRequest(&quot;posts&quot;); // 设置搜索的 indexsearchRequest.types(&quot;doc&quot;); // 设置搜索的 typesearchRequest.routing(&quot;routing&quot;); // 设置 routing 参数searchRequest.preference(&quot;_local&quot;); // 配置搜索时偏爱使用本地分片，默认是使用随机分片 SearchSourceBuilder对搜索行为的配置可以使用 SearchSourceBuilder 来完成: 12345678SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); // 默认配置sourceBuilder.query(QueryBuilders.termQuery(&quot;user&quot;, &quot;kimchy&quot;)); // 设置搜索，可以是任何类型的 QueryBuildersourceBuilder.from(0); // 起始 indexsourceBuilder.size(5); // 大小 sizesourceBuilder.timeout(new TimeValue(60, TimeUnit.SECONDS)); // 设置搜索的超时时间SearchRequest searchRequest = new SearchRequest();searchRequest.source(sourceBuilder); SearchSourceBuilder 可选配置有： 1. 构建查询条件查询请求是通过使用 QueryBuilder 对象来完成的，并且支持 Query DSL（领域特定语言，是指专注于某个应用程序领域的计算机语言）。 使用构造函数来创建 QueryBuilder： 123456MatchQueryBuilder matchQueryBuilder = new MatchQueryBuilder(&quot;user&quot;, &quot;kimchy&quot;); // 配置查询选项matchQueryBuilder.fuzziness(Fuzziness.AUTO); // 模糊查询matchQueryBuilder.prefixLength(3); // 前缀查询的长度matchQueryBuilder.maxExpansions(10); // max expansion 选项，用来控制模糊查询 也可以使用QueryBuilders 工具类来创建 QueryBuilder 对象。这个类提供了函数式编程风格的各种方法用来快速创建 QueryBuilder 对象。 1234QueryBuilder matchQueryBuilder = QueryBuilders.matchQuery(&quot;user&quot;, &quot;kimchy&quot;) .fuzziness(Fuzziness.AUTO) .prefixLength(3) .maxExpansions(10); 最后要添加到 SearchSourceBuilder 中: 1searchSourceBuilder.query(matchQueryBuilder); 2. 指定排序SearchSourceBuilder 允许添加一个或多个SortBuilder 实例。这里包含 4 种特殊的实现, (Field-, Score-, GeoDistance- 和 ScriptSortBuilder) 12sourceBuilder.sort(new ScoreSortBuilder().order(SortOrder.DESC)); // 根据分数 _score 降序排列 (默认行为)sourceBuilder.sort(new FieldSortBuilder(&quot;_uid&quot;).order(SortOrder.ASC)); // 根据 id 降序排列 3. 过滤数据源默认情况下，查询请求会返回文档的内容 _source ,当然我们也可以配置它。例如，禁止对 _source 的获取 1sourceBuilder.fetchSource(false); 也可以使用通配符模式以更细的粒度包含或排除特定的字段: 123String[] includeFields = new String[] &#123;&quot;title&quot;, &quot;user&quot;, &quot;innerObject.*&quot;&#125;;String[] excludeFields = new String[] &#123;&quot;_type&quot;&#125;;sourceBuilder.fetchSource(includeFields, excludeFields); 4. 高亮请求可以通过在 SearchSourceBuilder 上设置 HighlightBuilder 完成对结果的高亮，而且可以配置不同的字段具有不同的高亮行为。 123456789SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();HighlightBuilder highlightBuilder = new HighlightBuilder(); HighlightBuilder.Field highlightTitle = new HighlightBuilder.Field(&quot;title&quot;); // title 字段高亮highlightTitle.highlighterType(&quot;unified&quot;); // 配置高亮类型highlightBuilder.field(highlightTitle); // 添加到 builderHighlightBuilder.Field highlightUser = new HighlightBuilder.Field(&quot;user&quot;);highlightBuilder.field(highlightUser);searchSourceBuilder.highlighter(highlightBuilder); 5. 聚合请求要实现聚合请求分两步 创建合适的 AggregationBuilder 作为参数配置在 SearchSourceBuilder 123456SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();TermsAggregationBuilder aggregation = AggregationBuilders.terms(&quot;by_company&quot;) .field(&quot;company.keyword&quot;);aggregation.subAggregation(AggregationBuilders.avg(&quot;average_age&quot;) .field(&quot;age&quot;));searchSourceBuilder.aggregation(aggregation); 6. 建议请求 Requesting SuggestionsSuggestionBuilder 实现类是由 SuggestBuilders 工厂类来创建的。 123456SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();SuggestionBuilder termSuggestionBuilder = SuggestBuilders.termSuggestion(&quot;user&quot;).text(&quot;kmichy&quot;); SuggestBuilder suggestBuilder = new SuggestBuilder();suggestBuilder.addSuggestion(&quot;suggest_user&quot;, termSuggestionBuilder); searchSourceBuilder.suggest(suggestBuilder); 7. 对请求和聚合分析分析 API 可用来对一个特定的查询操作中的请求和聚合进行分析，此时要将SearchSourceBuilder 的 profile标志位设置为 true 12SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();searchSourceBuilder.profile(true); 执行同步执行 同步执行是阻塞式的，只有结果返回后才能继续执行 1SearchResponse searchResponse = client.search(searchRequest); 异步执行 异步执行使用的是 listener 对结果进行处理 12345678910111213ActionListener&lt;SearchResponse&gt; listener = new ActionListener&lt;SearchResponse&gt;() &#123; @Override public void onResponse(SearchResponse searchResponse) &#123; // 查询成功 &#125; @Override public void onFailure(Exception e) &#123; // 查询失败 &#125;&#125;;SearchResponse searchResponse = client.search(searchRequest); SearchResponse查询执行完成后，会返回 SearchResponse 对象，并在对象中包含查询执行的细节和符合条件的文档集合。 SerchResponse 包含的信息如下： 请求本身的信息，如 HTTP 状态码，执行时间，或者请求是否超时 1234RestStatus status = searchResponse.status(); // HTTP 状态码TimeValue took = searchResponse.getTook(); // 查询占用的时间Boolean terminatedEarly = searchResponse.isTerminatedEarly(); // 是否由于 SearchSourceBuilder 中设置 terminateAfter 而过早终止boolean timedOut = searchResponse.isTimedOut(); // 是否超时 查询影响的分片数量的统计信息，成功和失败的分片 123456int totalShards = searchResponse.getTotalShards();int successfulShards = searchResponse.getSuccessfulShards();int failedShards = searchResponse.getFailedShards();for (ShardSearchFailure failure : searchResponse.getShardFailures()) &#123; // failures should be handled here&#125; SearchHits 1234567891011121314151617181920SearchHits hits = searchResponse.getHits();long totalHits = hits.getTotalHits();float maxScore = hits.getMaxScore();SearchHit[] searchHits = hits.getHits();for (SearchHit hit : searchHits) &#123; // do something with the SearchHit String index = hit.getIndex(); String type = hit.getType(); String id = hit.getId(); float score = hit.getScore(); // 获取文档源数据 String sourceAsString = hit.getSourceAsString(); Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); String documentTitle = (String) sourceAsMap.get(&quot;title&quot;); List&lt;Object&gt; users = (List&lt;Object&gt;) sourceAsMap.get(&quot;user&quot;); Map&lt;String, Object&gt; innerObject = (Map&lt;String, Object&gt;) sourceAsMap.get(&quot;innerObject&quot;);&#125;","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"数据库","slug":"开发笔记/数据库","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"es","slug":"开发笔记/数据库/es","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/es/"}],"tags":[]},{"title":"","slug":"开发笔记/数据库/es/Elasticsearch版本特性","date":"2022-12-12T17:36:23.241Z","updated":"2022-12-12T17:36:23.245Z","comments":true,"path":"2022/12/12/开发笔记/数据库/es/Elasticsearch版本特性/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/es/Elasticsearch%E7%89%88%E6%9C%AC%E7%89%B9%E6%80%A7/","excerpt":"","text":"elasticsearch 各版本特性5.0支持Lucene 6.x Instant Aggregations，在Shard层面提供了Aggregation缓存 新增 Sliced Scroll类型，现在Scroll接口可以并发来进行数据遍历了。每个Scroll请求，可以分成多个Slice请求，可以理解为切片，各Slice独立并行，利用Scroll重建或者遍历要快很多倍。 新增了Profile API 同时支持search和aggregation的profile 有一个新的 Search After 机制，其实和 scroll 类似，也是游标的机制，它的原理是对文档按照多个字段进行排序，然后利用上一个结果的最后一个文档作为起始值，拿 size 个文档，一般我们建议使用 _uid 这个字段，它的值是唯一的 id 新增Shrink API 新增了Rollover API 新增Reindex 提供了第一个Java原生的REST客户端SDK 基于HTTP协议的客户端对Elasticsearch的依赖解耦，没有jar包冲突，提供了集群节点自动发现、日志处理、节点请求失败自动进行请求轮询，充分发挥Elasticsearch的高可用能力 新增Wait for refresh，提供了文档级别的Refresh 新增Ingest Node 新增Painless Scripting 新增Task Manager 新增Depreated logging 新增Cluster allocation explain API 新增 half_float 类型 新增 :Matrix Stats Aggregation 为索引写操作添加顺序号 引入新的字段类型 Text&#x2F;Keyword 来替换 String 关于 Index Settings 现在，配置验证更加严格和保证原子性，如果其中一项失败，那个整个都会更新请求都会失败，不会一半成功一半失败。下面主要说两点： 1.设置可以重设会默认值，只需要设置为 null即可 2.获取设置接口新增参数include_defaults,可以直接返回所有设置和默认值 集群管理方面，新增Deleted Index Tombstones Cluster state 的修改现在会和所有节点进行 ack 确认。 Shard 的一个副本如果失败了， Primary 标记失败的时候会和 Master 节点确认完毕再返回。 使用 UUID 来作为索引的物理的路径名，有很多好处，避免命名的冲突。 _timestamp 和 _ttl 已经移除，需要在 Ingest 或者程序端处理。 ES 可直接用 HDFS 来进行备份还原（ Snapshot&#x2F;Restore ）了 Delete-by-query 和 Update-by-query 重新回到 core ，以前是插件，现在可以直接使用了，也是构建在 Reindex 机制之上。(es1.x版本是直接支持，在es2.x中提取为插件，5.x继续回归直接支持) HTTP 请求默认支持压缩，当然 http 调用端需要在 header 信息里面传对应的支持信息。 创建索引不会再让集群变红了，不会因为这个卡死集群了。 默认使用 BM25 评分算法，效果更佳，之前是 TF&#x2F;IDF。 快照 Snapshots 添加 UUID 解决冲突 限制索引请求大小，避免大量并发请求压垮 ES 限制单个请求的 shards 数量，默认 1000 个 移除 site plugins ，就是说 head 、 bigdesk 都不能直接装 es 里面了，不过可以部署独立站点（反正都是静态文件）或开发 kibana 插件 允许现有 parent 类型新增 child 类型 这个功能对于使用parent-child特性的人应该非常有用。 支持分号（；）来分割 url 参数，与符号（ &amp; ）一样 6.0无宕机升级 使之能够从 5 的最后一个版本滚动升级到 6 的最后一个版本，不需要集群的完整重启。无宕机在线升级，无缝滚动升级 跨多个 Elasticsearch 群集搜索 和以前一样，Elasticsearch 6.0 能够读取在 5.x 中创建的 Indices ，但不能读取在 2.x 中创建的 Indices 。不同的是，现在不必重新索引所有的旧 Indices ，你可以选择将其保留在 5.x 群集中，并使用跨群集搜索同时在 6.x 和 5.x 群集上进行搜索 迁移助手 Kibana X-Pack 插件提供了一个简单的用户界面，可帮助重新索引旧 Indices ，以及将 Kibana、Security 和 Watcher 索引升级到 6.0 。 群集检查助手在现有群集上运行一系列检查，以帮助在升级之前更正任何问题。 你还应该查阅弃用日志，以确保您没有使用 6.0 版中已删除的功能 使用序列号更快地重启和还原 6.0 版本中最大的一个新特性就是序列 ID，它允许基于操作的分片恢复。 以前，如果由于网络问题或节点重启而从集群断开连接的节点，则节点上的每个分区都必须通过将分段文件与主分片进行比较并复制任何不同的分段来重新同步。 这可能是一个漫长而昂贵的过程，甚至使节点的滚动重新启动非常缓慢。 使用序列 ID，每个分片将只能重放该分片中缺少的操作，使恢复过程更加高效 使用排序索引更快查询 通过索引排序，只要收集到足够的命中，搜索就可以终止。它对通常用作过滤器的低基数字段（例如 age, gender, is_published）进行排序时可以更高效的搜索，因为所有潜在的匹配文档都被分组在一起。 稀疏区域改进 以前，每个列中的每个字段都预留了一个存储空间。如果只有少数文档出现很多字段，则可能会导致磁盘空间的巨大浪费。现在，你付出你使用的东西。密集字段将使用与以前相同的空间量，但稀疏字段将显着减小。这不仅可以减少磁盘空间使用量，还可以减少合并时间并提高查询吞吐量，因为可以更好地利用文件系统缓存 7.x集群连接变化：TransportClient被废弃 以至于，es7的java代码，只能使用restclient。然后，个人综合了一下，对于java编程，建议采用 High-level-rest-client 的方式操作ES集群 ES数据存储结构变化：去除了Type es6时，官方就提到了es7会删除type，并且es6时已经规定每一个index只能有一个type。在es7中使用默认的_doc作为type，官方说在8.x版本会彻底移除type。 api请求方式也发送变化，如获得某索引的某ID的文档：GET index&#x2F;_doc&#x2F;id其中index和id为具体的值 High-level REST client 改变 已删除接受Header参数的API方法；Cluster Health API默认为集群级别； ES程序包默认打包jdk：以至于7.x版本的程序包大小突然边300MB+ 对比6.x发现，包大了200MB+， 正是JDK的大小 默认配置变化：默认节点名称为主机名，默认分片数改为1，不再是5。 查询相关性速度优化：Weak-AND算法 啥是weak-and算法？ 核心原理：取TOP N结果集，估算命中记录数。 简单来说，一般我们在计算文本相关性的时候，会通过倒排索引的方式进行查询，通过倒排索引已经要比全量遍历节约大量时间，但是有时候仍然很慢。 原因是很多时候我们其实只是想要top n个结果，一些结果明显较差的也进行了复杂的相关性计算， 而weak-and算法通过计算每个词的贡献上限来估计文档的相关性上限，从而建立一个阈值对倒排中的结果进行减枝，从而得到提速的效果。 间隔查询(Intervals queries)： 某些搜索用例（例如，法律和专利搜索）引入了查找单词或短语彼此相距一定距离的记录的需要。 Elasticsearch 7.0中的间隔查询引入了一种构建此类查询的全新方式，与之前的方法（跨度查询span queries）相比，使用和定义更加简单。 与跨度查询相比，间隔查询对边缘情况的适应性更强。 引入新的集群协调子系统 移除 minimum_master_nodes 参数，让 Elasticsearch 自己选择可以形成仲裁的节点。 典型的主节点选举现在只需要很短的时间就可以完成。 集群的伸缩变得更安全、更容易，并且可能造成丢失数据的系统配置选项更少了。 节点更清楚地记录它们的状态，有助于诊断为什么它们不能加入集群或为什么无法选举出主节点。 时间戳纳秒级支持，提升数据精度 加粗样式 不再内存溢出 新的 Circuit Breaker 在JVM 堆栈层面监测内存使用，Elasticsearch 比之前更加健壮。 设置indices.breaker.fielddata.limit的默认值已从JVM堆大小的60％降低到40％。 ES7与旧版本的区别1. 关于 type（类型）使用 kibana 开发工具查询时候，指定类型查询会出现下面的提示： Deprecation: [types removal] Specifying types in document get requests is deprecated, use the &#x2F;{index}&#x2F;_doc&#x2F;{id} endpoint instead. es6时，官方就提到了es7会删除type，并且es6时已经规定每一个index只能有一个type。在es7中使用默认的_doc作为type，官方说在8.x版本会彻底移除type。 api请求方式也发送变化，如获得某索引的某ID的文档： 1GET index/_doc/id 其中index和id为具体的值 2. 弃用 “string”, 使用 “text” 域指定映射的时候使用 String 的话将会报错： 1No handler for type [string] declared on field xxx 使用 text 替代 string","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"数据库","slug":"开发笔记/数据库","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"es","slug":"开发笔记/数据库/es","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/es/"}],"tags":[]},{"title":"","slug":"开发笔记/Apdex 应用性能指数","date":"2022-12-12T17:36:23.237Z","updated":"2022-12-12T17:36:23.237Z","comments":true,"path":"2022/12/12/开发笔记/Apdex 应用性能指数/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/Apdex%20%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD%E6%8C%87%E6%95%B0/","excerpt":"","text":"Apdex 应用性能指数是站在用户角度衡量用户对应用满意度的数值。 假设用户对于服务的响应容忍度权值为 T 满意（1分） 容忍（0.5分） 失望（0分） 0~T T~4T 4T~ Apdex指数 &#x3D; (满意样本 x 1 + 容忍样本 x 0.5)&#x2F; 样本总数","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"","slug":"开发笔记/Elasticsearch Java Rest Client","date":"2022-12-12T17:36:23.237Z","updated":"2022-12-12T17:36:23.237Z","comments":true,"path":"2022/12/12/开发笔记/Elasticsearch Java Rest Client/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/Elasticsearch%20Java%20Rest%20Client/","excerpt":"","text":"基于 Elasticsearch 6.x 概述Rest client 分成两部分： Java Low Level REST Client官方低级别 es 客户端，使用 http 协议与 Elastiicsearch 集群通信，与所有 es 版本兼容。 Java High level REST Client官方高级别 es 客户端，基于低级别的客户端，它会暴露 API 特定的方法。 使用方法： 12345&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;6.3.2&lt;/version&gt;&lt;/dependency&gt; 初始化： 1234RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(&quot;localhost&quot;, 9200, &quot;http&quot;), new HttpHost(&quot;localhost&quot;, 9201, &quot;http&quot;))); 文档(Document) API单文档 API index API Get API Delete API Update API 多文档 API Bulk API Multi-Get API Index APIIndexRequest四种方式构建 IndexRequest： json 12345678910IndexRequest indexRequest = new IndexRequest( &quot;posts&quot;, // 索引 Index &quot;doc&quot;, // Type &quot;1&quot;); // 文档 Document Id String jsonString = &quot;&#123;&quot; + &quot;\\&quot;user\\&quot;:\\&quot;kimchy\\&quot;,&quot; + &quot;\\&quot;postDate\\&quot;:\\&quot;2013-01-30\\&quot;,&quot; + &quot;\\&quot;message\\&quot;:\\&quot;trying out Elasticsearch\\&quot;&quot; + &quot;&#125;&quot;;indexRequest.source(jsonString, XContentType.JSON); // 文档源格式为 json string Map 123456Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;();jsonMap.put(&quot;user&quot;, &quot;kimchy&quot;);jsonMap.put(&quot;postDate&quot;, new Date());jsonMap.put(&quot;message&quot;, &quot;trying out Elasticsearch&quot;);IndexRequest indexRequest = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .source(jsonMap); // 会自动将 Map 转换为 JSON 格式 XContentBuilder : Document Source 提供的帮助类，专门用来产生 json 格式的数据 12345678910XContentBuilder builder = XContentFactory.jsonBuilder();builder.startObject();&#123; builder.field(&quot;user&quot;, &quot;kimchy&quot;); builder.timeField(&quot;postDate&quot;, new Date()); builder.field(&quot;message&quot;, &quot;trying out Elasticsearch&quot;);&#125;builder.endObject();IndexRequest indexRequest = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .source(builder); Object 键值对 1234IndexRequest indexRequest = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .source(&quot;user&quot;, &quot;kimchy&quot;, &quot;postDate&quot;, new Date(), &quot;message&quot;, &quot;trying out Elasticsearch&quot;); 同步索引1IndexResponse indexResponse = client.index(indexRequest); 异步索引异步执行函数需要添加 listener 作为回调函数, 而对于 index 而言，这个 listener 的类型就是 ActionListener 12345678910111213ActionListener&lt;IndexResponse&gt; listener = new ActionListener&lt;IndexResponse&gt;() &#123; @Override public void onResponse(IndexResponse indexResponse) &#123; //执行成功，调用 onResponse 函数 &#125; @Override public void onFailure(Exception e) &#123; //执行失败，调用 onFailure 函数 &#125;&#125;;IndexResponse indexResponse = client.indexAsync(indexRequest, listener); IndexResponse不管是同步还是异步，如果调用成功，都会返回 IndexRespose 对象。 123456789101112131415161718tring index = indexResponse.getIndex();String type = indexResponse.getType();String id = indexResponse.getId();long version = indexResponse.getVersion();if (indexResponse.getResult() == DocWriteResponse.Result.CREATED) &#123; // 文档第一次创建 &#125; else if (indexResponse.getResult() == DocWriteResponse.Result.UPDATED) &#123; // 文档之前已存在，当前是重写&#125;ReplicationResponse.ShardInfo shardInfo = indexResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; // 成功的分片数量少于总分片数量 &#125;if (shardInfo.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); // 处理潜在的失败信息 &#125;&#125; GET APIGetRequest每个 GET 请求都必须需传入下面 3 个参数： Index Type Document id 1234GetRequest getRequest = new GetRequest( &quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;); 可选参数： 不获取源数据，默认是获取的 1getRequest.fetchSourceContext(FetchSourceContext.DO_NOT_FETCH_SOURCE); 配置返回数据中包含指定字段 12345String[] includes = new String[]&#123;&quot;message&quot;, &quot;*Date&quot;&#125;;String[] excludes = Strings.EMPTY_ARRAY;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);getRequest.fetchSourceContext(fetchSourceContext); 配置返回数据中排除指定字段 12345String[] includes = Strings.EMPTY_ARRAY;String[] excludes = new String[]&#123;&quot;message&quot;&#125;;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);getRequest.fetchSourceContext(fetchSourceContext); 实时 默认为 true 1getRequest.realtime(false); 版本 1getRequest.version(2); 版本类型 1getRequest.versionType(VersionType.EXTERNAL); 执行同步执行： 1GetResponse getResponse = client.get(getRequest); 异步执行： 12345678910111213ActionListener&lt;IndexResponse&gt; listener = new ActionListener&lt;IndexResponse&gt;() &#123; @Override public void onResponse(IndexResponse indexResponse) &#123; //执行成功，调用 onResponse 函数 &#125; @Override public void onFailure(Exception e) &#123; //执行失败，调用 onFailure 函数 &#125;&#125;;GetResponse getResponse = client.indexAsync(indexRequest, listener); GetResponse返回的 GetResponse 对象包含要请求的文档数据（包含元数据和字段） 1234567891011String index = getResponse.getIndex();String type = getResponse.getType();String id = getResponse.getId();if (getResponse.isExists()) &#123; long version = getResponse.getVersion(); String sourceAsString = getResponse.getSourceAsString(); // string 形式 Map&lt;String, Object&gt; sourceAsMap = getResponse.getSourceAsMap(); // map byte[] sourceAsBytes = getResponse.getSourceAsBytes(); // 字节形式 &#125; else &#123; // 没有发现请求的文档 &#125; Exists API如果文档存在 Exists API 返回 true, 否则返回 fasle。 GetRequest用法和 Get API 差不多，两个对象的可选参数是相同的。由于 exists() 方法只返回 true 或者 false， 应该将获取 _source 以及任何存储字段的值关闭，尽量使请求轻量级。 123456GetRequest getRequest = new GetRequest( &quot;posts&quot;, // Index &quot;doc&quot;, // Type &quot;1&quot;); // Document idgetRequest.fetchSourceContext(new FetchSourceContext(false)); // 禁用 _source 字段getRequest.storedFields(&quot;_none_&quot;); // 禁止存储任何字段 执行同步执行： 1boolean exists = client.exists(getRequest); 异步执行： 12345678910111213ActionListener&lt;Boolean&gt; listener = new ActionListener&lt;Boolean&gt;() &#123; @Override public void onResponse(Boolean exists) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;boolean exists = client.existsAsync(getRequest, listener); Delete APIDeleteRequestDeleteRequest 必须传入下面参数： Index Type Document id 1234DeleteRequest deleteRequest = new DeleteRequest( &quot;posts&quot;, // index &quot;doc&quot;, // doc &quot;1&quot;); // document id 可选参数： 超时时间 12deleteRequest.timeout(TimeValue.timeValueMinutes(2)); deleteRequest.timeout(&quot;2m&quot;); 刷新策略 12deleteRequest.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); deleteRequest.setRefreshPolicy(&quot;wait_for&quot;); 版本 1deleteRequest.version(2); 版本类型 1deleteRequest.versionType(VersionType.EXTERNAL); 执行同步执行： 1DeleteResponse deleteResponse = client.delete(deleteRequest); 异步执行 12345678910111213ActionListener&lt;DeleteResponse&gt; listener = new ActionListener&lt;DeleteResponse&gt;() &#123; @Override public void onResponse(DeleteResponse deleteResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;DeleteResponse deleteResponse = client.deleteAsync(deleteResponse, listener); DeleteResponseDeleteResponse 可以检索执行操作的信息 12345678910111213String index = deleteResponse.getIndex();String type = deleteResponse.getType();String id = deleteResponse.getId();long version = deleteResponse.getVersion();ReplicationResponse.ShardInfo shardInfo = deleteResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; // 成功分片数目小于总分片&#125;if (shardInfo.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); // 处理潜在失败 &#125;&#125; Update APIUpdateRequestUpdateRequest 必须传入下面参数： Index Type Document id 1234UpdateRequest updateRequest = new DeleteRequest( &quot;posts&quot;, // index &quot;doc&quot;, // doc &quot;1&quot;); // document id 和 index api 类似，UpdateRequest 也支持四种文档格式： json 123456UpdateRequest updateRequest = new UpdateRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;);String jsonString = &quot;&#123;&quot; + &quot;\\&quot;updated\\&quot;:\\&quot;2017-01-01\\&quot;,&quot; + &quot;\\&quot;reason\\&quot;:\\&quot;daily update\\&quot;&quot; + &quot;&#125;&quot;;request.doc(jsonString, XContentType.JSON); map 12345Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;();jsonMap.put(&quot;updated&quot;, new Date());jsonMap.put(&quot;reason&quot;, &quot;daily update&quot;);UpdateRequest updateRequest = new UpdateRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .doc(jsonMap); XContentBuilder 123456789XContentBuilder builder = XContentFactory.jsonBuilder();builder.startObject();&#123; builder.timeField(&quot;updated&quot;, new Date()); builder.field(&quot;reason&quot;, &quot;daily update&quot;);&#125;builder.endObject();UpdateRequest updateRequest = new UpdateRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .doc(builder); object 键值对 123UpdateRequest updateRequest = new UpdateRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .doc(&quot;updated&quot;, new Date(), &quot;reason&quot;, &quot;daily update&quot;); 可选参数： 超时时间 12updateRequest.timeout(TimeValue.timeValueSeconds(1)); updateRequest.timeout(&quot;1s&quot;); 刷新策略 12updateRequest.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); updateRequest.setRefreshPolicy(&quot;wait_for&quot;); 冲突后重试次数 1updateRequest.retryOnConflict(3); 获取数据源，默认是开启的 1updateRequest.fetchSource(true); 包括特定字段 123String[] includes = new String[]&#123;&quot;updated&quot;, &quot;r*&quot;&#125;;String[] excludes = Strings.EMPTY_ARRAY;updateRequest.fetchSource(new FetchSourceContext(true, includes, excludes)); 排除特定字段 123String[] includes = Strings.EMPTY_ARRAY;String[] excludes = new String[]&#123;&quot;updated&quot;&#125;;updateRequest.fetchSource(new FetchSourceContext(true, includes, excludes)); 指定版本 1updateRequest.version(2); 禁用 noop detection 1updateRequest.scriptedUpsert(true); 设置如果更新的文档不存在，就必须要创建一个 1updateRequest.docAsUpsert(true); 执行同步执行： 1UpdateResponse updateResponse = client.update(updateRequest); 异步执行： 12345678910111213ActionListener&lt;UpdateResponse&gt; listener = new ActionListener&lt;UpdateResponse&gt;() &#123; @Override public void onResponse(UpdateResponse updateResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;UpdateResponse updateResponse = client.updateAsync(request, listener); UpdateResponse12345678910111213String index = updateResponse.getIndex();String type = updateResponse.getType();String id = updateResponse.getId();long version = updateResponse.getVersion();if (updateResponse.getResult() == DocWriteResponse.Result.CREATED) &#123; // 文档已创建&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.UPDATED) &#123; // 文档已更新&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.DELETED) &#123; // 文档已删除&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.NOOP) &#123; // 文档不受更新的影响&#125; 如果在 UpdateRequest 中设置了获取源数据，响应中则包含了更新后的源文档信息： 12345678GetResult result = updateResponse.getGetResult(); if (result.isExists()) &#123; String sourceAsString = result.sourceAsString(); // 将获取的文档以 string 格式输出 Map&lt;String, Object&gt; sourceAsMap = result.sourceAsMap(); // 以 Map 格式输出 byte[] sourceAsBytes = result.source(); // 字节形式&#125; else &#123; // 默认情况下，不会返回文档源数据&#125; 检测是否分片失败： 123456789ReplicationResponse.ShardInfo shardInfo = updateResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; // 成功的分片数量小于总分片数量&#125;if (shardInfo.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); // 得到分片失败的原因 &#125;&#125; Bulk API 批量处理BulkRequest 批量请求使用 BulkRequest 可以在一次请求中执行多个索引，更新和删除的操作: 1234567BulkRequest request = new BulkRequest(); request.add(new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .source(XContentType.JSON,&quot;field&quot;, &quot;foo&quot;)); // 将第一个 IndexRequest 添加到批量请求中request.add(new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;2&quot;) .source(XContentType.JSON,&quot;field&quot;, &quot;bar&quot;)); // 第二个request.add(new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;3&quot;) .source(XContentType.JSON,&quot;field&quot;, &quot;baz&quot;)); // 第三个 在同一个 BulkRequest 也可以添加不同的操作类型: 123456BulkRequest bulkRequest = new BulkRequest();bulkRequest.add(new DeleteRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;3&quot;)); bulkRequest.add(new UpdateRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;2&quot;) .doc(XContentType.JSON,&quot;other&quot;, &quot;test&quot;));jbulkRequest.add(new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;4&quot;) .source(XContentType.JSON,&quot;field&quot;, &quot;baz&quot;)); 可选参数： 超时时间 12bulkRequest.timeout(TimeValue.timeValueMinutes(2)); bulkRequest.timeout(&quot;2m&quot;); 刷新策略 12bulkRequest.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); bulkRequest.setRefreshPolicy(&quot;wait_for&quot;); 设置在批量操作前必须有几个分片处于激活状态 1234bulkRequest.waitForActiveShards(2); bulkRequest.waitForActiveShards(ActiveShardCount.ALL); // 全部分片都处于激活状态bulkRequest.waitForActiveShards(ActiveShardCount.DEFAULT); // 默认bulkRequest.waitForActiveShards(ActiveShardCount.ONE); // 一个 执行同步请求： 1BulkResponse bulkResponse = client.bulk(request); 异步请求： 12345678910111213ActionListener&lt;BulkResponse&gt; listener = new ActionListener&lt;BulkResponse&gt;() &#123; @Override public void onResponse(BulkResponse bulkResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;BulkResponse bulkResponse = client.bulkAsync(request, listener); BulkResponseBulkResponse 中包含执行操作后的信息，并允许对每个操作结果迭代 1234567891011121314for (BulkItemResponse bulkItemResponse : bulkResponse) &#123; // 遍历所有的操作结果 DocWriteResponse itemResponse = bulkItemResponse.getResponse(); // 获取操作结果的响应，可以是 IndexResponse, UpdateResponse or DeleteResponse, 它们都可以惭怍是 DocWriteResponse 实例 if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.INDEX || bulkItemResponse.getOpType() == DocWriteRequest.OpType.CREATE) &#123; IndexResponse indexResponse = (IndexResponse) itemResponse; // index 操作后的响应结果 &#125; else if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.UPDATE) &#123; UpdateResponse updateResponse = (UpdateResponse) itemResponse; // update 操作后的响应结果 &#125; else if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.DELETE) &#123; DeleteResponse deleteResponse = (DeleteResponse) itemResponse; // delete 操作后的响应结果 &#125;&#125; 此外，批量响应还有一个非常便捷的方法来检测是否有一个或多个操作失败 12345678if (bulkResponse.hasFailures()) &#123; // 表示至少有一个操作失败 // 遍历所有的操作结果，检查是否是失败的操作，并获取对应的失败信息 for (BulkItemResponse bulkItemResponse : bulkResponse) &#123; if (bulkItemResponse.isFailed()) &#123; // 检测给定的操作是否失败 BulkItemResponse.Failure failure = bulkItemResponse.getFailure(); // 获取失败信息 &#125; &#125;&#125; BulkProcessorBulkProcessor 是为了简化 Bulk API 的操作提供的一个工具类，要执行操作，就需要下面组件: RestHighLevelClient 用来执行 BulkRequest 并获取 BulkResponse BulkProcessor.Listener 对 BulkRequest 执行前后以及失败时监听 BulkProcessor.builder 方法用来构建一个新的 BulkProcessor： 1234567891011121314151617181920ulkProcessor.Listener listener = new BulkProcessor.Listener() &#123; @Override public void beforeBulk(long executionId, BulkRequest request) &#123; // 在每个 BulkRequest 执行前调用 &#125; @Override public void afterBulk(long executionId, BulkRequest request, BulkResponse response) &#123; // 在每个 BulkRequest 执行后调用 &#125; @Override public void afterBulk(long executionId, BulkRequest request, Throwable failure) &#123; // 失败时调用 &#125;&#125;;BulkProcessor bulkProcessor = BulkProcessor.builder(client::bulkAsync, listener).build(); // 构建 BulkProcessor, RestHighLevelClient.bulkAsync() 用来执行 BulkRequest BulkProcessor.Builder 提供了多个方法来配置 BulkProcessor 如何来处理请求的执行: 1234567BulkProcessor.Builder builder = BulkProcessor.builder(client::bulkAsync, listener);builder.setBulkActions(500); // 指定多少操作时，就会刷新一次builder.setBulkSize(new ByteSizeValue(1L, ByteSizeUnit.MB)); builder.setConcurrentRequests(0); // 指定多大容量，就会刷新一次builder.setFlushInterval(TimeValue.timeValueSeconds(10L)); // 允许并发执行的数量 builder.setBackoffPolicy(BackoffPolicy .constantBackoff(TimeValue.timeValueSeconds(1L), 3)); BulkProcessor 创建后，各种请求就可以添加进去： 12345678910111213IndexRequest one = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;). source(XContentType.JSON, &quot;title&quot;, &quot;In which order are my Elasticsearch queries executed?&quot;);IndexRequest two = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;2&quot;) .source(XContentType.JSON, &quot;title&quot;, &quot;Current status and upcoming changes in Elasticsearch&quot;);IndexRequest three = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;3&quot;) .source(XContentType.JSON, &quot;title&quot;, &quot;The Future of Federated Search in Elasticsearch&quot;);bulkProcessor.add(one);bulkProcessor.add(two);bulkProcessor.add(three); BulkProcessor 执行时，会对每个 bulk request调用 BulkProcessor.Listener ， listener 提供了下面方法来访问 BulkRequest 和 BulkResponse: 123456789101112131415161718192021222324BulkProcessor.Listener listener = new BulkProcessor.Listener() &#123; @Override public void beforeBulk(long executionId, BulkRequest request) &#123; int numberOfActions = request.numberOfActions(); // 在执行前获取操作的数量 logger.debug(&quot;Executing bulk [&#123;&#125;] with &#123;&#125; requests&quot;, executionId, numberOfActions); &#125; @Override public void afterBulk(long executionId, BulkRequest request, BulkResponse response) &#123; if (response.hasFailures()) &#123; // 执行后查看响应中是否包含失败的操作 logger.warn(&quot;Bulk [&#123;&#125;] executed with failures&quot;, executionId); &#125; else &#123; logger.debug(&quot;Bulk [&#123;&#125;] completed in &#123;&#125; milliseconds&quot;, executionId, response.getTook().getMillis()); &#125; &#125; @Override public void afterBulk(long executionId, BulkRequest request, Throwable failure) &#123; logger.error(&quot;Failed to execute bulk&quot;, failure); // 请求失败时打印信息 &#125;&#125;; 请求添加到 BulkProcessor ， 它的实例可以使用下面两种方法关闭请求： awaitClose() 在请求返回后或等待一定时间关闭 1boolean terminated = bulkProcessor.awaitClose(30L, TimeUnit.SECONDS); close() 立刻关闭 1bulkProcessor.close(); 两个方法都会在关闭前对处理器中的请求进行刷新，并避免新的请求添加进去。 Multi-Get APImultiGet API 可以在单个 http 交互中并行的执行多个 get 请求。 MultiGetRequestMultiGetRequest 实例化时参数为空，实例化后可以通过添加 MultiGetRequest.Item 来配置获取的信息 123456MultiGetRequest request = new MultiGetRequest();request.add(new MultiGetRequest.Item( &quot;index&quot;, // 索引 &quot;type&quot;, // 类型 &quot;example_id&quot;)); // 文档 idjrequest.add(new MultiGetRequest.Item(&quot;index&quot;, &quot;type&quot;, &quot;another_id&quot;)); // 添加另外一个条目 可选参数： 与前面 Get API 可选参数相同 执行同步执行： 1MultiGetResponse response = client.multiGet(request); 异步执行： 12345678910111213ActionListener&lt;MultiGetResponse&gt; listener = new ActionListener&lt;MultiGetResponse&gt;() &#123; @Override public void onResponse(MultiGetResponse response) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;client.multiGetAsync(request, listener); MultiGetResponseMultiGetResponse 中getResponse 方法包含的 MultiGetItemResponse 顺序与请求时的相 MultiGetItemResponse ，如果执行成功，就会返回 GetResponse 对象，失败则返回 MultiGetResponse.Failure 12345678910111213141516MultiGetItemResponse firstItem = response.getResponses()[0];assertNull(firstItem.getFailure()); // 执行成功，则返回 null GetResponse firstGet = firstItem.getResponse(); // 返回 GetResponse 对象String index = firstItem.getIndex();String type = firstItem.getType();String id = firstItem.getId();if (firstGet.isExists()) &#123; long version = firstGet.getVersion(); String sourceAsString = firstGet.getSourceAsString(); // string 格式 Map&lt;String, Object&gt; sourceAsMap = firstGet.getSourceAsMap(); // Map byte[] sourceAsBytes = firstGet.getSourceAsBytes(); // bytes &#125; else &#123; // 没有发现文档 // 尽管响应中会返回 404 状态码，也会返回一个有效的 GetResponse // 这是可以使用 isExists 方法来判断&#125; 如果子请求中对应的 index 不存在，返回的响应中的getFailure 方法中会包含 exception: 1234567assertNull(missingIndexItem.getResponse()); // 获取的响应为空 Exception e = missingIndexItem.getFailure().getFailure(); // 获取 exceptionElasticsearchException ee = (ElasticsearchException) e; // TODO status is broken! fix in a followup// assertEquals(RestStatus.NOT_FOUND, ee.status()); assertThat(e.getMessage(), containsString(&quot;reason=no such index&quot;)); 查询（Search）APIJava High Level REST Client 支持下面的 Search API： Search API Search Scroll API Clear Scroll API Multi-Search API Ranking Evaluation API Search APISearchRequestsearchRequest 用来完成和搜索文档，聚等相关的操作同时也提供了各种方式来完成对查询结果的高亮操作。 最基本的查询操作如下: 1234SearchRequest searchRequest = new SearchRequest(); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchAllQuery()); // 添加 match_all 查询searchRequest.source(searchSourceBuilder); // 将 SearchSourceBuilder 添加到 SeachRequest 中 可选参数: 1234SearchRequest searchRequest = new SearchRequest(&quot;posts&quot;); // 设置搜索的 indexsearchRequest.types(&quot;doc&quot;); // 设置搜索的 typesearchRequest.routing(&quot;routing&quot;); // 设置 routing 参数searchRequest.preference(&quot;_local&quot;); // 配置搜索时偏爱使用本地分片，默认是使用随机分片 SearchSourceBuilder对搜索行为的配置可以使用 SearchSourceBuilder 来完成: 12345678SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); // 默认配置sourceBuilder.query(QueryBuilders.termQuery(&quot;user&quot;, &quot;kimchy&quot;)); // 设置搜索，可以是任何类型的 QueryBuildersourceBuilder.from(0); // 起始 indexsourceBuilder.size(5); // 大小 sizesourceBuilder.timeout(new TimeValue(60, TimeUnit.SECONDS)); // 设置搜索的超时时间SearchRequest searchRequest = new SearchRequest();searchRequest.source(sourceBuilder); SearchSourceBuilder 可选配置有： 1. 构建查询条件查询请求是通过使用 QueryBuilder 对象来完成的，并且支持 Query DSL（领域特定语言，是指专注于某个应用程序领域的计算机语言）。 使用构造函数来创建 QueryBuilder： 123456MatchQueryBuilder matchQueryBuilder = new MatchQueryBuilder(&quot;user&quot;, &quot;kimchy&quot;); // 配置查询选项matchQueryBuilder.fuzziness(Fuzziness.AUTO); // 模糊查询matchQueryBuilder.prefixLength(3); // 前缀查询的长度matchQueryBuilder.maxExpansions(10); // max expansion 选项，用来控制模糊查询 也可以使用QueryBuilders 工具类来创建 QueryBuilder 对象。这个类提供了函数式编程风格的各种方法用来快速创建 QueryBuilder 对象。 1234QueryBuilder matchQueryBuilder = QueryBuilders.matchQuery(&quot;user&quot;, &quot;kimchy&quot;) .fuzziness(Fuzziness.AUTO) .prefixLength(3) .maxExpansions(10); 最后要添加到 SearchSourceBuilder 中: 1searchSourceBuilder.query(matchQueryBuilder); 2. 指定排序SearchSourceBuilder 允许添加一个或多个SortBuilder 实例。这里包含 4 种特殊的实现, (Field-, Score-, GeoDistance- 和 ScriptSortBuilder) 12sourceBuilder.sort(new ScoreSortBuilder().order(SortOrder.DESC)); // 根据分数 _score 降序排列 (默认行为)sourceBuilder.sort(new FieldSortBuilder(&quot;_uid&quot;).order(SortOrder.ASC)); // 根据 id 降序排列 3. 过滤数据源默认情况下，查询请求会返回文档的内容 _source ,当然我们也可以配置它。例如，禁止对 _source 的获取 1sourceBuilder.fetchSource(false); 也可以使用通配符模式以更细的粒度包含或排除特定的字段: 123String[] includeFields = new String[] &#123;&quot;title&quot;, &quot;user&quot;, &quot;innerObject.*&quot;&#125;;String[] excludeFields = new String[] &#123;&quot;_type&quot;&#125;;sourceBuilder.fetchSource(includeFields, excludeFields); 4. 高亮请求可以通过在 SearchSourceBuilder 上设置 HighlightBuilder 完成对结果的高亮，而且可以配置不同的字段具有不同的高亮行为。 123456789SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();HighlightBuilder highlightBuilder = new HighlightBuilder(); HighlightBuilder.Field highlightTitle = new HighlightBuilder.Field(&quot;title&quot;); // title 字段高亮highlightTitle.highlighterType(&quot;unified&quot;); // 配置高亮类型highlightBuilder.field(highlightTitle); // 添加到 builderHighlightBuilder.Field highlightUser = new HighlightBuilder.Field(&quot;user&quot;);highlightBuilder.field(highlightUser);searchSourceBuilder.highlighter(highlightBuilder); 5. 聚合请求要实现聚合请求分两步 创建合适的 AggregationBuilder 作为参数配置在 SearchSourceBuilder 123456SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();TermsAggregationBuilder aggregation = AggregationBuilders.terms(&quot;by_company&quot;) .field(&quot;company.keyword&quot;);aggregation.subAggregation(AggregationBuilders.avg(&quot;average_age&quot;) .field(&quot;age&quot;));searchSourceBuilder.aggregation(aggregation); 6. 建议请求 Requesting SuggestionsSuggestionBuilder 实现类是由 SuggestBuilders 工厂类来创建的。 123456SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();SuggestionBuilder termSuggestionBuilder = SuggestBuilders.termSuggestion(&quot;user&quot;).text(&quot;kmichy&quot;); SuggestBuilder suggestBuilder = new SuggestBuilder();suggestBuilder.addSuggestion(&quot;suggest_user&quot;, termSuggestionBuilder); searchSourceBuilder.suggest(suggestBuilder); 7. 对请求和聚合分析分析 API 可用来对一个特定的查询操作中的请求和聚合进行分析，此时要将SearchSourceBuilder 的 profile标志位设置为 true 12SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();searchSourceBuilder.profile(true); 执行同步执行 同步执行是阻塞式的，只有结果返回后才能继续执行 1SearchResponse searchResponse = client.search(searchRequest); 异步执行 异步执行使用的是 listener 对结果进行处理 12345678910111213ActionListener&lt;SearchResponse&gt; listener = new ActionListener&lt;SearchResponse&gt;() &#123; @Override public void onResponse(SearchResponse searchResponse) &#123; // 查询成功 &#125; @Override public void onFailure(Exception e) &#123; // 查询失败 &#125;&#125;;SearchResponse searchResponse = client.search(searchRequest); SearchResponse查询执行完成后，会返回 SearchResponse 对象，并在对象中包含查询执行的细节和符合条件的文档集合。 SerchResponse 包含的信息如下： 请求本身的信息，如 HTTP 状态码，执行时间，或者请求是否超时 1234RestStatus status = searchResponse.status(); // HTTP 状态码TimeValue took = searchResponse.getTook(); // 查询占用的时间Boolean terminatedEarly = searchResponse.isTerminatedEarly(); // 是否由于 SearchSourceBuilder 中设置 terminateAfter 而过早终止boolean timedOut = searchResponse.isTimedOut(); // 是否超时 查询影响的分片数量的统计信息，成功和失败的分片 123456int totalShards = searchResponse.getTotalShards();int successfulShards = searchResponse.getSuccessfulShards();int failedShards = searchResponse.getFailedShards();for (ShardSearchFailure failure : searchResponse.getShardFailures()) &#123; // failures should be handled here&#125; SearchHits 1234567891011121314151617181920SearchHits hits = searchResponse.getHits();long totalHits = hits.getTotalHits();float maxScore = hits.getMaxScore();SearchHit[] searchHits = hits.getHits();for (SearchHit hit : searchHits) &#123; // do something with the SearchHit String index = hit.getIndex(); String type = hit.getType(); String id = hit.getId(); float score = hit.getScore(); // 获取文档源数据 String sourceAsString = hit.getSourceAsString(); Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); String documentTitle = (String) sourceAsMap.get(&quot;title&quot;); List&lt;Object&gt; users = (List&lt;Object&gt;) sourceAsMap.get(&quot;user&quot;); Map&lt;String, Object&gt; innerObject = (Map&lt;String, Object&gt;) sourceAsMap.get(&quot;innerObject&quot;);&#125;","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"","slug":"开发笔记/GraphQL 入门","date":"2022-12-12T17:36:23.237Z","updated":"2022-12-12T17:36:23.237Z","comments":true,"path":"2022/12/12/开发笔记/GraphQL 入门/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/GraphQL%20%E5%85%A5%E9%97%A8/","excerpt":"","text":"GraphQL 入门GraphQL 是一个用于 API 的查询语言，是一个使用基于类型系统来执行查询的服务端运行时（类型系统由你的数据定义）。GraphQL 并没有和任何特定数据库或者存储引擎绑定，而是依靠你现有的代码和数据支撑。 一个 GraphQL 服务是通过定义类型和类型上的字段来创建的，然后给每个类型上的每个字段提供解析函数。例如，一个 GraphQL 服务告诉我们当前登录用户是 me，这个用户的名称可能像这样： 12345678type Query &#123; me: User&#125;type User &#123; id: ID name: String&#125; 一并的还有每个类型上字段的解析函数： 1234567function Query_me(request) &#123; return request.auth.user;&#125;function User_name(user) &#123; return user.getName();&#125; 一旦一个 GraphQL 服务运行起来（通常在 web 服务的一个 URL 上），它就能接收 GraphQL 查询，并验证和执行。接收到的查询首先会被检查确保它只引用了已定义的类型和字段，然后运行指定的解析函数来生成结果。 例如： 12345&#123; me &#123; name &#125;&#125; 返回结果： 12345&#123; &quot;me&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot; &#125;&#125; GraphQL 的查询和变更字段（Fields）简单而言，GraphQL 是关于请求对象上的特定字段。我们以一个非常简单的查询以及其结果为例： 12345&#123; hero &#123; name &#125;&#125; 1234567&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot; &#125; &#125;&#125; 查询和其结果拥有几乎一样的结构。这是 GraphQL 最重要的特性，因为这样一来，你就总是能得到你想要的数据，而服务器也准确地知道客户端请求的字段。 name 字段返回 String 类型，在这个示例中是《星球大战》主角的名字是：&quot;R2-D2&quot;。 前一例子中，我们请求了我们主角的名字，返回了一个字符串类型（String），但是字段也能指代对象类型（Object）。这个时候，你可以对这个对象的字段进行次级选择（sub-selection）。GraphQL 查询能够遍历相关对象及其字段，使得客户端可以一次请求查询大量相关数据，而不像传统 REST 架构中那样需要多次往返查询。 123456789&#123; hero &#123; name # 查询可以有备注！ friends &#123; name &#125; &#125;&#125; 123456789101112131415161718&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;friends&quot;: [ &#123; &quot;name&quot;: &quot;Luke Skywalker&quot; &#125;, &#123; &quot;name&quot;: &quot;Han Solo&quot; &#125;, &#123; &quot;name&quot;: &quot;Leia Organa&quot; &#125; ] &#125; &#125;&#125; 这个例子中，friends 返回了一个数组的项目，GraphQL 查询会同等看待单个项目或者一个列表的项目，然而我们可以通过 schema 所指示的内容来预测将会得到哪一种。 参数（Arguments）即使我们能做的仅仅是遍历对象及其字段，GraphQL 就已经是一个非常有用的数据查询语言了。但是当你加入给字段传递参数的能力时，事情会变得更加有趣。 123456&#123; human(id: &quot;1000&quot;) &#123; name height &#125;&#125; 12345678&#123; &quot;data&quot;: &#123; &quot;human&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot;, &quot;height&quot;: 1.72 &#125; &#125;&#125; 参数可以是多种不同的类型。上面例子中，我们使用了一个枚举类型，其代表了一个有限选项集合（本例中为长度单位，即是 METER 或者 FOOT）。GraphQL 自带一套默认类型，但是 GraphQL 服务器可以声明一套自己的定制类型，只要能序列化成你的传输格式即可。 更多的 GraphQL 类型系统请点击这里 别名（Aliases）如果你眼睛够锐利，你可能已经发现，即便结果中的字段与查询中的字段能够匹配，但是因为他们并不包含参数，你就没法通过不同参数来查询相同字段。这便是为何你需要别名 —— 这可以让你重命名结果中的字段为任意你想到的名字。 12345678&#123; empireHero: hero(episode: EMPIRE) &#123; name &#125; jediHero: hero(episode: JEDI) &#123; name &#125;&#125; 12345678910&#123; &quot;data&quot;: &#123; &quot;empireHero&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot; &#125;, &quot;jediHero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot; &#125; &#125;&#125; 上例中，两个 hero 字段将会存在冲突，但是因为我们可以将其另取一个别名，我们也就可以在一次请求中得到两个结果。 片段（Fragments）假设我们的 app 有比较复杂的页面，将正反派主角及其友军分为两拨。你立马就能想到对应的查询会变得复杂，因为我们需要将一些字段重复至少一次 —— 两方各一次以作比较。 这就是为何 GraphQL 包含了称作片段的可复用单元。片段使你能够组织一组字段，然后在需要它们的的地方引入。下面例子展示了如何使用片段解决上述场景： 12345678910111213141516&#123; leftComparison: hero(episode: EMPIRE) &#123; ...comparisonFields &#125; rightComparison: hero(episode: JEDI) &#123; ...comparisonFields &#125;&#125;fragment comparisonFields on Character &#123; name appearsIn friends &#123; name &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445&#123; &quot;data&quot;: &#123; &quot;leftComparison&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot;, &quot;appearsIn&quot;: [ &quot;NEWHOPE&quot;, &quot;EMPIRE&quot;, &quot;JEDI&quot; ], &quot;friends&quot;: [ &#123; &quot;name&quot;: &quot;Han Solo&quot; &#125;, &#123; &quot;name&quot;: &quot;Leia Organa&quot; &#125;, &#123; &quot;name&quot;: &quot;C-3PO&quot; &#125;, &#123; &quot;name&quot;: &quot;R2-D2&quot; &#125; ] &#125;, &quot;rightComparison&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;appearsIn&quot;: [ &quot;NEWHOPE&quot;, &quot;EMPIRE&quot;, &quot;JEDI&quot; ], &quot;friends&quot;: [ &#123; &quot;name&quot;: &quot;Luke Skywalker&quot; &#125;, &#123; &quot;name&quot;: &quot;Han Solo&quot; &#125;, &#123; &quot;name&quot;: &quot;Leia Organa&quot; &#125; ] &#125; &#125;&#125; 你可以看到上面的查询如何漂亮地重复了字段。片段的概念经常用于将复杂的应用数据需求分割成小块，特别是你要将大量不同片段的 UI 组件组合成一个初始数据获取的时候。 在片段内使用变量 片段可以访问查询或变更中声明的变量。详见 变量。 1234567891011121314151617181920query HeroComparison($first: Int = 3) &#123; leftComparison: hero(episode: EMPIRE) &#123; ...comparisonFields &#125; rightComparison: hero(episode: JEDI) &#123; ...comparisonFields &#125;&#125;fragment comparisonFields on Character &#123; name friendsConnection(first: $first) &#123; totalCount edges &#123; node &#123; name &#125; &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&#123; &quot;data&quot;: &#123; &quot;leftComparison&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot;, &quot;friendsConnection&quot;: &#123; &quot;totalCount&quot;: 4, &quot;edges&quot;: [ &#123; &quot;node&quot;: &#123; &quot;name&quot;: &quot;Han Solo&quot; &#125; &#125;, &#123; &quot;node&quot;: &#123; &quot;name&quot;: &quot;Leia Organa&quot; &#125; &#125;, &#123; &quot;node&quot;: &#123; &quot;name&quot;: &quot;C-3PO&quot; &#125; &#125; ] &#125; &#125;, &quot;rightComparison&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;friendsConnection&quot;: &#123; &quot;totalCount&quot;: 3, &quot;edges&quot;: [ &#123; &quot;node&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot; &#125; &#125;, &#123; &quot;node&quot;: &#123; &quot;name&quot;: &quot;Han Solo&quot; &#125; &#125;, &#123; &quot;node&quot;: &#123; &quot;name&quot;: &quot;Leia Organa&quot; &#125; &#125; ] &#125; &#125; &#125;&#125; 变量（Variables）目前为止，我们将参数写在了查询字符串内。但是在很多应用中，字段的参数可能是动态的：例如，可能是一个”下拉菜单”让你选择感兴趣的《星球大战》续集，或者是一个搜索区，或者是一组过滤器。 将这些动态参数直接传进查询字符串并不是好主意，因为这样我们的客户端就得动态地在运行时操作这些查询字符串了，再把它序列化成 GraphQL 专用的格式。其实，GraphQL 拥有一级方法将动态值提取到查询之外，然后作为分离的字典传进去。这些动态值即称为变量。 使用变量之前，我们得做三件事： 使用 $variableName 替代查询中的静态值。 声明 $variableName 为查询接受的变量之一。 将 variableName: value 通过传输专用（通常是 JSON）的分离的变量字典中。 全部做完之后就像这个样子： 123456789# &#123; &quot;graphiql&quot;: true, &quot;variables&quot;: &#123; &quot;episode&quot;: JEDI &#125; &#125;query HeroNameAndFriends($episode: Episode) &#123; hero(episode: $episode) &#123; name friends &#123; name &#125; &#125;&#125; 这样一来，我们的客户端代码就只需要传入不同的变量，而不用构建一个全新的查询了。这事实上也是一个良好实践，意味着查询的参数将是动态的 —— 我们决不能使用用户提供的值来字符串插值以构建查询。 变量定义（Variable definitions）变量定义看上去像是上述查询中的 ($episode: Episode)。其工作方式跟类型语言中函数的参数定义一样。它以列出所有变量，变量前缀必须为 $，后跟其类型，本例中为 Episode。 所有声明的变量都必须是标量、枚举型或者输入对象类型。所以如果想要传递一个复杂对象到一个字段上，你必须知道服务器上其匹配的类型。可以从Schema页面了解更多关于输入对象类型的信息。 变量定义可以是可选的或者必要的。上例中，Episode 后并没有 !，因此其是可选的。但是如果你传递变量的字段要求非空参数，那变量一定是必要的。 如果想要进一步了解变量定义的句法，可以学习 GraphQL 的 schema 语言。schema 语言在 Schema 中有细述。 默认变量（Default variables）可以通过在查询中的类型定义后面附带默认值的方式，将默认值赋给变量。 12345678query HeroNameAndFriends($episode: Episode = &quot;JEDI&quot;) &#123; hero(episode: $episode) &#123; name friends &#123; name &#125; &#125;&#125; 当所有变量都有默认值的时候，你可以不传变量直接调用查询。如果任何变量作为变量字典的部分传递了，它将覆盖其默认值。 指令（Directives）我们上面讨论的变量使得我们可以避免手动字符串插值构建动态查询。传递变量给参数解决了一大堆这样的问题，但是我们可能也需要一个方式使用变量动态地改变我们查询的结构。譬如我们假设有个 UI 组件，其有概括视图和详情视图，后者比前者拥有更多的字段。 我们来构建一个这种组件的查询： 1234567891011121314query Hero($episode: Episode, $withFriends: Boolean!) &#123; hero(episode: $episode) &#123; name friends @include(if: $withFriends) &#123; name &#125; &#125;&#125;variables:&#123; &quot;episode&quot;: &quot;JEDI&quot;, &quot;withFriends&quot;: false&#125; 1234567&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot; &#125; &#125;&#125; 尝试修改上面的变量，传递 true 给 withFriends，看看结果的变化。 我们用了 GraphQL 中一种称作指令的新特性。一个指令可以附着在字段或者片段包含的字段上，然后以任何服务端期待的方式来改变查询的执行。GraphQL 的核心规范包含两个指令，其必须被任何规范兼容的 GraphQL 服务器实现所支持： @include(if: Boolean) 仅在参数为 true 时，包含此字段。 @skip(if: Boolean) 如果参数为 true，跳过此字段。 指令在你不得不通过字符串操作来增减查询的字段时解救你。服务端实现也可以定义新的指令来添加新的特性。 变更（Mutations）GraphQL 的大部分讨论集中在数据获取，但是任何完整的数据平台也都需要一个改变服务端数据的方法。 REST 中，任何请求都可能最后导致一些服务端副作用，但是约定上建议不要使用 GET 请求来修改数据。GraphQL 也是类似 —— 技术上而言，任何查询都可以被实现为导致数据写入。然而，建一个约定来规范任何导致写入的操作都应该显式通过变更（mutation）来发送。 就如同查询一样，如果任何变更字段返回一个对象类型，你也能请求其嵌套字段。获取一个对象变更后的新状态也是十分有用的。我们来看看一个变更例子： 123456789101112131415mutation CreateReviewForEpisode($ep: Episode!, $review: ReviewInput!) &#123; createReview(episode: $ep, review: $review) &#123; stars commentary &#125;&#125;variables:&#123; &quot;ep&quot;: &quot;JEDI&quot;, &quot;review&quot;: &#123; &quot;stars&quot;: 5, &quot;commentary&quot;: &quot;This is a great movie!&quot; &#125;&#125; 12345678&#123; &quot;data&quot;: &#123; &quot;createReview&quot;: &#123; &quot;stars&quot;: 5, &quot;commentary&quot;: &quot;This is a great movie!&quot; &#125; &#125;&#125; 注意 createReview 字段如何返回了新建的 review 的 stars 和 commentary 字段。这在变更已有数据时特别有用，例如，当一个字段自增的时候，我们可以在一个请求中变更并查询这个字段的新值。 你也可能注意到，这个例子中，我们传递的 review 变量并非标量。它是一个输入对象类型，一种特殊的对象类型，可以作为参数传递。你可以在 Schema 页面上了解到更多关于输入类型的信息。 变更中的多个字段（Multiple fields in mutations）一个变更也能包含多个字段，一如查询。查询和变更之间名称之外的一个重要区别是： 查询字段时，是并行执行，而变更字段时，是线性执行，一个接着一个。 这意味着如果我们一个请求中发送了两个 incrementCredits 变更，第一个保证在第二个之前执行，以确保我们不会出现竞态。 内联片段（Inline Fragments）跟许多类型系统一样，GraphQL schema 也具备定义接口和联合类型的能力。在 schema 指南中可了解更多。 如果你查询的字段返回的是接口或者联合类型，那么你可能需要使用内联片段来取出下层具体类型的数据： 12345678910111213141516query HeroForEpisode($ep: Episode!) &#123; hero(episode: $ep) &#123; name ... on Droid &#123; primaryFunction &#125; ... on Human &#123; height &#125; &#125;&#125;variables:&#123; &quot;ep&quot;: &quot;JEDI&quot;&#125; 12345678&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;primaryFunction&quot;: &quot;Astromech&quot; &#125; &#125;&#125; 这个查询中，hero 字段返回 Character 类型，取决于 episode 参数，其可能是 Human 或者 Droid 类型。在直接选择的情况下，你只能请求 Character 上存在的字段，譬如 name。 如果要请求具体类型上的字段，你需要使用一个类型条件内联片段。因为第一个片段标注为 ... on Droid，primaryFunction 仅在 hero 返回的 Character 为 Droid 类型时才会执行。同理适用于 Human 类型的 height 字段。 具名片段也可以用于同样的情况，因为具名片段总是附带了一个类型。 元字段（Meta fields）某些情况下，你并不知道你将从 GraphQL 服务获得什么类型，这时候你就需要一些方法在客户端来决定如何处理这些数据。GraphQL 允许你在查询的任何位置请求 __typename，一个元字段，以获得那个位置的对象类型名称。 1234567891011121314&#123; search(text: &quot;an&quot;) &#123; __typename ... on Human &#123; name &#125; ... on Droid &#123; name &#125; ... on Starship &#123; name &#125; &#125;&#125; 123456789101112131415161718&#123; &quot;data&quot;: &#123; &quot;search&quot;: [ &#123; &quot;__typename&quot;: &quot;Human&quot;, &quot;name&quot;: &quot;Han Solo&quot; &#125;, &#123; &quot;__typename&quot;: &quot;Human&quot;, &quot;name&quot;: &quot;Leia Organa&quot; &#125;, &#123; &quot;__typename&quot;: &quot;Starship&quot;, &quot;name&quot;: &quot;TIE Advanced x1&quot; &#125; ] &#125;&#125; 上面的查询中，search 返回了一个联合类型，其可能是三种选项之一。没有 __typename 字段的情况下，几乎不可能在客户端分辨开这三个不同的类型。 GraphQL 服务提供了不少元字段，剩下的部分用于描述 内省 系统。 Schema 和类型在本节中，，你将学到关于 GraphQL 类型系统中所有你需要了解的知识，以及类型系统如何描述可以查询的数据。因为 GraphQL 可以运行在任何后端框架或者编程语言之上，我们将摒除实现上的细节而仅仅专注于其概念。 类型系统（Type System）如果你之前见到过 GraphQL 查询，你就知道 GraphQL 查询语言基本上就是关于选择对象上的字段。因此，例如在下列查询中： 123456&#123; hero &#123; name appearsIn &#125;&#125; 123456789101112&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;appearsIn&quot;: [ &quot;NEWHOPE&quot;, &quot;EMPIRE&quot;, &quot;JEDI&quot; ] &#125; &#125;&#125; 我们以一个特殊的对象 “root” 开始 选择其上的 hero 字段 对于 hero 返回的对象，我们选择 name 和 appearsIn 字段 因为一个 GraphQL 查询的结构和结果非常相似，因此即便不知道服务器的情况，你也能预测查询会返回什么结果。但是一个关于我们所需要的数据的确切描述依然很有意义，我们能选择什么字段？服务器会返回哪种对象？这些对象下有哪些字段可用？这便是引入 schema 的原因。 每一个 GraphQL 服务都会定义一套类型，用以描述你可能从那个服务查询到的数据。每当查询到来，服务器就会根据 schema 验证并执行查询。 类型语言（Type Language）GraphQL 服务可以用任何语言编写，因为我们并不依赖于任何特定语言的句法句式（譬如 JavaScript）来与 GraphQL schema 沟通，我们定义了自己的简单语言，称之为 “GraphQL schema language” —— 它和 GraphQL 的查询语言很相似，让我们能够和 GraphQL schema 之间可以无语言差异地沟通。 对象类型和字段（Object Types and Fields）一个 GraphQL schema 中的最基本的组件是对象类型，它就表示你可以从服务上获取到什么类型的对象，以及这个对象有什么字段。使用 GraphQL schema language，我们可以这样表示它： 1234type Character &#123; name: String! appearsIn: [Episode!]!&#125; 虽然这语言可读性相当好，但我们还是一起看看其用语，以便我们可以有些共通的词汇： Character 是一个 GraphQL 对象类型，表示其是一个拥有一些字段的类型。你的 schema 中的大多数类型都会是对象类型。 name 和 appearsIn 是 Character 类型上的字段。这意味着在一个操作 Character 类型的 GraphQL 查询中的任何部分，都只能出现 name 和 appearsIn 字段。 String 是内置的标量类型之一 —— 标量类型是解析到单个标量对象的类型，无法在查询中对它进行次级选择。后面我们将细述标量类型。 String! 表示这个字段是非空的，GraphQL 服务保证当你查询这个字段后总会给你返回一个值。在类型语言里面，我们用一个感叹号来表示这个特性。 [Episode!]! 表示一个 Episode 数组。因为它也是非空的，所以当你查询 appearsIn 字段的时候，你也总能得到一个数组（零个或者多个元素）。且由于 Episode! 也是非空的，你总是可以预期到数组中的每个项目都是一个 Episode 对象。 现在你知道一个 GraphQL 对象类型看上去是怎样，也知道如何阅读基础的 GraphQL 类型语言了。 参数（Arguments）GraphQL 对象类型上的每一个字段都可能有零个或者多个参数，例如下面的 length 字段 12345type Starship &#123; id: ID! name: String! length(unit: LengthUnit = METER): Float&#125; 所有参数都是具名的，不像 JavaScript 或者 Python 之类的语言，函数接受一个有序参数列表，而在 GraphQL 中，所有参数必须具名传递。本例中，length 字段定义了一个参数，unit。 参数可能是必选或者可选的，当一个参数是可选的，我们可以定义一个默认值 —— 如果 unit 参数没有传递，那么它将会被默认设置为 METER。 查询和变更类型（The Query and Mutation Types）你的 schema 中大部分的类型都是普通对象类型，但是一个 schema 内有两个特殊类型： 1234schema &#123; query: Query mutation: Mutation&#125; 每一个 GraphQL 服务都有一个 query 类型，可能有一个 mutation 类型。这两个类型和常规对象类型无差，但是它们之所以特殊，是因为它们定义了每一个 GraphQL 查询的入口。因此如果你看到一个像这样的查询： 12345678query &#123; hero &#123; name &#125; droid(id: &quot;2000&quot;) &#123; name &#125;&#125; 12345678910&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot; &#125;, &quot;droid&quot;: &#123; &quot;name&quot;: &quot;C-3PO&quot; &#125; &#125;&#125; 那表示这个 GraphQL 服务需要一个 Query 类型，且其上有 hero 和 droid 字段： 1234type Query &#123; hero(episode: Episode): Character droid(id: ID!): Droid&#125; 变更也是类似的工作方式 —— 你在 Mutation 类型上定义一些字段，然后这些字段将作为 mutation 根字段使用，接着你就能在你的查询中调用。 有必要记住的是，除了作为 schema 的入口，Query 和 Mutation 类型与其它 GraphQL 对象类型别无二致，它们的字段也是一样的工作方式。 标量类型（Scalar Types）一个对象类型有自己的名字和字段，而某些时候，这些字段必然会解析到具体数据。这就是标量类型的来源：它们表示对应 GraphQL 查询的叶子节点。 下列查询中，name 和 appearsIn 字段将解析到标量类型： 123456&#123; hero &#123; name appearsIn &#125;&#125; 123456789101112&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;appearsIn&quot;: [ &quot;NEWHOPE&quot;, &quot;EMPIRE&quot;, &quot;JEDI&quot; ] &#125; &#125;&#125; 我们知道这些字段没有任何次级字段 —— 因为让它们是查询的叶子节点。 GraphQL 自带一组默认标量类型： Int：有符号 32 位整数。 Float：有符号双精度浮点值。 String：UTF‐8 字符序列。 Boolean：true 或者 false。 ID：ID 标量类型表示一个唯一标识符，通常用以重新获取对象或者作为缓存中的键。ID 类型使用和 String 一样的方式序列化；然而将其定义为 ID 意味着并不需要人类可读型。 大部分的 GraphQL 服务实现中，都有自定义标量类型的方式。例如，我们可以定义一个 Date 类型： 1scalar Date 然后就取决于我们的实现中如何定义将其序列化、反序列化和验证。例如，你可以指定 Date 类型应该总是被序列化成整型时间戳，而客户端应该知道去要求任何 date 字段都是这个格式。 枚举类型（Enumeration Types）也称作枚举（enum），枚举类型是一种特殊的标量，它限制在一个特殊的可选值集合内。这让你能够： 验证这个类型的任何参数是可选值的的某一个 与类型系统沟通，一个字段总是一个有限值集合的其中一个值。 下面是一个用 GraphQL schema 语言表示的 enum 定义： 12345enum Episode &#123; NEWHOPE EMPIRE JEDI&#125; 这表示无论我们在 schema 的哪处使用了 Episode，都可以肯定它返回的是 NEWHOPE、EMPIRE 和 JEDI 之一。 注意，各种语言实现的 GraphQL 服务会有其独特的枚举处理方式。对于将枚举作为一等公民的语言，它的实现就可以利用这个特性；而对于像 JavaScript 这样没有枚举支持的语言，这些枚举值可能就被内部映射成整数值。当然，这些细节都不会泄漏到客户端，客户端会根据字符串名称来操作枚举值。 列表和非空（Lists and Non-Null）对象类型、标量以及枚举是 GraphQL 中你唯一可以定义的类型种类。但是当你在 schema 的其他部分使用这些类型时，或者在你的查询变量声明处使用时，你可以给它们应用额外的类型修饰符来影响这些值的验证。我们先来看一个例子： 1234type Character &#123; name: String! appearsIn: [Episode]!&#125; 此处我们使用了一个 String 类型，并通过在类型名后面添加一个感叹号!将其标注为非空。这表示我们的服务器对于这个字段，总是会返回一个非空值，如果它结果得到了一个空值，那么事实上将会触发一个 GraphQL 执行错误，以让客户端知道发生了错误。 非空类型修饰符也可以用于定义字段上的参数，如果这个参数上传递了一个空值（不管通过 GraphQL 字符串还是变量），那么会导致服务器返回一个验证错误。 12345678910query DroidById($id: ID!) &#123; droid(id: $id) &#123; name &#125;&#125;variables:&#123; &quot;id&quot;: null&#125; 12345678910111213&#123; &quot;errors&quot;: [ &#123; &quot;message&quot;: &quot;Variable \\&quot;$id\\&quot; of required type \\&quot;ID!\\&quot; was not provided.&quot;, &quot;locations&quot;: [ &#123; &quot;line&quot;: 1, &quot;column&quot;: 17 &#125; ] &#125; ]&#125; 列表的运作方式也类似：我们也可以使用一个类型修饰符来标记一个类型为 List，表示这个字段会返回这个类型的数组。在 GraphQL schema 语言中，我们通过将类型包在方括号（[ 和 ]）中的方式来标记列表。列表对于参数也是一样的运作方式，验证的步骤会要求对应值为数组。 非空和列表修饰符可以组合使用。例如你可以要求一个非空字符串的数组： 1myField: [String!] 这表示数组本身可以为空，但是其不能有任何空值成员。用 JSON 举例如下： 1234myField: null // 有效myField: [] // 有效myField: [&#x27;a&#x27;, &#x27;b&#x27;] // 有效myField: [&#x27;a&#x27;, null, &#x27;b&#x27;] // 错误 然后，我们来定义一个不可为空的字符串数组： 1myField: [String]! 这表示数组本身不能为空，但是其可以包含空值成员： 1234myField: null // 错误myField: [] // 有效myField: [&#x27;a&#x27;, &#x27;b&#x27;] // 有效myField: [&#x27;a&#x27;, null, &#x27;b&#x27;] // 有效 你可以根据需求嵌套任意层非空和列表修饰符。 接口（Interfaces）跟许多类型系统一样，GraphQL 支持接口。一个接口是一个抽象类型，它包含某些字段，而对象类型必须包含这些字段，才能算实现了这个接口。 例如，你可以用一个 Character 接口用以表示《星球大战》三部曲中的任何角色： 123456interface Character &#123; id: ID! name: String! friends: [Character] appearsIn: [Episode]!&#125; 这意味着任何实现 Character 的类型都要具有这些字段，并有对应参数和返回类型。 例如，这里有一些可能实现了 Character 的类型： 12345678910111213141516type Human implements Character &#123; id: ID! name: String! friends: [Character] appearsIn: [Episode]! starships: [Starship] totalCredits: Int&#125;type Droid implements Character &#123; id: ID! name: String! friends: [Character] appearsIn: [Episode]! primaryFunction: String&#125; 可见这两个类型都具备 Character 接口的所有字段，但也引入了其他的字段 totalCredits、starships 和 primaryFunction，这都属于特定的类型的角色。 当你要返回一个对象或者一组对象，特别是一组不同的类型时，接口就显得特别有用。 注意下面例子的查询会产生错误： 1234567891011query HeroForEpisode($ep: Episode!) &#123; hero(episode: $ep) &#123; name primaryFunction &#125;&#125;variables:&#123; &quot;ep&quot;: &quot;JEDI&quot;&#125; 12345678910111213&#123; &quot;errors&quot;: [ &#123; &quot;message&quot;: &quot;Cannot query field \\&quot;primaryFunction\\&quot; on type \\&quot;Character\\&quot;. Did you mean to use an inline fragment on \\&quot;Droid\\&quot;?&quot;, &quot;locations&quot;: [ &#123; &quot;line&quot;: 4, &quot;column&quot;: 5 &#125; ] &#125; ]&#125; hero 字段返回 Character 类型，取决于 episode 参数，它可能是 Human 或者 Droid 类型。上面的查询中，你只能查询 Character 接口中存在的字段，而其中并不包含 primaryFunction。 如果要查询一个只存在于特定对象类型上的字段，你需要使用内联片段： 12345678910111213query HeroForEpisode($ep: Episode!) &#123; hero(episode: $ep) &#123; name ... on Droid &#123; primaryFunction &#125; &#125;&#125;variables:&#123; &quot;ep&quot;: &quot;JEDI&quot;&#125; 12345678&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;primaryFunction&quot;: &quot;Astromech&quot; &#125; &#125;&#125; 你可以在查询指南的 内联片段 章节了解更多相关信息。 联合类型（Union Types）联合类型和接口十分相似，但是它并不指定类型之间的任何共同字段。 1union SearchResult = Human | Droid | Starship 在我们的schema中，任何返回一个 SearchResult 类型的地方，都可能得到一个 Human、Droid 或者 Starship。注意，联合类型的成员需要是具体对象类型；你不能使用接口或者其他联合类型来创造一个联合类型。 这时候，如果你需要查询一个返回 SearchResult 联合类型的字段，那么你得使用条件片段才能查询任意字段。 1234567891011121314151617&#123; search(text: &quot;an&quot;) &#123; __typename ... on Human &#123; name height &#125; ... on Droid &#123; name primaryFunction &#125; ... on Starship &#123; name length &#125; &#125;&#125; 123456789101112131415161718192021&#123; &quot;data&quot;: &#123; &quot;search&quot;: [ &#123; &quot;__typename&quot;: &quot;Human&quot;, &quot;name&quot;: &quot;Han Solo&quot;, &quot;height&quot;: 1.8 &#125;, &#123; &quot;__typename&quot;: &quot;Human&quot;, &quot;name&quot;: &quot;Leia Organa&quot;, &quot;height&quot;: 1.5 &#125;, &#123; &quot;__typename&quot;: &quot;Starship&quot;, &quot;name&quot;: &quot;TIE Advanced x1&quot;, &quot;length&quot;: 9.2 &#125; ] &#125;&#125; _typename 字段解析为 String，它允许你在客户端区分不同的数据类型。 此外，在这种情况下，由于 Human 和 Droid 共享一个公共接口（Character），你可以在一个地方查询它们的公共字段，而不必在多个类型中重复相同的字段： 123456789101112131415161718&#123; search(text: &quot;an&quot;) &#123; __typename ... on Character &#123; name &#125; ... on Human &#123; height &#125; ... on Droid &#123; primaryFunction &#125; ... on Starship &#123; name length &#125; &#125;&#125; 注意 name 仍然需要指定在 Starship 上，否则它不会出现在结果中，因为 Starship 并不是一个 Character！ 输入类型（Input Types）目前为止，我们只讨论过将例如枚举和字符串等标量值作为参数传递给字段，但是你也能很容易地传递复杂对象。这在变更（mutation）中特别有用，因为有时候你需要传递一整个对象作为新建对象。在 GraphQL schema language 中，输入对象看上去和常规对象一模一样，除了关键字是 input 而不是 type： 1234input ReviewInput &#123; stars: Int! commentary: String&#125; 你可以像这样在变更（mutation）中使用输入对象类型： 123456789101112131415mutation CreateReviewForEpisode($ep: Episode!, $review: ReviewInput!) &#123; createReview(episode: $ep, review: $review) &#123; stars commentary &#125;&#125;variables:&#123; &quot;ep&quot;: &quot;JEDI&quot;, &quot;review&quot;: &#123; &quot;stars&quot;: 5, &quot;commentary&quot;: &quot;This is a great movie!&quot; &#125;&#125; 12345678&#123; &quot;data&quot;: &#123; &quot;createReview&quot;: &#123; &quot;stars&quot;: 5, &quot;commentary&quot;: &quot;This is a great movie!&quot; &#125; &#125;&#125; 输入对象类型上的字段本身也可以指代输入对象类型，但是你不能在你的 schema 混淆输入和输出类型。输入对象类型的字段当然也不能拥有参数。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"","slug":"开发笔记/REST风格理解","date":"2022-12-12T17:36:23.237Z","updated":"2022-12-12T17:36:23.237Z","comments":true,"path":"2022/12/12/开发笔记/REST风格理解/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/REST%E9%A3%8E%E6%A0%BC%E7%90%86%E8%A7%A3/","excerpt":"","text":"转载自 https://www.jianshu.com/p/6e8381c9b01d 一、什么是REST一句话来概括RESTful API(具有REST风格的API): 用URL定位资源，用HTTP动词（GET,HEAD,POST,PUT,PATCH,DELETE）描述操作，用响应状态码表示操作结果。 REST是一种软件架构风格，或者说是一种规范，其强调HTTP应当以资源为中心，并且规范了URI的风格；规范了HTTP请求动作（GET&#x2F;PUT&#x2F;POST&#x2F;DELETE&#x2F;HEAD&#x2F;OPTIONS）的使用，具有对应的语义。 核心概念包括： 资源（Resource）：在REST中，资源可以简单的理解为URI，表示一个网络实体。比如，&#x2F;users&#x2F;1&#x2F;name，对应id&#x3D;1的用户的属性name。既然资源是URI，就会具有以下特征：名词，代表一个资源；它对应唯一的一个资源，是资源的地址。 表现（Representation）：资源呈现出来的形式，比如上述URI返回的HTML或JSON，包括HTTP Header等； REST是一个无状态的架构模式，因为在任何时候都可以由客户端发出请求到服务端，最终返回自己想要的数据，当前请求不会受到上次请求的影响。也就是说，服务端将内部资源发布REST服务，客户端通过URL来定位这些资源并通过HTTP协议来访问它们。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"","slug":"开发笔记/dalin的服务器配置记录","date":"2022-12-12T17:36:23.237Z","updated":"2022-12-12T17:36:23.241Z","comments":true,"path":"2022/12/12/开发笔记/dalin的服务器配置记录/","link":"","permalink":"http://example.com/2022/12/12/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/dalin%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95/","excerpt":"","text":"阿里云上重新买了台穷鬼t5，菜是菜了点，但是该折腾还是要折腾的。。。 设置虚拟内存安装free -m 查看内存状态, Swap 的值都是0，说明还没有安装虚拟内存 在 &#x2F;opt 下创建虚拟内存文件 1dd if=/dev/zero of=/opt/swap bs=2048 count=2048000 将swap文件设置为swap分区文件 12chmod 600 /opt/swap //注意更改swap文件的权限mkswap /opt/swap 激活swap,启用分区交换文件 1swapon /opt/swap 查看结果 1234[root@dalin1 opt]# free -m total used free shared buff/cache availableMem: 1829 1329 169 0 330 357Swap: 3999 429 3570 重启自动启用设置，否则机器重启后分区就失效了 1vim /etc/rc.local 底部添加 1swapon /home/swap 卸载停止swap分区 1swapoff /opt/swap 删除掉swap文件 1rm -rf /opt/swap 查看磁盘情况： 12345678910[root@dalin1 opt]# df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 900M 0 900M 0% /devtmpfs 915M 0 915M 0% /dev/shmtmpfs 915M 612K 915M 1% /runtmpfs 915M 0 915M 0% /sys/fs/cgroup/dev/vda1 40G 9.5G 31G 24% /tmpfs 183M 0 183M 0% /run/user/1000overlay 40G 9.5G 31G 24% /var/lib/docker/overlay2/cb6202d7408b52de4ca486b57263e33e6dbb34d3adf35e86bfdffe62b9d33339/mergedoverlay 40G 9.5G 31G 24% /var/lib/docker/overlay2/25f9d8b78fa8906f7b379efce90fdd90f8e5771399f537988cf15ca450641596/merged mysql 安装上一次鄙人的mysql开启了远程访问，并且没有注意安全防范，被比特币勒索了。。。但是使用远程msql服务的需求还是需要的，毕竟真的是方便，这次注意一下安全方面的配置，应该不至于再没了吧。。。 1. centos8 安装mysql8使用最新的包管理器安装MySQL 1sudo dnf install @mysql 设置开机自启并启动 1sudo systemctl enable --now mysqld 运行mysql_secure_installation脚本，该脚本执行一些与安全性相关的操作并设置MySQL根密码： 1mysql_secure_installation 按提示往下走即可，注意在 Disallow root login remotely?选项中选择 n 2. 更换 mysql 默认端口vim /etc/my.cnf，添加字段 port=6612 systemctl restart mysqld 重启 mysql 防火墙添加6612端口白名单 12firewall-cmd --add-port=6612/tcp --permanentfirewall-cmd --reload centos默认使用的是firewall作为防火墙，一些常用命令： firewall-cmd –list-ports ##查看已开放的端口 firewall-cmd –add-port&#x3D;6612&#x2F;tcp –permanent ##永久开放6612端口 firewall-cmd –remove-port&#x3D;6612&#x2F;tcp –permanent ##永久关闭6612端口 firewall-cmd –reload ##刷新 阿里云控制台安全组开放 6612 端口 3. mysql 允许远程主机访问登录mysql 1mysql -uroot -p&lt;密码&gt; 将 mysql.user 中的 root 的 host 字段设为&#39;%&#39;： 123use mysql;update user set host=&#x27;%&#x27; where user=&#x27;root&#x27;;flush privileges; 4. 使用脚本自动备份数据1234567891011121314151617181920212223242526272829303132333435363738394041#!/bin/bash#数据库服务器dbserver=&#x27;localhost&#x27;#数据库用户名dbuser=&#x27;root&#x27;#数据库用密码dbpasswd=&#x27;********&#x27;#需要备份的数据库，多个数据库用空格分开dbname=&#x27;backdata01 backdata02&#x27;#备份时间backtime=`date +%Y%m%d`#日志备份路径logpath=&#x27;/opt/data/mysqlbak/&#x27;#数据备份路径datapath=&#x27;/opt/data/mysqlbak/&#x27; echo &#x27;##################$backtime##########################&#x27; #日志记录头部echo ‘&quot;备份时间为$&#123;backtime&#125;,备份数据库表 $&#123;dbname&#125; 开始&quot; &gt;&gt; $&#123;logpath&#125;/mysqlback.log#正式备份数据库for table in $dbname; dosource=`mysqldump -h $&#123;dbserver&#125; -u $&#123;dbuser&#125; -p$&#123;dbpasswd&#125; $&#123;table&#125; &gt; $&#123;logpath&#125;/$&#123;backtime&#125;.sql` 2&gt;&gt; $&#123;logpath&#125;/mysqlback.log;#备份成功以下操作if [ &quot;$?&quot; == 0 ];thencd $datapath#为节约硬盘空间，将数据库压缩tar zcf $&#123;table&#125;$&#123;backtime&#125;.tar.gz $&#123;backtime&#125;.sql &gt; /dev/null#删除原始文件，只留压缩后文件rm -f $&#123;datapath&#125;/$&#123;backtime&#125;.sql#删除七天前备份，也就是只保存7天内的备份find $datapath -name &quot;*.tar.gz&quot; -type f -mtime +7 -exec rm -rf &#123;&#125; \\; &gt; /dev/null 2&gt;&amp;1echo &quot;数据库表 $&#123;dbname&#125; 备份成功!!&quot; &gt;&gt; $&#123;logpath&#125;/mysqlback.logelse#备份失败则进行以下操作echo &quot;数据库表 $&#123;dbname&#125; 备份失败!!&quot; &gt;&gt; $&#123;logpath&#125;/mysqlback.logfidone echo &#x27;##################完成############################&#x27; 创建定时任务 12crontab -e59 23 * * * ./opt/mysqldata/mysqlbak.sh ## 每天23:59执行命令 redis 安装5. 安装redis并且设置远程访问和密码配置12[root@dalin1 ~]# yum -y install redis[root@dalin1 ~]# systemctl enable --now redis 修改redis端口、设置密码、允许远程访问 1[root@dalin1 ~]# vim /etc/redis.conf 修改 port 6369 注释掉 bind 127.0.0.1，以便让外网访问 去掉 #requirepass foobared 注释，foobared改为自己的密码 防火墙添加6369端口白名单 12firewall-cmd --add-port=6369/tcp --permanentfirewall-cmd --reload 阿里云控制台安全组开放 6369 端口 6. 创建普通用户，以后尽量使用普通用户操作123[root@dalin1 ~]# adduser dalin #创建普通用户 dalin[root@dalin1 ~]# passwd dalin #修改密码[root@dalin1 ~]# su dalin #切换用户 普通用户只在 /home/&lt;username&gt; 目录下有完整权限 docker 安装docker这么方便的东西怎么能不用呢，但是因为服务器实在太菜了，可能会卡顿，而且要时刻注意内存使用情况 1. 安装依赖包1[root@dalin1 ~]# yum install -y yum-utils device-mapper-persistent-data lvm2 2. 设置Docker源1[root@dalin1 ~]# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 3. 安装Docker CE3.1 docker安装版本查看1[root@dalin1 ~]# yum list docker-ce --showduplicates | sort -r 3.2 安装docker1[root@dalin1 ~]# yum install docker-ce-18.09.6 docker-ce-cli-18.09.6 containerd.io 指定安装的docker版本为18.09.6，由于该版本目前为最新版，故可以直接安装，不用指定版本： 1[root@dalin1 ~]# yum install -y docker-ce docker-ce-cli containerd.io 4. 启动Docker并设置开机自启1[root@dalin1 ~]# systemctl enable --now docker 5. 镜像加速使用阿里云镜像加速地址 123456[root@dalin1 ~]# mkdir -p /etc/docker[root@dalin1 ~]# tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123; &quot;registry-mirrors&quot;: [&quot;https://khv87vsk.mirror.aliyuncs.com&quot;]&#125;EOF docker 下安装Elasticsearch和Kibana服务器太菜，基本跑不动 安装Elasticsearch下载镜像： 1[root@dalin1 ~]# docker pull elasticsearch:7.2.0 启动容器 1[root@dalin1 ~]# docker run --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; -d elasticsearch:7.2.0 大概率启动失败，查看日志： 12345678910111213[root@dalin1 temp]# docker logs elasticsearchException in thread &quot;main&quot; java.lang.RuntimeException: starting java failed with [1]output:## There is insufficient memory for the Java Runtime Environment to continue.# Native memory allocation (mmap) failed to map 1073741824 bytes for committing reserved memory.# An error report file with more information is saved as:# logs/hs_err_pid132.logerror:OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x00000000c0000000, 1073741824, 0) failed; error=&#x27;Not enough space&#x27; (errno=12) at org.elasticsearch.tools.launchers.JvmErgonomics.flagsFinal(JvmErgonomics.java:126) at org.elasticsearch.tools.launchers.JvmErgonomics.finalJvmOptions(JvmErgonomics.java:88) ... jvm内存不足。。。 123[root@dalin1]# find / -name jvm.options/var/lib/docker/overlay2/aa7a9ac9f293452ddf8947e9fdf3af24d602566d54b6278284751239b43e37e5/diff/usr/share/elasticsearch/config/jvm.options[root@dalin1]# vim /var/lib/docker/overlay2/aa7a9ac9f293452ddf8947e9fdf3af24d602566d54b6278284751239b43e37e5/diff/usr/share/elasticsearch/config/jvm.options 1234567891011121314151617181920212223242526## JVM configuration################################################################## IMPORTANT: JVM heap size#################################################################### You should always set the min and max JVM heap## size to the same value. For example, to set## the heap to 4 GB, set:#### -Xms4g## -Xmx4g#### See https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html## for more information################################################################### Xms represents the initial size of total heap space# Xmx represents the maximum size of total heap space-Xms1g #服务器实在太菜了，我改成256m-Xmx1g #服务器实在太菜了，我改成256m################################################################ 重新启动容器 1[root@dalin1 ~]# docker start elasticsearch 检测是否启动成功 12345678910111213141516171819[root@dalin1 ~]# curl http://localhost:9200&#123; &quot;name&quot; : &quot;c19d1882a695&quot;, &quot;cluster_name&quot; : &quot;docker-cluster&quot;, &quot;cluster_uuid&quot; : &quot;-zKpqN7TQMqmPULGgdMz3w&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;7.2.0&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;docker&quot;, &quot;build_hash&quot; : &quot;508c38a&quot;, &quot;build_date&quot; : &quot;2019-06-20T15:54:18.811730Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.0.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 解决跨域访问问题 进入容器，修改elasticsearch.yml文件 12[root@dalin1 ~]# docker exec -it elasticsearch /bin/bashvim /usr/share/elasticsearch/config/elasticsearch.yml 在elasticsearch.yml的文件末尾加上: 12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; es自带的分词器对中文分词不是很友好，所以我们下载开源的IK分词器来解决这个问题。 123456````exit` 退出容器后 `docker restart elasticsearch` 重启容器#### kibana安装下载镜像 [root@dalin1 ~]# docker pull kibana:7.2.0 123启动kibana [root@dalin1 ~]# docker run –name kibana –link&#x3D;elasticsearch:es -e ELASTICSEARCH_URL&#x3D;http://172.17.0.2:9200 -p 5601:5601 -d kibana:7.7.0 123使用--link连接到elasticsearch容器，并添加环境变量，指定安装es的容器地址当然也可以进入容器内部修改配置文件来设置es访问地址 [root@dalin1 ~]# docker exec -it kibana &#x2F;bin&#x2F;bashvi config&#x2F;kibana.yml 12345kibana默认是优先使用环境变量的地址，然后才是配置文件kibana.yml&lt;br&gt;如何查询容器地址？ 获取到容器的元数据信息[root@dalin1 ~]# docker inspect [id&#x2F;name] 12最后，配置安全组和防火墙，开放9200、5601端口 [root@dalin1 ~]# firewall-cmd –add-port&#x3D;5601&#x2F;tcp –permanent[root@dalin1 ~]# firewall-cmd –add-port&#x3D;9200&#x2F;tcp –permanent 12这就结束了吗？是的，网上几乎所有的关于docker下安装kibana教程都是到了这一步就说完事收工、开始体验。。。但是！！！我遇到的情况是访问 `http//:ip:5601`，只会给我冰冷的大字： Kibana server is not ready yet 1`docker logs kibana`打印日志，报错： {“type”:”log”,”@timestamp”:”2020-06-04T08:25:57Z”,”tags”:[“warning”,”elasticsearch”,”admin”],”pid”:6,”message”:”Unable to revive connection: http://172.17.0.2:9200/&quot;}{“type”:”log”,”@timestamp”:”2020-06-04T08:25:57Z”,”tags”:[“warning”,”elasticsearch”,”admin”],”pid”:6,”message”:”No living connections”} 123ip地址是没问题的，es服务也确实起了，为什么呢？？这个问题花了我大半天的时间，找遍了网上的教程都没有相关的介绍，官网上关于docker安装kibana的教程更是少。 进入kibana容器中 [root@dalin1 ~]# docker exec -it kibana &#x2F;bin&#x2F;bashbash-4.2$ ping 172.17.0.2 #没有问题，能ping通bash-4.2$ curl http://120.79.43.44:9200curl: (7) Failed connect to 120.79.43.44:9200; No route to host 123问题就出在这里！应该是防火墙的原因导致容器之间无法进行通信解决方法，依次执行以下命令 [root@dalin1 ~]# nmcli connection modify docker0 connection.zone trusted [root@dalin1 ~]# systemctl stop NetworkManager.service [root@dalin1 ~]# firewall-cmd –permanent –zone&#x3D;trusted –change-interface&#x3D;docker0 [root@dalin1 ~]# systemctl start NetworkManager.service [root@dalin1 ~]# nmcli connection modify docker0 connection.zone trusted [root@dalin1 ~]# systemctl restart docker.service &#96;&#96;&#96;把 docker0 加入防火墙白名单 重新启动容器，访问地址 http://ip:5601 ，总算没有了 Kibana server is not ready yet,显示正在加载的图像，稍作等候即可，部署完成！","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[]}]}
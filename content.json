{"meta":{"title":"Dalin blog","subtitle":"","description":"","author":"Dalin","url":"https://tianxiafeiyu.github.io","root":"/"},"pages":[{"title":"About","date":"2023-06-16T09:34:49.530Z","updated":"2023-06-16T09:34:49.530Z","comments":true,"path":"about/index.html","permalink":"https://tianxiafeiyu.github.io/about/index.html","excerpt":"","text":""},{"title":"Categories","date":"2023-06-16T09:34:49.530Z","updated":"2023-06-16T09:34:49.530Z","comments":true,"path":"categories/index.html","permalink":"https://tianxiafeiyu.github.io/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2023-06-16T09:34:49.534Z","updated":"2023-06-16T09:34:49.534Z","comments":true,"path":"tags/index.html","permalink":"https://tianxiafeiyu.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"我的新冠经历","slug":"生活点滴/我的新冠经历","date":"2023-06-16T09:34:49.530Z","updated":"2023-06-16T09:34:49.530Z","comments":true,"path":"2023/06/16/生活点滴/我的新冠经历/","link":"","permalink":"https://tianxiafeiyu.github.io/2023/06/16/%E7%94%9F%E6%B4%BB%E7%82%B9%E6%BB%B4/%E6%88%91%E7%9A%84%E6%96%B0%E5%86%A0%E7%BB%8F%E5%8E%86/","excerpt":"","text":"从彻底放开两周以后，身边的同事陆陆续续都有了症状，工位上的人一个个消失。。。 12.21 日，早上起来我便感觉有一点点不舒服，头有点晕，嗓子也有点不舒服，不过症状很小，我还安慰是自己吓自己，再加上认为新冠也就那样，所以不是很在意。这一天正常上班，一整天下来，确实有点无力的感觉，喉咙的异物感越来越重，我便知道这次是真的来了。这天晚上很难入睡，翻来覆去睡不着。 22号早上醒来，我便感觉头昏脑胀，喉咙已经哑了，我赶紧跟领导请了假，拿出温度计量体温，不到37度，还没有开始烧。不过我整个人已经像火炉一样了，冒着热气。这一天整个人是无精打采的，很明显的感冒症状，但是有感觉哪里不同。 23号开始高烧了，一度烧到39度多，一整夜没睡，躺床上仿佛过了一个世纪，但是一看表，才凌晨两点钟，夜还长着，一夜无眠。临近早上，才昏昏沉沉睡过去，醒来时已经快11点了。这期间身体发烧，但是身体又发冷，又热又冷，冰火两重天。喉咙倒是没有进一步恶化，不是熟悉的扁桃体炎。 周末这两天，我几乎都是躺在床上，发烧还没退，身体冻得直哆嗦。不过，烧页渐渐的退了下来，趋于平缓，我开始洗热水澡。 26号周一，烧退的差不多了，开始远程上班，但是整个人都没有精神，工作不下去。 27号依然如此，咳嗽还一直再，有浓痰，身体完全虚了，多运动几下就喘得不行，也许是我呆久了吧。 今天28号，已经过去一周了，现在烧已经完全退了下来，我倒是不再担心复烧了，只是还是很没有精神，感觉哪里出了问题。 这个新冠没有想的那么简单，确实有一定的严重性，不同于普通的感冒发烧。很难想象，之前刚爆发时，是怎么过来的。虽然我全程没有吃药，全靠身体免疫力撑了过来，但是感觉已经元气大伤，不知道要过好久才能恢复呢。","categories":[{"name":"生活点滴","slug":"生活点滴","permalink":"https://tianxiafeiyu.github.io/categories/%E7%94%9F%E6%B4%BB%E7%82%B9%E6%BB%B4/"}],"tags":[]},{"title":"","slug":"技术开发/database/mysql中的NULL值解析","date":"2023-06-16T09:34:49.518Z","updated":"2023-06-16T09:34:49.518Z","comments":true,"path":"2023/06/16/技术开发/database/mysql中的NULL值解析/","link":"","permalink":"https://tianxiafeiyu.github.io/2023/06/16/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/mysql%E4%B8%AD%E7%9A%84NULL%E5%80%BC%E8%A7%A3%E6%9E%90/","excerpt":"","text":"mysql中的NULLNULL在MySQL中是一个非常特殊的值，官方表述为“一个未知的值”，NULL不与任何值相等（包括其本身）。 NULL的长度123456mysql&gt; select length(NULL), length(&#x27;&#x27;), length(0), length(FALSE);+--------------+------------+-----------+---------------+| length(NULL) | length(&#x27;&#x27;) | length(0) | length(FALSE) |+--------------+------------+-----------+---------------+| NULL | 0 | 1 | 1 |+--------------+------------+-----------+---------------+ 可以看出空值’’的长度是0，是不占用空间的；而的NULL长度是NULL，是需要占用额外空间的，所以在一些开发规范中，建议将数据库字段设置为Not NULL,并且设置默认值’’或0。 NULL值占用字节空间，具体是多少呢，好像找不到权威的相关资料，部分资料说InnoDB中是1字节 NULL对查询的影响NULL对数学比较运算符（&gt;, &#x3D;, &lt;&#x3D;, &lt;&gt;）运算出的结果都是FALSE NULL只支持IS NULL、IS NOT NULL、IFNULL()操作 MIN()、SUM()、COUNT()在运算时会忽略NULL值，但是COUNT(*)不会忽略； DISTINCT、GROUP BY、ORDER BY中认为所有的NULL值都是相等的；ORDER BY认为NULL是最小的值 NULL对索引的影响MySQL中某一列数据含有NULL，并不一定会造成索引失效。 MySQL可以在含有NULL的列上使用索引 在有NULL值得字段上使用常用的索引，如普通索引、复合索引、全文索引等不会使索引失效。但是在使用空间索引的情况下，该列就必须为 NOT NULL。 NULL对数据的影响TIMESTAMP类型的字段被插入NULL时，实际写入到表中的是当前时间； AUTO_INCREMENT属性的字段被插入NULL时，实际写入到表中的是顺序的下一个自增值 想要禁止某个字段被设置为NULL，则对此字段设置NOT NULL属性； 与oracle不同，mysql的唯一索引中允许有NULL字段，但是可能会出现意料之外的数据比如，uniq_index(a, b, c), insert(1, 2, NULL)；insert(1, 2, NULL)都会成功 因为对于联合索引 a-b-c，1-2-NULL和1-2-NULL的比较结果总会返回false","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"database","slug":"技术开发/database","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/"}],"tags":[]},{"title":"每日游戏报告（2023-06-15）","slug":"生活点滴/2023-06-15-game_report","date":"2023-06-15T12:43:17.000Z","updated":"2023-06-15T12:43:17.000Z","comments":true,"path":"2023/06/15/生活点滴/2023-06-15-game_report/","link":"","permalink":"https://tianxiafeiyu.github.io/2023/06/15/%E7%94%9F%E6%B4%BB%E7%82%B9%E6%BB%B4/2023-06-15-game_report/","excerpt":"","text":"每日游戏报告（2023-06-15）1. 龙之信条：黑暗觉者英文名：Dragon’s Dogma: Dark Arisen标签：动作，冒险，角色扮演原价：192¥折扣率：84% 史低好评率：89%好评率国区价格：30.72¥阿区价格：51.68ARS$ (1.52¥)价格差：20.21倍 2. 丧尸围城4英文名：Dead Rising 4标签：动作原价：162¥折扣率：75% 非史低好评率：58%好评率国区价格：40.5¥阿区价格：80.58ARS$ (2.37¥)价格差：17.09倍 3. 生化危机启示录2英文名：Resident Evil Revelations 2标签：动作，冒险原价：38.08¥折扣率：87% 非史低好评率：78%好评率国区价格：4.95¥阿区价格：9.86ARS$ (0.29¥)价格差：17.07倍 4. 恶果英文名：The Deed标签：冒险，角色扮演原价：6¥折扣率：71% 史低好评率：91%好评率国区价格：1.74¥阿区价格：3.74ARS$ (0.11¥)价格差：15.82倍 5. Gun Done英文名：Gun Done标签：休闲，独立原价：6¥折扣率：50% 史低好评率：89%好评率国区价格：3¥阿区价格：6.800000000000001ARS$ (0.2¥)价格差：15.0倍 6. 愤怒对抗：僵尸英文名：Rage Against The Zombies标签：休闲，动作原价：28¥折扣率：80% 非史低好评率：64%好评率国区价格：5.6¥阿区价格：13.26ARS$ (0.39¥)价格差：14.36倍 7. Alien Attack英文名：Alien Attack标签：休闲，动作，独立，冒险，模拟原价：11¥折扣率：70% 非史低好评率：82%好评率国区价格：3.3¥阿区价格：7.82ARS$ (0.23¥)价格差：14.35倍 8. 纸境奇缘英文名：Epistory - Typing Chronicles标签：动作，独立，冒险原价：74¥折扣率：60% 非史低好评率：94%好评率国区价格：29.6¥阿区价格：70.38ARS$ (2.07¥)价格差：14.3倍 9. 勿忘我英文名：Remember Me标签：动作，冒险原价：135¥折扣率：80% 史低好评率：83%好评率国区价格：27¥阿区价格：64.6ARS$ (1.9¥)价格差：14.21倍 10. 旭丽玛诸神英文名：Lords of Xulima标签：角色扮演原价：89¥折扣率：30% 非史低好评率：79%好评率国区价格：62.3¥阿区价格：154.36ARS$ (4.54¥)价格差：13.72倍 11. 热血格斗：大激战SP英文名：River City Melee : Battle Royal Special标签：体育，动作，冒险原价：88¥折扣率：85% 非史低好评率：56%好评率国区价格：13.2¥阿区价格：32.98ARS$ (0.97¥)价格差：13.61倍 12. 迷你小偷英文名：Mini Thief标签：休闲，独立，策略原价：10¥折扣率：77% 史低好评率：71%好评率国区价格：2.3¥阿区价格：5.78ARS$ (0.17¥)价格差：13.53倍 13. 幽浮2英文名：XCOM® 2标签：策略原价：190¥折扣率：90% 非史低好评率：84%好评率国区价格：19¥阿区价格：49.3ARS$ (1.45¥)价格差：13.1倍 14. Save the Dodos英文名：Save the Dodos标签：休闲，独立原价：15¥折扣率：80% 史低好评率：90%好评率国区价格：3¥阿区价格：7.82ARS$ (0.23¥)价格差：13.04倍 15. Annie Amber英文名：Annie Amber标签：休闲，独立，冒险原价：15¥折扣率：60% 非史低好评率：56%好评率国区价格：6¥阿区价格：15.64ARS$ (0.46¥)价格差：13.04倍 16. 口袋王国英文名：Pocket Kingdom标签：独立，冒险原价：34¥折扣率：80% 史低好评率：94%好评率国区价格：6.8¥阿区价格：18.36ARS$ (0.54¥)价格差：12.59倍 17. 丧尸围城3：天启版英文名：Dead Rising 3 Apocalypse Edition标签：动作原价：115¥折扣率：70% 非史低好评率：75%好评率国区价格：34.5¥阿区价格：96.9ARS$ (2.85¥)价格差：12.11倍 18. 主机守护者英文名：Mainframe Defenders标签：独立，策略原价：26¥折扣率：90% 史低好评率：89%好评率国区价格：2.6¥阿区价格：7.48ARS$ (0.22¥)价格差：11.82倍 19. 生化危机：保护伞小队英文名：Umbrella Corps标签：动作原价：112¥折扣率：75% 史低好评率：36%好评率国区价格：28¥阿区价格：80.58ARS$ (2.37¥)价格差：11.81倍 20. 月球6180英文名：6180 the moon标签：休闲，动作，独立原价：18¥折扣率：61% 非史低好评率：92%好评率国区价格：7.02¥阿区价格：20.4ARS$ (0.6¥)价格差：11.7倍 21. 轩辕剑外传 穹之扉英文名：Xuan-Yuan Sword: The Gate of Firmament标签：角色扮演原价：60¥折扣率：70% 史低好评率：72%好评率国区价格：18¥阿区价格：52.7ARS$ (1.55¥)价格差：11.61倍 22. Space Ribbon - Slipstream to the Extreme英文名：Space Ribbon - Slipstream to the Extreme标签：休闲，体育，动作，独立，模拟，竞速原价：18¥折扣率：60% 非史低好评率：60%好评率国区价格：7.2¥阿区价格：21.08ARS$ (0.62¥)价格差：11.61倍 23. OctaFight英文名：OctaFight标签：休闲，动作，独立原价：26¥折扣率：70% 史低好评率：None国区价格：7.8¥阿区价格：23.12ARS$ (0.68¥)价格差：11.47倍 24. Halloween Mysteries英文名：Halloween Mysteries标签：动作，独立，冒险原价：22¥折扣率：45% 非史低好评率：54%好评率国区价格：12.1¥阿区价格：36.38ARS$ (1.07¥)价格差：11.31倍 25. 无尽魔塔英文名：DungeonUp标签：独立，冒险，策略原价：22¥折扣率：80% 非史低好评率：84%好评率国区价格：4.4¥阿区价格：13.26ARS$ (0.39¥)价格差：11.28倍 26. 1000天逃生英文名：1000 days to escape标签：休闲，独立原价：22¥折扣率：50% 非史低好评率：82%好评率国区价格：11¥阿区价格：33.32ARS$ (0.98¥)价格差：11.22倍 27. 梦游逃生英文名：Back to Bed标签：休闲，动作，独立原价：25¥折扣率：80% 非史低好评率：78%好评率国区价格：5¥阿区价格：15.3ARS$ (0.45¥)价格差：11.11倍 28. DARQ英文名：DARQ: Complete Edition标签：动作，独立，冒险原价：70¥折扣率：66% 非史低好评率：93%好评率国区价格：23.8¥阿区价格：74.80000000000001ARS$ (2.2¥)价格差：10.82倍 29. 北方之魂英文名：Spirit of the North标签：休闲，独立，冒险原价：70¥折扣率：66% 非史低好评率：87%好评率国区价格：23.8¥阿区价格：74.80000000000001ARS$ (2.2¥)价格差：10.82倍 30. 火焰审判英文名：Trials of Fire标签：独立，策略，角色扮演原价：70¥折扣率：50% 非史低好评率：87%好评率国区价格：35¥阿区价格：110.16000000000001ARS$ (3.24¥)价格差：10.8倍 31. 极速大乱斗英文名：Speed Brawl标签：动作，独立，冒险原价：70¥折扣率：50% 非史低好评率：80%好评率国区价格：35¥阿区价格：110.16000000000001ARS$ (3.24¥)价格差：10.8倍 32. 火星地平线英文名：Mars Horizon标签：独立，策略，模拟原价：70¥折扣率：50% 非史低好评率：84%好评率国区价格：35¥阿区价格：110.16000000000001ARS$ (3.24¥)价格差：10.8倍 33. 魔境奇缘：文字大冒险英文名：Nanotale - Typing Chronicles标签：冒险，角色扮演原价：70¥折扣率：30% 非史低好评率：80%好评率国区价格：49¥阿区价格：154.36ARS$ (4.54¥)价格差：10.79倍 34. 复仇女神：神秘之旅3英文名：Nemezis: Mysterious Journey III标签：休闲，动作，独立，冒险，模拟原价：70¥折扣率：55% 史低好评率：61%好评率国区价格：31.5¥阿区价格：99.28ARS$ (2.92¥)价格差：10.79倍 35. 永恒之柱2：死亡之火英文名：Pillars of Eternity II: Deadfire标签：角色扮演原价：138¥折扣率：75% 史低好评率：87%好评率国区价格：34.5¥阿区价格：110.16000000000001ARS$ (3.24¥)价格差：10.65倍 36. Exile to Death英文名：Exile to Death标签：动作，独立，冒险，大型多人在线，角色扮演原价：68¥折扣率：90% 史低好评率：5%好评率国区价格：6.8¥阿区价格：21.76ARS$ (0.64¥)价格差：10.62倍 37. 虚构英文名：Figment标签：休闲，动作，独立，冒险原价：68¥折扣率：80% 非史低好评率：87%好评率国区价格：13.6¥阿区价格：43.86ARS$ (1.29¥)价格差：10.54倍 38. 逻辑机器人英文名：LogicBots标签：独立，模拟原价：68¥折扣率：80% 非史低好评率：78%好评率国区价格：13.6¥阿区价格：43.86ARS$ (1.29¥)价格差：10.54倍 39. 苍翼默示录：连续变换-扩展版英文名：BlazBlue: Continuum Shift Extend标签：动作原价：68¥折扣率：85% 非史低好评率：91%好评率国区价格：10.2¥阿区价格：32.98ARS$ (0.97¥)价格差：10.52倍 40. 旗帜的传说3英文名：The Banner Saga 3标签：独立，策略，角色扮演原价：85.01¥折扣率：80% 史低好评率：81%好评率国区价格：17¥阿区价格：55.080000000000005ARS$ (1.62¥)价格差：10.49倍 41. 旗帜的传说英文名：The Banner Saga标签：独立，策略，角色扮演原价：85¥折扣率：80% 非史低好评率：88%好评率国区价格：17¥阿区价格：55.080000000000005ARS$ (1.62¥)价格差：10.49倍 42. 旗帜的传说2英文名：The Banner Saga 2标签：独立，策略，角色扮演原价：85¥折扣率：80% 非史低好评率：90%好评率国区价格：17¥阿区价格：55.080000000000005ARS$ (1.62¥)价格差：10.49倍 43. 镜中的我英文名：Reflection of Mine标签：独立，冒险原价：31¥折扣率：90% 史低好评率：77%好评率国区价格：3.1¥阿区价格：10.2ARS$ (0.3¥)价格差：10.33倍 44. 龙之怒英文名：Dragon Rage标签：休闲，动作，独立原价：28¥折扣率：30% 非史低好评率：74%好评率国区价格：19.6¥阿区价格：64.94ARS$ (1.91¥)价格差：10.26倍 45. 七人杀阵英文名：七人杀阵 - Seven Sacrifices标签：休闲，独立，冒险原价：28¥折扣率：70% 史低好评率：81%好评率国区价格：8.4¥阿区价格：27.88ARS$ (0.82¥)价格差：10.24倍 46. 野生动物园大亨2英文名：Wildlife Park 2标签：休闲，独立，策略，模拟原价：28¥折扣率：25% 非史低好评率：70%好评率国区价格：21¥阿区价格：69.69999999999999ARS$ (2.05¥)价格差：10.24倍 47. 宝藏猎人模拟器英文名：Treasure Hunter Simulator标签：独立，模拟原价：57¥折扣率：90% 非史低好评率：63%好评率国区价格：5.7¥阿区价格：19.38ARS$ (0.57¥)价格差：10.0倍 48. Boiling Bolt英文名：Boiling Bolt标签：动作，独立原价：43¥折扣率：80% 非史低好评率：None国区价格：8.6¥阿区价格：29.24ARS$ (0.86¥)价格差：10.0倍 49. 亿万僵尸英文名：They Are Billions标签：策略原价：95¥折扣率：10% 非史低好评率：85%好评率国区价格：85.5¥阿区价格：291.04ARS$ (8.56¥)价格差：9.99倍 50. 突变元年：伊甸园之路英文名：Mutant Year Zero: Road to Eden标签：策略，角色扮演原价：115¥折扣率：60% 非史低好评率：90%好评率国区价格：46¥阿区价格：156.74ARS$ (4.61¥)价格差：9.98倍","categories":[{"name":"生活点滴","slug":"生活点滴","permalink":"https://tianxiafeiyu.github.io/categories/%E7%94%9F%E6%B4%BB%E7%82%B9%E6%BB%B4/"}],"tags":[{"name":"每日游戏报告（2023-06-15）","slug":"每日游戏报告（2023-06-15）","permalink":"https://tianxiafeiyu.github.io/tags/%E6%AF%8F%E6%97%A5%E6%B8%B8%E6%88%8F%E6%8A%A5%E5%91%8A%EF%BC%882023-06-15%EF%BC%89/"}]},{"title":"使用Fillder抓包安卓APP","slug":"技术开发/使用Fiddler抓包安卓APP","date":"2023-06-15T12:00:00.000Z","updated":"2023-06-15T12:00:00.000Z","comments":true,"path":"2023/06/15/技术开发/使用Fiddler抓包安卓APP/","link":"","permalink":"https://tianxiafeiyu.github.io/2023/06/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/%E4%BD%BF%E7%94%A8Fiddler%E6%8A%93%E5%8C%85%E5%AE%89%E5%8D%93APP/","excerpt":"","text":"fiddler 简介Fiddler是一个http协议调试代理工具，它能够记录并检查所有你的电脑和互联网之间的http通讯，设置断点，查看所有的“进出”Fiddler的数据（指cookie,html,js,css等文件）。 Fiddler 要比其他的网络调试器要更加简单，因为它不仅仅暴露http通讯还提供了一个用户友好的格式。 windows 端 fiddler 配置 允许https和远程连接 设置代理端口 获取本机ip地址 手机端 设置 wifi设置代理服务器，填写上面获取到的ip和设置的端口 浏览器访问 http://ip:port 下载证书 设置里安装证书 到此，fiddler 就可以抓手机上的请求了 fiddler 使用 请求过滤 格式化请求 获取响应体 实战，jump游戏资讯抓包","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"使用Fillder抓包安卓APP","slug":"使用Fillder抓包安卓APP","permalink":"https://tianxiafeiyu.github.io/tags/%E4%BD%BF%E7%94%A8Fillder%E6%8A%93%E5%8C%85%E5%AE%89%E5%8D%93APP/"}]},{"title":"深入浅出设计模式","slug":"技术开发/深入浅出设计模式","date":"2023-02-28T23:39:31.000Z","updated":"2023-02-28T23:39:31.000Z","comments":true,"path":"2023/02/28/技术开发/深入浅出设计模式/","link":"","permalink":"https://tianxiafeiyu.github.io/2023/02/28/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"说明如果你也曾有这样的疑惑——怎样更优雅地实现需求？ 那么设计模式便是打开这扇门的钥匙。程序界无数的前辈们花费无数心血，将程序设计的几种方式归纳总结，整理出 23 种常用的设计模式，涵盖了对象创建、行为交互、结构梳理等方方面面。无论是在框架的学习中，抑或是代码实战中，设计模式都扮演着不可或缺的角色。 你将： 系统归纳 3 大类设计模式，了解设计模式的 6 大原则 从生活中的例子出发，学习 23 种设计模式 在实战环节学习设计模式的应用 你可以这样学： 通过知识讲解与代码示例结合的方式深入理解各类设计模式 通过配套习题巩固学习内容 通过场景实战逐步掌握设计模式的应用 在评论区中与小伙伴一起沟通交流学习经验 前言概述 Introduction设计模式在面试中的考点通常是介绍其原理并说出优缺点。或者对比几个比较相似的模式的异同点。在笔试中可能会出现画出某个设计模式的 UML 图这样的题。虽说面试中占的比重不大，但并不代表它不重要。恰恰相反，设计模式于程序员而言相当重要，它是我们写出优秀程序的保障。设计模式与程序员的架构能力与阅读源码的能力息息相关，非常值得我们深入学习。 面向对象的特点是 可维护、可复用、可扩展、灵活性好，它最强大的地方在于：随着业务变得越来越复杂，面向对象依然能够使得程序结构良好，而面向过程却会导致程序越来越臃肿。 让面向对象保持结构良好的秘诀就是设计模式，面向对象结合设计模式，才能真正体会到程序变得可维护、可复用、可扩展、灵活性好。设计模式对于程序员而言并不陌生，每个程序员在编程时都会或多或少的接触到设计模式。无论是在大型程序的架构中，亦或是在源码的学习中，设计模式都扮演着非常重要的角色。 今天我们就一起来探索设计模式的世界！ 设计模式的六大原则 Six principles设计模式的世界丰富多彩，比如生产一个个“产品”的工厂模式，衔接两个不相关接口的适配器模式，用不同的方式做同一件事的策略模式，构建步骤稳定、根据构建过程的不同配置构建出不同对象的建造者模式等等。 无论何种设计模式，都是基于六大设计原则： 开闭原则：一个软件实体如类、模块和函数应该对修改封闭，对扩展开放。单一职责原则：一个类只做一件事，一个类应该只有一个引起它修改的原因。里氏替换原则：子类应该可以完全替换父类。也就是说在使用继承时，只扩展新功能，而不要破坏父类原有的功能。依赖倒置原则：细节应该依赖于抽象，抽象不应依赖于细节。把抽象层放在程序设计的高层，并保持稳定，程序的细节变化由低层的实现层来完成。迪米特法则：又名“最少知道原则”，一个类不应知道自己操作的类的细节，换言之，只和朋友谈话，不和朋友的朋友谈话。接口隔离原则：客户端不应依赖它不需要的接口。如果一个接口在实现时，部分方法由于冗余被客户端空实现，则应该将接口拆分，让实现类只需依赖自己需要的接口方法。 第一章：构建型模式 Creational Patterns工厂模式 Factory在平时编程中，构建对象最常用的方式是 new 一个对象。乍一看这种做法没什么不好，而实际上这也属于一种硬编码。每 new 一个对象，相当于调用者多知道了一个类，增加了类与类之间的联系，不利于程序的松耦合。其实构建过程可以被封装起来，工厂模式便是用于封装对象的设计模式 简单工厂模式举个例子，直接 new 对象的方式相当于当我们需要一个苹果时，我们需要知道苹果的构造方法，需要一个梨子时，需要知道梨子的构造方法。更好的实现方式是有一个水果工厂，我们告诉工厂需要什么种类的水果，水果工厂将我们需要的水果制造出来给我们就可以了。这样我们就无需知道苹果、梨子是怎么种出来的，只用和水果工厂打交道即可。 水果工厂： 12345678910public class FruitFactory &#123; public Fruit create(String type)&#123; switch (type)&#123; case &quot;苹果&quot;: return new Apple(); case &quot;梨子&quot;: return new Pear(); default: throw new IllegalArgumentException(&quot;暂时没有这种水果&quot;); &#125; &#125;&#125; 调用者： 12345678910public class User &#123; private void eat()&#123; FruitFactory fruitFactory = new FruitFactory(); Fruit apple = fruitFactory.create(&quot;苹果&quot;); Fruit pear = fruitFactory.create(&quot;梨子&quot;); apple.eat(); pear.eat(); &#125;&#125; 事实上，将构建过程封装的好处不仅可以降低耦合，如果某个产品构造方法相当复杂，使用工厂模式可以大大减少代码重复。比如，如果生产一个苹果需要苹果种子、阳光、水分，将工厂修改如下： 12345678910111213141516public class FruitFactory &#123; public Fruit create(String type) &#123; switch (type) &#123; case &quot;苹果&quot;: AppleSeed appleSeed = new AppleSeed(); Sunlight sunlight = new Sunlight(); Water water = new Water(); return new Apple(appleSeed, sunlight, water); case &quot;梨子&quot;: return new Pear(); default: throw new IllegalArgumentException(&quot;暂时没有这种水果&quot;); &#125; &#125;&#125; 调用者的代码则完全不需要变化，而且调用者不需要在每次需要苹果时，自己去构建苹果种子、阳光、水分以获得苹果。苹果的生产过程再复杂，也只是工厂的事。这就是封装的好处，假如某天科学家发明了让苹果更香甜的肥料，要加入苹果的生产过程中的话，也只需要在工厂中修改，调用者完全不用关心。 不知不觉中，我们就写出了简单工厂模式的代码。工厂模式一共有三种： 简单工厂模式 工厂方法模式 抽象工厂模式 注：在 GoF 所著的《设计模式》一书中，简单工厂模式被划分为工厂方法模式的一种特例，没有单独被列出来。 总而言之，简单工厂模式就是让一个工厂类承担构建所有对象的职责。调用者需要什么产品，让工厂生产出来即可。它的弊端也显而易见： 一是如果需要生产的产品过多，此模式会导致工厂类过于庞大，承担过多的职责，变成超级类。当苹果生产过程需要修改时，要来修改此工厂。梨子生产过程需要修改时，也要来修改此工厂。也就是说这个类不止一个引起修改的原因。违背了单一职责原则。二是当要生产新的产品时，必须在工厂类中添加新的分支。而开闭原则告诉我们：类应该对修改封闭。我们希望在添加新功能时，只需增加新的类，而不是修改既有的类，所以这就违背了开闭原则。 工厂方法模式为了解决简单工厂模式的这两个弊端，工厂方法模式应运而生，它规定每个产品都有一个专属工厂。比如苹果有专属的苹果工厂，梨子有专属的梨子工厂，代码如下： 苹果工厂： 123456public class AppleFactory &#123; public Fruit create()&#123; return new Apple(); &#125;&#125; 梨子工厂： 123456public class PearFactory &#123; public Fruit create()&#123; return new Pear(); &#125;&#125; 调用者： 1234567891011public class User &#123; private void eat()&#123; AppleFactory appleFactory = new AppleFactory(); Fruit apple = appleFactory.create(); PearFactory pearFactory = new PearFactory(); Fruit pear = pearFactory.create(); apple.eat(); pear.eat(); &#125;&#125; 有读者可能会开喷了，这样和直接 new 出苹果和梨子有什么区别？上文说工厂是为了减少类与类之间的耦合，让调用者尽可能少的和其他类打交道。用简单工厂模式，我们只需要知道 FruitFactory，无需知道 Apple 、Pear 类，很容易看出耦合度降低了。但用工厂方法模式，调用者虽然不需要和 Apple 、Pear 类打交道了，但却需要和 AppleFactory、PearFactory 类打交道。有几种水果就需要知道几个工厂类，耦合度完全没有下降啊，甚至还增加了代码量！ 这位读者请先放下手中的大刀，仔细想一想，工厂模式的第二个优点在工厂方法模式中还是存在的。当构建过程相当复杂时，工厂将构建过程封装起来，调用者可以很方便的直接使用，同样以苹果生产为例： 123456789public class AppleFactory &#123; public Fruit create()&#123; AppleSeed appleSeed = new AppleSeed(); Sunlight sunlight = new Sunlight(); Water water = new Water(); return new Apple(appleSeed, sunlight, water); &#125;&#125; 调用者无需知道苹果的生产细节，当生产过程需要修改时也无需更改调用端。同时，工厂方法模式解决了简单工厂模式的两个弊端。 当生产的产品种类越来越多时，工厂类不会变成超级类。工厂类会越来越多，保持灵活。不会越来越大、变得臃肿。如果苹果的生产过程需要修改时，只需修改苹果工厂。梨子的生产过程需要修改时，只需修改梨子工厂。符合单一职责原则。当需要生产新的产品时，无需更改既有的工厂，只需要添加新的工厂即可。保持了面向对象的可扩展性，符合开闭原则。 抽象工厂模式 Abstract factory上一节中的工厂方法模式可以进一步优化，提取出公共的工厂接口： 1234public interface IFactory &#123; Fruit create();&#125; 然后苹果工厂和梨子工厂都实现此接口： 1234567public class AppleFactory implements IFactory &#123; @Override public Fruit create()&#123; return new Apple(); &#125;&#125; 此时，调用者可以将 AppleFactory 和 PearFactory 统一作为 IFactory 对象使用，调用者代码如下： 12345678910public class User &#123; private void eat()&#123; IFactory appleFactory = new AppleFactory(); Fruit apple = appleFactory.create(); IFactory pearFactory = new PearFactory(); Fruit pear = pearFactory.create(); apple.eat(); pear.eat(); &#125;&#125; 可以看到，我们在创建时指定了具体的工厂类后，在使用时就无需再关心是哪个工厂类，只需要将此工厂当作抽象的 IFactory 接口使用即可。这种经过抽象的工厂方法模式被称作抽象工厂模式。 由于客户端只和 IFactory 打交道了，调用的是接口中的方法，使用时根本不需要知道是在哪个具体工厂中实现的这些方法，这就使得替换工厂变得非常容易。 例如： 1234567public class User &#123; private void eat()&#123; IFactory factory = new AppleFactory(); Fruit fruit = factory.create(); fruit.eat(); &#125;&#125; 如果需要替换为吃梨子，只需要更改一行代码即可： 1234567public class User &#123; private void eat()&#123; IFactory factory = new PearFactory(); Fruit fruit = factory.create(); fruit.eat(); &#125;&#125; IFactory 中只有一个抽象方法时，或许还看不出抽象工厂模式的威力。实际上抽象工厂模式主要用于替换一系列方法。例如将程序中的 SQL Server 数据库整个替换为 Access 数据库，使用抽象方法模式的话，只需在 IFactory 接口中定义好增删改查四个方法，让 SQLFactory 和 AccessFactory 实现此接口，调用时直接使用 IFactory 中的抽象方法即可，调用者无需知道使用的什么数据库，我们就可以非常方便的整个替换程序的数据库，并且让客户端毫不知情。 抽象工厂模式很好的发挥了开闭原则、依赖倒置原则，但缺点是抽象工厂模式太重了，如果 IFactory 接口需要新增功能，则会影响到所有的具体工厂类。使用抽象工厂模式，替换具体工厂时只需更改一行代码，但要新增抽象方法则需要修改所有的具体工厂类。所以抽象工厂模式适用于增加同类工厂这样的横向扩展需求，不适合新增功能这样的纵向扩展。 单例模式 Singleton单例模式非常常见，某个对象全局只需要一个实例时，就可以使用单例模式。它的优点也显而易见： 它能够避免对象重复创建，节约空间并提升效率避免由于操作不同实例导致的逻辑错误单例模式有两种实现方式：饿汉式和懒汉式。 饿汉式饿汉式：变量在声明时便初始化。 12345678910111213public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton() &#123; &#125; public static Singleton getInstance() &#123; return instance; &#125;&#125; 可以看到，我们将构造方法定义为 private，这就保证了其他类无法实例化此类，必须通过 getInstance 方法才能获取到唯一的 instance 实例，非常直观。但饿汉式有一个弊端，那就是即使这个单例不需要使用，它也会在类加载之后立即创建出来，占用一块内存，并增加类初始化时间。就好比一个电工在修理灯泡时，先把所有工具拿出来，不管是不是所有的工具都用得上。就像一个饥不择食的饿汉，所以称之为饿汉式。 懒汉式懒汉式：先声明一个空变量，需要用时才初始化。例如： 123456789101112131415public class Singleton &#123; private static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance()&#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 我们先声明了一个初始值为 null 的 instance 变量，当需要使用时判断此变量是否已被初始化，没有初始化的话才 new 一个实例出来。就好比电工在修理灯泡时，开始比较偷懒，什么工具都不拿，当发现需要使用螺丝刀时，才把螺丝刀拿出来。当需要用钳子时，再把钳子拿出来。就像一个不到万不得已不会行动的懒汉，所以称之为懒汉式。 懒汉式解决了饿汉式的弊端，好处是按需加载，避免了内存浪费，减少了类初始化时间。 上述代码的懒汉式单例乍一看没什么问题，但其实它不是线程安全的。如果有多个线程同一时间调用 getInstance 方法，instance 变量可能会被实例化多次。为了保证线程安全，我们需要给判空过程加上锁： 1234567891011121314151617public class Singleton &#123; private static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 这样就能保证多个线程调用 getInstance 时，一次最多只有一个线程能够执行判空并 new 出实例的操作，所以 instance 只会实例化一次。但这样的写法仍然有问题，当多个线程调用 getInstance 时，每次都需要执行 synchronized 同步化方法，这样会严重影响程序的执行效率。所以更好的做法是在同步化之前，再加上一层检查： 12345678910111213141516171819public class Singleton &#123; private static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 这样增加一种检查方式后，如果 instance 已经被实例化，则不会执行同步化操作，大大提升了程序效率。上面这种写法也就是我们平时较常用的双检锁方式实现的线程安全的单例模式。 但这样的懒汉式单例仍然有一个问题，JVM 底层为了优化程序运行效率，可能会对我们的代码进行指令重排序，在一些特殊情况下会导致出现空指针，为了防止这个问题，更进一步的优化是给 instance 变量加上 volatile 关键字。 有读者可能会有疑问，我们在外面检查了 instance &#x3D;&#x3D; null, 那么锁里面的空检查是否可以去掉呢？ 答案是不可以。如果里面不做空检查，可能会有两个线程同时通过了外面的空检查，然后在一个线程 new 出实例后，第二个线程进入锁中又 new 出一个实例，导致创建多个实例。 除了双检锁方式外，还有一种比较常见的静态内部类方式保证懒汉式单例的线程安全： 1234567891011121314public class Singleton &#123; private static class SingletonHolder &#123; public static Singleton instance = new Singleton(); &#125; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; return SingletonHolder.instance; &#125;&#125; 虽然我们经常使用这种静态内部类的懒加载方式，但其中的原理不一定每个人都清楚。接下来我们便来分析其原理，搞清楚两个问题： 静态内部类方式是怎么实现懒加载的 静态内部类方式是怎么保证线程安全的 Java 类的加载过程包括：加载、验证、准备、解析、初始化。初始化阶段即执行类的 clinit 方法（clinit &#x3D; class + initialize），包括为类的静态变量赋初始值和执行静态代码块中的内容。但不会立即加载内部类，内部类会在使用时才加载。所以当此 Singleton 类加载时，SingletonHolder 并不会被立即加载，所以不会像饿汉式那样占用内存。 另外，Java 虚拟机规定，当访问一个类的静态字段时，如果该类尚未初始化，则立即初始化此类。当调用Singleton 的 getInstance 方法时，由于其使用了 SingletonHolder 的静态变量 instance，所以这时才会去初始化 SingletonHolder，在 SingletonHolder 中 new 出 Singleton 对象。这就实现了懒加载。 第二个问题的答案是 Java 虚拟机的设计是非常稳定的，早已经考虑到了多线程并发执行的情况。虚拟机在加载类的 clinit 方法时，会保证 clinit 在多线程中被正确的加锁、同步。即使有多个线程同时去初始化一个类，一次也只有一个线程可以执行 clinit 方法，其他线程都需要阻塞等待，从而保证了线程安全。 懒加载方式在平时非常常见，比如打开我们常用的美团、饿了么、支付宝 app，应用首页会立刻刷新出来，但其他标签页在我们点击到时才会刷新。这样就减少了流量消耗，并缩短了程序启动时间。再比如游戏中的某些模块，当我们点击到时才会去下载资源，而不是事先将所有资源都先下载下来，这也属于懒加载方式，避免了内存浪费。 但懒汉式的缺点就是将程序加载时间从启动时延后到了运行时，虽然启动时间缩短了，但我们浏览页面时就会看到数据的 loading 过程。如果用饿汉式将页面提前加载好，我们浏览时就会特别的顺畅，也不失为一个好的用户体验。比如我们常用的 QQ、微信 app，作为即时通讯的工具软件，它们会在启动时立即刷新所有的数据，保证用户看到最新最全的内容。著名的软件大师 Martin 在《代码整洁之道》一书中也说到：不提倡使用懒加载方式，因为程序应该将构建与使用分离，达到解耦。饿汉式在声明时直接初始化变量的方式也更直观易懂。所以在使用饿汉式还是懒汉式时，需要权衡利弊。 一般的建议是：对于构建不复杂，加载完成后会立即使用的单例对象，推荐使用饿汉式。对于构建过程耗时较长，并不是所有使用此类都会用到的单例对象，推荐使用懒汉式。 建造者模式 Builder建造者模式用于创建过程稳定，但配置多变的对象。在《设计模式》一书中的定义是：将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示。 经典的“建造者-指挥者”模式现在已经不太常用了，现在建造者模式主要用来通过链式调用生成不同的配置。比如我们要制作一杯珍珠奶茶。它的制作过程是稳定的，除了必须要知道奶茶的种类和规格外，是否加珍珠和是否加冰是可选的。使用建造者模式表示如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class MilkTea &#123; private final String type; private final String size; private final boolean pearl; private final boolean ice; private MilkTea() &#123;&#125; private MilkTea(Builder builder) &#123; this.type = builder.type; this.size = builder.size; this.pearl = builder.pearl; this.ice = builder.ice; &#125; public String getType() &#123; return type; &#125; public String getSize() &#123; return size; &#125; public boolean isPearl() &#123; return pearl; &#125; public boolean isIce() &#123; return ice; &#125; public static class Builder &#123; private final String type; private String size = &quot;中杯&quot;; private boolean pearl = true; private boolean ice = false; public Builder(String type) &#123; this.type = type; &#125; public Builder size(String size) &#123; this.size = size; return this; &#125; public Builder pearl(boolean pearl) &#123; this.pearl = pearl; return this; &#125; public Builder ice(boolean cold) &#123; this.ice = cold; return this; &#125; public MilkTea build() &#123; return new MilkTea(this); &#125; &#125;&#125; 可以看到，我们将 MilkTea 的构造方法设置为私有的，所以外部不能通过 new 构建出 MilkTea 实例，只能通过 Builder 构建。对于必须配置的属性，通过 Builder 的构造方法传入，可选的属性通过 Builder 的链式调用方法传入，如果不配置，将使用默认配置，也就是中杯、加珍珠、不加冰。根据不同的配置可以制作出不同的奶茶： 123456789101112131415161718192021222324252627282930313233343536public class User &#123; private void buyMilkTea() &#123; MilkTea milkTea = new MilkTea.Builder(&quot;原味&quot;).build(); show(milkTea); MilkTea chocolate =new MilkTea.Builder(&quot;巧克力味&quot;) .ice(false) .build(); show(chocolate); MilkTea strawberry = new MilkTea.Builder(&quot;草莓味&quot;) .size(&quot;大杯&quot;) .pearl(false) .ice(true) .build(); show(strawberry); &#125; private void show(MilkTea milkTea) &#123; String pearl; if (milkTea.isPearl()) pearl = &quot;加珍珠&quot;; else pearl = &quot;不加珍珠&quot;; String ice; if (milkTea.isIce()) &#123; ice = &quot;加冰&quot;; &#125; else &#123; ice = &quot;不加冰&quot;; &#125; System.out.println(&quot;一份&quot; + milkTea.getSize() + &quot;、&quot; + pearl + &quot;、&quot; + ice + &quot;的&quot; + milkTea.getType() + &quot;奶茶&quot;); &#125;&#125; 运行程序，输出如下： 一份中杯、加珍珠、不加冰的原味奶茶 一份中杯、加珍珠、不加冰的巧克力味奶茶 一份大杯、不加珍珠、加冰的草莓味奶茶 原型模式 Prototype原型模式：用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。 定义看起来有点绕口，实际上在 Java 中，Object 的 clone() 方法就属于原型模式，不妨简单的理解为：原型模式就是用来克隆对象的。 举个例子，比如有一天，周杰伦到奶茶店点了一份不加冰的原味奶茶，你说我是周杰伦的忠实粉，我也要一份跟周杰伦一样的。用程序表示如下： 奶茶类： 1234public class MilkTea &#123; public String type; public boolean ice;&#125; 下单： 1234567private void order()&#123; MilkTea milkTeaOfJay = new MilkTea(); milkTeaOfJay.type = &quot;原味&quot;; milkTeaOfJay.ice = false; MilkTea yourMilkTea = milkTeaOfJay;&#125; 好像没什么问题，将周杰伦的奶茶直接赋值到你的奶茶上就行了，看起来我们并不需要 clone 方法。但是这样真的是复制了一份奶茶吗？ 当然不是，Java 对非基本类型对象的赋值只是传递地址。这样赋值之后，yourMilkTea 仍然指向的周杰伦的奶茶，并不会多一份一样的奶茶。 那么我们要怎么做才能点一份一样的奶茶呢？将程序修改如下就可以了： 123456789private void order()&#123; MilkTea milkTeaOfJay = new MilkTea(); milkTeaOfJay.type = &quot;原味&quot;; milkTeaOfJay.ice = false; MilkTea yourMilkTea = new MilkTea(); yourMilkTea.type = &quot;原味&quot;; yourMilkTea.ice = false;&#125; 只有这样，yourMilkTea 才是 new 出来的一份全新的奶茶。我们设想一下，如果有一千个粉丝都需要点和周杰伦一样的奶茶的话，按照现在的写法就需要 new 一千次，并为每一个新的对象赋值一千次，造成大量的重复。 更糟糕的是，如果周杰伦临时决定加个冰，那么粉丝们的奶茶配置也要跟着修改： 123456789101112private void order()&#123; MilkTea milkTeaOfJay = new MilkTea(); milkTeaOfJay.type = &quot;原味&quot;; milkTeaOfJay.ice = true; MilkTea yourMilkTea = new MilkTea(); yourMilkTea.type = &quot;原味&quot;; yourMilkTea.ice = true; // 将一千个粉丝的 ice 都修改为 true ...&#125; 大批量的修改无疑是非常丑陋的做法，这就是我们需要 clone 方法的理由！ 运用原型模式，在 MilkTea 中新增 clone 方法： 1234567891011public class MilkTea&#123; public String type; public boolean ice; public MilkTea clone()&#123; MilkTea milkTea = new MilkTea(); milkTea.type = this.type; milkTea.ice = this.ice; return milkTea; &#125;&#125; 下单： 12345678910private void order()&#123; MilkTea milkTeaOfJay = new MilkTea(); milkTeaOfJay.type = &quot;原味&quot;; milkTeaOfJay.ice = false; MilkTea yourMilkTea = milkTeaOfJay.clone(); // 一千位粉丝都调用 milkTeaOfJay 的 clone 方法即可 ...&#125; 这就是原型模式，Java 中有一个语法糖，让我们并不需要手写 clone 方法。这个语法糖就是 Cloneable 接口，我们只要让需要拷贝的类实现此接口即可。 12345678910public class MilkTea implements Cloneable&#123; public String type; public boolean ice; @NonNull @Override protected MilkTea clone() throws CloneNotSupportedException &#123; return (MilkTea) super.clone(); &#125;&#125; 值得注意的是，Java 自带的 clone 方法是浅拷贝的。也就是说调用此对象的 clone 方法，只有基本类型的参数会被拷贝一份，非基本类型的对象不会被拷贝一份，而是继续使用传递引用的方式。如果需要实现深拷贝，必须要自己手动修改 clone 方法才行。 小结 Summary构建型模式 工厂方法模式：为每一类对象建立工厂，将对象交由工厂创建，客户端只和工厂打交道。 抽象工厂模式：为每一类工厂提取出抽象接口，使得新增工厂、替换工厂变得非常容易。 单例模式：全局使用同一个对象，分为饿汉式和懒汉式。懒汉式有双检锁和内部类两种实现方式。 建造者模式：用于创建构造过程稳定的对象，不同的 Builder 可以定义不同的配置。 原型模式：为一个类定义 clone 方法，使得创建相同的对象更方便。 第二章：结构型模式 Structural Patterns适配器模式 Adapter说到适配器，我们最熟悉的莫过于电源适配器了，也就是手机的充电头。它就是适配器模式的一个应用。 试想一下，你有一条连接电脑和手机的 USB 数据线，连接电脑的一端从电脑接口处接收 5V 的电压，连接手机的一端向手机输出 5V 的电压，并且他们工作良好。 中国的家用电压都是 220V，所以 USB 数据线不能直接拿来给手机充电，这时候我们有两种方案： 单独制作手机充电器，接收 220V 家用电压，输出 5V 电压。添加一个适配器，将 220V 家庭电压转化为类似电脑接口的 5V 电压，再连接数据线给手机充电。如果你使用过早期的手机，就会知道以前的手机厂商采用的就是第一种方案：早期的手机充电器都是单独制作的，充电头和充电线是连在一起的。现在的手机都采用了电源适配器加数据线的方案。这是生活中应用适配器模式的一个进步。 适配器模式：将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。 适配的意思是适应、匹配。通俗地讲，适配器模式适用于有相关性但不兼容的结构，源接口通过一个中间件转换后才可以适用于目标接口，这个转换过程就是适配，这个中间件就称之为适配器。 家用电源和 USB 数据线有相关性：家用电源输出电压，USB 数据线输入电压。但两个接口无法兼容，因为一个输出 220V，一个输入 5V，通过适配器将输出 220V 转换成输出 5V 之后才可以一起工作。 让我们用程序来模拟一下这个过程。 首先，家庭电源提供 220V 的电压： 123456789101112131415161718class HomeBattery &#123; int supply() &#123; // 家用电源提供一个 220V 的输出电压 return 220; &#125;&#125;USB 数据线只接收 5V 的充电电压：Javaclass USBLine &#123; void charge(int volt) &#123; // 如果电压不是 5V，抛出异常 if (volt != 5) throw new IllegalArgumentException(&quot;只能接收 5V 电压&quot;); // 如果电压是 5V，正常充电 System.out.println(&quot;正常充电&quot;); &#125;&#125; 先来看看适配之前，用户如果直接用家庭电源给手机充电： 1234567891011public class User &#123; @Test public void chargeForPhone() &#123; HomeBattery homeBattery = new HomeBattery(); int homeVolt = homeBattery.supply(); System.out.println(&quot;家庭电源提供的电压是 &quot; + homeVolt + &quot;V&quot;); USBLine usbLine = new USBLine(); usbLine.charge(homeVolt); &#125;&#125; 运行程序，输出如下： 123家庭电源提供的电压是 220Vjava.lang.IllegalArgumentException: 只能接收 5V 电压 这时，我们加入电源适配器： 1234567class Adapter &#123; int convert(int homeVolt) &#123; // 适配过程：使用电阻、电容等器件将其降低为输出 5V int chargeVolt = homeVolt - 215; return chargeVolt; &#125;&#125; 然后，用户再使用适配器将家庭电源提供的电压转换为充电电压： 123456789101112131415public class User &#123; @Test public void chargeForPhone() &#123; HomeBattery homeBattery = new HomeBattery(); int homeVolt = homeBattery.supply(); System.out.println(&quot;家庭电源提供的电压是 &quot; + homeVolt + &quot;V&quot;); Adapter adapter = new Adapter(); int chargeVolt = adapter.convert(homeVolt); System.out.println(&quot;使用适配器将家庭电压转换成了 &quot; + chargeVolt + &quot;V&quot;); USBLine usbLine = new USBLine(); usbLine.charge(chargeVolt); &#125;&#125; 运行程序，输出如下： 1234家庭电源提供的电压是 220V使用适配器将家庭电压转换成了 5V正常充电这就是适配器模式。在我们日常的开发中经常会使用到各种各样的 Adapter，都属于适配器模式的应用。 但适配器模式并不推荐多用。因为未雨绸缪好过亡羊补牢，如果事先能预防接口不同的问题，不匹配问题就不会发生，只有遇到源接口无法改变时，才应该考虑使用适配器。比如现代的电源插口中很多已经增加了专门的 USB 充电接口，让我们不需要再使用适配器转换接口，这又是社会的一个进步。 补充： 收到不少读者的反馈，认为文中的这个例子举得过于简单。但实际上这个例子已经反映出了适配器模式的基本概念了。 在本例中，适配前的 A 表示 220V，适配后的 B 表示 5V，C 就是适配过程，本例中的适配过程是使用电阻、电容等器件将其降低为输出 5V。适配器的核心思想就是使用适配器包装适配过程，这个适配器通常被命名为 Adapter 或者 Wrapper。 只不过通常我们见到的适配器模式是基于接口的适配。那么我们不妨看一个接口适配的例子。 设想我们已经有了一个 Task 类，实现了 Callable 接口： 12345678public class Task implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; System.out.println(&quot;I&#x27;m called.&quot;); return null; &#125;&#125; 这时我们需要这个 Task 类在一个子线程中执行： 1234567891011public class Client &#123; @Test public void call() throws InterruptedException &#123; Callable&lt;Integer&gt; callable = new Task(); // 这一行无法编译通过 Thread thread = new Thread(callable); thread.start(); // 等待 1s 保证 thread 执行完成 Thread.sleep(1000); &#125;&#125; 但我们会发现，Thread thread &#x3D; new Thread(callable); 这一行是无法编译通过的，因为 Thread 中需要接收的参数类型是 Runnable。 在业务上来说，Runnable 的 run 方法和 Callable 的 call 方法意义是一样的，这里的问题是接口不一致。所以我们可以通过接口适配器将接口转换成一致的。 1234567891011121314151617public class RunnableAdapter implements Runnable &#123; private final Callable&lt;?&gt; callable; public RunnableAdapter(Callable&lt;?&gt; callable) &#123; this.callable = callable; &#125; @Override public void run() &#123; try &#123; callable.call(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 可以看到，在 RunnableAdapter 中，我们包装了原始的 Callable 接口，并实现了新的 Runnable 接口。在 Runnable 接口的 run 方法中，调用 Callable 接口的 call 方法。实现同样的业务功能。 在客户端中使用 RunnableAdapter 类： 12345678910public class Client &#123; @Test public void call() throws InterruptedException &#123; Callable&lt;Integer&gt; callable = new Task(); Thread thread = new Thread(new RunnableAdapter(callable)); thread.start(); // 等待 1s 保证 thread 执行完成 Thread.sleep(1000); &#125;&#125; 运行程序，输出如下： I&#39;m called. 可以看到，通过添加适配器，使得原本不兼容的两个接口能够正常工作了。适配器在其中的职责是包装了原有的接口，这样的适配器称为接口适配器。类似地，包装一个对象的适配器被称之为对象适配器。 适配器模式的核心思想是添加一个中间件，包装原有的接口或对象，将其转换为另一个接口或对象，以适应新的业务场景。适配器模式和后文介绍的装饰者模式、代理模式同属于包装模式。与其他两种包装模式不同的是，适配器模式重在转换，不改变原有的功能。而装饰者模式会在包装的基础上增强或添加功能，代理模式用于加强对原有类的控制。 桥接模式 Bridge考虑这样一个需求：绘制矩形、圆形、三角形这三种图案。按照面向对象的理念，我们至少需要三个具体类，对应三种不同的图形。 抽象接口 IShape： 123public interface IShape &#123; void draw();&#125; 三个具体形状类： 12345678910111213141516171819202122class Rectangle implements IShape &#123; @Override public void draw() &#123; System.out.println(&quot;绘制矩形&quot;); &#125;&#125;class Round implements IShape &#123; @Override public void draw() &#123; System.out.println(&quot;绘制圆形&quot;); &#125;&#125;class Triangle implements IShape &#123; @Override public void draw() &#123; System.out.println(&quot;绘制三角形&quot;); &#125;&#125; 接下来我们有了新的需求，每种形状都需要有四种不同的颜色：红、蓝、黄、绿。 这时我们很容易想到两种设计方案： 为了复用形状类，将每种形状定义为父类，每种不同颜色的图形继承自其形状父类。此时一共有 12 个类。 为了复用颜色类，将每种颜色定义为父类，每种不同颜色的图形继承自其颜色父类。此时一共有 12 个类。 乍一看没什么问题，我们使用了面向对象的继承特性，复用了父类的代码并扩展了新的功能。 但仔细想一想，如果以后要增加一种颜色，比如黑色，那么我们就需要增加三个类；如果再要增加一种形状，我们又需要增加五个类，对应 5 种颜色。 更不用说遇到增加 20 个形状，20 种颜色的需求，不同的排列组合将会使工作量变得无比的庞大。看来我们不得不重新思考设计方案。 形状和颜色，都是图形的两个属性。他们两者的关系是平等的，所以不属于继承关系。更好的的实现方式是：将形状和颜色分离，根据需要对形状和颜色进行组合，这就是桥接模式的思想。 桥接模式：将抽象部分与它的实现部分分离，使它们都可以独立地变化。它是一种对象结构型模式，又称为柄体模式或接口模式。 官方定义非常精准、简练，但却有点不易理解。通俗地说，如果一个对象有两种或者多种分类方式，并且两种分类方式都容易变化，比如本例中的形状和颜色。这时使用继承很容易造成子类越来越多，所以更好的做法是把这种分类方式分离出来，让他们独立变化，使用时将不同的分类进行组合即可。 说到这里，不得不提一个设计原则：合成 &#x2F; 聚合复用原则。虽然它没有被划分到六大设计原则中，但它在面向对象的设计中也非常的重要。 合成 &#x2F; 聚合复用原则：优先使用合成 &#x2F; 聚合，而不是类继承。 继承虽然是面向对象的三大特性之一，但继承会导致子类与父类有非常紧密的依赖关系，它会限制子类的灵活性和子类的复用性。而使用合成 &#x2F; 聚合，也就是使用接口实现的方式，就不存在依赖问题，一个类可以实现多个接口，可以很方便地拓展功能。 让我们一起来看一下本例使用桥接模式的程序实现： 新建接口类 IColor，仅包含一个获取颜色的方法： 123public interface IColor &#123; String getColor();&#125; 每种颜色都实现此接口： 123456789101112131415161718192021222324252627282930public class Red implements IColor &#123; @Override public String getColor() &#123; return &quot;红&quot;; &#125;&#125;public class Blue implements IColor &#123; @Override public String getColor() &#123; return &quot;蓝&quot;; &#125;&#125;public class Yellow implements IColor &#123; @Override public String getColor() &#123; return &quot;黄&quot;; &#125;&#125;public class Green implements IColor &#123; @Override public String getColor() &#123; return &quot;绿&quot;; &#125;&#125; 在每个形状类中，桥接 IColor 接口： 12345678910111213141516171819202122232425262728293031323334353637383940414243class Rectangle implements IShape &#123; private IColor color; void setColor(IColor color) &#123; this.color = color; &#125; @Override public void draw() &#123; System.out.println(&quot;绘制&quot; + color.getColor() + &quot;矩形&quot;); &#125;&#125;class Round implements IShape &#123; private IColor color; void setColor(IColor color) &#123; this.color = color; &#125; @Override public void draw() &#123; System.out.println(&quot;绘制&quot; + color.getColor() + &quot;圆形&quot;); &#125;&#125;class Triangle implements IShape &#123; private IColor color; void setColor(IColor color) &#123; this.color = color; &#125; @Override public void draw() &#123; System.out.println(&quot;绘制&quot; + color.getColor() + &quot;三角形&quot;); &#125;&#125; 测试函数： 1234567891011121314@Testpublic void drawTest() &#123; Rectangle rectangle = new Rectangle(); rectangle.setColor(new Red()); rectangle.draw(); Round round = new Round(); round.setColor(new Blue()); round.draw(); Triangle triangle = new Triangle(); triangle.setColor(new Yellow()); triangle.draw();&#125; 运行程序，输出如下： 绘制红矩形 绘制蓝圆形 绘制黄三角形 这时我们再来回顾一下官方定义：将抽象部分与它的实现部分分离，使它们都可以独立地变化。抽象部分指的是父类，对应本例中的形状类，实现部分指的是不同子类的区别之处。将子类的区别方式 —— 也就是本例中的颜色 —— 分离成接口，通过组合的方式桥接颜色和形状，这就是桥接模式，它主要用于两个或多个同等级的接口。 组合模式 Composite上文说到，桥接模式用于将同等级的接口互相组合，那么组合模式和桥接模式有什么共同点吗？ 事实上组合模式和桥接模式的组合完全不一样。组合模式用于整体与部分的结构，当整体与部分有相似的结构，在操作时可以被一致对待时，就可以使用组合模式。例如： 文件夹和子文件夹的关系：文件夹中可以存放文件，也可以新建文件夹，子文件夹也一样。 总公司子公司的关系：总公司可以设立部门，也可以设立分公司，子公司也一样。 树枝和分树枝的关系：树枝可以长出叶子，也可以长出树枝，分树枝也一样。 在这些关系中，虽然整体包含了部分，但无论整体或部分，都具有一致的行为。 组合模式：又叫部分整体模式，是用于把一组相似的对象当作一个单一的对象。组合模式依据树形结构来组合对象，用来表示部分以及整体层次。这种类型的设计模式属于结构型模式，它创建了对象组的树形结构 考虑这样一个实际应用：设计一个公司的人员分布结。人员结构中有两种结构，一是管理者，如老板，PM，CFO，CTO，二是职员。其中有的管理者不仅仅要管理职员，还会管理其他的管理者。这就是一个典型的整体与部分的结构。 不使用组合模式的设计方案要描述这样的结构，我们很容易想到以下设计方案： 新建管理者类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class Manager &#123; // 职位 private String position; // 工作内容 private String job; // 管理的管理者 private List&lt;Manager&gt; managers = new ArrayList&lt;&gt;(); // 管理的职员 private List&lt;Employee&gt; employees = new ArrayList&lt;&gt;(); public Manager(String position, String job) &#123; this.position = position; this.job = job; &#125; public void addManager(Manager manager) &#123; managers.add(manager); &#125; public void removeManager(Manager manager) &#123; managers.remove(manager); &#125; public void addEmployee(Employee employee) &#123; employees.add(employee); &#125; public void removeEmployee(Employee employee) &#123; employees.remove(employee); &#125; // 做自己的本职工作 public void work() &#123; System.out.println(&quot;我是&quot; + position + &quot;，我正在&quot; + job); &#125; // 检查下属 public void check() &#123; work(); for (Employee employee : employees) &#123; employee.work(); &#125; for (Manager manager : managers) &#123; manager.check(); &#125; &#125;&#125; 新建职员类： 12345678910111213141516public class Employee &#123; // 职位 private String position; // 工作内容 private String job; public Employee(String position, String job) &#123; this.position = position; this.job = job; &#125; // 做自己的本职工作 public void work() &#123; System.out.println(&quot;我是&quot; + position + &quot;，我正在&quot; + job); &#125;&#125; 客户端建立人员结构关系： 1234567891011121314151617181920212223242526272829public class Client &#123; @Test public void test() &#123; Manager boss = new Manager(&quot;老板&quot;, &quot;唱怒放的生命&quot;); Employee HR = new Employee(&quot;人力资源&quot;, &quot;聊微信&quot;); Manager PM = new Manager(&quot;产品经理&quot;, &quot;不知道干啥&quot;); Manager CFO = new Manager(&quot;财务主管&quot;, &quot;看剧&quot;); Manager CTO = new Manager(&quot;技术主管&quot;, &quot;划水&quot;); Employee UI = new Employee(&quot;设计师&quot;, &quot;画画&quot;); Employee operator = new Employee(&quot;运营人员&quot;, &quot;兼职客服&quot;); Employee webProgrammer = new Employee(&quot;程序员&quot;, &quot;学习设计模式&quot;); Employee backgroundProgrammer = new Employee(&quot;后台程序员&quot;, &quot;CRUD&quot;); Employee accountant = new Employee(&quot;会计&quot;, &quot;背九九乘法表&quot;); Employee clerk = new Employee(&quot;文员&quot;, &quot;给老板递麦克风&quot;); boss.addEmployee(HR); boss.addManager(PM); boss.addManager(CFO); PM.addEmployee(UI); PM.addManager(CTO); PM.addEmployee(operator); CTO.addEmployee(webProgrammer); CTO.addEmployee(backgroundProgrammer); CFO.addEmployee(accountant); CFO.addEmployee(clerk); boss.check(); &#125;&#125; 运行测试方法，输出如下（为方便查看，笔者添加了缩进）： 1234567891011我是老板，我正在唱怒放的生命 我是人力资源，我正在聊微信 我是产品经理，我正在不知道干啥 我是设计师，我正在画画 我是运营人员，我正在兼职客服 我是技术主管，我正在划水 我是程序员，我正在学习设计模式 我是后台程序员，我正在CRUD 我是财务主管，我正在看剧 我是会计，我正在背九九乘法表 我是文员，我正在给老板递麦克风 这样我们就设计出了公司的结构，但是这样的设计有两个弊端： name 字段，job 字段，work 方法重复了。 管理者对其管理的管理者和职员需要区别对待。 关于第一个弊端，虽然这里为了讲解，只有两个字段和一个方法重复，实际工作中这样的整体部分结构会有相当多的重复。比如此例中还可能有工号、年龄等字段，领取工资、上下班打卡、开各种无聊的会等方法。 大量的重复显然是很丑陋的代码，分析一下可以发现， Manager 类只比 Employee 类多一个管理人员的列表字段，多几个增加 &#x2F; 移除人员的方法，其他的字段和方法全都是一样的。 有读者应该会想到：我们可以将重复的字段和方法提取到一个工具类中，让 Employee 和 Manager 都去调用此工具类，就可以消除重复了。 这样固然可行，但属于 Employee 和 Manager 类自己的东西却要通过其他类调用，并不利于程序的高内聚。 关于第二个弊端，此方案无法解决，此方案中 Employee 和 Manager 类完全是两个不同的对象，两者的相似性被忽略了。 所以我们有更好的设计方案，那就是组合模式！ 使用组合模式的设计方案组合模式最主要的功能就是让用户可以一致对待整体和部分结构，将两者都作为一个相同的组件，所以我们先新建一个抽象的组件类： 12345678910111213141516171819202122public abstract class Component &#123; // 职位 private String position; // 工作内容 private String job; public Component(String position, String job) &#123; this.position = position; this.job = job; &#125; // 做自己的本职工作 public void work() &#123; System.out.println(&quot;我是&quot; + position + &quot;，我正在&quot; + job); &#125; abstract void addComponent(Component component); abstract void removeComponent(Component component); abstract void check();&#125; 管理者继承自此抽象类： 123456789101112131415161718192021222324252627public class Manager extends Component &#123; // 管理的组件 private List&lt;Component&gt; components = new ArrayList&lt;&gt;(); public Manager(String position, String job) &#123; super(position, job); &#125; @Override public void addComponent(Component component) &#123; components.add(component); &#125; @Override void removeComponent(Component component) &#123; components.remove(component); &#125; // 检查下属 @Override public void check() &#123; work(); for (Component component : components) &#123; component.check(); &#125; &#125;&#125; 职员同样继承自此抽象类： 123456789101112131415161718192021public class Employee extends Component &#123; public Employee(String position, String job) &#123; super(position, job); &#125; @Override void addComponent(Component component) &#123; System.out.println(&quot;职员没有管理权限&quot;); &#125; @Override void removeComponent(Component component) &#123; System.out.println(&quot;职员没有管理权限&quot;); &#125; @Override void check() &#123; work(); &#125;&#125; 修改客户端如下： 1234567891011121314151617181920212223242526272829public class Client &#123; @Test public void test()&#123; Component boss = new Manager(&quot;老板&quot;, &quot;唱怒放的生命&quot;); Component HR = new Employee(&quot;人力资源&quot;, &quot;聊微信&quot;); Component PM = new Manager(&quot;产品经理&quot;, &quot;不知道干啥&quot;); Component CFO = new Manager(&quot;财务主管&quot;, &quot;看剧&quot;); Component CTO = new Manager(&quot;技术主管&quot;, &quot;划水&quot;); Component UI = new Employee(&quot;设计师&quot;, &quot;画画&quot;); Component operator = new Employee(&quot;运营人员&quot;, &quot;兼职客服&quot;); Component webProgrammer = new Employee(&quot;程序员&quot;, &quot;学习设计模式&quot;); Component backgroundProgrammer = new Employee(&quot;后台程序员&quot;, &quot;CRUD&quot;); Component accountant = new Employee(&quot;会计&quot;, &quot;背九九乘法表&quot;); Component clerk = new Employee(&quot;文员&quot;, &quot;给老板递麦克风&quot;); boss.addComponent(HR); boss.addComponent(PM); boss.addComponent(CFO); PM.addComponent(UI); PM.addComponent(CTO); PM.addComponent(operator); CTO.addComponent(webProgrammer); CTO.addComponent(backgroundProgrammer); CFO.addComponent(accountant); CFO.addComponent(clerk); boss.check(); &#125;&#125; 运行测试方法，输出结果与之前的结果一模一样。 可以看到，使用组合模式后，我们解决了之前的两个弊端。一是将共有的字段与方法移到了父类中，消除了重复，并且在客户端中，可以一致对待 Manager 和 Employee 类： Manager 类和 Employee 类统一声明为 Component 对象 统一调用 Component 对象的 addComponent 方法添加子对象即可。 组合模式中的安全方式与透明方式读者可能已经注意到了，Employee 类虽然继承了父类的 addComponent 和 removeComponent 方法，但是仅仅提供了一个空实现，因为 Employee 类是不支持添加和移除组件的。这样是否违背了接口隔离原则呢？ 接口隔离原则：客户端不应依赖它不需要的接口。如果一个接口在实现时，部分方法由于冗余被客户端空实现，则应该将接口拆分，让实现类只需依赖自己需要的接口方法。 答案是肯定的，这样确实违背了接口隔离原则。这种方式在组合模式中被称作透明方式. 透明方式：在 Component 中声明所有管理子对象的方法，包括 add 、remove 等，这样继承自 Component 的子类都具备了 add、remove 方法。对于外界来说叶节点和枝节点是透明的，它们具备完全一致的接口。 这种方式有它的优点：让 Manager 类和 Employee 类具备完全一致的行为接口，调用者可以一致对待它们。 但它的缺点也显而易见：Employee 类并不支持管理子对象，不仅违背了接口隔离原则，而且客户端可以用 Employee 类调用 addComponent 和 removeComponent 方法，导致程序出错，所以这种方式是不安全的。 那么我们可不可以将 addComponent 和 removeComponent 方法移到 Manager 子类中去单独实现，让 Employee 不再实现这两个方法呢？我们来尝试一下。 将抽象类修改为： 123456789101112131415161718public abstract class Component &#123; // 职位 private String position; // 工作内容 private String job; public Component(String position, String job) &#123; this.position = position; this.job = job; &#125; // 做自己的本职工作 public void work() &#123; System.out.println(&quot;我是&quot; + position + &quot;，我正在&quot; + job); &#125; abstract void check();&#125; 可以看到，我们在父类中去掉了 addComponent 和 removeComponent 这两个抽象方法。 Manager 类修改为： 12345678910111213141516171819202122232425public class Manager extends Component &#123; // 管理的组件 private List&lt;Component&gt; components = new ArrayList&lt;&gt;(); public Manager(String position, String job) &#123; super(position, job); &#125; public void addComponent(Component component) &#123; components.add(component); &#125; void removeComponent(Component component) &#123; components.remove(component); &#125; // 检查下属 @Override public void check() &#123; work(); for (Component component : components) &#123; component.check(); &#125; &#125;&#125; Manager 类单独实现了 addComponent 和 removeComponent 这两个方法，去掉了 @Override 注解。 Employee 类修改为： 1234567891011public class Employee extends Component &#123; public Employee(String position, String job) &#123; super(position, job); &#125; @Override void check() &#123; work(); &#125;&#125; 客户端建立人员结构关系： 1234567891011121314151617181920212223242526272829public class Client &#123; @Test public void test()&#123; Manager boss = new Manager(&quot;老板&quot;, &quot;唱怒放的生命&quot;); Employee HR = new Employee(&quot;人力资源&quot;, &quot;聊微信&quot;); Manager PM = new Manager(&quot;产品经理&quot;, &quot;不知道干啥&quot;); Manager CFO = new Manager(&quot;财务主管&quot;, &quot;看剧&quot;); Manager CTO = new Manager(&quot;技术主管&quot;, &quot;划水&quot;); Employee UI = new Employee(&quot;设计师&quot;, &quot;画画&quot;); Employee operator = new Employee(&quot;运营人员&quot;, &quot;兼职客服&quot;); Employee webProgrammer = new Employee(&quot;程序员&quot;, &quot;学习设计模式&quot;); Employee backgroundProgrammer = new Employee(&quot;后台程序员&quot;, &quot;CRUD&quot;); Employee accountant = new Employee(&quot;会计&quot;, &quot;背九九乘法表&quot;); Employee clerk = new Employee(&quot;文员&quot;, &quot;给老板递麦克风&quot;); boss.addComponent(HR); boss.addComponent(PM); boss.addComponent(CFO); PM.addComponent(UI); PM.addComponent(CTO); PM.addComponent(operator); CTO.addComponent(webProgrammer); CTO.addComponent(backgroundProgrammer); CFO.addComponent(accountant); CFO.addComponent(clerk); boss.check(); &#125;&#125; 运行程序，输出结果与之前一模一样。 这种方式在组合模式中称之为安全方式。 安全方式：在 Component 中不声明 add 和 remove 等管理子对象的方法，这样叶节点就无需实现它，只需在枝节点中实现管理子对象的方法即可。 安全方式遵循了接口隔离原则，但由于不够透明，Manager 和 Employee 类不具有相同的接口，在客户端中，我们无法将 Manager 和 Employee 统一声明为 Component 类了，必须要区别对待，带来了使用上的不方便。 安全方式和透明方式各有好处，在使用组合模式时，需要根据实际情况决定。但大多数使用组合模式的场景都是采用的透明方式，虽然它有点不安全，但是客户端无需做任何判断来区分是叶子结点还是枝节点，用起来是真香。 装饰模式 Decorator提到装饰，我们先来想一下生活中有哪些装饰： 女生的首饰：戒指、耳环、项链等装饰品 家居装饰品：粘钩、镜子、壁画、盆栽等等 我们为什么需要这些装饰品呢？我们很容易想到是为了美，戒指、耳环、项链、壁画、盆栽都是为了提高颜值或增加美观度。但粘钩、镜子不一样，它们是为了方便我们挂东西、洗漱。所以我们可以总结出装饰品共有两种功能： 增强原有的特性：我们本身就是有一定颜值的，添加装饰品提高了我们的颜值。同样地，房屋本身就有一定的美观度，家居装饰提高了房屋的美观度。 添加新的特性：在墙上挂上粘钩，让墙壁有了挂东西的功能。在洗漱台装上镜子，让洗漱台有了照镜子的功能。 并且我们发现，装饰品并不会改变物品本身，只是起到一个锦上添花的作用。装饰模式也一样，它的主要作用就是： 增强一个类原有的功能 为一个类添加新的功能 并且装饰模式也不会改变原有的类。 装饰模式：动态地给一个对象增加一些额外的职责，就增加对象功能来说，装饰模式比生成子类实现更为灵活。其别名也可以称为包装器，与适配器模式的别名相同，但它们适用于不同的场合。根据翻译的不同，装饰模式也有人称之为“油漆工模式”。 用于增强功能的装饰模式我们用程序来模拟一下戴上装饰品提高我们颜值的过程： 新建颜值接口： 1234567891011121314public interface IBeauty &#123; int getBeautyValue();&#125;新建 Me 类，实现颜值接口：Javapublic class Me implements IBeauty &#123; @Override public int getBeautyValue() &#123; return 100; &#125;&#125; 戒指装饰类，将 Me 包装起来： 123456789101112public class RingDecorator implements IBeauty &#123; private final IBeauty me; public RingDecorator(IBeauty me) &#123; this.me = me; &#125; @Override public int getBeautyValue() &#123; return me.getBeautyValue() + 20; &#125;&#125; 客户端测试： 12345678910public class Client &#123; @Test public void show() &#123; IBeauty me = new Me(); System.out.println(&quot;我原本的颜值：&quot; + me.getBeautyValue()); IBeauty meWithRing = new RingDecorator(me); System.out.println(&quot;戴上了戒指后，我的颜值：&quot; + meWithRing.getBeautyValue()); &#125;&#125; 运行程序，输出如下： 我原本的颜值：100 戴上了戒指后，我的颜值：120 这就是最简单的增强功能的装饰模式。以后我们可以添加更多的装饰类，比如： 耳环装饰类： 123456789101112public class EarringDecorator implements IBeauty &#123; private final IBeauty me; public EarringDecorator(IBeauty me) &#123; this.me = me; &#125; @Override public int getBeautyValue() &#123; return me.getBeautyValue() + 50; &#125;&#125; 项链装饰类： 123456789101112public class NecklaceDecorator implements IBeauty &#123; private final IBeauty me; public NecklaceDecorator(IBeauty me) &#123; this.me = me; &#125; @Override public int getBeautyValue() &#123; return me.getBeautyValue() + 80; &#125;&#125; 客户端测试： 12345678910111213141516171819public class Client &#123; @Test public void show() &#123; IBeauty me = new Me(); System.out.println(&quot;我原本的颜值：&quot; + me.getBeautyValue()); // 随意挑选装饰 IBeauty meWithNecklace = new NecklaceDecorator(me); System.out.println(&quot;戴上了项链后，我的颜值：&quot; + meWithNecklace.getBeautyValue()); // 多次装饰 IBeauty meWithManyDecorators = new NecklaceDecorator(new RingDecorator(new EarringDecorator(me))); System.out.println(&quot;戴上耳环、戒指、项链后，我的颜值：&quot; + meWithManyDecorators.getBeautyValue()); // 任意搭配装饰 IBeauty meWithNecklaceAndRing = new NecklaceDecorator(new RingDecorator(me)); System.out.println(&quot;戴上戒指、项链后，我的颜值：&quot; + meWithNecklaceAndRing.getBeautyValue()); &#125;&#125; 运行程序，输出如下： 我原本的颜值：100 戴上了项链后，我的颜值：180 戴上耳环、戒指、项链后，我的颜值：250 戴上戒指、项链后，我的颜值：200 可以看到，装饰器也实现了 IBeauty 接口，并且没有添加新的方法，也就是说这里的装饰器仅用于增强功能，并不会改变 Me 原有的功能，这种装饰模式称之为透明装饰模式，由于没有改变接口，也没有新增方法，所以透明装饰模式可以无限装饰。 装饰模式是继承的一种替代方案。本例如果不使用装饰模式，而是改用继承实现的话，戴着戒指的 Me 需要派生一个子类、戴着项链的 Me 需要派生一个子类、戴着耳环的 Me 需要派生一个子类、戴着戒指 + 项链的需要派生一个子类…各种各样的排列组合会造成类爆炸。而采用了装饰模式就只需要为每个装饰品生成一个装饰类即可，所以说就增加对象功能来说，装饰模式比生成子类实现更为灵活。 用于添加功能的装饰模式我们用程序来模拟一下房屋装饰粘钩后，新增了挂东西功能的过程： 新建房屋接口： 123public interface IHouse &#123; void live();&#125; 房屋类： 1234567public class House implements IHouse&#123; @Override public void live() &#123; System.out.println(&quot;房屋原有的功能：居住功能&quot;); &#125;&#125; 新建粘钩装饰器接口，继承自房屋接口： 123public interface IStickyHookHouse extends IHouse&#123; void hangThings();&#125; 粘钩装饰类： 1234567891011121314151617public class StickyHookDecorator implements IStickyHookHouse &#123; private final IHouse house; public StickyHookDecorator(IHouse house) &#123; this.house = house; &#125; @Override public void live() &#123; house.live(); &#125; @Override public void hangThings() &#123; System.out.println(&quot;有了粘钩后，新增了挂东西功能&quot;); &#125;&#125; 客户端测试： 1234567891011public class Client &#123; @Test public void show() &#123; IHouse house = new House(); house.live(); IStickyHookHouse stickyHookHouse = new StickyHookDecorator(house); stickyHookHouse.live(); stickyHookHouse.hangThings(); &#125;&#125; 运行程序，显示如下： 房屋原有的功能：居住功能 房屋原有的功能：居住功能 有了粘钩后，新增了挂东西功能 这就是用于新增功能的装饰模式。我们在接口中新增了方法：hangThings，然后在装饰器中将 House 类包装起来，之前 House 中的方法仍然调用 house 去执行，也就是说我们并没有修改原有的功能，只是扩展了新的功能，这种模式在装饰模式中称之为半透明装饰模式。 为什么叫半透明呢？由于新的接口 IStickyHookHouse 拥有之前 IHouse 不具有的方法，所以我们如果要使用装饰器中添加的功能，就不得不区别对待装饰前的对象和装饰后的对象。也就是说客户端要使用新方法，必须知道具体的装饰类 StickyHookDecorator，所以这个装饰类对客户端来说是可见的、不透明的。而被装饰者不一定要是 House，它可以是实现了 IHouse 接口的任意对象，所以被装饰者对客户端是不可见的、透明的。由于一半透明，一半不透明，所以称之为半透明装饰模式。 我们可以添加更多的装饰器： 新建镜子装饰器的接口，继承自房屋接口： 123public interface IMirrorHouse extends IHouse &#123; void lookMirror();&#125; 镜子装饰类： 1234567891011121314151617public class MirrorDecorator implements IMirrorHouse&#123; private final IHouse house; public MirrorDecorator(IHouse house) &#123; this.house = house; &#125; @Override public void live() &#123; house.live(); &#125; @Override public void lookMirror() &#123; System.out.println(&quot;有了镜子后，新增了照镜子功能&quot;); &#125;&#125; 客户端测试： 1234567891011public class Client &#123; @Test public void show() &#123; IHouse house = new House(); house.live(); IMirrorHouse mirrorHouse = new MirrorDecorator(house); mirrorHouse.live(); mirrorHouse.lookMirror(); &#125;&#125; 运行程序，输出如下： 房屋原有的功能：居住功能 房屋原有的功能：居住功能 有了镜子后，新增了照镜子功能 现在我们仿照透明装饰模式的写法，同时添加粘钩和镜子装饰试一试： 12345678910111213public class Client &#123; @Test public void show() &#123; IHouse house = new House(); house.live(); IStickyHookHouse stickyHookHouse = new StickyHookDecorator(house); IMirrorHouse houseWithStickyHookMirror = new MirrorDecorator(stickyHookHouse); houseWithStickyHookMirror.live(); houseWithStickyHookMirror.hangThings(); // 这里会报错，找不到 hangThings 方法 houseWithStickyHookMirror.lookMirror(); &#125;&#125; 我们会发现，第二次装饰时，无法获得上一次装饰添加的方法。原因很明显，当我们用 IMirrorHouse 装饰器后，接口变为了 IMirrorHouse，这个接口中并没有 hangThings 方法。 那么我们能否让 IMirrorHouse 继承自 IStickyHookHouse，以实现新增两个功能呢？可以，但那样做的话两个装饰类之间有了依赖关系，那就不是装饰模式了。装饰类不应该存在依赖关系，而应该在原本的类上进行装饰。这就意味着，半透明装饰模式中，我们无法多次装饰。 有的同学会问了，既增强了功能，又添加了新功能的装饰模式叫什么呢？ —— 举一反三，肯定是叫全不透明装饰模式！ —— 并不是！只要添加了新功能的装饰模式都称之为半透明装饰模式，他们都具有不可以多次装饰的特点。仔细理解上文半透明名称的由来就知道了，“透明”指的是我们无需知道被装饰者具体的类，既增强了功能，又添加了新功能的装饰模式仍然具有半透明特性。 Java中的InputStream系列接口就是典型的装饰者模式 外观模式 Facade外观模式非常简单，体现的就是 Java 中封装的思想。将多个子系统封装起来，提供一个更简洁的接口供外部调用。 外观模式：外部与一个子系统的通信必须通过一个统一的外观对象进行，为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。外观模式又称为门面模式。 举个例子，比如我们每天打开电脑时，都需要做三件事： 打开浏览器 打开 IDE 打开微信 每天下班时，关机前需要做三件事： 关闭浏览器 关闭 IDE 关闭微信 用程序模拟如下： 新建浏览器类： 123456789public class Browser &#123; public static void open() &#123; System.out.println(&quot;打开浏览器&quot;); &#125; public static void close() &#123; System.out.println(&quot;关闭浏览器&quot;); &#125;&#125; 新建 IDE 类： 123456789public class IDE &#123; public static void open() &#123; System.out.println(&quot;打开 IDE&quot;); &#125; public static void close() &#123; System.out.println(&quot;关闭 IDE&quot;); &#125;&#125; 新建微信类： 123456789public class Wechat &#123; public static void open() &#123; System.out.println(&quot;打开微信&quot;); &#125; public static void close() &#123; System.out.println(&quot;关闭微信&quot;); &#125;&#125; 客户端调用： 1234567891011121314public class Client &#123; @Test public void test() &#123; System.out.println(&quot;上班:&quot;); Browser.open(); IDE.open(); Wechat.open(); System.out.println(&quot;下班:&quot;); Browser.close(); IDE.close(); Wechat.close(); &#125;&#125; 运行程序，输出如下： 上班: 打开浏览器 打开 IDE 打开微信 下班: 关闭浏览器 关闭 IDE 关闭微信 由于我们每天都要做这几件事，所以我们可以使用外观模式，将这几个子系统封装起来，提供更简洁的接口： 12345678910111213public class Facade &#123; public void open() &#123; Browser.open(); IDE.open(); Wechat.open(); &#125; public void close() &#123; Browser.close(); IDE.close(); Wechat.close(); &#125;&#125; 客户端就可以简化代码，只和这个外观类打交道： 1234567891011public class Client &#123; @Test public void test() &#123; Facade facade = new Facade(); System.out.println(&quot;上班:&quot;); facade.open(); System.out.println(&quot;下班:&quot;); facade.close(); &#125;&#125; 运行程序，输出与之前一样。 外观模式就是这么简单，它使得两种不同的类不用直接交互，而是通过一个中间件——也就是外观类——间接交互。外观类中只需要暴露简洁的接口，隐藏内部的细节，所以说白了就是封装的思想。 外观模式非常常用，（当然了！写代码哪有不封装的！）尤其是在第三方库的设计中，我们应该提供尽量简洁的接口供别人调用。另外，在 MVC 架构中，C 层（Controller）就可以看作是外观类，Model 和 View 层通过 Controller 交互，减少了耦合。 享元模式 Flyweight享元模式体现的是程序可复用的特点，为了节约宝贵的内存，程序应该尽可能地复用，就像《极限编程》作者 Kent 在书里说到的那样：Don’t repeat yourself. 简单来说享元模式就是共享对象，提高复用性，官方的定义倒是显得文绉绉的： 享元模式：运用共享技术有效地支持大量细粒度对象的复用。系统只使用少量的对象，而这些对象都很相似，状态变化很小，可以实现对象的多次复用。由于享元模式要求能够共享的对象必须是细粒度对象，因此它又称为轻量级模式。 有个细节值得注意：有些对象本身不一样，但通过一点点变化后就可以复用，我们编程时可能稍不注意就会忘记复用这些对象。比如说伟大的超级玛丽，谁能想到草和云更改一下颜色就可以实现复用呢？还有里面的三种乌龟，换一个颜色、加一个装饰就变成了不同的怪。 在超级玛丽中，这样的细节还有很多，正是这些精湛的复用使得这一款红遍全球的游戏仅有 40KB 大小。正是印证了那句名言：神在细节之中。 代理模式 Proxy现在我们有一个人类，他整天就只负责吃饭、睡觉。 人类的接口 1234public interface IPerson &#123; void eat(); void sleep();&#125; 人类： 123456789101112public class Person implements IPerson&#123; @Override public void eat() &#123; System.out.println(&quot;我在吃饭&quot;); &#125; @Override public void sleep() &#123; System.out.println(&quot;我在睡觉&quot;); &#125;&#125; 客户端测试： 12345678public class Client &#123; @Test public void test() &#123; Person person = new Person(); person.eat(); person.sleep(); &#125;&#125; 运行程序，输出如下： 我在吃饭 我在睡觉 我们可以把这个类包装到另一个类中，实现完全一样的行为： 123456789101112131415161718public class PersonProxy implements IPerson &#123; private final Person person; public PersonProxy(Person person) &#123; this.person = person; &#125; @Override public void eat() &#123; person.eat(); &#125; @Override public void sleep() &#123; person.sleep(); &#125;&#125; 将客户端修改为调用这个新的类： 123456789public class Client &#123; @Test public void test() &#123; Person person = new Person(); PersonProxy proxy = new PersonProxy(person); proxy.eat(); proxy.sleep(); &#125;&#125; 运行程序，输出如下： 我在吃饭 我在睡觉 这就是代理模式。 笔者力图用最简洁的代码讲解此模式，只要理解了上述这个简单的例子，你就知道代理模式是怎么一回事了。我们在客户端和 Person 类之间新增了一个中间件 PersonProxy，这个类就叫做代理类，他实现了和 Person 类一模一样的行为。 代理模式：给某一个对象提供一个代理，并由代理对象控制对原对象的引用。 现在这个代理类还看不出任何意义，我们来模拟一下工作中的需求。在实际工作中，我们可能会遇到这样的需求：在网络请求前后，分别打印将要发送的数据和接收到数据作为日志信息。此时我们就可以新建一个网络请求的代理类，让它代为处理网络请求，并在代理类中打印这些日志信息。 新建网络请求接口： 12345public interface IHttp &#123; void request(String sendData); void onSuccess(String receivedData);&#125; 新建 Http 请求工具类： 1234567891011public class HttpUtil implements IHttp &#123; @Override public void request(String sendData) &#123; System.out.println(&quot;网络请求中...&quot;); &#125; @Override public void onSuccess(String receivedData) &#123; System.out.println(&quot;网络请求完成。&quot;); &#125;&#125; 新建 Http 代理类： 1234567891011121314151617public class HttpProxy implements IHttp &#123; private final HttpUtil httpUtil; public HttpProxy(HttpUtil httpUtil) &#123; this.httpUtil = httpUtil; &#125; @Override public void request(String sendData) &#123; httpUtil.request(sendData); &#125; @Override public void onSuccess(String receivedData) &#123; httpUtil.onSuccess(receivedData); &#125;&#125; 到这里，和我们上述吃饭睡觉的代码是一模一样的，现在我们在 HttpProxy 中新增打印日志信息： 12345678910111213141516171819public class HttpProxy implements IHttp &#123; private final HttpUtil httpUtil; public HttpProxy(HttpUtil httpUtil) &#123; this.httpUtil = httpUtil; &#125; @Override public void request(String sendData) &#123; System.out.println(&quot;发送数据:&quot; + sendData); httpUtil.request(sendData); &#125; @Override public void onSuccess(String receivedData) &#123; System.out.println(&quot;收到数据:&quot; + receivedData); httpUtil.onSuccess(receivedData); &#125;&#125; 客户端验证： 123456789public class Client &#123; @Test public void test() &#123; HttpUtil httpUtil = new HttpUtil(); HttpProxy proxy = new HttpProxy(httpUtil); proxy.request(&quot;request data&quot;); proxy.onSuccess(&quot;received result&quot;); &#125;&#125; 运行程序，输出如下： 发送数据:request data 网络请求中... 收到数据:received result 网络请求完成。 这就是代理模式的一个应用，除了打印日志，它还可以用来做权限管理。读者看到这里可能已经发现了，这个代理类看起来和装饰模式的 FilterInputStream 一模一样，但两者的目的不同，装饰模式是为了增强功能或添加功能，代理模式主要是为了加以控制。 动态代理上例中的代理被称之为静态代理，动态代理与静态代理的原理一模一样，只是换了一种写法。使用动态代理，需要把一个类传入，然后根据它正在调用的方法名判断是否需要加以控制。用伪代码表示如下： 1234567891011121314151617181920public class HttpProxy &#123; private final HttpUtil httpUtil; public HttpProxy(HttpUtil httpUtil) &#123; this.httpUtil = httpUtil; &#125; // 假设调用 httpUtil 的任意方法时，都要通过这个方法间接调用, methodName 表示方法名，args 表示方法中传入的参数 public visit(String methodName, Object[] args) &#123; if (methodName.equals(&quot;request&quot;)) &#123; // 如果方法名是 request，打印日志，并调用 request 方法，args 的第一个值就是传入的参数 System.out.println(&quot;发送数据:&quot; + args[0]); httpUtil.request(args[0].toString()); &#125; else if (methodName.equals(&quot;onSuccess&quot;)) &#123; // 如果方法名是 onSuccess，打印日志，并调用 onSuccess 方法，args 的第一个值就是传入的参数 System.out.println(&quot;收到数据:&quot; + args[0]); httpUtil.onSuccess(args[0].toString()); &#125; &#125;&#125; 伪代码看起来还是很简单的，实现起来唯一的难点就是怎么让 httpUtil 调用任意方法时，都通过一个方法间接调用。这里需要用到反射技术，不了解反射技术也没有关系，不妨把它记做固定的写法。实际的动态代理类代码如下： 123456789101112131415161718192021222324public class HttpProxy implements InvocationHandler &#123; private HttpUtil httpUtil; public IHttp getInstance(HttpUtil httpUtil) &#123; this.httpUtil = httpUtil; return (IHttp) Proxy.newProxyInstance(httpUtil.getClass().getClassLoader(), httpUtil.getClass().getInterfaces(), this); &#125; // 调用 httpUtil 的任意方法时，都要通过这个方法调用 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object result = null; if (method.getName().equals(&quot;request&quot;)) &#123; // 如果方法名是 request，打印日志，并调用 request 方法 System.out.println(&quot;发送数据:&quot; + args[0]); result = method.invoke(httpUtil, args); &#125; else if (method.getName().equals(&quot;onSuccess&quot;)) &#123; // 如果方法名是 onSuccess，打印日志，并调用 onSuccess 方法 System.out.println(&quot;收到数据:&quot; + args[0]); result = method.invoke(httpUtil, args); &#125; return result; &#125;&#125; 先看 getInstance 方法，Proxy.newProxyInstance 方法是 Java 系统提供的方法，专门用于动态代理。其中传入的第一个参数是被代理的类的 ClassLoader，第二个参数是被代理类的 Interfaces，这两个参数都是 Object 中的，每个类都有，这里就是固定写法。我们只要知道系统需要这两个参数才能让我们实现我们的目的：调用被代理类的任意方法时，都通过一个方法间接调用。现在我们给系统提供了这两个参数，系统就会在第三个参数中帮我们实现这个目的。 第三个参数是 InvocationHandler 接口，这个接口中只有一个方法： 1public Object invoke(Object proxy, Method method, Object[] args) throws Throwable; 那么不用猜就知道，现在我们调用被代理类 httpUtil 的任意方法时，都会通过这个 invoke 方法调用了。invoke 方法中，第一个参数我们暂时用不上，第二个参数 method 就是调用的方法，使用 method.getName() 可以获取到方法名，第三个参数是调用 method 方法需要传入的参数。本例中无论 request 还是 onSuccess 都只有一个 String 类型的参数，对应到这里就是 args[0]。返回的 Object 是 method 方法的返回值，本例中都是无返回值的。 我们在 invoke 方法中判断了当前调用方法的方法名，如果现在调用的方法是 request，那么打印请求参数，并使用这一行代码继续执行当前方法： 1result = method.invoke(httpUtil, args); 这就是反射调用函数的写法，如果不了解可以记做固定写法，想要了解的同学可以看之前的这篇文章：详解Java 反射。虽然这个函数没有返回值，但我们还是将 result 返回，这是标准做法。 如果现在调用的方法是 onSuccess，那么打印接收到的数据，并反射继续执行当前方法。 修改客户端验证一下： 123456789public class Client &#123; @Test public void test() &#123; HttpUtil httpUtil = new HttpUtil(); IHttp proxy = new HttpProxy().getInstance(httpUtil); proxy.request(&quot;request data&quot;); proxy.onSuccess(&quot;received result&quot;); &#125;&#125; 运行程序，输出与之前一样： 发送数据:request data 网络请求中... 收到数据:received result 网络请求完成。 动态代理本质上与静态代理没有区别，它的好处是节省代码量。比如被代理类有 20 个方法，而我们只需要控制其中的两个方法，就可以用动态代理通过方法名对被代理类进行动态的控制，而如果用静态方法，我们就需要将另外的 18 个方法也写出来，非常繁琐。这就是动态代理的优势所在。 小结 Summary 适配器模式：用于有相关性但不兼容的接口 桥接模式：用于同等级的接口互相组合 组合模式：用于整体与部分的结构 装饰模式: 用于功能增强和添加新功能 外观模式：体现封装的思想 享元模式：体现面向对象的可复用性 代理模式：主要用于对某个对象加以控制 第三章：行为型模式 Behavioral Patterns责任链模式 Chain of responsibility我们每个人在工作中都承担着一定的责任，比如程序员承担着开发新功能、修改 bug 的责任，运营人员承担着宣传的责任、HR 承担着招聘新人的责任。我们每个人的责任与这个责任链有什么关系吗？ ——答案是并没有太大关系。 但也不是完全没有关系，主要是因为每个人在不同岗位上的责任是分散的，分散的责任组合在一起更像是一张网，无法组成一条链。 同一个岗位上的责任，就可以组成一条链。 举个切身的例子，比如：普通的程序员可以解决中等难度的 bug，优秀程序员可以解决困难的 bug，而菜鸟程序员只能解决简单的 bug。为了将其量化，我们用一个数字来表示 bug 的难度，(0, 20] 表示简单，(20,50] 表示中等， (50,100] 表示困难，我们来模拟一个 bug 解决的流程。 “解决 bug” 程序 1.0新建一个 bug 类： 12345678public class Bug &#123; // bug 的难度值 int value; public Bug(int value) &#123; this.value = value; &#125;&#125; 新建一个程序员类： 123456789101112public class Programmer &#123; // 程序员类型：菜鸟、普通、优秀 public String type; public Programmer(String type) &#123; this.type = type; &#125; public void solve(Bug bug) &#123; System.out.println(type + &quot;程序员解决了一个难度为 &quot; + bug.value + &quot; 的 bug&quot;); &#125;&#125; 客户端： 12345678910111213141516171819202122232425262728293031323334353637import org.junit.Test;public class Client &#123; @Test public void test() &#123; Programmer newbie = new Programmer(&quot;菜鸟&quot;); Programmer normal = new Programmer(&quot;普通&quot;); Programmer good = new Programmer(&quot;优秀&quot;); Bug easy = new Bug(20); Bug middle = new Bug(50); Bug hard = new Bug(100); // 依次尝试解决 bug handleBug(newbie, easy); handleBug(normal, easy); handleBug(good, easy); handleBug(newbie, middle); handleBug(normal, middle); handleBug(good, middle); handleBug(newbie, hard); handleBug(normal, hard); handleBug(good, hard); &#125; public void handleBug(Programmer programmer, Bug bug) &#123; if (programmer.type.equals(&quot;菜鸟&quot;) &amp;&amp; bug.value &gt; 0 &amp;&amp; bug.value &lt;= 20) &#123; programmer.solve(bug); &#125; else if (programmer.type.equals(&quot;普通&quot;) &amp;&amp; bug.value &gt; 20 &amp;&amp; bug.value &lt;= 50) &#123; programmer.solve(bug); &#125; else if (programmer.type.equals(&quot;优秀&quot;) &amp;&amp; bug.value &gt; 50 &amp;&amp; bug.value &lt;= 100) &#123; programmer.solve(bug); &#125; &#125;&#125; 代码逻辑很简单，我们让三种类型的程序员依次尝试解决 bug，如果 bug 难度在自己能解决的范围内，则自己处理此 bug。 运行程序，输出如下： 123菜鸟程序员解决了一个难度为 20 的 bug普通程序员解决了一个难度为 50 的 bug优秀程序员解决了一个难度为 100 的 bug 输出没有问题，说明功能完美实现了，但在这个程序中，我们让每个程序员都尝试处理了每一个 bug，这也就相当于大家围着讨论每个 bug 该由谁解决，这无疑是非常低效的做法。那么我们要怎么才能优化呢？ “解决 bug” 程序 2.0实际上，许多公司会选择让项目经理来分派任务，项目经理会根据 bug 的难度指派给不同的人解决。 引入 ProjectManager 类： 123456789101112131415161718public class ProjectManager &#123; Programmer newbie = new Programmer(&quot;菜鸟&quot;); Programmer normal = new Programmer(&quot;普通&quot;); Programmer good = new Programmer(&quot;优秀&quot;); public void assignBug(Bug bug) &#123; if (bug.value &gt; 0 &amp;&amp; bug.value &lt;= 20) &#123; System.out.println(&quot;项目经理将这个简单的 bug 分配给了菜鸟程序员&quot;); newbie.solve(bug); &#125; else if (bug.value &gt; 20 &amp;&amp; bug.value &lt;= 50) &#123; System.out.println(&quot;项目经理将这个中等的 bug 分配给了普通程序员&quot;); normal.solve(bug); &#125; else if (bug.value &gt; 50 &amp;&amp; bug.value &lt;= 100) &#123; System.out.println(&quot;项目经理将这个困难的 bug 分配给了优秀程序员&quot;); good.solve(bug); &#125; &#125;&#125; 我们让项目经理管理所有的程序员，并且根据 bug 的难度指派任务。这样一来，所有的 bug 只需传给项目经理分配即可，修改客户端如下： 12345678910111213141516import org.junit.Test;public class Client2 &#123; @Test public void test() &#123; ProjectManager manager = new ProjectManager(); Bug easy = new Bug(20); Bug middle = new Bug(50); Bug hard = new Bug(100); manager.assignBug(easy); manager.assignBug(middle); manager.assignBug(hard); &#125;&#125; 运行程序，输出如下： 123456项目经理将这个简单的 bug 分配给了菜鸟程序员菜鸟程序员解决了一个难度为 20 的 bug项目经理将这个中等的 bug 分配给了普通程序员普通程序员解决了一个难度为 50 的 bug项目经理将这个困难的 bug 分配给了优秀程序员优秀程序员解决了一个难度为 100 的 bug 看起来很美好，除了项目经理在骂骂咧咧地反驳这个方案。 在这个经过修改的程序中，项目经理一个人承担了分配所有 bug 这个体力活。程序没有变得简洁，只是把复杂的逻辑从客户端转移到了项目经理类中。 而且项目经理类承担了过多的职责，如果以后新增一类程序员，必须改动项目经理类，将其处理 bug 的职责插入分支判断语句中，违反了单一职责原则和开闭原则。 所以，我们需要更优的解决方案，那就是——责任链模式！ “解决 bug” 程序 3.0 责任链模式：使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止。 在本例的场景中，每个程序员的责任都是“解决这个 bug”，当测试提出一个 bug 时，可以走这样一条责任链： 先交由菜鸟程序员之手，如果是简单的 bug，菜鸟程序员自己处理掉。如果这个 bug 对于菜鸟程序员来说太难了，交给普通程序员如果是中等难度的 bug，普通程序员处理掉。如果他也解决不了，交给优秀程序员优秀程序员处理掉困难的 bug有的读者会提出疑问，如果优秀程序员也无法处理这个 bug 呢？ ——那当然是处理掉这个假冒优秀程序员。 修改客户端如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import org.junit.Test;public class Client3 &#123; @Test public void test() throws Exception &#123; Programmer newbie = new Programmer(&quot;菜鸟&quot;); Programmer normal = new Programmer(&quot;普通&quot;); Programmer good = new Programmer(&quot;优秀&quot;); Bug easy = new Bug(20); Bug middle = new Bug(50); Bug hard = new Bug(100); // 链式传递责任 if (!handleBug(newbie, easy)) &#123; if (!handleBug(normal, easy)) &#123; if (!handleBug(good, easy)) &#123; throw new Exception(&quot;Kill the fake good programmer!&quot;); &#125; &#125; &#125; if (!handleBug(newbie, middle)) &#123; if (!handleBug(normal, middle)) &#123; if (!handleBug(good, middle)) &#123; throw new Exception(&quot;Kill the fake good programmer!&quot;); &#125; &#125; &#125; if (!handleBug(newbie, hard)) &#123; if (!handleBug(normal, hard)) &#123; if (!handleBug(good, hard)) &#123; throw new Exception(&quot;Kill the fake good programmer!&quot;); &#125; &#125; &#125; &#125; public boolean handleBug(Programmer programmer, Bug bug) &#123; if (programmer.type.equals(&quot;菜鸟&quot;) &amp;&amp; bug.value &gt; 0 &amp;&amp; bug.value &lt;= 20) &#123; programmer.solve(bug); return true; &#125; else if (programmer.type.equals(&quot;普通&quot;) &amp;&amp; bug.value &gt; 20 &amp;&amp; bug.value &lt;= 50) &#123; programmer.solve(bug); return true; &#125; else if (programmer.type.equals(&quot;优秀&quot;) &amp;&amp; bug.value &gt; 50 &amp;&amp; bug.value &lt;= 100) &#123; programmer.solve(bug); return true; &#125; return false; &#125;&#125; 三个嵌套的 if 条件句就组成了一条 菜鸟-&gt; 普通 -&gt; 优秀 的责任链。我们使 handleBug 方法返回一个 boolean 值，如果此 bug 被处理了，返回 true；否则返回 false，使得责任沿着 菜鸟-&gt; 普通 -&gt; 优秀这条链继续传递，这就是责任链模式的思路。 运行程序，输出如下： 123菜鸟程序员解决了一个难度为 20 的 bug普通程序员解决了一个难度为 50 的 bug优秀程序员解决了一个难度为 100 的 bug 熟悉责任链模式的同学应该可以看出，这个责任链模式和我们平时使用的不太一样。事实上，这段代码已经很好地体现了责任链模式的基本思想。我们平时使用的责任链模式只是在面向对象的基础上，将这段代码封装了一下。那么接下来我们就来对这段代码进行封装，将它变成规范的责任链模式的写法。 “解决 bug” 程序 4.0新建一个程序员抽象类： 123456789public abstract class Programmer &#123; protected Programmer next; public void setNext(Programmer next) &#123; this.next = next; &#125; abstract void handle(Bug bug);&#125; 在这个抽象类中： next 对象表示如果自己解决不了，需要将责任传递给的下一个人； handle 方法表示自己处理此 bug 的逻辑，在这里判断是自己解决或者继续传递。 新建菜鸟程序员类： 123456789101112131415public class NewbieProgrammer extends Programmer &#123; @Override public void handle(Bug bug) &#123; if (bug.value &gt; 0 &amp;&amp; bug.value &lt;= 20) &#123; solve(bug); &#125; else if (next != null) &#123; next.handle(bug); &#125; &#125; private void solve(Bug bug) &#123; System.out.println(&quot;菜鸟程序员解决了一个难度为 &quot; + bug.value + &quot; 的 bug&quot;); &#125;&#125; 新建普通程序员类： 123456789101112131415public class NormalProgrammer extends Programmer &#123; @Override public void handle(Bug bug) &#123; if (bug.value &gt; 20 &amp;&amp; bug.value &lt;= 50) &#123; solve(bug); &#125; else if (next != null) &#123; next.handle(bug); &#125; &#125; private void solve(Bug bug) &#123; System.out.println(&quot;普通程序员解决了一个难度为 &quot; + bug.value + &quot; 的 bug&quot;); &#125;&#125; 新建优秀程序员类： 123456789101112131415public class GoodProgrammer extends Programmer &#123; @Override public void handle(Bug bug) &#123; if (bug.value &gt; 50 &amp;&amp; bug.value &lt;= 100) &#123; solve(bug); &#125; else if (next != null) &#123; next.handle(bug); &#125; &#125; private void solve(Bug bug) &#123; System.out.println(&quot;优秀程序员解决了一个难度为 &quot; + bug.value + &quot; 的 bug&quot;); &#125;&#125; 客户端测试： 1234567891011121314151617181920212223import org.junit.Test;public class Client4 &#123; @Test public void test() &#123; NewbieProgrammer newbie = new NewbieProgrammer(); NormalProgrammer normal = new NormalProgrammer(); GoodProgrammer good = new GoodProgrammer(); Bug easy = new Bug(20); Bug middle = new Bug(50); Bug hard = new Bug(100); // 组成责任链 newbie.setNext(normal); normal.setNext(good); // 从菜鸟程序员开始，沿着责任链传递 newbie.handle(easy); newbie.handle(middle); newbie.handle(hard); &#125;&#125; 在客户端中，我们通过 setNext() 方法将三个程序员组成了一条责任链，由菜鸟程序员接收所有的 bug，发现自己不能处理的 bug，就传递给普通程序员，普通程序员收到 bug 后，如果发现自己不能解决，则传递给优秀程序员，这就是规范的责任链模式的写法了。 责任链思想在生活中有很多应用，比如假期审批、加薪申请等，在员工提出申请后，从经理开始，由你的经理决定自己处理或是交由更上一层的经理处理。 再比如处理客户投诉时，从基层的客服人员开始，决定自己回应或是上报给领导，领导再判断是否继续上报。 理清了责任链模式，笔者突然回想起，公司的测试组每次提出 bug 后，总是先指派给我！一瞬间仿佛明白了什么了不得的道理，不禁陷入了沉思。 责任链模式小结通过这个例子，我们已经了解到，责任链主要用于处理 职责相同，程度不同的类。 其主要优点有： 降低了对象之间的耦合度。在责任链模式中，客户只需要将请求发送到责任链上即可，无须关心请求的处理细节和请求的传递过程，所以责任链将请求的发送者和请求的处理者解耦了。 扩展性强，满足开闭原则。可以根据需要增加新的请求处理类。 灵活性强。可以动态地改变链内的成员或者改变链的次序来适应流程的变化。 简化了对象之间的连接。每个对象只需保持一个指向其后继者的引用，不需保持其他所有处理者的引用，这避免了使用众多的条件判断语句。 责任分担。每个类只需要处理自己该处理的工作，不该处理的传递给下一个对象完成，明确各类的责任范围，符合类的单一职责原则。不再需要 “项目经理” 来处理所有的责任分配任务。 但我们在使用中也发现了它的一个明显缺点，如果这个 bug 没人处理，可能导致 “程序员祭天” 异常。其主要缺点有： 不能保证每个请求一定被处理，该请求可能一直传到链的末端都得不到处理。 如果责任链过长，请求的处理可能涉及多个处理对象，系统性能将受到一定影响。 责任链建立的合理性要靠客户端来保证，增加了客户端的复杂性，可能会由于责任链拼接次序错误而导致系统出错，比如可能出现循环调用。 命令模式 Command近年来，智能家居越来越流行。躺在家中，只需要打开对应的 app，就可以随手控制家电开关。但随之而来一个问题，手机里的 app 实在是太多了，每一个家具公司都想要提供一个 app 给用户，以求增加用户粘性，推广他们的其他产品等。 站在用户的角度来看，有时我们只想打开一下电灯，却要先看到恼人的 “新式电灯上新” 的弹窗通知，让人烦不胜烦。如果能有一个万能遥控器将所有的智能家居开关综合起来，统一控制，一定会方便许多。 说干就干，笔者立马打开 PS，设计了一张草图： “咳咳，我对这个 app 的设计理念呢，是基于 “简洁就是美” 的原则。一个好的设计，首先，最重要的一点就是 ‘接地气’。当然，我也可以用一些华丽的素材拼接出一个花里胡哨的设计，但，那是一个最低级的设计师才会做的事情…” 翻译：He has no UI design skills. 总之 UI 设计完成啦，我们再来看下四个智能家居类的结构。 大门类： 123456789public class Door &#123; public void openDoor() &#123; System.out.println(&quot;门打开了&quot;); &#125; public void closeDoor() &#123; System.out.println(&quot;门关闭了&quot;); &#125;&#125; 电灯类： 123456789public class Light &#123; public void lightOn() &#123; System.out.println(&quot;打开了电灯&quot;); &#125; public void lightOff() &#123; System.out.println(&quot;关闭了电灯&quot;); &#125;&#125; 电视类： 123456789public class Tv &#123; public void TurnOnTv() &#123; System.out.println(&quot;电视打开了&quot;); &#125; public void TurnOffTv() &#123; System.out.println(&quot;电视关闭了&quot;); &#125;&#125; 音乐类： 123456789public class Music &#123; public void play() &#123; System.out.println(&quot;开始播放音乐&quot;); &#125; public void stop() &#123; System.out.println(&quot;停止播放音乐&quot;); &#125;&#125; 由于是不同公司的产品，所以接口有所不同，接下来就一起来实现我们的万能遥控器！ 万能遥控器 1.0不一会儿，我们就写出了下面的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 初始化开关Switch switchDoor = 省略绑定UI代码;Switch switchLight = 省略绑定UI代码;Switch switchTv = 省略绑定UI代码;Switch switchMusic = 省略绑定UI代码;// 初始化智能家居Door door = new Door();Light light = new Light();Tv tv = new Tv();Music music = new Music();// 大门开关遥控switchDoor.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; if (isChecked) &#123; door.openDoor(); &#125; else &#123; door.closeDoor(); &#125;&#125;);// 电灯开关遥控switchLight.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; if (isChecked) &#123; light.lightOn(); &#125; else &#123; light.lightOff(); &#125;&#125;);// 电视开关遥控switchTv.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; if (isChecked) &#123; tv.TurnOnTv(); &#125; else &#123; tv.TurnOffTv(); &#125;&#125;);// 音乐开关遥控switchMusic.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; if (isChecked) &#123; music.play(); &#125; else &#123; music.stop(); &#125;&#125;); 这份代码很直观，在每个开关状态改变时，调用对应家居的 API 实现打开或关闭。 只有这样的功能实在是太单一了，接下来我们再为它添加一个有趣的功能。 万能遥控器 2.0一般来说，电视遥控器上都有一个回退按钮，用来回到上一个频道。相当于文本编辑器中的 “撤销” 功能，既然别的小朋友都有，那我们也要！ 设计狮本狮马不停蹄地设计了 UI 2.0： UI 设计倒是简单，底部添加一个按钮即可。代码设计就比较复杂了，我们需要保存上一步操作，并且将其回退。 一个很容易想到的想法是：设计一个枚举类 Operation，代表每一步的操作： 12345678910public enum Operation &#123; DOOR_OPEN, DOOR_CLOSE, LIGHT_ON, LIGHT_OFF, TV_TURN_ON, TV_TURN_OFF, MUSIC_PLAY, MUSIC_STOP&#125; 然后在客户端定义一个 Operation 变量，变量名字叫 lastOperation，在每一步操作后，更新此变量。然后在撤销按钮的点击事件中，根据上一步的操作实现回退： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class Client &#123; // 上一步的操作 Operation lastOperation; @Test protected void test() &#123; // 初始化开关和撤销按钮 Switch switchDoor = 省略绑定UI代码; Switch switchLight = 省略绑定UI代码; Switch switchTv = 省略绑定UI代码; Switch switchMusic = 省略绑定UI代码; Button btnUndo = 省略绑定UI代码; // 初始化智能家居 Door door = new Door(); Light light = new Light(); Tv tv = new Tv(); Music music = new Music(); // 大门开关遥控 switchDoor.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; if (isChecked) &#123; lastOperation = Operation.DOOR_OPEN; door.openDoor(); &#125; else &#123; lastOperation = Operation.DOOR_CLOSE; door.closeDoor(); &#125; &#125;); // 电灯开关遥控 switchLight.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; if (isChecked) &#123; lastOperation = Operation.LIGHT_ON; light.lightOn(); &#125; else &#123; lastOperation = Operation.LIGHT_OFF; light.lightOff(); &#125; &#125;); ... 电视、音乐类似 btnUndo.setOnClickListener(view -&gt; &#123; if (lastOperation == null) return; // 撤销上一步 switch (lastOperation) &#123; case DOOR_OPEN: door.closeDoor(); break; case DOOR_CLOSE: door.openDoor(); break; case LIGHT_ON: light.lightOff(); break; case LIGHT_OFF: light.lightOn(); break; ... 电视、音乐类似 &#125; &#125;); &#125;&#125; 大功告成，不过这份代码只实现了撤销一步，如果我们需要实现撤销多步怎么做呢？ 思考一下，每次回退时，都是先将最后一步 Operation 撤销。对于这种后进先出的结构，我们自然就会想到——栈结构。使用栈结构实现回退多步的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class Client &#123; // 所有的操作 Stack&lt;Operation&gt; operations = new Stack&lt;&gt;(); @Test protected void test() &#123; // 初始化开关和撤销按钮 Switch switchDoor = 省略绑定UI代码; Switch switchLight = 省略绑定UI代码; Switch switchTv = 省略绑定UI代码; Switch switchMusic = 省略绑定UI代码; Button btnUndo = 省略绑定UI代码; // 初始化智能家居 Door door = new Door(); Light light = new Light(); Tv tv = new Tv(); Music music = new Music(); // 大门开关遥控 switchDoor.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; if (isChecked) &#123; operations.push(Operation.DOOR_OPEN); door.openDoor(); &#125; else &#123; operations.push(Operation.DOOR_CLOSE); door.closeDoor(); &#125; &#125;); // 电灯开关遥控 switchLight.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; if (isChecked) &#123; operations.push(Operation.LIGHT_ON); light.lightOn(); &#125; else &#123; operations.push(Operation.LIGHT_OFF); light.lightOff(); &#125; &#125;); ...电视、音乐类似 // 撤销按钮 btnUndo.setOnClickListener(view -&gt; &#123; if (operations.isEmpty()) return; // 弹出栈顶的上一步操作 Operation lastOperation = operations.pop(); // 撤销上一步 switch (lastOperation) &#123; case DOOR_OPEN: door.closeDoor(); break; case DOOR_CLOSE: door.openDoor(); break; case LIGHT_ON: light.lightOff(); break; case LIGHT_OFF: light.lightOn(); break; ...电视、音乐类似 &#125; &#125;); &#125;&#125; 我们将每一步 Operation 记录到栈中，每次撤销时，弹出栈顶的 Operation，再使用 switch 语句判断，将其恢复。 虽然实现了功能，但代码明显已经变得越来越臃肿了，因为遥控器知道了太多的细节，它必须要知道每个家居的调用方式。以后有开关加入时，不仅要修改 Status 类，增加新的 Operation，还要修改客户端，增加新的分支判断，导致这个类变成一个庞大的类。不仅违背了单一权责原则，还违背了开闭原则，所以我们不得不思考怎么优化这份代码。 万能遥控器 3.0我们期待能有一种设计，让遥控器不需要知道家居的接口。它只需要负责监听用户按下开关，再根据开关状态发出正确的命令，对应的家居在收到命令后做出响应。就可以达到将 “行为请求者” 和 ”行为实现者“ 解耦的目的。 先定义一个命令接口： 123public interface ICommand &#123; void execute();&#125; 接口中只有一个 execute 方法，表示 “执行” 命令。 定义开门命令，实现此接口： 123456789101112public class DoorOpenCommand implements ICommand &#123; private Door door; public void setDoor(Door door) &#123; this.door = door; &#125; @Override public void execute() &#123; door.openDoor(); &#125;&#125; 关门命令： 12345678910111213public class DoorCloseCommand implements ICommand &#123; private Door door; public void setDoor(Door door) &#123; this.door = door; &#125; @Override public void execute() &#123; door.closeDoor(); &#125;&#125; 开灯命令： 12345678910111213public class LightOnCommand implements ICommand &#123; Light light; public void setLight(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.lightOn(); &#125;&#125; 关灯命令： 12345678910111213public class LightOffCommand implements ICommand &#123; Light light; public void setLight(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.lightOff(); &#125;&#125; 电视、音乐的命令类似。 可以看到，我们将家居控制的代码转移到了命令类中，当命令执行时，调用对应家具的 API 实现开启或关闭。 客户端代码： 12345678910111213141516171819202122232425262728// 初始化命令DoorOpenCommand doorOpenCommand = new DoorOpenCommand();DoorCloseCommand doorCloseCommand = new DoorCloseCommand();doorOpenCommand.setDoor(door);doorCloseCommand.setDoor(door);LightOnCommand lightOnCommand = new LightOnCommand();LightOffCommand lightOffCommand = new LightOffCommand();lightOnCommand.setLight(light);lightOffCommand.setLight(light);...电视、音乐类似// 大门开关遥控switchDoor.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; if (isChecked) &#123; doorOpenCommand.execute(); &#125; else &#123; doorCloseCommand.execute(); &#125;&#125;);// 电灯开关遥控switchLight.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; if (isChecked) &#123; lightOnCommand.execute(); &#125; else &#123; lightOffCommand.execute(); &#125;&#125;);...电视、音乐类似 现在，遥控器只知道用户控制开关后，需要执行对应的命令，遥控器并不知道这个命令会执行什么内容，它只负责调用 execute 方法，达到了隐藏技术细节的目的。 与此同时，我们还获得了一个附带的好处。由于每个命令都被抽象成了同一个接口，我们可以将开关代码统一起来。客户端优化如下： 1234567891011121314151617181920212223242526272829303132public class Client &#123; @Test protected void test() &#123; ...初始化 // 大门开关遥控 switchDoor.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; handleCommand(isChecked, doorOpenCommand, doorCloseCommand); &#125;); // 电灯开关遥控 switchLight.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; handleCommand(isChecked, lightOnCommand, lightOffCommand); &#125;); // 电视开关遥控 switchTv.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; handleCommand(isChecked, turnOnTvCommand, turnOffTvCommand); &#125;); // 音乐开关遥控 switchMusic.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; handleCommand(isChecked, musicPlayCommand, musicStopCommand); &#125;); &#125; private void handleCommand(boolean isChecked, ICommand openCommand, ICommand closeCommand) &#123; if (isChecked) &#123; openCommand.execute(); &#125; else &#123; closeCommand.execute(); &#125; &#125;&#125; 不知不觉中，我们就写出了命令模式的代码。来看下命令模式的定义： 命令模式：将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化，对请求排队或记录请求日志，以及支持可撤销的操作。 使用命令模式后，现在我们要实现撤销功能会非常容易。 首先，在命令接口中，新增 undo 方法： 123456public interface ICommand &#123; void execute(); void undo();&#125; 开门命令中新增 undo： 1234567891011121314151617public class DoorOpenCommand implements ICommand &#123; private Door door; public void setDoor(Door door) &#123; this.door = door; &#125; @Override public void execute() &#123; door.openDoor(); &#125; @Override public void undo() &#123; door.closeDoor(); &#125;&#125; 关门命令中新增 undo： 1234567891011121314151617public class DoorCloseCommand implements ICommand &#123; private Door door; public void setDoor(Door door) &#123; this.door = door; &#125; @Override public void execute() &#123; door.closeDoor(); &#125; @Override public void undo() &#123; door.openDoor(); &#125;&#125; 开灯命令中新增 undo： 123456789101112131415161718public class LightOnCommand implements ICommand &#123; Light light; public void setLight(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.lightOn(); &#125; @Override public void undo() &#123; light.lightOff(); &#125;&#125; 关灯命令中新增 undo： 123456789101112131415161718public class LightOffCommand implements ICommand &#123; Light light; public void setLight(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.lightOff(); &#125; @Override public void undo() &#123; light.lightOn(); &#125;&#125; 电视、音乐命令类似。 客户端： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Client &#123; // 所有的命令 Stack&lt;ICommand&gt; commands = new Stack&lt;&gt;(); @Test protected void test() &#123; ...初始化 // 大门开关遥控 switchDoor.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; handleCommand(isChecked, doorOpenCommand, doorCloseCommand); &#125;); // 电灯开关遥控 switchLight.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; handleCommand(isChecked, lightOnCommand, lightOffCommand); &#125;); // 电视开关遥控 switchTv.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; handleCommand(isChecked, turnOnTvCommand, turnOffTvCommand); &#125;); // 音乐开关遥控 switchMusic.setOnCheckedChangeListener((view, isChecked) -&gt; &#123; handleCommand(isChecked, musicPlayCommand, musicStopCommand); &#125;); // 撤销按钮 btnUndo.setOnClickListener(view -&gt; &#123; if (commands.isEmpty()) return; // 撤销上一个命令 ICommand lastCommand = commands.pop(); lastCommand.undo(); &#125;); &#125; private void handleCommand(boolean isChecked, ICommand openCommand, ICommand closeCommand) &#123; if (isChecked) &#123; commands.push(openCommand); openCommand.execute(); &#125; else &#123; commands.push(closeCommand); closeCommand.execute(); &#125; &#125;&#125; 我们同样使用了一个栈结构，用于存储所有的命令，在每次执行命令前，将命令压入栈中。撤销时，弹出栈顶的命令，执行其 undo 方法即可。 命令模式使得客户端的职责更加简洁、清晰了，命令执行、撤销的代码都被隐藏到了命令类中。唯一的缺点是 —— 多了很多的命令类，因为我们必须针对每一个命令都设计一个命令类，容易导致类爆炸。 除了撤销方便外，命令模式还有一个优点，那就是宏命令的使用，宏命令也就是组合多个命令的 “宏大的命令”。 宏命令宏命令就是 将多个命令合并起来组成的命令。 接下来我们给遥控器添加一个 “睡眠” 按钮，按下时可以一键关闭大门，关闭电灯，关闭电视、打开音乐（听着音乐睡觉，就是这么优雅）。UI 设计…就不看了吧，这时就可以使用宏命令： 123456789101112131415161718192021222324public class MacroCommand implements ICommand &#123; // 定义一组命令 List&lt;ICommand&gt; commands; public MacroCommand(List&lt;ICommand&gt; commands) &#123; this.commands = commands; &#125; @Override public void execute() &#123; // 宏命令执行时，每个命令依次执行 for (int i = 0; i &lt; commands.size(); i++) &#123; commands.get(i).execute(); &#125; &#125; @Override public void undo() &#123; // 宏命令撤销时，每个命令依次撤销 for (int i = 0; i &lt; commands.size(); i++) &#123; commands.get(i).undo(); &#125; &#125;&#125; 有了宏命令，我们就可以任意组合多个命令，并且完全不会增加程序结构的复杂度。 客户端代码如下： 123456789// 定义睡眠宏命令MacroCommand sleepCommand = new MacroCommand(Arrays.asList(doorCloseCommand, lightOffCommand, turnOffTvCommand, musicPlayCommand));// 睡眠按钮btnSleep.setOnClickListener(view -&gt; &#123; // 将执行的命令保存到栈中，以便撤销 commands.push(sleepCommand); // 执行睡眠命令 sleepCommand.execute();&#125;); 可以看到，我们将 doorCloseCommand, lightOffCommand, turnOffTvCommand, musicPlayCommand 三个命令组合到了宏命令 sleepCommand 中，这个宏命令的使用方式和普通命令一模一样，因为它本身也是一个实现了 ICommand 接口的命令而已。 请求排队前文的定义中讲到，命令模式还可以用于请求排队。那么怎么实现请求排队功能呢？ 要实现请求排队功能，只需创建一个命令队列，将每个需要执行的命令依次传入队列中，然后工作线程不断地从命令队列中取出队列头的命令，再执行命令即可。 事实上，安卓 app 的界面就是这么实现的。源码中使用了一个阻塞式死循环 Looper，不断地从 MessageQueue 中取出消息，交给 Handler 处理，用户的每一个操作也会通过 Handler 传递到 MessageQueue 中排队执行。 命令模式小结命令模式可以说将封装发挥得淋漓尽致。在我们平时的程序设计中，最常用的封装是将拥有一类职责的对象封装成类，而命令对象的唯一职责就是通过 execute 去调用一个方法，也就是说它将 “方法调用” 这个步骤封装起来了，使得我们可以对 “方法调用” 进行排队、撤销等处理。 命令模式的主要优点如下： 降低系统的耦合度。将 “行为请求者” 和 ”行为实现者“ 解耦。 扩展性强。增加或删除命令非常方便，并且不会影响其他类。 封装 “方法调用”，方便实现 Undo 和 Redo 操作。 灵活性强，可以实现宏命令。 它的主要缺点是： 会产生大量命令类。增加了系统的复杂性。 解释器模式 Interpreter我国 IT 界历来有一个汉语编程梦，虽然各方对于汉语编程争论不休，甚至上升到民族大义的高度，本文不讨论其对与错，但我们不妨来尝试一下，定义一个简单的中文编程语法。 在设计模式中，解释器模式就是用来自定义语法的，它的定义如下。 解释器模式（Interpreter Pattern）：给定一门语言，定义它的文法的一种表示，并定义一个解释器，该解释器使用该表示来解释语言中的句子。 解释器模式较为晦涩难懂，但本文我们仍然深入浅出，通过一个简单的例子来学习解释器模式：使用中文编写出十以内的加减法公式。比如： 12345输入“一加一”，输出结果 2输入“一加一加一”，输出结果 3输入“二加五减三”，输出结果 4输入“七减五加四减一”，输出结果 5输入“九减五加三减一”，输出结果 6 看到这个需求，我们很容易想到一种写法：将输入的字符串分割成单个字符，把数字字符通过switch-case转换为数字，再通过计算符判断是加法还是减法，对应做加、减计算，最后返回结果即可。 的确可行，但这实在太面向过程了。众所周知，面向过程编程会有耦合度高，不易扩展等缺点。接下来我们尝试按照面向对象的写法来实现这个功能。 按照面向对象的编程思想，我们应该为公式中不同种类的元素建立一个对应的对象。那么我们先分析一下公式中的成员： 数字：零到九对应 0 ~ 9 计算符：加、减对应+、- 公式中仅有这两种元素，其中对于数字的处理比较简单，只需要通过 switch-case 将中文名翻译成阿拉伯数字即可。 计算符怎么处理呢？计算符左右两边可能是单个数字，也可能是另一个计算公式。但无论是数字还是公式，两者都有一个共同点，那就是他们都会返回一个整数：数字返回其本身，公式返回其计算结果。 所以我们可以根据这个共同点提取出一个返回整数的接口，数字和计算符都作为该接口的实现类。在计算时，使用栈结构存储数据，将数字和计算符统一作为此接口的实现类压入栈中计算。 talk is cheap, show me the code. 数字和计算符公共的接口： 123interface Expression &#123; int interpret();&#125; 上文已经说到，数字和计算符都属于表达式的一部分，他们的共同点是都会返回一个整数。从表达式计算出整数的过程，我们称之为解释（interpret）。 对数字类的解释实现起来相对比较简单： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Number implements Expression &#123; int number; public Number(char word) &#123; switch (word) &#123; case &#x27;零&#x27;: number = 0; break; case &#x27;一&#x27;: number = 1; break; case &#x27;二&#x27;: number = 2; break; case &#x27;三&#x27;: number = 3; break; case &#x27;四&#x27;: number = 4; break; case &#x27;五&#x27;: number = 5; break; case &#x27;六&#x27;: number = 6; break; case &#x27;七&#x27;: number = 7; break; case &#x27;八&#x27;: number = 8; break; case &#x27;九&#x27;: number = 9; break; default: break; &#125; &#125; @Override public int interpret() &#123; return number; &#125;&#125; 在 Number 类的构造函数中，先将传入的字符转换为对应的数字。在解释时将转换后的数字返回即可。 无论是加法还是减法，他们都是对左右两个表达式进行操作，所以我们可以将计算符提取出共同的抽象父类： 123456789abstract class Operator implements Expression &#123; Expression left; Expression right; Operator(Expression left, Expression right) &#123; this.left = left; this.right = right; &#125;&#125; 在此抽象父类中，我们存入了两个变量，表达计算符左右两边的表达式。 加法类实现如下： 1234567891011class Add extends Operator &#123; Add(Expression left, Expression right) &#123; super(left, right); &#125; @Override public int interpret() &#123; return left.interpret() + right.interpret(); &#125;&#125; 减法类： 1234567891011class Sub extends Operator &#123; Sub(Expression left, Expression right) &#123; super(left, right); &#125; @Override public int interpret() &#123; return left.interpret() - right.interpret(); &#125;&#125; 加法类和减法类都继承自 Operator 类，在对他们进行解释时，将左右两边表达式解释出的值相加或相减即可。 数字类和计算符内都定义好了，这时我们只需要再编写一个计算类将他们综合起来，统一计算即可。 计算类： 1234567891011121314151617181920class Calculator &#123; int calculate(String expression) &#123; Stack&lt;Expression&gt; stack = new Stack&lt;&gt;(); for (int i = 0; i &lt; expression.length(); i++) &#123; char word = expression.charAt(i); switch (word) &#123; case &#x27;加&#x27;: stack.push(new Add(stack.pop(), new Number(expression.charAt(++i)))); break; case &#x27;减&#x27;: stack.push(new Sub(stack.pop(), new Number(expression.charAt(++i)))); break; default: stack.push(new Number(word)); break; &#125; &#125; return stack.pop().interpret(); &#125;&#125; 在计算类中，我们使用栈结构保存每一步操作。遍历 expression 公式： 遇到数字则将其压入栈中；遇到计算符时，先将栈顶元素 pop 出来，再和下一个数字一起传入计算符的构造函数中，组成一个计算符公式压入栈中。 需要注意的是，入栈出栈过程并不会执行真正的计算，栈操作只是将表达式组装成一个嵌套的类对象而已。比如： “一加一”表达式，经过入栈出栈操作后，生成的对象是 new Add(new Number(&#39;一&#39;), new Number(&#39;一&#39;)) “二加五减三”表达式，经过入栈出栈操作后，生成的对象是 new Sub(new Add(new Number(&#39;二&#39;), new Number(&#39;五&#39;)), new Number(&#39;三&#39;)) 最后一步 stack.pop().interpret()，将栈顶的元素弹出，执行 interpret() ，这时才会执行真正的计算。计算时会将中文的数字和运算符分别解释成计算机能理解的指令。 测试类： 123456789101112131415161718192021public class Client &#123; @Test public void test() &#123; Calculator calculator = new Calculator(); String expression1 = &quot;一加一&quot;; String expression2 = &quot;一加一加一&quot;; String expression3 = &quot;二加五减三&quot;; String expression4 = &quot;七减五加四减一&quot;; String expression5 = &quot;九减五加三减一&quot;; // 输出： 一加一 等于 2 System.out.println(expression1 + &quot; 等于 &quot; + calculator.calculate(expression1)); // 输出： 一加一加一 等于 3 System.out.println(expression2 + &quot; 等于 &quot; + calculator.calculate(expression2)); // 输出： 二加五减三 等于 4 System.out.println(expression3 + &quot; 等于 &quot; + calculator.calculate(expression3)); // 输出： 七减五加四减一 等于 5 System.out.println(expression4 + &quot; 等于 &quot; + calculator.calculate(expression4)); // 输出： 九减五加三减一 等于 6 System.out.println(expression5 + &quot; 等于 &quot; + calculator.calculate(expression5)); &#125;&#125; 这就是解释器模式，我们将一句中文的公式解释给计算机，然后计算机为我们运算出了正确的结果。 分析本例中公式的组成，我们可以发现几条显而易见的性质： 数字类不可被拆分，属于计算中的最小单元； 加法类、减法类可以被拆分成两个数字（或两个公式）加一个计算符，他们不是计算的最小单元。 在解释器模式中，我们将不可拆分的最小单元称之为终结表达式，可以被拆分的表达式称之为非终结表达式。 解释器模式具有一定的拓展性，当需要添加其他计算符时，我们可以通过添加 Operator 的子类来完成。但添加后需要按照运算优先级修改计算规则。可见一个完整的解释器模式是非常复杂的，实际开发中几乎没有需要自定义解释器的情况。 解释器模式有一个常见的应用，在我们平时匹配字符串时，用到的正则表达式就是一个解释器。 解释器主要角色 抽象表达式（Abstract Expression）角色：定义解释器的接口，约定解释器的解释操作，主要包含解释方法 interpret()。例如本文Expression() 终结符表达式（Terminal Expression）角色：是抽象表达式的子类，用来实现文法中与终结符相关的操作，文法中的每一个终结符都有一个具体终结表达式与之相对应。例如本文Number() 非终结符表达式（Nonterminal Expression）角色：也是抽象表达式的子类，用来实现文法中与非终结符相关的操作，文法中的每条规则都对应于一个非终结符表达式。例如本文Operator() 环境（Context）角色：通常包含各个解释器需要的数据或是公共的功能，一般用来传递被所有解释器共享的数据，后面的解释器可以从这里获取这些值。 客户端（Client）：主要任务是将需要分析的句子或表达式转换成使用解释器对象描述的抽象语法树，然后调用解释器的解释方法，当然也可以通过环境角色间接访问解释器的解释方法。 迭代器模式 Iterator设想一个场景：我们有一个类中存在一个列表。这个列表需要提供给外部类访问，但我们不希望外部类修改其中的数据。 123public class MyList &#123; private List&lt;String&gt; data = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);&#125; 通常来说，将成员变量提供给外部类访问有两种方式： 将此列表设置为 public 变量； 添加 getData() 方法，返回此列表。 但这两种方式都有一个致命的缺点，它们无法保证外部类不修改其中的数据。外部类拿到 data 对象后，可以随意修改列表内部的元素，这会造成极大的安全隐患。 那么有什么更好的方式吗？使得外部类只能读取此列表中的数据，无法修改其中的任何数据，保证其安全性。 分析可知，我们可以通过提供两个方法实现此效果： 提供一个 String next() 方法，使得外部类可以按照次序，一条一条的读取数据； 提供一个 boolean hasNext() 方法，告知外部类是否还有下一条数据。 代码实现如下： 12345678910111213public class MyList &#123; private List&lt;String&gt; data = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;); private int index = 0; public String next() &#123; // 返回数据后，将 index 加 1，使得下次访问时返回下一条数据 return data.get(index++); &#125; public boolean hasNext() &#123; return index &lt; data.size(); &#125;&#125; 客户端就可以使用一个 while 循环来访问此列表了： 12345678910public class Client &#123; @Test public void test() &#123; MyList list = new MyList(); // 输出：abc while (list.hasNext()) &#123; System.out.print(list.next()); &#125; &#125;&#125; 由于没有给外部类暴露 data 成员变量，所以我们可以保证数据是安全的。 但这样的实现还有一个问题：当遍历完成后，hasNext() 方法就会一直返回 false，无法再一次遍历了，所以我们必须在一个合适的地方把 index 重置成 0。 在哪里重置比较合适呢？实际上，使用 next() 方法和 hasNext() 方法来遍历列表是一个完全通用的方法，我们可以为其创建一个接口，取名为 Iterator，Iterator 的意思是迭代器，迭代的意思是重复反馈，这里是指我们依次遍历列表中的元素。 123456public interface Iterator &#123; boolean hasNext(); String next();&#125; 然后在 MyList 类中，每次遍历时生成一个迭代器，将 index 变量放到迭代器中。由于每个迭代器都是新生成的，所以每次遍历时的 index 自然也就被重置成 0 了。代码如下： 12345678910111213141516171819202122public class MyList &#123; private List&lt;String&gt; data = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;); // 每次生成一个新的迭代器，用于遍历列表 public Iterator iterator() &#123; return new Itr(); &#125; private class Itr implements Iterator &#123; private int index = 0; @Override public boolean hasNext() &#123; return index &lt; data.size(); &#125; @Override public String next() &#123; return data.get(index++); &#125; &#125;&#125; 客户端访问此列表的代码修改如下： 123456789101112public class Client &#123; @Test public void test() &#123; MyList list = new MyList(); // 获取迭代器，用于遍历列表 Iterator iterator = list.iterator(); // 输出：abc while (iterator.hasNext()) &#123; System.out.print(iterator.next()); &#125; &#125;&#125; 这就是迭代器模式，《设计模式》一书中将其定义如下： 迭代器模式（Iterator Pattern）：提供一种方法访问一个容器对象中各个元素，而又不需暴露该对象的内部细节。 迭代器模式的核心就在于定义出 next() 方法和 hasNext() 方法，让外部类使用这两个方法来遍历列表，以达到隐藏列表内部细节的目的。 事实上，Java 已经为我们内置了 Iterator 接口，源码中使用了泛型使得此接口更加的通用： 1234public interface Iterator&lt;E&gt; &#123; boolean hasNext(); E next();&#125; 并且，本例中使用的迭代器模式是仿照 ArrayList 的源码实现的，ArrayList 源码中使用迭代器模式的部分代码如下： 1234567891011121314151617181920public class ArrayList&lt;E&gt; &#123; ... public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; private class Itr implements Iterator&lt;E&gt; &#123; protected int limit = ArrayList.this.size; int cursor; public boolean hasNext() &#123; return cursor &lt; limit; &#125; public E next() &#123; ... &#125; &#125;&#125; 我们平时常用的 for-each 循环，也是迭代器模式的一种应用。在 Java 中，只要实现了 Iterable 接口的类，都被视为可迭代访问的。Iterable 中的核心方法只有一个，也就是刚才我们在 MyList 类中实现过的用于获取迭代器的 iterator() 方法： 1234public interface Iterable&lt;T&gt; &#123; Iterator&lt;T&gt; iterator(); ...&#125; 只要我们将 MyList 类修改为继承此接口，便可以使用 for-each 来迭代访问其中的数据了： 123456789101112131415161718192021222324public class MyList implements Iterable&lt;String&gt; &#123; private List&lt;String&gt; data = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;); @NonNull @Override public Iterator&lt;String&gt; iterator() &#123; // 每次生成一个新的迭代器，用于遍历列表 return new Itr(); &#125; private class Itr implements Iterator&lt;String&gt; &#123; private int index = 0; @Override public boolean hasNext() &#123; return index &lt; data.size(); &#125; @Override public String next() &#123; return data.get(index++); &#125; &#125;&#125; 客户端使用 for-each 访问： 12345678910public class Client &#123; @Test public void test() &#123; MyList list = new MyList(); // 输出：abc for (String item : list) &#123; System.out.print(item); &#125; &#125;&#125; 这就是迭代器模式。基本上每种语言都会在语言层面为所有列表提供迭代器，我们只需要直接拿来用即可，这是一个比较简单又很常用的设计模式。 迭代器模式一个典型应用：读取文件或者数据库 中介者模式 Mediator顾名思义，中介这个名字对我们来说实在太熟悉了。平时走在上班路上就会经常见到各种房产中介，他们的工作就是使得买家与卖家不需要直接打交道，只需要分别与中介打交道，就可以完成交易，用计算机术语来说就是减少了耦合度。 当类与类之间的关系呈现网状时，引入一个中介者，可以使类与类之间的关系变成星形。将每个类与多个类的耦合关系简化为每个类与中介者的耦合关系。 举个例子，在我们打麻将时，每两个人之间都可能存在输赢关系。如果每笔交易都由输家直接发给赢家，就会出现一种网状耦合关系。 我们用程序来模拟一下这个过程。 玩家类： 1234567891011class Player &#123; // 初始资金 100 元 public int money = 100; public void win(Player player, int money) &#123; // 输钱的人扣减相应的钱 player.money -= money; // 自己的余额增加 this.money += money; &#125;&#125; 此类中有一个 money 变量，表示自己的余额。当自己赢了某位玩家的钱时，调用 win 方法修改输钱的人和自己的余额。 需要注意的是，我们不需要输钱的方法，因为在 win 方法中，已经将输钱的人对应余额扣除了。 客户端代码： 1234567891011121314151617181920public class Client &#123; @Test public void test() &#123; Player player1 = new Player(); Player player2 = new Player(); Player player3 = new Player(); Player player4 = new Player(); // player1 赢了 player3 5 元 player1.win(player3, 5); // player2 赢了 player1 10 元 player2.win(player1, 10); // player2 赢了 player4 10 元 player2.win(player4, 10); // player4 赢了 player3 7 元 player4.win(player3, 7); // 输出：四人剩余的钱：105,120,88,97 System.out.println(&quot;四人剩余的钱：&quot; + player1.money + &quot;,&quot; + player2.money + &quot;,&quot; + player3.money + &quot;,&quot; + player4.money); &#125;&#125; 在客户端中，每两位玩家需要进行交易时，都会增加程序耦合度，相当于每位玩家都需要和其他所有玩家打交道，这是一种不好的做法。 此时，我们可以引入一个中介类 —— 微信群，只要输家将自己输的钱发到微信群里，赢家从微信群中领取对应金额即可。网状的耦合结构就变成了星形结构： 此时，微信群就充当了一个中介者的角色，由它来负责与所有人进行交易，每个玩家只需要与微信群打交道即可。 微信群类： 123class Group &#123; public int money;&#125; 此类中只有一个 money 变量表示群内的余额。 玩家类修改如下： 123456789101112131415class Player &#123; public int money = 100; public Group group; public Player(Group group) &#123; this.group = group; &#125; public void change(int money) &#123; // 输了钱将钱发到群里 或 在群里领取自己赢的钱 group.money += money; // 自己的余额改变 this.money += money; &#125;&#125; 玩家类中新增了一个构造方法，在构造方法中将中介者传进来。每当自己有输赢时，只需要将钱发到群里或者在群里领取自己赢的钱，然后修改自己的余额即可。 客户端代码对应修改如下： 123456789101112131415161718192021public class Client &#123; @Test public void test()&#123; Group group = new Group(); Player player1 = new Player(group); Player player2 = new Player(group); Player player3 = new Player(group); Player player4 = new Player(group); // player1 赢了 5 元 player1.change(5); // player2 赢了 20 元 player2.change(20); // player3 输了 12 元 player3.change(-12); // player4 输了 3 元 player4.change(-3); // 输出：四人剩余的钱：105,120,88,97 System.out.println(&quot;四人剩余的钱：&quot; + player1.money + &quot;,&quot; + player2.money + &quot;,&quot; + player3.money + &quot;,&quot; + player4.money); &#125;&#125; 可以看到，通过引入中介者，客户端的代码变得更加清晰了。大家不需要再互相打交道，所有交易通过中介者完成即可。 事实上，这段代码还存在一点不足。因为我们忽略了一个前提：微信群里的钱不可以为负数。也就是说，输家必须先将钱发到微信群内，赢家才能去微信群里领钱。这个功能可以用我们在 Java 多线程王国奇遇记 中学到的 wait&#x2F;notify 机制完成，与中介者模式无关，故这里不再给出相关代码，感兴趣的读者可以自行实现。 总而言之，中介者模式就是用于将类与类之间的多对多关系简化成多对一、一对多关系的设计模式，它的定义如下： 中介者模式（Mediator Pattern）：定义一个中介对象来封装一系列对象之间的交互，使原有对象之间的耦合松散，且可以独立地改变它们之间的交互。 中介者模式的缺点也很明显：由于它将所有的职责都移到了中介者类中，也就是说中介类需要处理所有类之间的协调工作，这可能会使中介者演变成一个超级类。所以使用中介者模式时需要权衡利弊。 备忘录模式 Memento备忘录模式最常见的实现就是游戏中的存档、读档功能，通过存档、读档，使得我们可以随时恢复到之前的状态。 当我们在玩游戏时，打大 Boss 之前，通常会将自己的游戏进度存档保存，以保证自己打不过 Boss 的话，还能重新读档恢复状态。 玩家类： 123456789101112131415161718192021222324252627282930class Player &#123; // 生命值 private int life = 100; // 魔法值 private int magic = 100; public void fightBoss() &#123; life -= 100; magic -= 100; if (life &lt;= 0) &#123; System.out.println(&quot;壮烈牺牲&quot;); &#125; &#125; public int getLife() &#123; return life; &#125; public void setLife(int life) &#123; this.life = life; &#125; public int getMagic() &#123; return magic; &#125; public void setMagic(int magic) &#123; this.magic = magic; &#125;&#125; 我们为玩家定义了两个属性：生命值和魔法值。其中有一个 fightBoss() 方法，每次打 Boss 都会扣减 100 点体力、100 点魔法值。如果生命值小于等于 0，则提示用户已“壮烈牺牲”。 客户端实现如下： 12345678910111213141516public class Client &#123; @Test public void test() &#123; Player player = new Player(); // 存档 int savedLife = player.getLife(); int savedMagic = player.getMagic(); // 打 Boss，打不过，壮烈牺牲 player.fightBoss(); // 读档，恢复到打 Boss 之前的状态 player.setLife(savedLife); player.setMagic(savedMagic); &#125;&#125; 客户端中，我们在 fightBoss() 之前，先去存档，把自己当前的生命值和魔法值保存起来。打完 Boss 发现自己牺牲之后，再回去读档，将自己恢复到打 Boss 之前的状态。 这就是备忘录模式……吗？不完全是，事情并没有这么简单。 还记得我们在 原型模式 中，买的那杯和周杰伦一模一样的奶茶吗？开始时，为了克隆一杯奶茶，我们将奶茶的各个属性分别赋值成和周杰伦买的那杯奶茶一样。但这样存在一个弊端：我们不可能为一千个粉丝写一千份挨个赋值操作。所以最终我们在奶茶类内部实现了 Cloneable 接口，定义了 clone() 方法，来实现一行代码拷贝所有属性。 备忘录模式也应该采取类似的做法。我们不应该采用将单个属性挨个存取的方式来进行读档、存档。更好的做法是将存档、读档交给需要存档的类内部去实现。 新建备忘录类： 123456789class Memento &#123; int life; int magic; Memento(int life, int magic) &#123; this.life = life; this.magic = magic; &#125;&#125; 在此类中，管理需要存档的数据。 玩家类中，通过备忘录类实现存档、读档： 1234567891011121314class Player &#123; ... // 存档 public Memento saveState() &#123; return new Memento(life, magic); &#125; // 读档 public void restoreState(Memento memento) &#123; this.life = memento.life; this.magic = memento.magic; &#125;&#125; 客户端类对应修改如下： 1234567891011121314public class Client &#123; @Test public void test() &#123; Player player = new Player(); // 存档 Memento memento = player.saveState(); // 打 Boss，打不过，壮烈牺牲 player.fightBoss(); // 读档 player.restoreState(memento); &#125;&#125; 这才是完整的备忘录模式。这个设计模式的定义如下： 备忘录模式：在不破坏封装的条件下，通过备忘录对象存储另外一个对象内部状态的快照，在将来合适的时候把这个对象还原到存储起来的状态。 备忘录模式的优点是： 给用户提供了一种可以恢复状态的机制，使用户能够比较方便的回到某个历史的状态 实现了信息的封装，使得用户不需要关心状态的保存细节 缺点是： 消耗资源，如果类的成员变量过多，势必会占用比较大的资源，而且每一次保存都会消耗一定的内存。 总体而言，备忘录模式是利大于弊的，所以许多程序都为用户提供了备份方案。比如 IDE 中，用户可以将自己的设置导出成 zip，当需要恢复设置时，再将导出的 zip 文件导入即可。这个功能内部的原理就是备忘录模式。 备忘录模式的主要角色1.发起人（Originator）角色：记录当前时刻的内部状态信息，提供创建备忘录和恢复备忘录数据的功能，实现其他业务功能，它可以访问备忘录里的所有信息。2.备忘录（Memento）角色：负责存储发起人的内部状态，在需要的时候提供这些内部状态给发起人。3.管理者（Caretaker）角色：对备忘录进行管理，提供保存与获取备忘录的功能，但其不能对备忘录的内容进行访问与修改。 观察者模式 Observer观察者模式非常常见，近年来逐渐流行的响应式编程就是观察者模式的应用之一。观察者模式的思想就是一个对象发生一个事件后，逐一通知监听着这个对象的监听者，监听者可以对这个事件马上做出响应。 生活中有很多观察者模式的例子，比如我们平时的开关灯。当我们打开灯的开关时，灯马上亮了；当我们关闭灯的开关时，灯马上熄了。这个过程中，灯就对我们控制开关的事件做出了响应，这就是一个最简单的一对一观察者模式。当力扣公众号发表一篇文章，所有关注了公众号的读者立即收到了文章，这个过程中所有关注了公众号的微信客户端就对公众号发表文章的事件做出了响应，这就是一个典型的一对多观察者模式。 再举个例子，比如警察一直观察着张三的一举一动，只要张三有什么违法行为，警察马上行动，抓捕张三。 这个过程中： 警察称之为观察者（Observer） 张三称之为被观察者（Observable，可观察的） 警察观察张三的这个行为称之为订阅（subscribe），或者注册（register） 张三违法后，警察抓捕张三的行动称之为响应（update） 众所周知，张三坏事做尽，是一个老法外狂徒了，所以不止一个警察会盯着张三，也就是说一个被观察者可以有多个观察者。当被观察者有事件发生时，所有观察者都能收到通知并响应。观察者模式主要处理的是一种一对多的依赖关系。它的定义如下： 观察者模式（Observer Pattern）：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 我们使用程序来模拟一下这个过程。 观察者的接口： 123public interface Observer &#123; void update(String event);&#125; 接口中只有一个 update 方法，用于对被观察者发出的事件做出响应。 被观察者的父类： 123456789101112131415161718public class Observable &#123; private List&lt;Observer&gt; observers = new ArrayList&lt;&gt;(); public void addObserver(Observer observer) &#123; observers.add(observer); &#125; public void removeObserver(Observer observer) &#123; observers.remove(observer); &#125; public void notifyObservers(String event) &#123; for (Observer observer : observers) &#123; observer.update(event); &#125; &#125;&#125; 被观察者中维护了一个观察者列表，提供了三个方法： addObserver：将 observer 对象添加到观察者列表中 removeObserver：将 observer 对象从观察者列表中移除 notifyObservers：通知所有观察者有事件发生，具体实现是调用所有观察者的 update 方法 有了这两个基类，我们就可以定义出具体的罪犯与警察类。 警察属于观察者： 123456public class PoliceObserver implements Observer &#123; @Override public void update(String event) &#123; System.out.println(&quot;警察收到消息，罪犯在&quot; + event); &#125;&#125; 警察实现了观察者接口，当警察收到事件后，做出响应，这里的响应就是简单的打印了一条日志。 罪犯属于被观察者： 123456public class CriminalObservable extends Observable &#123; public void crime(String event) &#123; System.out.println(&quot;罪犯正在&quot; + event); notifyObservers(event); &#125;&#125; 罪犯继承自被观察者类，当罪犯有犯罪行为时，所有的观察者都会收到通知。 客户端测试： 12345678910111213public class Client &#123; @Test public void test() &#123; CriminalObservable zhangSan = new CriminalObservable(); PoliceObserver police1 = new PoliceObserver(); PoliceObserver police2 = new PoliceObserver(); PoliceObserver police3 = new PoliceObserver(); zhangSan.addObserver(police1); zhangSan.addObserver(police2); zhangSan.addObserver(police3); zhangSan.crime(&quot;放狗咬人&quot;); &#125;&#125; 在客户端中，我们 new 了一个张三，为其添加了三个观察者：police1，police2，police3。 运行程序，输出如下： 1234罪犯正在放狗咬人警察收到消息，罪犯在放狗咬人警察收到消息，罪犯在放狗咬人警察收到消息，罪犯在放狗咬人 可以看到，所有的观察者都被通知到了。当某个观察者不需要继续观察时，调用 removeObserver 即可。 这就是观察者模式，它并不复杂，由于生活中一对多的关系非常常见，所以观察者模式应用广泛。 Java 源码中的观察者模式实际上，Java 已经为我们提供了的 Observable 类和 Observer 类，我们在用到观察者模式时，无需自己创建这两个基类，我们来看一下 Java 中提供的源码： java.util.Observer 类： 123public interface Observer &#123; void update(Observable o, Object arg);&#125; Observer 类和我们上例中的定义基本一致，都是只有一个 update 方法用于响应 Observable 的事件。区别有两点： update 方法将 Observable 对象也提供给了 Observer update 方法中的参数类型变成了 Object 这两点区别都是为了保证此 Observer 的适用范围更广。 java.util.Observable 类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class Observable &#123; private boolean changed = false; private Vector&lt;Observer&gt; obs; public Observable() &#123; obs = new Vector&lt;&gt;(); &#125; public synchronized void addObserver(java.util.Observer o) &#123; if (o == null) throw new NullPointerException(); if (!obs.contains(o)) &#123; obs.addElement(o); &#125; &#125; public synchronized void deleteObserver(java.util.Observer o) &#123; obs.removeElement(o); &#125; public void notifyObservers() &#123; notifyObservers(null); &#125; public void notifyObservers(Object arg) &#123; Object[] arrLocal; synchronized (this) &#123; if (!hasChanged()) return; arrLocal = obs.toArray(); clearChanged(); &#125; for (int i = arrLocal.length - 1; i &gt;= 0; i--) ((Observer) arrLocal[i]).update(this, arg); &#125; public synchronized void deleteObservers() &#123; obs.removeAllElements(); &#125; protected synchronized void setChanged() &#123; changed = true; &#125; protected synchronized void clearChanged() &#123; changed = false; &#125; public synchronized boolean hasChanged() &#123; return changed; &#125; public synchronized int countObservers() &#123; return obs.size(); &#125;&#125; Observable 类和我们上例中的定义也是类似的，区别在于： 用于保存观察者列表的容器不是 ArrayList，而是 Vector 添加了一个 changed 字段，以及 setChanged 和 clearChanged 方法。分析可知，当 changed 字段为 true 时，才会通知所有观察者，否则不通知观察者。所以当我们使用此类时，想要触发 notifyObservers 方法，必须先调用 setChanged 方法。这个字段相当于在被观察者和观察者之间添加了一个可控制的阀门。 提供了 countObservers 方法，用于计算观察者数量 添加了一些 synchronized 关键字保证线程安全 这些区别仍然是为了让 Observable 的适用范围更广，核心思想与本文介绍的都是一致的。 状态模式 State状态模式（State Pattern）：当一个对象的内在状态改变时允许改变其行为，这个对象看起来像是改变了其类。 通俗地说，状态模式就是一个关于多态的设计模式。 如果一个对象有多种状态，并且每种状态下的行为不同，一般的做法是在这个对象的各个行为中添加 if-else 或者 switch-case 语句。但更好的做法是为每种状态创建一个状态对象，使用状态对象替换掉这些条件判断语句，使得状态控制更加灵活，扩展性也更好。 举个例子，力扣的用户有两种状态：普通用户和 PLUS 会员。PLUS 会员有非常多的专享功能，其中“模拟面试”功能非常有特色，我们便以此为例。 当普通用户点击模拟面试功能时，提示用户：模拟面试是 Plus 会员专享功能； 当 PLUS 会员点击模拟面试功能时，开始一场模拟面试。 先来看看不使用状态模式的写法，看出它的缺点后，我们再用状态模式来重构代码。 首先定义一个用户状态枚举类： 123public enum State &#123; NORMAL, PLUS&#125; NORMAL 代表普通用户状态，PLUS 代表 PLUS 会员状态。 用户的功能接口： 123public interface IUser &#123; void mockInterview();&#125; 本例中我们只定义了一个模拟面试的方法，实际开发中这里可能会有许许多多的方法。 用户状态切换接口： 12345public interface ISwitchState &#123; void purchasePlus(); void expire();&#125; 此接口中定义了两个方法：purchasePlus 方法表示购买 Plus 会员，用户状态变为 PLUS 会员状态，expire 方法表示会员过期，用户状态变为普通用户状态。 力扣用户类： 12345678910111213141516171819202122public class User implements IUser, ISwitchState &#123; private State state = State.NORMAL; @Override public void mockInterview() &#123; if (state == State.PLUS) &#123; System.out.println(&quot;开始模拟面试&quot;); &#125; else &#123; System.out.println(&quot;模拟面试是 Plus 会员专享功能&quot;); &#125; &#125; @Override public void purchasePlus() &#123; state = State.PLUS; &#125; @Override public void expire() &#123; state = State.NORMAL; &#125;&#125; 用户类实现了 IUser 接口，IUser 接口中的每个功能都需要判断用户是否为 Plus 会员，也就是说每个方法中都有if (state == State.PLUS) &#123;&#125; else &#123;&#125;语句，如果状态不止两种，还需要用上 switch-case 语句来判断状态，这就是不使用状态模式的弊端： 判断用户状态会产生大量的分支判断语句，导致代码冗长； 当状态有增加或减少时，需要改动多个地方，违反开闭原则。 在《代码整洁之道》、《重构》两本书中都提到：应使用多态取代条件表达式。接下来我们就利用多态特性重构这份代码。 为每个状态新建一个状态类，普通用户： 1234567class Normal implements IUser &#123; @Override public void mockInterview() &#123; System.out.println(&quot;模拟面试是 Plus 会员专享功能&quot;); &#125;&#125; PLUS 会员： 1234567class Plus implements IUser &#123; @Override public void mockInterview() &#123; System.out.println(&quot;开始模拟面试&quot;); &#125;&#125; 每个状态类都实现了 IUser 接口，在接口方法中实现自己特定的行为。 用户类： 12345678910111213141516171819class User implements IUser, ISwitchState &#123; IUser state = new Normal(); @Override public void mockInterview() &#123; state.mockInterview(); &#125; @Override public void purchasePlus() &#123; state = new Plus(); &#125; @Override public void expire() &#123; state = new Normal(); &#125;&#125; 可以看到，丑陋的状态判断语句消失了，无论 IUser 接口中有多少方法，User 类都只需要调用状态类的对应方法即可。 客户端测试： 1234567891011121314151617181920public class Client &#123; @Test public void test() &#123; // 用户初始状态为普通用户 User user = new User(); // 输出：模拟面试是 Plus 会员专享功能 user.mockInterview(); // 用户购买 Plus 会员，状态改变 user.purchasePlus(); // 输出：开始模拟面试 user.mockInterview(); // Plus 会员过期，变成普通用户，状态改变 user.expire(); // 输出：模拟面试是 Plus 会员专享功能 user.mockInterview(); &#125;&#125; 可以看到，用户状态改变后，行为也随着改变了，这就是状态模式定义的由来。 它的优点是：将与特定状态相关的行为封装到一个状态对象中，使用多态代替 if-else 或者 switch-case 状态判断。 缺点是：必然导致类增加，这也是使用多态不可避免的缺点。 策略模式 Strategy策略模式用一个成语就可以概括 —— 殊途同归。当我们做同一件事有多种方法时，就可以将每种方法封装起来，在不同的场景选择不同的策略，调用不同的方法。 策略模式（Strategy Pattern）：定义了一系列算法，并将每一个算法封装起来，而且使它们还可以相互替换。策略模式让算法独立于使用它的客户而独立变化。 我们以排序算法为例。排序算法有许多种，如冒泡排序、选择排序、插入排序，算法不同但目的相同，我们可以将其定义为不同的策略，让用户自由选择采用哪种策略完成排序。 首先定义排序算法接口： 123interface ISort &#123; void sort(int[] arr);&#125; 接口中只有一个 sort 方法，传入一个整型数组进行排序，所有的排序算法都实现此接口。 冒泡排序： 123456789101112131415class BubbleSort implements ISort&#123; @Override public void sort(int[] arr) &#123; for (int i = 0; i &lt; arr.length - 1; i++) &#123; for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123; if (arr[j] &gt; arr[j + 1]) &#123; // 如果左边的数大于右边的数，则交换，保证右边的数字最大 arr[j + 1] = arr[j + 1] + arr[j]; arr[j] = arr[j + 1] - arr[j]; arr[j + 1] = arr[j + 1] - arr[j]; &#125; &#125; &#125; &#125;&#125; 选择排序： 12345678910111213141516171819202122232425262728293031323334353637383940class SelectionSort implements ISort &#123; @Override public void sort(int[] arr) &#123; int minIndex; for (int i = 0; i &lt; arr.length - 1; i++) &#123; minIndex = i; for (int j = i + 1; j &lt; arr.length; j++) &#123; if (arr[minIndex] &gt; arr[j]) &#123; // 记录最小值的下标 minIndex = j; &#125; &#125; // 将最小元素交换至首位 int temp = arr[i]; arr[i] = arr[minIndex]; arr[minIndex] = temp; &#125; &#125;&#125;````插入排序：```Javaclass InsertSort implements ISort &#123; @Override public void sort(int[] arr) &#123; // 从第二个数开始，往前插入数字 for (int i = 1; i &lt; arr.length; i++) &#123; int currentNumber = arr[i]; int j = i - 1; // 寻找插入位置的过程中，不断地将比 currentNumber 大的数字向后挪 while (j &gt;= 0 &amp;&amp; currentNumber &lt; arr[j]) &#123; arr[j + 1] = arr[j]; j--; &#125; // 两种情况会跳出循环：1. 遇到一个小于或等于 currentNumber 的数字，跳出循环，currentNumber 就坐到它后面。 // 2. 已经走到数列头部，仍然没有遇到小于或等于 currentNumber 的数字，也会跳出循环，此时 j 等于 -1，currentNumber 就坐到数列头部。 arr[j + 1] = currentNumber; &#125; &#125;&#125; 这三种都是基本的排序算法，就不再详细介绍了。接下来我们需要创建一个环境类，将每种算法都作为一种策略封装起来，客户端将通过此环境类选择不同的算法完成排序。 123456789101112131415161718class Sort implements ISort &#123; private ISort sort; Sort(ISort sort) &#123; this.sort = sort; &#125; @Override public void sort(int[] arr) &#123; sort.sort(arr); &#125; // 客户端通过此方法设置不同的策略 public void setSort(ISort sort) &#123; this.sort = sort; &#125;&#125; 在此类中，我们保存了一个 ISort 接口的实现对象，在构造方法中，将其初始值传递进来，排序时调用此对象的 sort 方法即可完成排序。 我们也可以为 ISort 对象设定一个默认值，客户端如果没有特殊需求，直接使用默认的排序策略即可。 setSort 方法就是用来选择不同的排序策略的，客户端调用如下： 12345678910111213public class Client &#123; @Test public void test() &#123; int[] arr = new int[]&#123;6, 1, 2, 3, 5, 4&#125;; Sort sort = new Sort(new BubbleSort()); // 这里可以选择不同的策略完成排序 // sort.setSort(new InsertSort()); // sort.setSort(new SelectionSort()); sort.sort(arr); // 输出 [1, 2, 3, 4, 5, 6] System.out.println(Arrays.toString(arr)); &#125;&#125; 这就是基本的策略模式，通过策略模式我们可以为同一个需求选择不同的算法，以应付不同的场景。比如我们知道冒泡排序和插入排序是稳定的，而选择排序是不稳定的，当我们需要保证排序的稳定性就可以采用冒泡排序和插入排序，不需要保证排序的稳定性时可以采用选择排序。 策略模式还可以应用在图片缓存中，当我们开发一个图片缓存框架时，可以通过提供不同的策略类，让用户根据需要选择缓存解码后的图片、缓存未经解码的数据或者不缓存任何内容。在一些开源的图片加载框架中，就采用了这种设计。 策略模式扩展性和灵活性都相当不错。当有新的策略时，只需要增加一个策略类；要修改某个策略时，只需要更改具体的策略类，其他地方的代码都无需做任何调整。 但现在这样的策略模式还有一个弊端，如本系列第一篇文章中的工厂模式所言：每 new 一个对象，相当于调用者多知道了一个类，增加了类与类之间的联系，不利于程序的松耦合。 所以使用策略模式时，更好的做法是与工厂模式结合，将不同的策略对象封装到工厂类中，用户只需要传递不同的策略类型，然后从工厂中拿到对应的策略对象即可。接下来我们就来一起实现这种工厂模式与策略模式结合的混合模式。 创建排序策略枚举类： 12345enum SortStrategy &#123; BUBBLE_SORT, SELECTION_SORT, INSERT_SORT&#125; 在 Sort 类中使用简单工厂模式： 123456789101112131415161718192021222324252627282930class Sort implements ISort &#123; private ISort sort; Sort(SortStrategy strategy) &#123; setStrategy(strategy); &#125; @Override public void sort(int[] arr) &#123; sort.sort(arr); &#125; // 客户端通过此方法设置不同的策略 public void setStrategy(SortStrategy strategy) &#123; switch (strategy) &#123; case BUBBLE_SORT: sort = new BubbleSort(); break; case SELECTION_SORT: sort = new SelectionSort(); break; case INSERT_SORT: sort = new InsertSort(); break; default: throw new IllegalArgumentException(&quot;There&#x27;s no such strategy yet.&quot;); &#125; &#125;&#125; 利用简单工厂模式，我们将创建策略类的职责移到了 Sort 类中。如此一来，客户端只需要和 Sort 类打交道，通过 SortStrategy 选择不同的排序策略即可。 客户端： 12345678910111213public class Client &#123; @Test public void test() &#123; int[] arr = new int[]&#123;6, 1, 2, 3, 5, 4&#125;; Sort sort = new Sort(SortStrategy.BUBBLE_SORT); // 可以通过选择不同的策略完成排序 // sort.setStrategy(SortStrategy.SELECTION_SORT); // sort.setStrategy(SortStrategy.INSERT_SORT); sort.sort(arr); // 输出 [1, 2, 3, 4, 5, 6] System.out.println(Arrays.toString(arr)); &#125;&#125; 通过简单工厂模式与策略模式的结合，我们最大化地减轻了客户端的压力。这是我们第一次用到混合模式，但实际开发中会遇到非常多的混合模式，学习设计模式的过程只能帮助我们各个击破，真正融会贯通还需要在实际开发中多加操练。 需要注意的是，策略模式与状态模式非常类似，甚至他们的 UML 类图都是一模一样的。两者都是采用一个变量来控制程序的行为。策略模式通过不同的策略执行不同的行为，状态模式通过不同的状态值执行不同的行为。两者的代码很类似，他们的区别主要在于程序的目的不同。 使用策略模式时，程序只需选择一种策略就可以完成某件事。也就是说每个策略类都是完整的，都能独立完成这件事情，如上文所言，强调的是殊途同归。 使用状态模式时，程序需要在不同的状态下不断切换才能完成某件事，每个状态类只能完成这件事的一部分，需要所有的状态类组合起来才能完整的完成这件事，强调的是随势而动。 现在很多程序中的多数据库支持，也是策略模式的一种应用。 模板方法模式 Template method 模板方法模式（Template Method Pattern）：定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 通俗地说，模板方法模式就是一个关于继承的设计模式。 每一个被继承的父类都可以认为是一个模板，它的某些步骤是稳定的，某些步骤被延迟到子类中实现。 这和我们平时生活中使用的模板也是一样的。比如我们请假时，通常会给我们一份请假条模板，内容是已经写好的，只需要填写自己的姓名和日期即可。 本人 ____ 因 ____ 需请假 ___ 天，望批准！ 这个模板用代码表示如下： 123456789101112131415161718abstract class LeaveRequest &#123; void request() &#123; System.out.print(&quot;本人&quot;); System.out.print(name()); System.out.print(&quot;因&quot;); System.out.print(reason()); System.out.print(&quot;需请假&quot;); System.out.print(duration()); System.out.print(&quot;天，望批准&quot;); &#125; abstract String name(); abstract String reason(); abstract String duration();&#125; 在这份模板中，所有的其他步骤（固定字符串）都是稳定的，只有姓名、请假原因、请假时长是抽象的，需要延迟到子类去实现。 继承此模板，实现具体步骤的子类： 12345678910111213141516class MyLeaveRequest extends LeaveRequest &#123; @Override String name() &#123; return &quot;阿笠&quot;; &#125; @Override String reason() &#123; return &quot;参加力扣周赛&quot;; &#125; @Override String duration() &#123; return &quot;0.5&quot;; &#125;&#125; 测试： 12// 输出：本人阿笠因参加力扣周赛需请假0.5天，望批准new MyLeaveRequest().request(); 在使用模板方法模式时，我们可以为不同的模板方法设置不同的控制权限： 如果不希望子类覆写模板中的某个方法，使用 final 修饰此方法； 如果要求子类必须覆写模板中的某个方法，使用 abstract 修饰此方法； 如果没有特殊要求，可使用 protected 或 public 修饰此方法，子类可根据实际情况考虑是否覆写。 访问者模式 Visitor许多设计模式的书中都说访问者模式是最复杂的设计模式，实际上只要我们对它抽丝剥茧，就会发现访问者模式的核心思想并不复杂。 以我们去吃自助餐为例，每个人喜欢的食物是不一样的，比如 Aurora 喜欢吃龙虾和西瓜，Kevin 喜欢吃牛排和香蕉，餐厅不可能单独为某一位顾客专门准备食物。所以餐厅的做法是将所有的食物都准备好，顾客按照需求自由取用。此时，顾客和餐厅之间就形成了一种访问者与被访问者的关系。 准备好各种食物的餐厅： 123456class Restaurant &#123; private String lobster = &quot;lobster&quot;; private String watermelon = &quot;watermelon&quot;; private String steak = &quot;steak&quot;; private String banana = &quot;banana&quot;;&#125; 在餐厅类中，我们提供了四种食物：龙虾、西瓜、牛排、香蕉。 为顾客提供的接口： 123456789public interface IVisitor &#123; void chooseLobster(String lobster); void chooseWatermelon(String watermelon); void chooseSteak(String steak); void chooseBanana(String banana);&#125; 接口中提供了四个方法， 让顾客依次选择每种食物。 在餐厅中提供接收访问者的方法： 12345678910class Restaurant &#123; ... public void welcome(IVisitor visitor) &#123; visitor.chooseLobster(lobster); visitor.chooseWatermelon(watermelon); visitor.chooseSteak(steak); visitor.chooseBanana(banana); &#125;&#125; 在 welcome 方法中，我们将食物依次传递给访问者对应的访问方法。这时候，顾客如果想要访问餐厅选择自己喜欢的食物，只需要实现 IVisitor 接口即可。 比如顾客 Aurora 类： 123456789101112131415161718192021public class Aurora implements IVisitor &#123; @Override public void chooseLobster(String lobster) &#123; System.out.println(&quot;Aurora gets a &quot; + lobster); &#125; @Override public void chooseWatermelon(String watermelon) &#123; System.out.println(&quot;Aurora gets a &quot; + watermelon); &#125; @Override public void chooseSteak(String steak) &#123; System.out.println(&quot;Aurora doesn&#x27;t like &quot; + steak); &#125; @Override public void chooseBanana(String banana) &#123; System.out.println(&quot;Aurora doesn&#x27;t like &quot; + banana); &#125;&#125; 在此类中，顾客根据自己的喜好依次选择每种食物。 客户端测试： 12345678public class Client &#123; @Test public void test() &#123; Restaurant restaurant = new Restaurant(); IVisitor Aurora = new Aurora(); restaurant.welcome(Aurora); &#125;&#125; 运行程序，输出如下： 1234Aurora gets a lobsterAurora gets a watermelonAurora doesn&#x27;t like steakAurora doesn&#x27;t like banana 可以看到，Aurora 对每一种食物做出了自己的选择，这就是一个最简单的访问者模式，它已经体现出了访问者模式的核心思想：将数据的结构和对数据的操作分离。 访问者模式（Visitor Pattern）：表示一个作用于某对象结构中的各元素的操作。它使你可以在不改变各元素的类的前提下定义作用于这些元素的新操作。 本例中，顾客需要选择餐厅的食物，由于每个顾客对食物的选择是不一样的，如果在餐厅类中处理每位顾客的需求，必然导致餐厅类职责过多。所以我们并没有在餐厅类中处理顾客的需求，而是将所有的食物通过接口暴露出去，欢迎每位顾客来访问。顾客只要实现访问者接口就能访问到所有的食物，然后在接口方法中做出自己的选择。 相信这个例子还是非常简单直观的，看起来访问者模式也不是那么难理解。那么为什么很多书中说访问者模式是最复杂的设计模式呢？原因就在于《设计模式》一书中给访问者模式设计了一个“双重分派”的机制，而 Java 只支持单分派，用单分派语言强行模拟出双重分派才导致了访问者模式看起来比较复杂。要理解这一点，我们先来了解一下何谓单分派、何谓双重分派。 单分派与双重分派先看一段代码： Food 类： 12345public class Food &#123; public String name() &#123; return &quot;food&quot;; &#125;&#125; Watermelon 类，继承自 Food 类： 123456public class Watermelon extends Food &#123; @Override public String name() &#123; return &quot;watermelon&quot;; &#125;&#125; 在 Watermelon 类中，我们重写了 name() 方法。 客户端： 1234567public class Client &#123; @Test public void test() &#123; Food food = new Watermelon(); System.out.println(food.name()); &#125;&#125; 思考一下，在客户端中，我们 new 出了一个 Watermelon 对象，但他的声明类型是 Food，当我们调用此对象的 name 方法时，会输出 “food” 还是 “watermelon” 呢？ 了解过 Java 多态特性的同学都知道，这里肯定是输出 “watermelon” ，因为 Java 调用重写方法时，会根据运行时的具体类型来确定调用哪个方法。 再来看一段测试代码： 123456789101112131415public class Client &#123; @Test public void test() &#123; Food food = new Watermelon(); eat(food); &#125; public void eat(Food food) &#123; System.out.println(&quot;eat food&quot;); &#125; public void eat(Watermelon watermelon) &#123; System.out.println(&quot;eat watermelon&quot;); &#125;&#125; 在这段代码中，我们仍然 new 出了一个 Watermelon 对象，他的声明类型是 Food，在客户端中有 eat(Food food) 和 eat(Watermelon watermelon) 两个重载方法，这段代码会调用哪一个方法呢？ 我们运行这段代码会发现输出的是： 1eat food 这是由于 Java 在调用重载方法时，只会根据方法签名中声明的参数类型来判断调用哪个方法，不会去判断参数运行时的具体类型是什么。 从这两个例子中，我们可以看出 Java 对重写方法和重载方法的调用方式是不同的。 调用重写方法时，与对象的运行时类型有关； 调用重载方法时，只与方法签名中声明的参数类型有关，与对象运行时的具体类型无关。 了解了重写方法和重载方法调用方式的区别之后，我们将其综合起来就能理解何谓双重分派了。 测试代码： 123456789101112131415public class Client &#123; @Test public void test() &#123; Food food = new Watermelon(); eat(food); &#125; public void eat(Food food) &#123; System.out.println(&quot;eat food: &quot; + food.name()); &#125; public void eat(Watermelon watermelon) &#123; System.out.println(&quot;eat watermelon&quot; + watermelon.name()); &#125;&#125; 在这段测试代码中，仍然是 new 出了一个 Watermelon 对象，它的声明类型为 Food。运行 test() 函数，输出如下： 1eat food: watermelon 在面向对象的编程语言中，我们将方法调用称之为分派，这段测试代码运行时，经过了两次分派： 调用重载方法：选择调用 eat(Food food) 还是 eat(Watermelon watermelon) 。虽然这里传入的这个参数实际类型是 Watermelon，但这里会调用 eat(Food food) ，这是由于调用哪个重载方法是在编译期就确定了的，也称之为静态分派。 调用重写方法：选择调用 Food 的 name 方法还是 Watermelon 的 name 方法。这里会根据参数运行时的实际类型，调用 Watermelon 的 name 方法，称之为动态分派。 单分派、双重分派的定义如下： 方法的接收者和方法的参数统称为方法的宗量。 根据分派基于多少个宗量，可以将分派分为单分派和多分派。单分派是指根据一个宗量就可以知道应该调用哪个方法，多分派是指需要根据多个宗量才能确定调用目标。 这段定义可能不太好理解，通俗地讲，单分派和双重分派的区别就是：程序在选择重载方法和重写方法时，如果两种情况都是动态分派的，则称之为双重分派；如果其中一种情况是动态分派，另一种是静态分派，则称之为单分派。 说了这么多，这和我们的访问者模式有什么关系呢？首先我们要知道，架构的演进往往都是由复杂的业务驱动的，当程序需要更好的扩展性，更灵活的架构便诞生出来。 上例中的程序非常简单，但它无法处理某种食物有多个的情形。接下来我们就来修改一下程序，来应对每种食物有多个的场景。 自助餐程序 2.0 版在上面的例子中，为了突出访问者模式的特点，我们将每种食物都简化为了 String 类型，实际开发中，每种食物都应该是一个单独的对象，统一继承自父类 Food： 123public abstract class Food &#123; public abstract String name();&#125; 继承自 Food 的四种食物： 龙虾 123456public class Lobster extends Food &#123; @Override public String name() &#123; return &quot;lobster&quot;; &#125;&#125; 西瓜 123456public class Watermelon extends Food &#123; @Override public String name() &#123; return &quot;watermelon&quot;; &#125;&#125; 牛排 123456public class Steak extends Food &#123; @Override public String name() &#123; return &quot;steak&quot;; &#125;&#125; 香蕉 123456public class Banana extends Food &#123; @Override public String name() &#123; return &quot;banana&quot;; &#125;&#125; 四个子类中分别重写了 name 方法，返回自己的食物名。 IVisitor 接口对应修改为： 123456789public interface IVisitor &#123; void chooseFood(Lobster lobster); void chooseFood(Watermelon watermelon); void chooseFood(Steak steak); void chooseFood(Banana banana);&#125; 每种食物都继承自 Food，所以我们将接口中的方法名都修改为了 chooseFood。 餐厅类修改如下： 1234567891011121314151617181920212223242526class Restaurant &#123; // 准备当天的食物 private List&lt;Food&gt; prepareFoods() &#123; List&lt;Food&gt; foods = new ArrayList&lt;&gt;(); // 简单模拟，每种食物添加 10 份 for (int i = 0; i &lt; 10; i++) &#123; foods.add(new Lobster()); foods.add(new Watermelon()); foods.add(new Steak()); foods.add(new Banana()); &#125; return foods; &#125; // 欢迎顾客来访 public void welcome(IVisitor visitor) &#123; // 获取当天的食物 List&lt;Food&gt; foods = prepareFoods(); // 将食物依次提供给顾客选择 for (Food food : foods) &#123; // 由于单分派机制，此处无法编译通过 visitor.chooseFood(food); &#125; &#125;&#125; 餐厅类中新增了 prepareFoods 方法，在这个方法中，我们简单模拟了准备多个食物的过程，将每种食物添加了 10 份。在接收访问者的 welcome 方法中，遍历所有食物，分别提供给顾客。 看起来很美好，实际上，visitor.chooseFood(food) 这一行是无法编译通过的，原因就在于上一节中提到的单分派机制。虽然每种食物都继承自 Food 类，但由于接口中没有 chooseFood(Food food) 这个重载方法，所以这一行会报错 &lt;font color=red&gt;&quot;Cannot resolve method chooseFood&quot;&lt;/font&gt;。 试想，如果 Java 在调用重载方法时也采用动态分派，也就是根据参数的运行时类型选择对应的重载方法，这里遇到的问题就迎刃而解了，我们的访问者模式讲到这里也就可以结束了。 但由于 Java 是单分派语言，所以我们不得不想办法解决这个 bug，目的就是 使用单分派的 Java 语言模拟出双分派的效果，能够根据运行时的具体类型调用对应的重载方法。 我们很容易想到一种解决方式，采用 instanceOf 判断对象的具体子类型，再将父类强制转换为具体子类型，调用对应的接口方法： 123456// 通过 instanceOf 判断具体子类型，再强制向下转型if (food instanceof Lobster) visitor.chooseFood((Lobster) food);else if (food instanceof Watermelon) visitor.chooseFood((Watermelon) food);else if (food instanceof Steak) visitor.chooseFood((Steak) food);else if (food instanceof Banana) visitor.chooseFood((Banana) food);else throw new IllegalArgumentException(&quot;Unsupported type of food.&quot;); 的确可行，在某些开源代码中便是这么做的，但这种强制转型的方式既冗长又不符合开闭原则，所以《设计模式》一书中给我们推荐了另一种做法。 首先在 Food 类中添加 accept(Visitor visitor) 抽象方法： 123456public abstract class Food &#123; public abstract String name(); // Food 中添加 accept 方法，接收访问者 public abstract void accept(IVisitor visitor);&#125; 在具体子类中，实现此方法： 1234567891011public class Lobster extends Food &#123; @Override public String name() &#123; return &quot;lobster&quot;; &#125; @Override public void accept(IVisitor visitor) &#123; visitor.chooseFood(this); &#125;&#125; 经过这两步修改，餐厅类就可以将接收访问者的方法修改如下： 1234567891011121314151617181920212223242526class Restaurant &#123; // 准备当天的食物 private List&lt;Food&gt; prepareFoods() &#123; List&lt;Food&gt; foods = new ArrayList&lt;&gt;(); // 简单模拟，每种食物添加 10 份 for (int i = 0; i &lt; 10; i++) &#123; foods.add(new Lobster()); foods.add(new Watermelon()); foods.add(new Steak()); foods.add(new Banana()); &#125; return foods; &#125; // 欢迎顾客来访 public void welcome(IVisitor visitor) &#123; // 获取当天的食物 List&lt;Food&gt; foods = prepareFoods(); // 将食物依次提供给顾客选择 for (Food food : foods) &#123; // 由于重写方法是动态分派的，所以这里会调用具体子类的 accept 方法， food.accept(visitor); &#125; &#125;&#125; 经过这三步修改，我们将访问者来访的代码由： 1visitor.chooseFood(food); 改成了 1food.accept(visitor); 这样我们就将重载方法模拟成了动态分派。这里的实现非常巧妙，由于 Java 调用重写方法时是动态分派的，所以 food.accept(visitor) 会调用具体子类的 accept 方法，在具体子类的 accept 方法中，调用 visitor.chooseFood(this)，由于这个 accept 方法是属于具体子类的，所以这里的 this 一定是指具体的子类型，不会产生歧义。 再深入分析一下：之前的代码中，调用 visitor.chooseFood(food) 这行代码时，由于重载方法不知道 Food 的具体子类型导致了编译失败，但实际上这时我们是可以拿到 Food 的具体子类型的。利用重写方法会动态分派的特性，我们在子类的重写方法中去调用这些重载的方法，使得重载方法使用起来也像是动态分派的一样。 顾客 Aurora 类： 12345678910111213141516171819202122public class Aurora implements IVisitor &#123; @Override public void chooseFood(Lobster lobster) &#123; System.out.println(&quot;Aurora gets a &quot; + lobster.name()); &#125; @Override public void chooseFood(Watermelon watermelon) &#123; System.out.println(&quot;Aurora gets a &quot; + watermelon.name()); &#125; @Override public void chooseFood(Steak steak) &#123; System.out.println(&quot;Aurora doesn&#x27;t like &quot; + steak.name()); &#125; @Override public void chooseFood(Banana banana) &#123; System.out.println(&quot;Aurora doesn&#x27;t like &quot; + banana.name()); &#125;&#125; 顾客 Kevin 类： 12345678910111213141516171819202122public class Kevin implements IVisitor &#123; @Override public void chooseFood(Lobster lobster) &#123; System.out.println(&quot;Kevin doesn&#x27;t like &quot; + lobster.name()); &#125; @Override public void chooseFood(Watermelon watermelon) &#123; System.out.println(&quot;Kevin doesn&#x27;t like &quot; + watermelon.name()); &#125; @Override public void chooseFood(Steak steak) &#123; System.out.println(&quot;Kevin gets a &quot; + steak.name()); &#125; @Override public void chooseFood(Banana banana) &#123; System.out.println(&quot;Kevin gets a &quot; + banana.name()); &#125;&#125; 客户端测试： 12345678910public class Client &#123; @Test public void test() &#123; Restaurant restaurant = new Restaurant(); IVisitor Aurora = new Aurora(); IVisitor Kevin = new Kevin(); restaurant.welcome(Aurora); restaurant.welcome(Kevin); &#125;&#125; 运行程序，输出如下： 12345678910Aurora gets a lobsterAurora gets a watermelonAurora doesn&#x27;t like steakAurora doesn&#x27;t like banana... 输出 10 遍Kevin doesn&#x27;t like lobsterKevin doesn&#x27;t like watermelonKevin gets a steakKevin gets a banana... 输出 10 遍 这就是访问者模式，它的核心思想其实非常简单，就是第一小节中体现的将数据的结构与对数据的操作分离。之所以说它复杂，主要在于大多数语言都是单分派语言，所以不得不模拟出一个双重分派，也就是 用重写方法的动态分派特性将重载方法也模拟成动态分派。 但模拟双重分派只是手段，不是目的。有的文章中说模拟双重分派是访问者模式的核心，还有的文章中说双分派语言不需要访问者模式，笔者认为这些说法都有点舍本逐末了。 小结 Summary行为型模式重点关注类与类之间的交互与协作。如同在工作中，每个人的行为都可能影响到其他同事，同时每个人也会受到别人的影响。我们一边接收上级的指令，一边派发任务给下级，在这样的协作中完成一项项伟大的工作。程序在运行时，每个对象都不是孤立的，他们可以通过通信与协作完成种种复杂的功能。 责任链模式：处理职责相同，程度不同的对象，使其在一条链上传递 命令模式：封装“方法调用”，将行为请求者和行为实现者解耦 解释器模式：定义自己的语法规则 迭代器模式：定义 next() 方法和 hasNext() 方法，让外部类使用这两个方法来遍历列表，以达到隐藏列表内部细节的目的 中介者模式：通过引入中介者，将网状耦合结构变成星型结构 备忘录模式：存储对象的状态，以便恢复 观察者模式：处理一对多的依赖关系，被观察的对象改变时，多个观察者都能收到通知 状态模式：关于多态的设计模式，每个状态类处理对象的一种状态 策略模式：殊途同归，用多种方法做同一件事 模板方法模式：关于继承的设计模式，父类是子类的模板 访问者模式：将数据的结构和对数据的操作分离 随堂小测简答题1. 面向对象的特点是什么？可维护、可复用、可扩展、灵活性好。 2. 让面向对象保持结构良好的秘诀是什么？让面向对象保持结构良好的秘诀就是设计模式，面向对象结合设计模式，才能真正体会到程序变得可维护、可复用、可扩展、灵活性好。 3. 六大设计原则是什么？开闭原则、单一职责原则、里氏替换原则、依赖倒置原则、迪米特原则、接口隔离原则。 4. 什么是里氏替换原则？子类应该可以完全替换父类。也就是说在使用继承时，只扩展新功能，而不要破坏父类原有的功能。 5. 工厂模式是用于达到什么目的的设计模式？封装对象。 6. 工厂模式有哪三种？简单工厂模式、工厂方法模式、抽象工厂模式。 7. 工厂方法模式解决了简单工厂模式的哪两个弊端？当生产的产品种类越来越多时，工厂类不会变成超级类。工厂类会越来越多，保持灵活。不会越来越大、变得臃肿。如果苹果的生产过程需要修改时，只需修改苹果工厂。梨子的生产过程需要修改时，只需修改梨子工厂。符合单一职责原则。当需要生产新的产品时，无需更改既有的工厂，只需要添加新的工厂即可。保持了面向对象的可扩展性，符合开闭原则。 8. 抽象工厂模式是什么样的？在创建时指定了具体的工厂类后，在使用时就无需再关心是哪个工厂类，只需要将此工厂当作抽象的 IFactory 接口使用即可。这种经过抽象的工厂方法模式被称作抽象工厂模式。 9. 抽象工厂模式很好的发挥了哪些原则？开闭原则、依赖倒置原则。 10. 抽象工厂模式的缺点是什么？缺点是抽象工厂模式太重了，如果 IFactory 接口需要新增功能，则会影响到所有的具体工厂类。使用抽象工厂模式，替换具体工厂时只需更改一行代码，但要新增抽象方法则需要修改所有的具体工厂类。 11. 抽象工厂模式适用于和不适用于哪些情况？适用于增加同类工厂这样的横向扩展需求，不适合新增功能这样的纵向扩展。 12. 什么时候可以使用单例模式？某个对象全局只需要一个实例时即可。 13. 单例模式的优点是什么？ 它能够避免对象重复创建，节约空间并提升效率 避免由于操作不同实例导致的逻辑错误 14. 单例模式有哪两种实现方式？请分别简单解释。饿汉式和懒汉式。饿汉式指变量在声明时便初始化。懒汉式指先声明一个空变量，需要用时才初始化。 15. 饿汉式的弊端是什么？即使这个单例不需要使用，它也会在类加载之后立即创建出来，占用一块内存，并增加类初始化时间。 16. 静态内部类方式是怎么保证线程安全的？Java 虚拟机的设计是非常稳定的，早已经考虑到了多线程并发执行的情况。虚拟机在加载类的 clinit 方法时，会保证 clinit 在多线程中被正确的加锁、同步。即使有多个线程同时去初始化一个类，一次也只有一个线程可以执行 clinit 方法，其他线程都需要阻塞等待，从而保证了线程安全。 17. 建造者模式用于什么时候？创建过程稳定，但配置多变的对象。 18. 建造者模式是什么意思？将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示。 19. 现在建造者模式主要用来做什么？通过链式调用生成不同的配置。 20. 使用建造者模式的好处是什么？不用担心忘了指定某个配置，保证了构建过程是稳定的。 21. 原型模式是什么？用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。 22. 适配器模式适用于什么结构？有相关性但不兼容的结构。 23. 什么是适配？什么是适配器？源接口通过一个中间件转换后才可以适用于目标接口，这个转换过程就是适配，这个中间件就称之为适配器。 24. 需要绘制矩形、圆形、三角形这三种图案，按照桥接模式的思想会怎么做？将形状和颜色分离，根据需要对形状和颜色进行组合。 25. 什么是桥接模式？将抽象部分与它的实现部分分离，使它们都可以独立地变化。它是一种对象结构型模式，又称为柄体模式或接口模式。 26. 组合模式适用于什么结构？组合模式用于整体与部分的结构，当整体与部分有相似的结构，在操作时可以被一致对待时，就可以使用组合模式。 27. 组合模式最主要的功能是什么？组合模式最主要的功能是让用户可以一致对待整体和部分结构，将两者都作为一个相同的组件。 28. 什么是组合模式中的透明方式？违背了接口隔离原则的组合模式。 29. 什么是安全方式？在 Component 中不声明 add 和 remove 等管理子对象的方法，这样叶节点就无需实现它，只需在枝节点中实现管理子对象的方法即可。 30. 什么是透明装饰模式？装饰器仅用于增强功能，并不会改变 Me 原有的功能，这种装饰模式称之为透明装饰模式。 31. 装饰模式的缺点是什么？容易造成程序中有大量相似的类。 32. 动态代理相对于静态代理的优势是什么？节省代码量。 33. 简述责任链模式的有优点有哪些？ 降低了对象之间的耦合度。 扩展性强，满足开闭原则。可以根据需要增加新的请求处理类。 灵活性强。可以动态地改变链内的成员或者改变链的次序来适应流程的变化。 简化了对象之间的连接。每个对象只需保持一个指向其后继者的引用。 34. 什么是宏命令？宏命令是将多个命令合并起来组成的命令。 35. 请写出解释器模式的一个常见应用。在我们平时匹配字符串时，用到的正则表达式就是一个解释器。 36. 怎样使得外部类只能读取此列表中的数据，无法修改其中的任何数据，保证其安全性？ 提供一个 String next() 方法，使得外部类可以按照次序，一条一条的读取数据； 提供一个 boolean hasNext() 方法，告知外部类是否还有下一条数据。 附录原文链接：https://leetcode.cn/leetbook/read/design-patterns/nw26e3/","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"深入浅出设计模式","slug":"深入浅出设计模式","permalink":"https://tianxiafeiyu.github.io/tags/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"cpu加压脚本","slug":"技术开发/grocery/cpu加压脚本","date":"2022-12-30T23:10:53.000Z","updated":"2022-12-30T21:36:16.000Z","comments":true,"path":"2022/12/30/技术开发/grocery/cpu加压脚本/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/30/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/cpu%E5%8A%A0%E5%8E%8B%E8%84%9A%E6%9C%AC/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#! /bin/bash############################################################## this scripts for cpu usage testing# eg. cpu_test.sh start 50 #start testing use 50% cpu# eg. cpu_test.sh stop #stop testing#############################################################op=$1num=$2mkcsp()&#123; touch ./killcpu.c echo &#x27;int main()&#123;while(1);return 0;&#125;&#x27; &gt; killcpu.c gcc -o out killcpu.c chmod +x ./out&#125;start()&#123;cpu_num=$(cat /proc/cpuinfo | grep &quot;physical id&quot; | wc -l)for i in `seq 1 $(expr $num \\* $cpu_num / 100)` do ./out &amp; done&#125;stop()&#123;for i in $( ps -ef | grep &#x27;./out&#x27;| grep -v grep | awk &#x27;&#123;print $2&#125;&#x27;) do kill -9 $i donerm -rf killcpu.c out&#125;main()&#123;if [ $op == &quot;start&quot; ]then mkcspfi $op&#125;main","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"cpu加压脚本","slug":"cpu加压脚本","permalink":"https://tianxiafeiyu.github.io/tags/cpu%E5%8A%A0%E5%8E%8B%E8%84%9A%E6%9C%AC/"}]},{"title":"Chrome年度热门扩展程序","slug":"技术开发/grocery/Chrome年度热门 扩展程序","date":"2022-12-16T15:18:00.000Z","updated":"2023-06-16T09:34:49.522Z","comments":true,"path":"2022/12/16/技术开发/grocery/Chrome年度热门 扩展程序/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/16/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/Chrome%E5%B9%B4%E5%BA%A6%E7%83%AD%E9%97%A8%20%E6%89%A9%E5%B1%95%E7%A8%8B%E5%BA%8F/","excerpt":"","text":"Google 官方统计的年度榜单，多看涨姿势~~ 2022：https://www.oschina.net/news/221758/chrome-extension-favorite-2022 2021：https://www.oschina.net/news/172732/chrome-extension-favorite-2021","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[]},{"title":"Prometheus监控kubernetes方案及实现","slug":"技术开发/grocery/Prometheus监控kubernetes方案及实现","date":"2022-12-16T00:43:25.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/16/技术开发/grocery/Prometheus监控kubernetes方案及实现/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/16/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/Prometheus%E7%9B%91%E6%8E%A7kubernetes%E6%96%B9%E6%A1%88%E5%8F%8A%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"promtheus监控kubernetesKubernetes监控策略Kubernetes作为开源的容器编排工具，为用户提供了一个可以统一调度，统一管理的云操作系统。其解决如用户应用程序如何运行的问题。而一旦在生产环境中大量基于Kubernetes部署和管理应用程序后，作为系统管理员，还需要充分了解应用程序以及Kubernetes集群服务运行质量如何，通过对应用以及集群运行状态数据的收集和分析，持续优化和改进，从而提供一个安全可靠的生产运行环境。这一小节中我们将讨论当使用Kubernetes时的监控策略该如何设计。 从物理结构上讲Kubernetes主要用于整合和管理底层的基础设施资源，对外提供应用容器的自动化部署和管理能力，这些基础设施可能是物理机、虚拟机、云主机等等。因此，基础资源的使用直接影响当前集群的容量和应用的状态。在这部分，我们需要关注集群中各个节点的主机负载，CPU使用率、内存使用率、存储空间以及网络吞吐等监控指标。 从自身架构上讲，kube-apiserver是Kubernetes提供所有服务的入口，无论是外部的客户端还是集群内部的组件都直接与kube-apiserver进行通讯。因此，kube-apiserver的并发和吞吐量直接决定了集群性能的好坏。其次，对于外部用户而言，Kubernetes是否能够快速的完成pod的调度以及启动，是影响其使用体验的关键因素。而这个过程主要由kube-scheduler负责完成调度工作，而kubelet完成pod的创建和启动工作。因此在Kubernetes集群本身我们需要评价其自身的服务质量，主要关注在Kubernetes的API响应时间，以及Pod的启动时间等指标上。 Kubernetes的最终目标还是需要为业务服务，因此我们还需要能够监控应用容器的资源使用情况。对于内置了对Prometheus支持的应用程序，也要支持从这些应用程序中采集内部的监控指标。最后，结合黑盒监控模式，对集群中部署的服务进行探测，从而当应用发生故障后，能够快速处理和恢复。 在Kubernetes集群上也需要监控Pod、DaemonSet、Deployment、Job、Cronjob等资源对象的状态，这样可以反映出使用这些资源部署的应用状态。但通过查看api-server或者cAdvisor的指标，并没有具体的各种资源对象的状态指标，对于Prometheus来说，当然需要引入新的exporter来暴露这些指标，Kubernetes提供了名为kube-state-metrics的项目（项目地址：https://github.com/kubernetes/kube-state-metrics ）。 综上所述，我们需要综合使用白盒监控和黑盒监控模式，建立从基础设施，Kubernetes核心组件，应用容器等全面的监控体系。 在白盒监控层面我们需要关注： 基础设施层（Node）：为整个集群和应用提供运行时资源，需要通过各节点的kubelet获取节点的基本状态，同时通过在节点上部署Node Exporter获取节点的资源使用情况； 容器基础设施（Container）：为应用提供运行时环境，Kubelet内置了对cAdvisor的支持，用户可以直接通过Kubelet组件获取给节点上容器相关监控指标； 用户应用（Pod）：Pod中会包含一组容器，它们一起工作，并且对外提供一个（或者一组）功能。如果用户部署的应用程序内置了对Prometheus的支持，那么我们还应该采集这些Pod暴露的监控指标； Kubernetes组件：获取并监控Kubernetes核心组件的运行状态，确保平台自身的稳定运行。 Kubernetes资源对象：监控Pod、DaemonSet、Deployment、Job、Cronjob等资源对象的状态，反映出使用这些资源部署的应用状态 而在黑盒监控层面，则主要需要关注以下： 内部服务负载均衡（Service）：在集群内，通过Service在集群暴露应用功能，集群内应用和应用之间访问时提供内部的负载均衡。通过Balckbox Exporter探测Service的可用性，确保当Service不可用时能够快速得到告警通知； 外部访问入口（Ingress）：通过Ingress提供集群外的访问入口，从而可以使外部客户端能够访问到部署在Kubernetes集群内的服务。因此也需要通过Blackbox Exporter对Ingress的可用性进行探测，确保外部用户能够正常访问集群内的功能； 下表中，梳理了监控Kubernetes集群监控的各个维度以及策略： 目标 描述 服务发现方式 监控方法 数据源 集群外监控 api-server 获取API Server组件的访问地址，并从中获取Kubernetes集群相关的运行监控指标 endpoints 白盒监控 api server ✓ kube-schedule kube-schedule的metrics接口 （Scheduler服务端口默认为10251） - 白盒监控 kube-schedule ✓ control-manager control-manager的metrics接口（ControllerManager服务端口默认为10252） - 白盒监控 control-manager ✓ kubelet 从集群各节点kubelet组件中获取节点kubelet的基本运行状态的监控指标 node 白盒监控 kubelet ✓ kube-proxy kube-proxy的metrics接口（ControllerManager服务端口默认为10252） - 白盒监控 kube-proxy ✓ kube-dns 从集群各节点获取kube-dns的基本运行状态的监控指标 - 白盒监控 kube-dns ✓ cAdvisor 从集群各节点kubelet内置的cAdvisor中获取，节点中运行的容器的监控指标 node 白盒监控 kubelet ✓ node 从部署到各个节点的Node Exporter中采集主机资源相关的运行资源 node 白盒监控 node exporter ✓ pod 对于内置了Promthues支持的应用，需要从Pod实例中采集其自定义监控指标 pod 白盒监控 custom pod ✓ 资源对象 监控Pod、DaemonSet、Deployment、Job、Cronjob等资源对象的状态，反映出使用这些资源部署的应用状态 endpoints 白盒监控 kube-state-metrics ✓ service 获取集群中Service的访问地址，并通过Blackbox Exporter获取网络探测指标 service 黑盒监控 blackbox exporter ✓ ingress 获取集群中Ingress的访问信息，并通过Blackbox Exporter获取网络探测指标 ingress 黑盒监控 blackbox exporter ✓ kubernetes监控实现使用prometheus监控kubernetes，基本上有两个场景： prometheus部署在k8s集群内部； prometheus部署在k8s集群外部。 两种场景大同小异，原理上都是基于kubernetes服务发现，promtheus自身已经实现了基于kubernetes的服务发现。但目前prometheus部署在k8s集群外部对于service和ingress的监控暂无合适方案 prometheus部署在k8s集群外部监控实现Kubernetes访问授权为了能够让Prometheus能够访问收到认证保护的Kubernetes API，我们首先需要做的是，对Prometheus进行访问授权。在Kubernetes中主要使用基于角色的访问控制模型(Role-Based Access Control)，用于管理Kubernetes下资源访问权限。首先我们需要在Kubernetes下定义角色（ClusterRole），并且为该角色赋予响应的访问权限。同时创建Prometheus所使用的账号（ServiceAccount），最后则是将该账号与角色进行绑定（ClusterRoleBinding）。这些所有的操作在Kubernetes同样被视为是一系列的资源，可以通过YAML文件进行描述并创建，这里创建prometheus-rbac-setup.yml文件，并写入以下内容： 1234567891011121314151617181920212223242526272829303132333435363738394041apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRolemetadata: name: prometheusrules:- apiGroups: [&quot;&quot;] resources: - nodes - nodes/proxy - services - services/proxy - endpoints - pods - pods/proxy verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]- apiGroups: - extensions resources: - ingresses verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]- nonResourceURLs: [&quot;/metrics&quot;] verbs: [&quot;get&quot;]---apiVersion: v1kind: ServiceAccountmetadata: name: prometheus namespace: default---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: prometheusroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: prometheussubjects:- kind: ServiceAccount name: prometheus namespace: default 通过kubectl命令创建RBAC对应的各个资源： 1234$ kubectl create -f prometheus-rbac-setup.ymlclusterrole &quot;prometheus&quot; createdserviceaccount &quot;prometheus&quot; createdclusterrolebinding &quot;prometheus&quot; created 外部的prometheus需要获取Bearer Token来访问kubernetes api： 12$ SECRET=$(kubectl get serviceaccount prometheus -ojsonpath=&#x27;&#123;.secrets[0].name&#125;&#x27;)$ kubectl get secret $&#123;SECRET&#125; -o jsonpath=&quot;&#123;.data.token&#125;&quot; | base64 -d &gt; /tmp/prometheus-sa-token 从kube-apiserver获取集群运行监控指标kube-apiserver扮演了整个Kubernetes集群管理的入口的角色，负责对外暴露Kubernetes API。kube-apiserver组件一般是独立部署在集群外的，为了能够让部署在集群内的应用（kubernetes插件或者用户应用）能够与kube-apiserver交互，Kubernetes会默认在命名空间下创建一个名为kubernetes的服务，如下所示： 123$ kubectl get svc kubernetes -o wideNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTORkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 166d &lt;none&gt; 而该kubernetes服务代理的后端实际地址通过endpoints进行维护，如下所示： 123$ kubectl get endpoints kubernetesNAME ENDPOINTS AGEkubernetes 192.168.1.4:6443 166d 通过这种方式集群内的应用或者系统主机就可以通过集群内部的DNS域名kubernetes.default.svc访问到部署外部的kube-apiserver实例。 因此，如果我们想要监控kube-apiserver相关的指标，只需要通过endpoints资源找到kubernetes对应的所有后端地址即可。 如下所示，创建监控任务kubernetes-apiservers，这里指定了服务发现模式为endpoints。Promtheus会查找当前集群中所有的endpoints配置，并通过relabel进行判断是否为apiserver对应的访问地址： 123456789101112131415- job_name: &#x27;kubernetes-apiservers&#x27; scheme: https tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token kubernetes_sd_configs: - role: endpoints api_server: https://192.168.1.4:6443 bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token tls_config: insecure_skip_verify: true relabel_configs: - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name] action: keep regex: default;kubernetes;https 在relabel_configs配置中用于判断当前endpoints是否为kube-apiserver对用的地址。重新加载配置文件，重建Promthues实例，得到以下结果。 监控kube-schedule、kube-control-manager、kube-proxy在prometheus里手动添加kubernetes-schedule、kubernetes-control-manager组件的连接配置，非证书连接！以下组件的配置，还不需要使用证书连接，直接ip+port就可以，默认路径就是&#x2F;metrics确保以下四个组件的metrcis数据可以通过下面方式正常获取。 schedule的metrics接口 （Scheduler服务端口默认为10251） 1234- job_name: &#x27;kubernetes-schedule&#x27; #任务名 scrape_interval: 5s #本任务的抓取间隔，覆盖全局配置 static_configs: - targets: [&#x27;192.168.1.4:10251&#x27;] control-manager的metrics接口（ControllerManager服务端口默认为10252） 1234- job_name: &#x27;kubernetes-control-manager&#x27; scrape_interval: 5s static_configs: - targets: [&#x27;192.168.1.4:10252&#x27;] kube-proxy的metrics接口(kube-proxy服务端口默认为10249） 1234- job_name: &#x27;kubernetes-proxy&#x27; scrape_interval: 5s static_configs: - targets: [&#x27;192.168.1.4:10249&#x27;, &#x27;192.168.1.5：10249&#x27;, &#x27;192.168.1.6:10249&#x27; ] 当然，还可用服务发现的方式监控，具体如下：创建service： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263apiVersion: v1kind: Servicemetadata: namespace: kube-system name: kube-scheduler-prometheus-discovery labels: k8s-app: kube-scheduler annotations: prometheus.io/scrape: &#x27;true&#x27;spec: selector: component: kube-scheduler type: ClusterIP clusterIP: None ports: - name: http-metrics port: 10251 targetPort: 10251 protocol: TCP ---apiVersion: v1kind: Servicemetadata: namespace: kube-system name: kube-controller-manager-prometheus-discovery labels: k8s-app: kube-controller-manager annotations: prometheus.io/scrape: &#x27;true&#x27;spec: selector: component: kube-controller-manager type: ClusterIP clusterIP: None ports: - name: http-metrics port: 10252 targetPort: 10252 protocol: TCP ---apiVersion: v1kind: Servicemetadata: namespace: kube-system name: kube-proxy-prometheus-discovery labels: k8s-app: kube-proxy annotations: prometheus.io/scrape: &#x27;true&#x27;spec: selector: k8s-app: kube-proxy type: NodePort ports: - name: http-metrics port: 10249 targetPort: 10249 nodePort: 30025 protocol: TCP 创建监控任务： 12345678910111213141516171819202122232425262728293031323334353637383940414243- job_name: &#x27;kube-scheduler-prometheus-discovery&#x27; kubernetes_sd_configs: - role: endpoints api_server: https://192.168.1.4:6443 tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token relabel_configs: # 选择哪些label - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape, __meta_kubernetes_namespace, __meta_kubernetes_service_name] # 上述选择的label的值需要与下述对应 regex: true;kube-system;kube-scheduler-prometheus-discovery # 含有符合regex的source_label的endpoints进行保留 action: keep- job_name: &#x27;kube-controller-manager-discovery&#x27; kubernetes_sd_configs: - role: endpoints api_server: https://192.168.1.4:6443 tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token relabel_configs: # 选择哪些label - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape, __meta_kubernetes_namespace, __meta_kubernetes_service_name] # 上述选择的label的值需要与下述对应 regex: true;kube-system;kube-controller-manager-prometheus-discovery # 含有符合regex的source_label的endpoints进行保留 action: keep- job_name: &#x27;kube-proxy-prometheus-discovery&#x27; kubernetes_sd_configs: - role: endpoints api_server: https://192.168.1.4:6443 tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token relabel_configs: # 选择哪些label - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape, __meta_kubernetes_namespace, __meta_kubernetes_service_name] # 上述选择的label的值需要与下述对应 regex: true;kube-system;kube-proxy-prometheus-discovery # 含有符合regex的source_label的endpoints进行保留 action: keep 从Kubelet获取节点运行状态Kubelet组件运行在Kubernetes集群的各个节点中，其负责维护和管理节点上Pod的运行状态。kubelet组件的正常运行直接关系到该节点是否能够正常的被Kubernetes集群正常使用。 基于Node模式，Prometheus会自动发现Kubernetes中所有Node节点的信息并作为监控的目标Target。 而这些Target的访问地址实际上就是Kubelet的访问地址，并且Kubelet实际上直接内置了对Promtheus的支持。 实际探索过程中，直接从kuberlet获取数据有报错。这里采用第二种方式：不直接通过kubelet的metrics服务采集监控数据，而通过Kubernetes的api-server提供的代理API访问各个节点中kubelet的metrics服务，如下所示： 修改prometheus.yml配置文件，并添加以下采集任务配置： 1234567891011121314151617181920- job_name: &#x27;kubernetes-kubelet&#x27; scheme: https tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token kubernetes_sd_configs: - role: node api_server: https://192.168.1.4:6443 bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token tls_config: insecure_skip_verify: true relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) - target_label: __address__ replacement: 192.168.1.4:6443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/$&#123;1&#125;/proxy/metrics 通过relabeling，将从Kubernetes获取到的默认地址__address__替换为192.168.1.4:6443。同时将__metrics_path__替换为api-server的代理地址&#x2F;api&#x2F;v1&#x2F;nodes&#x2F;${1}&#x2F;proxy&#x2F;metrics。 监控kube-dnskube-dns会在9153端口暴露采集指标，通过服务发现可以实现对kube-dns的监控 1234567891011121314151617181920212223242526272829303132- job_name: &#x27;kube-dns-discovery&#x27; tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token scheme: https kubernetes_sd_configs: - role: endpoints api_server: https://192.168.1.4:6443 tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token relabel_configs: - source_labels: [__meta_kubernetes_endpoint_port_name] separator: ; regex: metrics replacement: $1 action: keep - source_labels: [__address__] action: replace target_label: instance - target_label: __address__ replacement: 192.168.1.4:6443 - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_pod_name, __meta_kubernetes_pod_container_port_number] regex: ([^;]+);([^;]+);([^;]+) target_label: __metrics_path__ replacement: /api/v1/namespaces/$&#123;1&#125;/pods/$&#123;2&#125;:$&#123;3&#125;/proxy/metrics # 选择哪些label - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name] # 上述选择的label的值需要与下述对应 regex: kube-system;kube-dns # 含有符合regex的source_label的endpoints进行保留 action: keep 从cadvisor获取容器的监控数据cAdvisor可以对节点机器上的资源及容器进行实时监控和性能数据采集，包括CPU使用情况、内存使用情况、网络吞吐量及文件系统使用情况。Kubernetes内置对cAdvisor支持。外部的Prometheus可以通过Api Server的代理访问到cAdvisor： 1234567891011121314151617181920- job_name: &#x27;kubernetes-cadvisor&#x27; scheme: https tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token kubernetes_sd_configs: - role: node api_server: https://192.168.1.4:6443 bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token tls_config: insecure_skip_verify: true relabel_configs: - target_label: __address__ replacement: 192.168.1.4:6443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/$&#123;1&#125;/proxy/metrics/cadvisor - action: labelmap regex: __meta_kubernetes_node_label_(.+) 使用NodeExporter监控集群资源使用情况为了能够采集集群中各个节点的资源使用情况，我们需要在各节点中部署一个Node Exporter实例。在本章的“部署Prometheus”小节，我们使用了Kubernetes内置的控制器之一Deployment。Deployment能够确保Prometheus的Pod能够按照预期的状态在集群中运行，而Pod实例可能随机运行在任意节点上。而与Prometheus的部署不同的是，对于Node Exporter而言每个节点只需要运行一个唯一的实例，此时，就需要使用Kubernetes的另外一种控制器Daemonset。顾名思义，Daemonset的管理方式类似于操作系统中的守护进程。Daemonset会确保在集群中所有（也可以指定）节点上运行一个唯一的Pod实例。 创建node-exporter-daemonset.yml文件，并写入以下内容： 1234567891011121314151617181920212223242526272829303132apiVersion: apps/v1kind: DaemonSetmetadata: name: node-exporterspec: selector: matchLabels: app: node-exporter template: metadata: annotations: prometheus.io/scrape: &#x27;true&#x27; prometheus.io/port: &#x27;9100&#x27; prometheus.io/path: &#x27;metrics&#x27; labels: app: node-exporter name: node-exporter spec: tolerations: - key: &quot;node-role.kubernetes.io/master&quot; operator: &quot;Equal&quot; effect: &quot;NoSchedule&quot; containers: - image: prom/node-exporter imagePullPolicy: IfNotPresent name: node-exporter ports: - containerPort: 9100 hostPort: 9100 name: scrape hostNetwork: true hostPID: true 由于Node Exporter需要能够访问宿主机，因此这里指定了hostNetwork和hostPID，让Pod实例能够以主机网络以及系统进程的形式运行。同时YAML文件中也创建了NodeExporter相应的Service。这样通过Service就可以访问到对应的NodeExporter实例。 123$ kubectl create -f node-exporter-daemonset.ymlservice &quot;node-exporter&quot; createddaemonset &quot;node-exporter&quot; created 目前为止，通过Daemonset的形式将Node Exporter部署到了集群中的各个节点中。接下来，我们只需要通过Prometheus的pod服务发现模式，找到当前集群中部署的Node Exporter实例即可。 需要注意的是，由于Kubernetes中并非所有的Pod都提供了对Prometheus的支持，有些可能只是一些简单的用户应用，为了区分哪些Pod实例是可以供Prometheus进行采集的，这里我们为Node Exporter添加了注解： 1prometheus.io/scrape: &#x27;true&#x27; 由于Kubernetes中Pod可能会包含多个容器，还需要用户通过注解指定用户提供监控指标的采集端口： 1prometheus.io/port: &#x27;9100&#x27; 而有些情况下，Pod中的容器可能并没有使用默认的&#x2F;metrics作为监控采集路径，因此还需要支持用户指定采集路径： 1prometheus.io/path: &#x27;metrics&#x27; 为Prometheus创建监控采集任务kubernetes-nodes，如下所示： 123456789101112131415161718192021222324252627282930- job_name: &#x27;kubernetes-nodes&#x27; kubernetes_sd_configs: - role: pod api_server: https://192.168.1.4:6443 bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token tls_config: insecure_skip_verify: true relabel_configs: - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape] action: keep regex: true - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path] action: replace target_label: __metrics_path__ regex: (.+) - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port] action: replace regex: ([^:]+)(?::\\d+)?;(\\d+) replacement: $1:$2 target_label: __address__ - action: labelmap regex: __meta_kubernetes_pod_label_(.+) - source_labels: [__meta_kubernetes_namespace] action: replace target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_pod_name] action: replace target_label: kubernetes_pod_name - source_labels: [&quot;__mkubernetes_pod_node_name&quot;] target_label: &quot;node_name&quot; 使用kube-state-metrics监控资源对象通过kube-state-metrics可以获取以下指标 CronJob Metrics DaemonSet Metrics Deployment Metrics Job Metrics LimitRange Metrics Node Metrics PersistentVolume Metrics PersistentVolumeClaim Metrics Pod Metrics ReplicaSet Metrics ReplicationController Metrics ResourceQuota Metrics Service Metrics StatefulSet Metrics Namespace Metrics Horizontal Pod Autoscaler Metrics Endpoint Metrics Kubernetes版本支持kube-state-metrics用于client-go与Kubernetes集群通信。支持的Kubernetes集群版本由决定client-go。可以在此处找到client-go和Kubernetes集群的兼容性矩阵 。 kube-state-metrics Kubernetes 1.12 Kubernetes 1.13 Kubernetes 1.14 Kubernetes 1.15 Kubernetes 1.16 Kubernetes 1.17 v1.5.0 ✓ - - - - - v1.6.0 ✓ ✓ - - - - v1.7.2 ✓ ✓ ✓ - - - v1.8.0 ✓ ✓ ✓ ✓ - - v1.9.4 ✓ ✓ ✓ ✓ ✓ - master ✓ ✓ ✓ ✓ ✓ ✓ 部署kube-state-metrics123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: labels: app.kubernetes.io/name: kube-state-metrics app.kubernetes.io/version: v1.9.4 name: kube-state-metricsrules:- apiGroups: - &quot;&quot; resources: - configmaps - secrets - nodes - nodes/proxy - pods - pods/proxy - services/proxy - services - resourcequotas - replicationcontrollers - limitranges - persistentvolumeclaims - persistentvolumes - namespaces - endpoints verbs: - list - watch - get- apiGroups: - extensions resources: - daemonsets - deployments - replicasets - ingresses verbs: - list - watch- apiGroups: - apps resources: - statefulsets - daemonsets - deployments - replicasets verbs: - list - watch- apiGroups: - batch resources: - cronjobs - jobs verbs: - list - watch- apiGroups: - autoscaling resources: - horizontalpodautoscalers verbs: - list - watch- apiGroups: - authentication.k8s.io resources: - tokenreviews verbs: - create- apiGroups: - authorization.k8s.io resources: - subjectaccessreviews verbs: - create- apiGroups: - policy resources: - poddisruptionbudgets verbs: - list - watch- apiGroups: - certificates.k8s.io resources: - certificatesigningrequests verbs: - list - watch- apiGroups: - storage.k8s.io resources: - storageclasses - volumeattachments verbs: - list - watch- apiGroups: - admissionregistration.k8s.io resources: - mutatingwebhookconfigurations - validatingwebhookconfigurations verbs: - list - watch- apiGroups: - networking.k8s.io resources: - networkpolicies verbs: - list - watch---apiVersion: v1kind: ServiceAccountmetadata: labels: app.kubernetes.io/name: kube-state-metrics app.kubernetes.io/version: v1.9.4 name: kube-state-metrics namespace: kube-system ---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: labels: app.kubernetes.io/name: kube-state-metrics app.kubernetes.io/version: v1.9.4 name: kube-state-metricsroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: kube-state-metricssubjects:- kind: ServiceAccount name: kube-state-metrics namespace: kube-system---apiVersion: apps/v1kind: Deploymentmetadata: labels: app.kubernetes.io/name: kube-state-metrics app.kubernetes.io/version: v1.9.4 name: kube-state-metrics namespace: kube-systemspec: replicas: 1 selector: matchLabels: app.kubernetes.io/name: kube-state-metrics template: metadata: labels: app.kubernetes.io/name: kube-state-metrics app.kubernetes.io/version: v1.9.4 spec: containers: - image: quay.io/coreos/kube-state-metrics:v1.9.4 livenessProbe: httpGet: path: /healthz port: 8080 initialDelaySeconds: 5 timeoutSeconds: 5 name: kube-state-metrics ports: - containerPort: 8080 name: http-metrics - containerPort: 8081 name: telemetry readinessProbe: httpGet: path: / port: 8081 initialDelaySeconds: 5 timeoutSeconds: 5 nodeSelector: kubernetes.io/os: linux serviceAccountName: kube-state-metrics---apiVersion: v1kind: Servicemetadata: labels: app.kubernetes.io/name: kube-state-metrics app.kubernetes.io/version: v1.9.4 name: kube-state-metrics namespace: kube-systemspec: clusterIP: None ports: - name: http-metrics port: 8080 targetPort: http-metrics - name: telemetry port: 8081 targetPort: telemetry selector: app.kubernetes.io/name: kube-state-metrics prometheus创建kube-state-netrics监控任务通过kubernetes服务发现，监控kube-state-metrics 1234567891011121314151617181920212223242526272829303132- job_name: &#x27;kubernetes-kube-state-metrics&#x27; tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token scheme: https kubernetes_sd_configs: - role: endpoints api_server: https://192.168.1.4:6443 tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token relabel_configs: - source_labels: [ __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name] action: keep regex: kube-state-metrics;http-metrics - source_labels: [__address__] action: replace target_label: instance - target_label: __address__ replacement: 192.168.1.4:6443 - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_pod_name, __meta_kubernetes_pod_container_port_number] regex: ([^;]+);([^;]+);([^;]+) target_label: __metrics_path__ replacement: /api/v1/namespaces/$&#123;1&#125;/pods/http:$&#123;2&#125;:$&#123;3&#125;/proxy/metrics - action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: [__meta_kubernetes_namespace] action: replace target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_service_name] action: replace target_label: kubernetes_name 内置对prometheus支持的应用监控对于内置了Promthues支持的应用，需要从Pod实例中采集其自定义监控指标。在这需要对应用添加以annotations： prometheus.io&#x2F;scrape: ‘true’ prometheus.io&#x2F;port: ‘your_port’ prometheus.io&#x2F;path: ‘your_metrics_path’ 通过这些标签可以筛选掉无用的应用。 添加promtheus任务 1234567891011121314151617181920212223242526272829303132- job_name: &#x27;kubernetes-kube-service&#x27; tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token scheme: https kubernetes_sd_configs: - role: endpoints api_server: https://192.168.1.4:6443 tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token relabel_configs: - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape] action: keep regex: true - source_labels: [__address__] action: replace target_label: instance - target_label: __address__ replacement: 192.168.1.4:6443 - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_pod_name, __meta_kubernetes_pod_container_port_number, __meta_kubernetes_service_annotation_prometheus_io_path] regex: ([^;]+);([^;]+);([^;]+);([^;]+) target_label: __metrics_path__ replacement: /api/v1/namespaces/$&#123;1&#125;/pods/http:$&#123;2&#125;:$&#123;3&#125;/proxy/$&#123;4&#125; - action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: [__meta_kubernetes_namespace] action: replace target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_service_name] action: replace target_label: kubernetes_name 对Ingress和Service进行网络探测为了能够对Ingress和Service进行探测，我们需要在集群部署Blackbox Exporter实例。 如下所示，创建blackbox-exporter.yaml用于描述部署相关的内容 1234567891011121314151617181920212223242526272829303132333435apiVersion: v1kind: Servicemetadata: labels: app: blackbox-exporter name: blackbox-exporterspec: ports: - name: blackbox port: 9115 protocol: TCP selector: app: blackbox-exporter type: ClusterIP---apiVersion: apps/v1kind: Deploymentmetadata: labels: app: blackbox-exporter name: blackbox-exporterspec: replicas: 1 selector: matchLabels: app: blackbox-exporter template: metadata: labels: app: blackbox-exporter spec: containers: - image: prom/blackbox-exporter imagePullPolicy: IfNotPresent name: blackbox-exporter 为了能够让Prometheus能够自动的对Service进行探测，我们需要通过服务发现自动找到所有的Service信息。 如下所示，在Prometheus的配置文件中添加名为kubernetes-services的监控采集任务： 12345678910111213141516171819202122232425262728293031- job_name: &#x27;kubernetes-services&#x27; tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token scheme: https params: module: [http_2xx] kubernetes_sd_configs: - role: service api_server: https://192.168.1.4:6443 tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token relabel_configs: - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe] action: keep regex: true - source_labels: [__address__] target_label: __param_target - target_label: __address__ replacement: 192.168.1.4:6443 - target_label: __metrics_path__ replacement: api/v1/namespaces/default/services/blackbox-exporter:9115/proxy/probe - source_labels: [__param_target] target_label: instance - action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: [__meta_kubernetes_namespace] target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_service_name] target_label: kubernetes_name 在该任务配置中，通过指定kubernetes_sd_config的role为service指定服务发现模式： 123456kubernetes_sd_configs: - role: service api_server: https://192.168.1.4:6443 tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token 为了区分集群中需要进行探测的Service实例，我们通过标签‘prometheus.io&#x2F;probe: true’进行判断，从而过滤出需要探测的所有Service实例： 123- source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe] action: keep regex: true 为了能够在外部访问k8s集群内部的blackbox，这里使用的Kubernetes proxy api 1234- target_label: __address__ replacement: 192.168.1.4:6443- target_label: __metrics_path__ replacement: api/v1/namespaces/default/services/blackbox-exporter:9115/proxy/probe 对于Ingress而言，也是一个相对类似的过程，这里给出对Ingress探测的Promthues任务配置作为参考： 123456789101112131415161718192021222324252627282930313233- job_name: &#x27;kubernetes-ingresses&#x27; tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token scheme: https params: module: [http_2xx] kubernetes_sd_configs: - role: ingress api_server: https://192.168.1.4:6443 tls_config: insecure_skip_verify: true bearer_token_file: C:/Users/Administrator/Desktop/prometheus-token relabel_configs: - source_labels: [__meta_kubernetes_ingress_annotation_prometheus_io_probe] action: keep regex: true - source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path] regex: (.+);(.+);(.+) replacement: $&#123;1&#125;://$&#123;2&#125;$&#123;3&#125; target_label: __param_target - target_label: __address__ replacement: 192.168.1.4:6443 - target_label: __metrics_path__ replacement: api/v1/namespaces/default/services/blackbox-exporter:9115/proxy/probe - source_labels: [__param_target] target_label: instance - action: labelmap regex: __meta_kubernetes_ingress_label_(.+) - source_labels: [__meta_kubernetes_namespace] target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_ingress_name] target_label: kubernetes_name prometheus部署在k8s集群内部监控实现prometheus部署在k8s集群内部监控k8s和部署在外部监控的原理是一样的，唯一的区别： 集群内部，可以通过集群的DNS访问监控对象，不需要通过api server代理。 服务发现时，不需要制定api server 的地址。 具体过程如下： 1.授权 12345678910111213141516171819202122232425262728293031323334353637383940414243apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRolemetadata: name: prometheusrules:- apiGroups: [&quot;&quot;] resources: - nodes - nodes/proxy - pods - proxy - pods/proxy - services - services/proxy - endpoints - pods verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]- apiGroups: - extensions resources: - ingresses verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]- nonResourceURLs: [&quot;/metrics&quot;] verbs: [&quot;get&quot;]---apiVersion: v1kind: ServiceAccountmetadata: name: prometheus namespace: default---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: prometheusroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: prometheussubjects:- kind: ServiceAccount name: prometheus namespace: default 2.将prometheus的配置放在configmap中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211apiVersion: v1data: prometheus.yml: |- global: scrape_interval: 15s evaluation_interval: 15s scrape_configs: - job_name: &#x27;kubernetes-apiservers&#x27; kubernetes_sd_configs: - role: endpoints scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token relabel_configs: - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name] action: keep regex: default;kubernetes;https - target_label: __address__ replacement: kubernetes.default.svc:443 - job_name: &#x27;kube-scheduler&#x27; tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: endpoints relabel_configs: - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape, __meta_kubernetes_namespace, __meta_kubernetes_service_name] regex: true;kube-system;kube-scheduler-prometheus-discovery action: keep - job_name: &#x27;kube-controller-manager&#x27; tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: endpoints relabel_configs: - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape, __meta_kubernetes_namespace, __meta_kubernetes_service_name] regex: true;kube-system;kube-controller-manager-prometheus-discovery action: keep - job_name: &#x27;kubernetes-kubelet&#x27; scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) - target_label: __address__ replacement: kubernetes.default.svc:443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/$&#123;1&#125;/proxy/metrics - source_labels: [__meta_kubernetes_node_name] target_label: &quot;kubernetes_node_name&quot; - job_name: &#x27;kubernetes-cadvisor&#x27; scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - target_label: __address__ replacement: kubernetes.default.svc:443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/$&#123;1&#125;/proxy/metrics/cadvisor - action: labelmap regex: __meta_kubernetes_node_label_(.+) - job_name: &#x27;kube-proxy&#x27; tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: endpoints relabel_configs: - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape, __meta_kubernetes_namespace, __meta_kubernetes_service_name] regex: true;kube-system;kube-proxy-prometheus-discovery action: keep - job_name: &#x27;kube-dns-discovery&#x27; tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: endpoints relabel_configs: - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name] regex: kube-system;kube-dns action: keep - source_labels: [__meta_kubernetes_endpoint_port_name] separator: ; regex: metrics replacement: $1 action: keep - source_labels: [__address__] action: replace target_label: instance - job_name: &#x27;kube-state-metrics&#x27; tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: endpoints relabel_configs: - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name] regex: kube-state-metrics;http-metrics action: keep - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme] action: replace target_label: __scheme__ regex: (https?) - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path] action: replace target_label: __metrics_path__ regex: (.+) - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port] action: replace target_label: __address__ regex: (.+)(?::\\d+);(\\d+) replacement: $1:$2 - action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: [__meta_kubernetes_namespace] action: replace target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_service_name] action: replace target_label: kubernetes_name - job_name: &#x27;kubernetes-pods&#x27; kubernetes_sd_configs: - role: pod relabel_configs: - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape] action: keep regex: true - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path] action: replace target_label: __metrics_path__ regex: (.+) - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port] action: replace regex: ([^:]+)(?::\\d+)?;(\\d+) replacement: $1:$2 target_label: __address__ - action: labelmap regex: __meta_kubernetes_pod_label_(.+) - source_labels: [__meta_kubernetes_namespace] action: replace target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_pod_name] action: replace target_label: kubernetes_pod_name - source_labels: [__meta_kubernetes_pod_node_name] target_label: kubernetes_node_name - job_name: &#x27;kubernetes-services&#x27; metrics_path: /probe params: module: [http_2xx] kubernetes_sd_configs: - role: service relabel_configs: - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe] action: keep regex: true - source_labels: [__address__] target_label: __param_target - target_label: __address__ replacement: blackbox-exporter.default.svc.cluster.local:9115 - source_labels: [__param_target] target_label: instance - action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: [__meta_kubernetes_namespace] target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_service_name] target_label: kubernetes_name - job_name: &#x27;kubernetes-ingresses&#x27; metrics_path: /probe params: module: [http_2xx] kubernetes_sd_configs: - role: ingress relabel_configs: - source_labels: [__meta_kubernetes_ingress_annotation_prometheus_io_probe] action: keep regex: true - source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path] regex: (.+);(.+);(.+) replacement: $&#123;1&#125;://$&#123;2&#125;$&#123;3&#125; target_label: __param_target - target_label: __address__ replacement: blackbox-exporter.default.svc.cluster.local:9115 - source_labels: [__param_target] target_label: instance - action: labelmap regex: __meta_kubernetes_ingress_label_(.+) - source_labels: [__meta_kubernetes_namespace] target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_ingress_name] target_label: kubernetes_namekind: ConfigMapmetadata: name: prometheus-config 3.创建prometheus service和deployment 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556apiVersion: apps/v1kind: Deploymentmetadata: labels: name: prometheus name: prometheusspec: replicas: 1 selector: matchLabels: app: prometheus template: metadata: labels: app: prometheus spec: serviceAccountName: prometheus serviceAccount: prometheus containers: - name: prometheus image: prom/prometheus:v2.2.1 command: - &quot;/bin/prometheus&quot; args: - &quot;--config.file=/etc/prometheus/prometheus.yml&quot; - &quot;--web.enable-lifecycle&quot; ports: - containerPort: 9090 protocol: TCP volumeMounts: - mountPath: &quot;/etc/prometheus&quot; name: prometheus-config volumes: - name: prometheus-config configMap: name: prometheus-config ---apiVersion: v1kind: &quot;Service&quot;metadata: name: prometheus labels: name: prometheusspec: ports: - name: prometheus protocol: TCP port: 9090 targetPort: 9090 nodePort: 30090 selector: app: prometheus type: NodePort 这里创建的prometheus service是NodePort类型，可以直接通过ip:30090访问prometheus。 kubernetes监控方案上面讲述了如何在集群外部和集群内部监控k8s 。对于单集群来说，这两种方案已经能够满足我们的需求。那对于多集群监控呢。下面列出两种方案： 方案 优势 劣势 采用外部部署prometheus的方式，写多套配置 无需对k8s造成额外的资源占用 增加了api server的负载 利用联邦集群，每个k8s中部署一个prometheus，由外部prometheus汇总 api server负载小 对k8s造成额外的资源占用 两种方案各有各自的优缺点，在部署实施过程中，可根据需求选择对应方案。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"Prometheus监控kubernetes方案及实现","slug":"Prometheus监控kubernetes方案及实现","permalink":"https://tianxiafeiyu.github.io/tags/Prometheus%E7%9B%91%E6%8E%A7kubernetes%E6%96%B9%E6%A1%88%E5%8F%8A%E5%AE%9E%E7%8E%B0/"}]},{"title":"Elasticsearch学习","slug":"技术开发/database/es/Elasticsearch学习","date":"2022-12-16T00:43:25.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/16/技术开发/database/es/Elasticsearch学习/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/16/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/es/Elasticsearch%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"最近在做skywalking相关的项目，skywalking使用了Elasticsearch对数据指标进行存取，要理解skywalking的工程项目，就需要对 Elasticsearch 有一定的了解。 转载自 https://www.jianshu.com/p/d48c32423789 什么是 Elasticsearchhttps://www.elastic.co/cn/elasticsearch Elasticsearch是一个开源的分布式、RESTful 风格的搜索和数据分析引擎，它的底层是开源库Apache Lucene。 Elasticsearch用 Java 编写，内部采用 Lucene 做索引与搜索，但是它的目标是使全文检索变得更简单，简单来说，就是对Lucene 做了一层封装，它提供了一套简单一致的 RESTful API 来帮助我们实现存储和检索。 Elasticsearch 不仅仅是 Lucene，并且也不仅仅只是一个全文搜索引擎。 它可以被下面这样准确地形容： 一个分布式的实时文档存储系统，每个字段可以被索引与搜索； 一个分布式实时分析搜索引擎； 能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据。 现在，Elasticsearch已成为全文搜索领域的主流软件之一。维基百科、卫报、Stack Overflow、GitHub等都纷纷采用它来做搜索。 Elasticsearch 一些概念【Cluster】 集群,一个ES集群由一个或多个节点(Node)组成,每个集群都有一个cluster name作为标识 【node】 节点,一个ES实例就是一个node,一个机器可以有多个实例,所以并不能说一台机器就是一个node，大多数情况下每个node运行在一个独立的环境或者虚拟机上。 【index】索引，即文档的集合 【shard】 分片,ES是分布式搜索引擎,每个索引有一个或多个分片,索引的数据被分配到各个分片上，相当于一桶水分N个杯子装。 分片有助于横向扩展，N个分片会尽可能平均地分配在不同的节点上。（2个节点，4个分片，则每个节点会分到2个分片。后面增加2个节点后，ES会自动感知进行分配，每个节点一个分片） 分片是独立的。 每个分片都是一个Lucene Index，所以一个分片只能存放Integer.MAX_VALUE-128&#x3D;2,147,483,519个docs。 分片中有 主分片（primary shard）和备份分片（replica shard），主分片和备份分片不会出现在同一个节点上（防止单点故障），默认情况下一个索引会创建5个分片及它们的备份（5primary 5replica&#x3D;10个分片）。如果只有一个节点，备份分片将会无法分配（unassigned）,此时集群状态为Yellow。 对于一个索引，除非重建索引，否则不能调整分片数目（主分片数目, number_of_shards）,但是可以随时调整备份分片数目（number_of_replicas） 【ES集群状态】 Green：所有主分片和备份分片都准备就绪（分配成功）。 Yellow：所有主分片准备就绪，存在至少一个备份分片没有准备就绪。 Red：存在至少一个主分片没有准备就绪，此时查询可能会出现数据丢失。 【replica作用】 容灾：primary分片丢失,replica分片就会被顶上去成为新的主分片,同时根据这个新的主分片创建新的replica，集群数据安然无恙。 提高查询性能：主分片和备份分片的数据是相同的，所有对于查询请求既可以查主分片也可以查备份分片，在合适的范围内多个replica性能会更优。 1. 文档1.1 什么是文档？对象 or 文档 1234567891011121314151617181920&#123; &quot;name&quot;: &quot;John Smith&quot;, &quot;age&quot;: 42, &quot;confirmed&quot;: true, &quot;join_date&quot;: &quot;2014-06-01&quot;, &quot;home&quot;: &#123; &quot;lat&quot;: 51.5, &quot;lon&quot;: 0.1 &#125;, &quot;accounts&quot;: [ &#123; &quot;type&quot;: &quot;facebook&quot;, &quot;id&quot;: &quot;johnsmith&quot; &#125;, &#123; &quot;type&quot;: &quot;twitter&quot;, &quot;id&quot;: &quot;johnsmith&quot; &#125; ]&#125; 通常情况下，我们使用的术语 对象 和 文档 是可以互相替换的。不过，有一个区别： 一个对象仅仅是类似于 hash 、 hashmap 、字典或者关联数组的 JSON 对象，对象中也可以嵌套其他的对象。 对象可能包含了另外一些对象。在 Elasticsearch 中，文档 有着特定的含义。它是指最顶层或者根对象, 这个根对象被序列化成 JSON 并存储到 Elasticsearch 中，指定了唯一 ID。 1.2 文档元数据一个文档不仅仅包含它的数据 ，也包含 元数据 —— 有关 文档的信息。三个必须的元数据元素如下： _index 文档在哪存放我们可以简单理解为一个文档存储在一个索引内，索引和文档是一对多的关系。 实际上，在 Elasticsearch 中，我们的数据是被存储和索引在 分片 中，而一个索引仅仅是逻辑上的命名空间， 这个命名空间由一个或者多个分片组合在一起。 然而，这是一个内部细节，我们的应用程序根本不应该关心分片，对于应用程序而言，只需知道文档位于一个 索引 内。 Elasticsearch 会处理所有的细节。 _type 文档表示的对象类别types （类型）允许在索引中对数据进行逻辑分区。不同 types 的文档可能有不同的字段，但最好能够非常相似。一个 _type 命名可以是大写或者小写，但是不能以下划线或者句号开头，不应该包含逗号， 并且长度限制为256个字符。 _id文档唯一标识它和 _index 以及 _type 组合就可以唯一确定 Elasticsearch 中的一个文档。创建一个新的文档时，可以指定 _id ，也可以让 Elasticsearch 自动生成。 当然，还有很多其他的元数据 2. 分布式文档存储2.1 文档的存放位置当索引一个文档的时候，文档会被存储到一个主分片中。 Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？当我们创建文档时，它如何决定这个文档应当被存储在分片 1 还是分片 2 中呢？ 首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。实际上，这个过程是根据下面这个公式决定的： 1shard = hash(routing) % number_of_primary_shards routing : 可变值，默认是文档的 _id ，也可以设置成一个自定义的值 number_of_primary_shards : 主分片的数量 shard : 文档所在分片的位置，取值范围 [0, number_of_primary_shards-1] 这也解释了为什么创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。 你可能觉得由于 Elasticsearch 主分片数量是固定的会使索引难以进行扩容。实际上当你需要时有很多技巧可以轻松实现扩容。 所有的文档 API（ get 、 index 、 delete 、 bulk 、 update 以及 mget ）都接受一个叫做 routing 的路由参数 ，通过这个参数我们可以自定义文档到分片的映射。一个自定义的路由参数可以用来确保所有相关的文档——例如所有属于同一个用户的文档——都被存储到同一个分片中。 2.2 主分片和副本分片如何交互2.2.1 分片分布规则假设有一个集群由三个节点组成。 它包含一个叫 blogs 的索引，有两个主分片，每个主分片有两个副本分片，相同分片的副本不会放在同一节点。类似如下图： 我们可以发送请求到集群中的任一节点。 每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。负责转发的节点称为 ***协调节点(coordinating node)***。 2.2.2 索引、新建和删除12345678910111213141516171819202122232425# 索引文档- 存储和使文档可被搜索 (也可以作为更新功能)PUT /&#123;index&#125;/&#123;type&#125;/&#123;id&#125;&#123; &quot;field&quot;: &quot;value&quot;, ...&#125;// 例如PUT /website/blog/123&#123; &quot;title&quot;: &quot;My first blog entry&quot;, &quot;text&quot;: &quot;Just trying this out...&quot;, &quot;date&quot;: &quot;2014/01/01&quot;&#125;# 新建新文档（与索引的区分就是确保生成新的文档，而不是覆盖）POST /website/blog/ # es自动生成_id，保证唯一&#123; ... &#125;PUT /website/blog/123/_create # 指定 _id 为 123，若是已存在_id，则创建失败并且返回409&#123; ... &#125;# 删除文档DELETE /&#123;index&#125;/&#123;type&#125;/&#123;id&#125; 注意：在 Elasticsearch 中文档是 不可改变 的，不能修改它们。如果想要更新现有的文档，需要 重建索引 或者进行替换 新建、索引和删除 请求都是 写 操作， 必须在主分片上面完成之后才能被复制到相关的副本分片，如下图所示： 以下是在主副分片和任何副本分片上面 成功新建，索引和删除文档所需要的步骤顺序： 客户端向 Node 1 发送新建、索引或者删除请求。 节点使用文档的 _id 确定文档属于分片 0 。请求会被转发到 Node 3，因为分片 0 的主分片目前被分配在 Node 3 上。 Node 3 在主分片上面执行请求。如果成功了，它将请求并行转发到 Node 1 和 Node 2 的副本分片上。一旦所有的副本分片都报告成功, Node 3 将向协调节点报告成功，协调节点向客户端报告成功。 在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成，变更是安全的。 2.2.3 单文档查询12345678GET /website/blog/123?pretty#pretty 参数，将会调用 Elasticsearch 的 pretty-print 功能，该功能将会格式化数据，提高可读性。# 获取文档部分内容GET /website/blog/123?_source=title,text# 只想得到 _source 字段，不需要任何元数据GET /website/blog/123?_source 响应体包括常见元数据元素，再加上 _source 字段，这个字段包含我们索引数据时发送给 Elasticsearch 的原始 JSON 文档： 123456789101112&#123; &quot;_index&quot; : &quot;website&quot;, &quot;_type&quot; : &quot;blog&quot;, &quot;_id&quot; : &quot;123&quot;, &quot;_version&quot; : 1, &quot;found&quot; : true, &quot;_source&quot; : &#123; &quot;title&quot;: &quot;My first blog entry&quot;, &quot;text&quot;: &quot;Just trying this out...&quot;, &quot;date&quot;: &quot;2014/01/01&quot; &#125;&#125; Get 获取文档，可以从主分片或者从其它任意副本分片检索文档 ，如下图所示： 以下是从主分片或者副本分片检索文档的步骤顺序： 客户端向 Node 1 发送获取请求。 节点使用文档的 _id 来确定文档属于分片 0 。分片 0 的副本分片存在于所有的三个节点上。 在这种情况下，它将请求转发到 Node 2 。 Node 2 将文档返回给 Node 1 ，然后将文档返回给客户端。 在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡。 在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。 在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的。 2.2.4 局部更新文档update 请求最简单的一种形式是接收文档的一部分作为 doc 的参数， 它只是与现有的文档进行合并。对象被合并到一起，覆盖现有的字段，增加新的字段。 例如，我们增加字段 tags 和 views 到我们的博客文章，如下所示： 1234567POST /website/blog/1/_update&#123; &quot;doc&quot; : &#123; &quot;tags&quot; : [ &quot;testing&quot; ], &quot;views&quot;: 0 &#125;&#125; 如果请求成功，我们看到类似于 index 请求的响应： 123456&#123; &quot;_index&quot; : &quot;website&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_type&quot; : &quot;blog&quot;, &quot;_version&quot; : 3&#125; 检索文档显示了更新后的 _source 字段： 12345678910111213&#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;blog&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 3, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;title&quot;: &quot;My first blog entry&quot;, &quot;text&quot;: &quot;Starting to get the hang of this...&quot;, &quot;tags&quot;: [ &quot;testing&quot; ], #新添加 &quot;views&quot;: 0 #新添加 &#125;&#125; 局部更新文档，update API 结合了先前说明的读取和写入模式： 以下是部分更新一个文档的步骤： 客户端向 Node 1 发送更新请求。 它将请求转发到主分片所在的 Node 3 。 Node 3 从主分片检索文档，修改 _source 字段中的 JSON ，并且尝试重新索引主分片的文档。 如果文档已经被另一个进程修改，它会重试步骤 3 ，超过 retry_on_conflict 次后放弃。 如果 Node 3 成功地更新文档，它将新版本的文档并行转发到 Node 1 和 Node 2 上的副本分片，重新建立索引。 一旦所有副本分片都返回成功， Node 3 向协调节点也返回成功，协调节点向客户端返回成功。 update API 还接受在 新建、索引和删除文档 章节中介绍的 routing 、 replication 、 consistency 和 timeout 参数。 当主分片把更改转发到副本分片时， 它不会转发更新请求。 相反，它转发完整文档的新版本。请记住，这些更改将会异步转发到副本分片，并且不能保证它们以发送它们相同的顺序到达。 如果Elasticsearch仅转发更改请求，则可能以错误的顺序应用更改，导致得到损坏的文档。 2.2.5 多文档操作将多个请求合并成一个，避免单独处理每个请求花费的网络延时和开销。 如果你需要从 Elasticsearch 检索很多文档，那么使用 multi-get 或者 mget API 来将这些检索请求放在一个请求中，将比逐个文档请求更快地检索到全部文档。 mget API 要求有一个 docs 数组作为参数，每个元素包含需要检索文档的元数据， 包括 _index 、 _type 和 _id 。如果你想检索一个或者多个特定的字段，那么你可以通过 _source 参数来指定这些字段的名字： 1234567891011121314151617181920212223242526272829303132#查询多个文档GET /_mget&#123; &quot;docs&quot; : [ &#123; &quot;_index&quot; : &quot;website&quot;, &quot;_type&quot; : &quot;blog&quot;, &quot;_id&quot; : 2 &#125;, &#123; &quot;_index&quot; : &quot;website&quot;, &quot;_type&quot; : &quot;pageviews&quot;, &quot;_id&quot; : 1, &quot;_source&quot;: &quot;views&quot; #指定查询字段 &#125; ]&#125;#GET /website/blog/_mget&#123; &quot;docs&quot; : [ &#123; &quot;_id&quot; : 2 &#125;, &#123; &quot;_type&quot; : &quot;pageviews&quot;, &quot;_id&quot; : 1 &#125; ]&#125;#GET /website/blog/_mget&#123; &quot;ids&quot; : [ &quot;2&quot;, &quot;1&quot; ]&#125; 单个文档的检索是异步执行的，相互之间不会有影响。 以下是使用单个 mget 请求取回多个文档所需的步骤顺序： 客户端向 Node 1 发送 mget 请求。 Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复， Node 1 构建响应并将其返回给客户端。 可以对 docs 数组中每个文档设置 routing 参数。 2.2.6 多文档创建、索引、删除和更新mget 可以使我们一次取回多个文档同样的方式， bulk API 允许在单个步骤中进行多次 create 、 index 、 update 或 delete 请求。 如果你需要索引一个数据流比如日志事件，它可以排队和索引数百或数千批次。 bulk 与其他的请求体格式稍有不同，如下所示： 12345&#123; action: &#123; metadata &#125;&#125;\\n&#123; request body &#125;\\n&#123; action: &#123; metadata &#125;&#125;\\n&#123; request body &#125;\\n... 一个完整的 bulk 请求： 12345678POST /_bulk&#123; &quot;delete&quot;: &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;blog&quot;, &quot;_id&quot;: &quot;123&quot; &#125;&#125; &#123; &quot;create&quot;: &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;blog&quot;, &quot;_id&quot;: &quot;123&quot; &#125;&#125;&#123; &quot;title&quot;: &quot;My first blog post&quot; &#125;&#123; &quot;index&quot;: &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;blog&quot; &#125;&#125;&#123; &quot;title&quot;: &quot;My second blog post&quot; &#125;&#123; &quot;update&quot;: &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;blog&quot;, &quot;_id&quot;: &quot;123&quot;, &quot;_retry_on_conflict&quot; : 3&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;title&quot; : &quot;My updated blog post&quot;&#125; &#125; 每个子请求都是独立执行，因此某个子请求的失败不会对其他子请求的成功与否造成影响。 mget 和 bulk API 的模式类似于单文档模式。区别在于协调节点知道每个文档存在于哪个分片中。 它将整个多文档请求分解成 每个分片 的多文档请求，并且将这些请求并行转发到每个参与节点。 协调节点一旦收到来自每个节点的应答，就将每个节点的响应收集整理成单个响应，返回给客户端。 bulk API，允许在单个批量请求中执行多个创建、索引、删除和更新请求，如下图所示： bulk API 按如下步骤顺序执行： 客户端向 Node 1 发送 bulk 请求。 Node 1 为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。 主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。 bulk API 还可以在整个批量请求的最顶层使用 consistency 参数，以及在每个请求中的元数据中使用 routing 参数。 “为什么 bulk API 需要有换行符的有趣格式，而不是发送包装在 JSON 数组中的请求，例如 mget API？” 在批量请求中引用的每个文档可能属于不同的主分片， 每个文档可能被分配给集群中的任何节点。这意味着批量请求 bulk 中的每个 操作 都需要被转发到正确节点上的正确分片。 如果单个请求被包装在 JSON 数组中，那就意味着我们需要执行以下操作： 将 JSON 解析为数组（包括文档数据，可以非常大） 查看每个请求以确定应该去哪个分片 为每个分片创建一个请求数组 将这些数组序列化为内部传输格式 将请求发送到每个分片 这是可行的，但需要大量的 RAM 来存储原本相同的数据的副本，并将创建更多的数据结构，Java虚拟机（JVM）将不得不花费时间进行垃圾回收。 相反，Elasticsearch可以直接读取被网络缓冲区接收的原始数据。 它使用换行符字符来识别和解析小的 action&#x2F;metadata 行来决定哪个分片应该处理每个请求。 这些原始请求会被直接转发到正确的分片。没有冗余的数据复制，没有浪费的数据结构。整个请求尽可能在最小的内存中处理。 Elasticsearch 搜索 Elasticsearch 真正强大之处在于可以从无规律的数据中找出有意义的信息——从“大数据”到“大信息”。 搜索（search） 可以做到： 在类似于 gender 或者 age 这样的字段上使用结构化查询，join_date 这样的字段上使用排序，就像SQL的结构化查询一样。 全文检索，找出所有匹配关键字的文档并按照_相关性（relevance）_ 排序后返回结果。 以上二者兼而有之。 关键概念： 映射（Mapping）描述数据在每个字段内如何存储 分析（Analysis）全文是如何处理使之可以被搜索的 领域特定查询语言（Query DSL）Elasticsearch 中强大灵活的查询语言 空搜索搜索API的最基础的形式是没有指定任何查询的空搜索，它简单地返回集群中所有索引下的所有文档： 1GET /_search 返回的结果（为了界面简洁编辑过的）类似如下： 12345678910111213141516171819202122232425262728&#123; &quot;hits&quot; : &#123; &quot;total&quot; : 14, #匹配到的文档总数 &quot;hits&quot; : [ #hits 数组包含所查询结果的前十个文档。 &#123; &quot;_index&quot;: &quot;us&quot;, &quot;_type&quot;: &quot;tweet&quot;, &quot;_id&quot;: &quot;7&quot;, &quot;_score&quot;: 1, #衡量了文档与查询的匹配程度,默认情况下，首先返回最相关的文档结果，即返回的文档是按照 _score 降序排列的， &quot;_source&quot;: &#123; &quot;date&quot;: &quot;2014-09-17&quot;, &quot;name&quot;: &quot;John Smith&quot;, &quot;tweet&quot;: &quot;The Query DSL is really powerful and flexible&quot;, &quot;user_id&quot;: 2 &#125; &#125;, ... 9 RESULTS REMOVED ... ], &quot;max_score&quot; : 1 #查询所匹配文档的 _score 的最大值 &#125;, &quot;took&quot; : 4, #执行整个搜索请求耗费了多少毫秒 &quot;_shards&quot; : &#123; #查询中参与分片的总数和查询情况 &quot;failed&quot; : 0, &quot;successful&quot; : 10, &quot;total&quot; : 10 &#125;, &quot;timed_out&quot; : false #查询是否超时，默认情况下，搜索请求不会超时，可以自定义超时时间 GET /_search?timeout=10ms&#125; 多索引、多类型搜索在一个或多个特殊的索引并且在一个或者多个特殊的类型中进行搜索，如下所示： &#x2F;_search在所有的索引中搜索所有的类型 &#x2F;gb&#x2F;_search在 gb 索引中搜索所有的类型 &#x2F;gb,us&#x2F;_search在 gb 和 us 索引中搜索所有的文档 &#x2F;g*,u*&#x2F;_search在任何以 g 或者 u 开头的索引中搜索所有的类型 &#x2F;gb&#x2F;user&#x2F;_search在 gb 索引中搜索 user 类型 &#x2F;gb,us&#x2F;user,tweet&#x2F;_search在 gb 和 us 索引中搜索 user 和 tweet 类型 &#x2F;_all&#x2F;user,tweet&#x2F;_search在所有的索引中搜索 user 和 tweet 类型 当然，可以在url后面加上 pretty 提高返回结果的可阅读性，如 /gb/_search?pretty 当在单一的索引下进行搜索的时候，Elasticsearch 转发请求到索引的每个分片中，可以是主分片也可以是副本分片，然后从每个分片中收集结果。多索引搜索恰好也是用相同的方式工作的—只是会涉及到更多的分片。 tip：搜索一个索引有五个主分片和搜索五个索引各有一个分片准确来所说是等价的。 分页默认情况下hits 数组中只有前 10 个文档（有10个或以上的话），要在搜索中显示其余的文档，需要使用分页功能。 和 SQL 使用 LIMIT 关键字返回单个 page 结果的方法相同，Elasticsearch 接受 from 和 size 参数： size显示应该返回的结果数量，默认是 10 from显示应该跳过的初始结果数量，默认是 0 如果每页展示 5 条结果，可以用下面方式请求得到 1 到 3 页的结果： 123GET /_search?size=5 #第1页GET /_search?size=5&amp;from=5 #第2页GET /_search?size=5&amp;from=10 #第3页 轻量搜索两种形式的搜索 API： “轻量的” 查询字符串 版本使用 Get 请求，参数通过url传递 请求体 版本使用 Post 请求，使用 JSON 格式和更丰富的查询表达式作为搜索语言 现介绍轻量搜索 查询字符串搜索非常适用于通过命令行做即席查询（用户自定义查询条件）。例如，查询在 tweet 类型中 tweet 字段包含 elasticsearch 单词的所有文档： 1GET /_all/tweet/_search?q=tweet:elasticsearch 查询在 name 字段中包含 john 并且在 tweet 字段中包含 mary 的文档，实际的地址是这样子的： 1GET /_search?q=%2Bname%3Ajohn+%2Btweet%3Amary #在url编码中，%2B为“+”，%3A为“:” + 前缀表示必须与查询条件匹配。类似地， - 前缀表示一定不与查询条件匹配。没有 + 或者 - 的所有其他条件都是可选的——匹配的越多，文档就越相关。 _all 字段查询字段值中存在mary的文档： 1GET /_search?q=mary 其实，当索引一个文档的时候，Elasticsearch 取出所有字段的值拼接成一个大的字符串，作为 _all 字段进行索引。相当于增加了一个名叫 _all 的额外字段，所以如果不指定字段名，将会匹配 _all字段，也即匹配所有字段。 例如，当索引这个文档时： 123456&#123; &quot;tweet&quot;: &quot;However did I manage before Elasticsearch?&quot;, &quot;date&quot;: &quot;2014-09-14&quot;, &quot;name&quot;: &quot;Mary Jones&quot;, &quot;user_id&quot;: 1&#125; 这就好似增加了一个名叫 _all 的额外字段： 1&quot;_all&quot;: &quot;However did I manage before Elasticsearch? 2014-09-14 Mary Jones 1&quot; 当然，也可以设置 _all 字段无效。 更复杂一点的查询下面的查询针对 tweents 类型，并使用以下的条件： name 字段中包含 mary 或者 john date 值大于 2014-09-10 _all 字段包含 aggregations 或者 geo12# GET /_all/tweents/_search?q=+name:(mary john) +date:&gt;2014-09-10 +(aggregations geo)GET /_all/tweents/_search?q=%2Bname%3A(mary+john)+%2Bdate%3A%3E2014-09-10+%2B(aggregations+geo) Get查询虽然比较简洁轻量，但是可读性很差，难以扩展，不好维护，主要是用于开发测试和简单的查询，生产环境中更多地使用功能全面的 request body 查询API 分析和映射精确值和全文Elasticsearch 中的数据可以概括的分为两类：精确值和全文 精确值如日期、数字等数据，字符串也可以作为精确值。对于精确值来讲，Foo 和 foo 是不同的，2014 和 2014-09-15 也是不同的。 全文通常是指非结构化的数据，例如一个推文的内容或一封邮件的内容。 精确值很容易查询。结果是二进制的：要么匹配查询，要么不匹配。这种查询很容易用 SQL 表示： 123WHERE name = &quot;John Smith&quot; AND user_id = 2 AND date &gt; &quot;2014-09-15&quot; 我们很少对全文类型的域做精确匹配。相反，我们希望在文本类型的域中搜索。不仅如此，我们还希望搜索能够理解我们的 意图 ： 搜索 UK ，会返回包含 United Kindom 的文档。 搜索 jump ，会匹配 jumped ， jumps ， jumping ，甚至是 leap 。 搜索 johnny walker 会匹配 Johnnie Walker ， johnnie depp 应该匹配 Johnny Depp 。 fox news hunting 应该返回福克斯新闻（ Foxs News ）中关于狩猎的故事，同时， fox hunting news 应该返回关于猎狐的故事。 Elasticsearch 使用到排索引完成这类查询。 倒排索引Elasticsearch 使用一种称为 倒排索引 的结构，它适用于快速的全文搜索。一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。 例如，假设我们有两个文档，每个文档的 content 域包含如下内容： The quick brown fox jumped over the lazy dog Quick brown foxes leap over lazy dogs in summer 为了创建倒排索引，我们首先将每个文档的 content 域拆分成单独的 词（我们称它为 词条 或 tokens ），创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。结果如下所示： 123456789101112131415161718Term Doc_1 Doc_2 ------------------------- Quick | | X The | X |brown | X | Xdog | X |dogs | | Xfox | X |foxes | | Xin | | Xjumped | X |lazy | X | Xleap | | Xover | X | Xquick | X |summer | | Xthe | X |------------------------ 现在，如果我们想搜索 quick brown ，我们只需要查找包含每个词条的文档： 1234567891011TermTerm Doc_1 Doc_2-------------------------brown | X | Xquick | X |------------------------Total | 2 | 1 -------------------------brown | X | Xquick | X |------------------------Total | 2 | 1 两个文档都匹配，但是第一个文档比第二个匹配度更高。如果我们使用仅计算匹配词条数量的简单 相似性算法 ，那么，我们可以说，对于我们查询的相关性来讲，第一个文档比第二个文档更佳。 但是，我们目前的倒排索引有一些问题： Quick 和 quick 以独立的词条出现，然而用户可能认为它们是相同的词。 fox 和 foxes 非常相似, 就像 dog 和 dogs ；他们有相同的词根。 jumped 和 leap, 尽管没有相同的词根，但他们的意思很相近。他们是同义词。 我们的用户可以合理的期望两个文档与查询匹配。我们可以做的更好。 如果我们将词条规范为标准模式，那么我们可以找到与用户搜索的词条不完全一致，但具有足够相关性的文档。例如： Quick 可以小写化为 quick 。 foxes 可以 词干提取 –变为词根的格式– 为 fox 。类似的， dogs 可以为提取为 dog 。 jumped 和 leap 是同义词，可以索引为相同的单词 jump 。 现在索引看上去像这样： 12345678910111213Term Doc_1 Doc_2-------------------------brown | X | Xdog | X | Xfox | X | Xin | | Xjump | X | Xlazy | X | Xover | X | Xquick | X | Xsummer | | Xthe | X | X------------------------ 这还远远不够。我们搜索 +Quick +fox 仍然 会失败，因为在我们的索引中，已经没有 Quick 了。但是，如果我们对搜索的字符串使用与 content 域相同的标准化规则，会变成查询 +quick +fox ，这样两个文档都会匹配！ 分词和标准化的过程称为 分析。 分析分析是决定文档如何被搜索到的方式。 分析 包含下面的过程： 首先，将一块文本分成适合于倒排索引的独立的 词条 ， 之后，将这些词条统一化为标准格式以提高它们的“可搜索性”，或者 recall 分析器执行上面的工作。 分析器 实际上是将三个功能封装到了一个包里： 字符过滤器首先，字符串按顺序通过每个 字符过滤器 。他们的任务是在分词前整理字符串。一个字符过滤器可以用来去掉HTML，或者将 &amp; 转化成 and。 分词器其次，字符串被 分词器 分为单个的词条。一个简单的分词器遇到空格和标点的时候，可能会将文本拆分成词条。 Token 过滤器最后，词条按顺序通过每个 token 过滤器 。这个过程可能会改变词条（例如，小写化 Quick ），删除词条（例如， 像 a， and， the 等无用词），或者增加词条（例如，像 jump 和 leap 这种同义词）。 Elasticsearch提供了开箱即用的字符过滤器、分词器和token 过滤器。 这些可以组合起来形成自定义的分析器以用于不同的目的。 内置分析器Elasticsearch 内置了常用的分析器。用下面字符串举例： &quot;Set the shape to semi-transparent by calling set_trans(5)&quot; 使用不同的分析器将会得到不同的结果： 1. 标准分析器标准分析器是Elasticsearch默认使用的分析器。它是分析各种语言文本最常用的选择。它根据 Unicode 联盟 定义的 单词边界 划分文本。删除绝大部分标点。最后，将词条小写。它会产生： 1set, the, shape, to, semi, transparent, by, calling, set_trans, 5 2. 简单分析器简单分析器在任何不是字母的地方分隔文本，将词条小写。它会产生： 1set, the, shape, to, semi, transparent, by, calling, set, trans 3. 空格分析器空格分析器在空格的地方划分文本。它会产生： 1Set, the, shape, to, semi-transparent, by, calling, set_trans(5) 4. 语言分析器特定语言分析器可用于 很多语言。它们可以考虑指定语言的特点。例如， 英语 分析器附带了一组英语无用词（常用单词，例如 and 或者 the ，它们对相关性没有多少影响），它们会被删除。 由于理解英语语法的规则，这个分词器可以提取英语单词的 词干 。 英语 分词器会产生下面的词条： 12# transparent、 calling 和 set_trans 已经变为词根格式。set, shape, semi, transpar, call, set_tran, 5 测试分析器有些时候很难理解分词的过程和实际被存储到索引中的词条，特别是你刚接触Elasticsearch。为了理解发生了什么，你可以使用 analyze API 来看文本是如何被分析的。在消息体里，指定分析器和要分析的文本： 12345GET /_analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;Text to analyze&quot;&#125; 结果中每个元素代表一个单独的词条： 12345678910111213141516171819202122232425&#123; &quot;tokens&quot;: [ &#123; &quot;token&quot;: &quot;text&quot;, #实际存储到索引中的词条 &quot;start_offset&quot;: 0, #指明字符在原始字符串中的开始位置 &quot;end_offset&quot;: 4, #指明字符在原始字符串中的结束位置 &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 1 #指明词条在原始文本中出现的位置 &#125;, &#123; &quot;token&quot;: &quot;to&quot;, &quot;start_offset&quot;: 5, &quot;end_offset&quot;: 7, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 2 &#125;, &#123; &quot;token&quot;: &quot;analyze&quot;, &quot;start_offset&quot;: 8, &quot;end_offset&quot;: 15, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 3 &#125; ]&#125; 可以在在映射中指定分析器。 映射（Mapping）映射定义了文档结构，类似与关系数据库中的表结构概念。 在 Elasticsearch 中，索引中每个文档都有 类型 。每种类型都有它自己的 映射。映射定义了类型中的域，每个域的数据类型，以及Elasticsearch如何处理这些域。映射也用于配置与类型有关的元数据。 注：“域”指的是数据类型、属性，比如时间域、数字域、字符串域 核心简单域类型Elasticsearch 支持如下简单域类型： 字符串: string 整数 : byte, short, integer, long 浮点数: float, double 布尔型: boolean 日期: date 索引（创建）一个包含新域的文档—之前未曾出现– Elasticsearch 会使用 动态映射 ，通过JSON中基本数据类型，尝试猜测域类型，使用如下规则： JSON type 域 type 布尔型: true 或者 false boolean 整数: 123 long 浮点数: 123.45 double 字符串，有效日期: 2014-09-15 date 字符串: foo bar string 这意味着如果你通过引号( “123” )索引一个数字，它会被映射为 string 类型，而不是 long 。但是，如果这个域已经映射为 long ，那么 Elasticsearch 会尝试将这个字符串转化为 long ，如果无法转化，则抛出一个异常。 查看映射通过 /_mapping ，我们可以查看 Elasticsearch 在一个或多个索引中的一个或多个类型的映射。比如获取索引 gb 中类型 tweet 的映射： 1GET /gb/_mapping/tweet Elasticsearch 根据我们索引的文档，为域(称为 属性 )动态生成的映射: 1234567891011121314151617181920212223&#123; &quot;gb&quot;: &#123; &quot;mappings&quot;: &#123; &quot;tweet&quot;: &#123; &quot;properties&quot;: &#123; &quot;date&quot;: &#123; &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;strict_date_optional_time||epoch_millis&quot; &#125;, &quot;name&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125;, &quot;tweet&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125;, &quot;user_id&quot;: &#123; &quot;type&quot;: &quot;long&quot; &#125; &#125; &#125; &#125; &#125;&#125; 自定义域映射尽管在很多情况下基本域数据类型已经够用，但你经常需要为单独域自定义映射，特别是字符串域。自定义映射允许你执行下面的操作： 全文字符串域和精确值字符串域的区别 使用特定语言分析器 优化域以适应部分匹配 指定自定义数据格式 更多 域最重要的属性是 type 。对于不是 string 的域，一般只需要设置 type ： 12345&#123; &quot;number_of_clicks&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;&#125; 默认， string 类型域会被认为包含全文。就是说，它们的值在索引前，会通过一个分析器，针对于这个域的查询在搜索前也会经过一个分析器。 string 域映射的两个最重要属性是 index 和 analyzer 。 indexindex 属性控制怎样索引字符串。它可以是下面三个值： 1. analyzed 首先分析字符串，然后索引它。换句话说，以全文索引这个域。 2. not_analyzed 索引这个域，所以它能够被搜索，但索引的是精确值。不会对它进行分析。 3. no 不索引这个域。这个域不会被搜索到。 string 域 index 属性默认是 analyzed 。如果我们想映射这个字段为一个精确值，我们需要设置它为 not_analyzed ： 123456&#123; &quot;tag&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125;&#125; 其他简单类型（例如 long ， double ， date 等）也接受 index 参数，但有意义的值只有 no 和 not_analyzed ， 因为它们永远不会被分析，总是使用精确匹配。 analyzer对于 analyzed 字符串域，用 analyzer 属性指定在搜索和索引时使用的分析器。默认， Elasticsearch 使用 standard 分析器， 但你可以指定一个内置的分析器替代它，例如 whitespace 、 simple 和 english，当然也可以自定义分析器。 1234567&#123; &quot;tweet&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;analyzed&quot;, &quot;analyzer&quot;: &quot;english&quot; &#125;&#125; 更新映射首次创建一个索引的时候，可以指定类型的映射。也可以使用 _mapping 为新类型增加映射或者为已存在的类型更新映射。 我们可以更新一个映射来添加一个新域，但不能将一个存在的域从 analyzed 改为 not_analyzed 。 创建一个新索引，指定 tweet 域使用 english 分析器： 12345678910111213141516171819202122PUT /gb &#123; &quot;mappings&quot;: &#123; &quot;tweet&quot; : &#123; &quot;properties&quot; : &#123; &quot;tweet&quot; : &#123; &quot;type&quot; : &quot;string&quot;, &quot;analyzer&quot;: &quot;english&quot; &#125;, &quot;date&quot; : &#123; &quot;type&quot; : &quot;date&quot; &#125;, &quot;name&quot; : &#123; &quot;type&quot; : &quot;string&quot; &#125;, &quot;user_id&quot; : &#123; &quot;type&quot; : &quot;long&quot; &#125; &#125; &#125; &#125;&#125; 更新这个索引的类型的映射，tweet 映射增加一个新的名为 tag 的 not_analyzed 的文本域，使用 _mapping ： 123456789PUT /gb/_mapping/tweet&#123; &quot;properties&quot; : &#123; &quot;tag&quot; : &#123; &quot;type&quot; : &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125; &#125;&#125; 不能修改和删除映射已存在域，只能新增域。 测试映射使用 analyze API 测试字符串域的映射： 1234567891011GET /gb/_analyze&#123; &quot;field&quot;: &quot;name&quot;, &quot;text&quot;: &quot;Black-cats&quot; &#125;GET /gb/_analyze&#123; &quot;field&quot;: &quot;tag&quot;, &quot;text&quot;: &quot;Black-cats&quot; &#125; name 域产生两个词条 black 和 cat（分词） ， tag 域产生单独的词条 Black-cats （不分词）。换句话说，我们的映射正常工作。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"database","slug":"技术开发/database","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/"},{"name":"es","slug":"技术开发/database/es","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/es/"}],"tags":[{"name":"Elasticsearch学习","slug":"Elasticsearch学习","permalink":"https://tianxiafeiyu.github.io/tags/Elasticsearch%E5%AD%A6%E4%B9%A0/"}]},{"title":"websocket学习","slug":"技术开发/grocery/websocket学习","date":"2022-12-15T23:41:44.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/websocket学习/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/websocket%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"WebSocke简述随着互联网的发展，传统的HTTP协议已经很难满足Web应用日益复杂的需求了。近年来，随着HTML5的诞生，WebSocket协议被提出，它实现了浏览器与服务器的全双工通信，扩展了浏览器与服务端的通信功能，使服务端也能主动向客户端发送数据。 我们知道，传统的HTTP协议是无状态的，每次请求（request）都要由客户端（如 浏览器）主动发起，服务端进行处理后返回response结果，而服务端很难主动向客户端发送数据；这种客户端是主动方，服务端是被动方的传统Web模式 对于信息变化不频繁的Web应用来说造成的麻烦较小，而对于涉及实时信息的Web应用却带来了很大的不便，如带有即时通信、实时数据、订阅推送等功能的应 用。在WebSocket规范提出之前，开发人员若要实现这些实时性较强的功能，经常会使用折衷的解决方法：轮询（polling）和Comet技术。其实后者本质上也是一种轮询，只不过有所改进。 轮询是最原始的实现实时Web应用的解决方案。轮询技术要求客户端以设定的时间间隔周期性地向服务端发送请求，频繁地查询是否有新的数据改动。明显地，这种方法会导致过多不必要的请求，浪费流量和服务器资源。 Comet技术又可以分为长轮询和流技术。长轮询改进了上述的轮询技术，减小了无用的请求。它会为某些数据设定过期时间，当数据过期后才会向服务端发送请求；这种机制适合数据的改动不是特别频繁的情况。流技术通常是指客户端使用一个隐藏的窗口与服务端建立一个HTTP长连接，服务端会不断更新连接状态以保持HTTP长连接存活；这样的话，服务端就可以通过这条长连接主动将数据发送给客户端；流技术在大并发环境下，可能会考验到服务端的性能。 这两种技术都是基于请求-应答模式，都不算是真正意义上的实时技术；它们的每一次请求、应答，都浪费了一定流量在相同的头部信息上，并且开发复杂度也较大。 伴随着HTML5推出的WebSocket，真正实现了Web的实时通信，使B&#x2F;S模式具备了C&#x2F;S模式的实时通信能力。WebSocket的工作流程是这 样的：浏览器通过JavaScript向服务端发出建立WebSocket连接的请求，在WebSocket连接建立成功后，客户端和服务端就可以通过 TCP连接传输数据。因为WebSocket连接本质上是TCP连接，不需要每次传输都带上重复的头部数据，所以它的数据传输量比轮询和Comet技术小 了很多 WebSocke是 HTML5 提供的一种在单个 TCP 连接上进行全双工通讯的协议。 WebSocket协议是基于TCP的一种新的网络协议，是一个应用层协议，是TCP&#x2F;IP协议的子集。 它实现了浏览器与服务器全双工（full-duplex）通信，客户端和服务器都可以向对方主动发送和接收数据。在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。 在JS中创建WebSocket后，会有一个HTTP请求从浏览器发向服务器。在取得服务器响应后，建立的连接会使用HTTP升级将HTTP协议转换为WebSocket协议。也就是说，使用标准的HTTP协议无法实现WebSocket，只有支持那些协议的专门浏览器才能正常工作。由于WebScoket使用了自定义协议，所以URL与HTTP协议略有不同。未加密的连接为ws:&#x2F;&#x2F;，而不是http:&#x2F;&#x2F;。加密的连接为wss:&#x2F;&#x2F;，而不是https:&#x2F;&#x2F;，所以如果你的项目使用了网关，又想使用WebSocket，在网关转发这方面，就会遇到问题。 WebSocket特点（1）建立在 TCP 协议之上，服务器端的实现比较容易。 （2）与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。 （3）数据格式比较轻量，性能开销小，通信高效。 （4）可以发送文本，也可以发送二进制数据。 （5）没有同源限制，客户端可以与任意服务器通信。 （6）协议标识符是ws（如果加密，则为wss），服务器网址就是 URL。如 ws:localhost:80\\test gorilla&#x2F;websocket 介绍https://github.com/gorilla/websocket 这是一个封装了go原生websocket的库。 使用方法创建websocket连接地址 1http.HandleFunc(&quot;/ws&quot;, serveWs) 123456789101112131415func serveWs(w http.ResponseWriter, r *http.Request) &#123; ws, err := upgrader.Upgrade(w, r, nil) if err != nil &#123; log.Println(&quot;upgrade:&quot;, err) return &#125; defer ws.Close() //... // 数据写入，发送消息 ws.WriteMessage(websocket.TextMessage, s.Bytes()) // 数据读取，接受消息 _, message, err := ws.ReadMessage() //...&#125; 使用示例 聊天室 c&#x2F;s 架构使用websocket通信 文件监听 远程命令 WebSocket网关如果是全新的服务和架构，原生支持websocket固然值最好的 痛点： 新服务需要考虑到ws部分的实现和支持；前后端对接增加工作 不能使用原先的框架快速开发 旧服务设计之初就不支持ws，服务多，需要重新对接，容易改动引发，改造耗时耗力 如果存在这样一个服务：","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"websocket学习","slug":"websocket学习","permalink":"https://tianxiafeiyu.github.io/tags/websocket%E5%AD%A6%E4%B9%A0/"}]},{"title":"交换机端口标识含义","slug":"技术开发/grocery/交换机端口标识含义","date":"2022-12-15T23:41:44.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/交换机端口标识含义/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/%E4%BA%A4%E6%8D%A2%E6%9C%BA%E7%AB%AF%E5%8F%A3%E6%A0%87%E8%AF%86%E5%90%AB%E4%B9%89/","excerpt":"","text":"交换机端口标识含义 FastEthernet 百兆端口 GigabitEthernet 千兆端口 TenGigabitEthernet 万兆端口 vlan 逻辑端口，划分物理端口的逻辑分区 StackSub 堆叠端口，支持堆叠的交换机一般有专门的堆叠模块和端口堆叠是指将一台以上的交换机组合起来共同工作，以便在有限的空间内提供尽可能多的端口。 Port-channel 加入port group 中的物理端口满足某种条件时进行端口汇聚，形成一个port channel。所以Port-channel是逻辑端口。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"交换机端口标识含义","slug":"交换机端口标识含义","permalink":"https://tianxiafeiyu.github.io/tags/%E4%BA%A4%E6%8D%A2%E6%9C%BA%E7%AB%AF%E5%8F%A3%E6%A0%87%E8%AF%86%E5%90%AB%E4%B9%89/"}]},{"title":"基于etcd实现的分布式锁","slug":"技术开发/grocery/基于etcd实现的分布式锁","date":"2022-12-15T23:41:44.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/基于etcd实现的分布式锁/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/%E5%9F%BA%E4%BA%8Eetcd%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"","text":"lock.sh123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114\\#!/bin/bash# @CreateTime: 2021-03-23 16:00:00# @Description: 分布式锁# @Note: 在axis中实现分布式锁时，由于Python的语言特性，导致性能特别差；# 因此这里直接基于etcd进行实现，对性能有大幅提升！# 锁名LOCK\\_NAME=&quot;&quot;# 会话超时时间，即服务异常退出时锁的最长自动释放时间，单位/秒TTL=30# 是否本地锁，如果是本地锁，那么作用和flock类似，不会对集群的其他节点造成影响IS\\_LOCAL=false# 待执行命令COMMAND=&quot;&quot;# 连接|获取锁|释放锁的超时时间，单位/秒TIMEOUT=&quot;&quot;# 是否输出调试信息DEBUG=false# 函数: 用法说明function usage()&#123;echoecho &quot;Usage: dlock \\[-n|--name] \\[-t|--ttl] \\[-w|--timeout] \\[-l|--local] \\[-d|--debug] \\[-h|--help] \\&lt;command&gt; \\[command args]&quot;echoecho &quot;Options:&quot;echo &quot; -n --name 锁名，默认为被执行命令名&quot;echo &quot; -t --ttl 会话超时时间，即服务异常退出时锁的最长自动释放时间，单位/秒&quot;echo &quot; -w --timeout 连接超时时间，单位/秒&quot;echo &quot; -l --local 本地锁，类似flock&quot;echo &quot; -d --debug 输出调试信息&quot;echo &quot; -h --help 输出帮助信息并退出&quot;echo exit 1&#125;# 函数: 解析命令行参数function parse\\_cmdline\\_args()&#123;local parsed\\_argsparsed\\_args=`$(getopt -a -n dlock -o n:t:w:ldh --long name:,ttl:,timeout:,local,debug,help -- &quot;$`@&quot;)if \\[ \\$? -ne 0 ]; thenusagefi eval set -- &quot;$parsed_args&quot; while true; do case &quot;$1&quot; in -n | --name) LOCK_NAME=&quot;$2&quot; ; shift 2 ;; -t | --ttl) TTL=$2 ; shift 2 ;; -w | --timeout) TIMEOUT=$2 ; shift 2 ;; -l | --local) IS_LOCAL=true ; shift ;; -d | --debug) DEBUG=true ; shift ;; -h | --help) usage ;; --) shift; break ;; *) usage ;; esac done # 剩余参数就当做被执行命令看待 COMMAND=&quot;$@&quot; if [ -z &quot;$COMMAND&quot; ]; then usage fi&#125;# 函数: 主函数function main()&#123;parse\\_cmdline\\_args &quot;\\$@&quot; # 未指定锁名的情况下，默认使用可执行文件作为锁名 if [ -z &quot;$LOCK_NAME&quot; ]; then LOCK_NAME=$(echo $COMMAND | awk &#x27;&#123;print $1&#125;&#x27;) fi # 为本地锁的情况下，使用主机名作为锁名前缀 if [ $IS_LOCAL = true ]; then local hostname hostname=$(hostname) LOCK_NAME=&quot;$hostname/$LOCK_NAME&quot; fi # 目前基于etcd来实现分布式锁 if [ ! -z &quot;$TIMEOUT&quot; ]; then export ETCDCTL_CONNECTION_TIMEOUT=$TIMEOUT fi # TODO: 需要把etcdctl的第一行warning日志去掉或者过滤掉 /sf/bin/etcdctl lock --debug=$DEBUG --ttl=$TTL &quot;$LOCK_NAME&quot; $COMMAND&#125;main &quot;\\$@&quot;","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"基于etcd实现的分布式锁","slug":"基于etcd实现的分布式锁","permalink":"https://tianxiafeiyu.github.io/tags/%E5%9F%BA%E4%BA%8Eetcd%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"}]},{"title":"数据结构与算法---常见算法减治、分治、递归、迭代、回溯、动态规划、贪心的基本思想","slug":"技术开发/grocery/数据结构与算法---常见算法减治、分治、递归、迭代、回溯、动态规划、贪心的基本思想【转】","date":"2022-12-15T23:41:44.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/数据结构与算法---常见算法减治、分治、递归、迭代、回溯、动态规划、贪心的基本思想【转】/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95---%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95%E5%87%8F%E6%B2%BB%E3%80%81%E5%88%86%E6%B2%BB%E3%80%81%E9%80%92%E5%BD%92%E3%80%81%E8%BF%AD%E4%BB%A3%E3%80%81%E5%9B%9E%E6%BA%AF%E3%80%81%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E3%80%81%E8%B4%AA%E5%BF%83%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3%E3%80%90%E8%BD%AC%E3%80%91/","excerpt":"","text":"转载自 https://blog.csdn.net/cqfdcw/article/details/100063987 一、减而治之减而治之与分而治之都是递归中常用的算法策略。其中减而治之是将一个大规模的问题，将其划分为两个子问题，其一是平凡问题，另一个规模缩减。递归每深入一层，待求解问题的规模都缩减一个常数，直至最终蜕化为平凡问题。 应用举例1：求解数组元素的和 123int sum(int A[], int n)&#123; return (n&lt;1)?0:sum(A,n-1)+A[n-1];&#125; 应用举例2：数组中元素倒置 12345678//为得到整个数组的倒置，可以先对换其首、末元素，然后递归地倒置除这两个元素以外的部分。void reverse(int *A, int lo, int hi)&#123; if(lo &lt; hi) &#123; swap(A[lo],A[hi]); reverse(A, lo + 1, hi - 1); &#125;&#125; 二、分而治之可以将其划分为多个（通常情况下为两个）子问题，两个问题的规模大体相同。由子问题的解，通过递归得到原问题的解。 应用举例1：求解数组元素的和 123int sum(int A[], int low, int high)&#123; return (low == high) ? A[low] : sum(A, low, (low + high) &gt;&gt; 1) + sum(A, ((low + high) &gt;&gt; 1) + 1, high);&#125; 应用举例2：归并排序 1234567891011121314151617181920212223242526272829303132template&lt;typename T&gt;void merge(vector&lt;T&gt; &amp;arr, int L, int mid, int R) &#123; //有序向量的逐层归并 vector&lt;int&gt; temp; //临时变量用来存放本次合并后的数组 int p1 = L; int p2 = mid + 1; // 比较左右两部分的元素，哪个小，把那个元素填入temp中 while (p1 &lt;= mid &amp;&amp; p2 &lt;= R) &#123; temp.push_back(arr[p1] &lt; arr[p2] ? arr[p1++] : arr[p2++]); &#125; // 上面的循环退出后，把剩余的元素依次填入到temp中，只有一个while会执行 while (p1 &lt;= mid) &#123; temp.push_back(arr[p1++]); &#125; while (p2 &lt;= R) &#123; temp.push_back(arr[p2++]); &#125; // 把最终的排序的结果复制给原数组 for (int i = 0; i &lt; temp.size(); i++) &#123; arr[L + i] = temp[i]; &#125;&#125; template&lt;typename T&gt;void mergeSort(vector&lt;T&gt; &amp;arr , int L, int R) &#123; //无序向量的逐层分解 if (L == R) &#123; //只有一个元素的时候返回 return; &#125; int mid = L + ((R - L) &gt;&gt; 1); mergeSort(arr, L, mid); mergeSort(arr, mid + 1, R); merge(arr, L, mid, R);&#125; 三、递归与迭代递归重复调用函数自身实现循环，A函数调用A函数。简而言之，通过不断地深层调用函数，直到函数有返回才会逐层的返回，把一个大型复杂的问题层层转化为一个与原问题相似的规模较小的问题来求解(子问题须与原始问题为同样的事，且更为简单)；递归是用栈机制实现的，每深入一层，都要占去一块栈数据区域。 应用举例1：二叉树的先序遍历 12345678public void preorder(Node node)&#123; if(node == null)&#123; return; &#125; sytem.out.println(node.val); preorder(node.left); preorder(node.right);&#125; 应用举例2：递归求阶乘 123456public static int factorial(int num)&#123; if(num &lt; 1)&#123; return 1; &#125; return num * factorial(num-1);&#125; 迭代利用变量的原值推出新值称为迭代，或着说迭代是函数内某段代码实现循环，A函数调用B函数；每一次对过程的重复称为一次“迭代”，而每一次迭代得到的结果会作为下一次迭代的初始值。重复执行一系列运算步骤，从前面的量依次求出后面的量的过程。 应用举例1：迭代法求阶乘 1234567891011//迭代 阶乘public static int factorial(int num)&#123; if (num &lt;= 0)&#123; return 1; &#125; int result = 1; for (int i = num; i &gt;= 1; i--)&#123; result *= i; &#125; return result;&#125; 递归与迭代比较递归满足条件后，逐层返回，每层都计算完后才返回结果；迭代满足条件后，通过计数器结束循环，直接返回计算结果。 递归与迭代相比较，递归的效率较低。 | 定义 | 优点 | 缺点—|— | —|—递归 |重复调用函数自身实现循环|a.用有限的循环语句实现无限集合；b.代码易读；c.大问题转化成小问题，减少了代码量。|a.递归不断调用函数，浪费空间；b.容易造成堆栈溢出迭代 |利用变量的原值推出新值；函数内某段代码实现循环。|a.效率高，运行时间只随循环的增加而增加；b.无额外开销。|a.代码难理解；b.代码不如递归代码简洁；c.编写复杂问题时，代码逻辑不易想出关系|a.递归中一定有迭代，但是迭代中不一定有递归；大部分可以相互转换。b.相对来说，能用迭代不用递归（因为递归不断调用函数，浪费空间，容易造成堆栈溢出）|| 四、回溯又称为试探法，可以理解为尝试不同岔路口，遇到错误原路返回到岔路口走另外一条路，当解决问题的每一步都有多种选择时候，在某一步选择了其中一个选项时，则进入此选项，然后继续新的选择。若选择符合题目要求则此选择是正确的；若此选择不符合题目要求则此选择是不正确的，此时就需要(递归)返回上一步，重新进行选择。 回溯法说白了就是穷举法。回溯法一般用递归来解决。 回溯法通常要确定三个要素： 选择 对于每个特定的解，肯定是由一步步构建而来的，而每一步怎么构建，肯定都是有限个选择，要怎么选择，这个要知道；同时，在编程时候要定下，优先或合法的每一步选择的顺序，一般是通过多个if或者for循环来排列 条件 对于每个特定的解的某一步，他必然要符合某个解要求符合的条件，如果不符合条件，就要回溯，其实回溯也就是递归调用的返回。 结束 当到达一个特定结束条件时候，就认为这个一步步构建的解是符合要求的解了。把解存下来或者打印出来。对于这一步来说，有时候也可以另外写一个issolution函数来进行判断。注意，当到达第三步后，有时候还需要构建一个数据结构，把符合要求的解存起来，便于当得到所有解后，把解空间输出来。这个数据结构必须是全局的，作为参数之一传递给递归函数。 回溯法中，递归函数的设计需要遵循以下四个原则： 必须要有一个临时变量(可以就直接传递一个字面量或者常量进去)传递不完整的解，因为每一步选择后，暂时还没构成完整的解，这个时候这个选择的不完整解，也要想办法传递给递归函数。也就是，把每次递归的不同情况传递给递归调用的函数。 可以有一个全局变量，用来存储完整的每个解，一般是个集合容器（也不一定要有这样一个变量，因为每次符合结束条件，不完整解就是完整解了，直接打印即可）。 最重要的一点，一定要在参数设计中，可以得到结束条件。一个选择是可以传递一个量n，也许是数组的长度，也许是数量，等等。 要保证递归函数返回后，状态可以恢复到递归前，以此达到真正回溯。 例题分析题目1：给出n对括号，打印出所有可能的括号排列序列。123456789101112131415161718public class BackTracking &#123; public static void main(String[] args) &#123; int n=3; int leftnum=n,rightnum=n;//左括号和右括号都各有n个 ArrayList&lt;String&gt; results=new ArrayList&lt;String&gt;();//用于存放解空间 parentheses(&quot;&quot;, results, leftnum, rightnum); for(String s:results) System.out.println(s); &#125; public static void parentheses(String sublist, ArrayList&lt;String&gt; results, int leftnum, int rightnum)&#123; if(leftnum==0&amp;&amp;rightnum==0)//结束 results.add(sublist); if(rightnum&gt;leftnum)//选择和条件。对于不同的if顺序，输出的结果顺序是不一样的，但是构成一样的解空间 parentheses(sublist+&quot;)&quot;, results, leftnum, rightnum-1); if(leftnum&gt;0) parentheses(sublist+&quot;(&quot;, results, leftnum-1, rightnum); &#125;&#125; 对应回溯法三要素： 选择。在这个例子中，解就是一个合法的括号组合形式，而选择无非是放入左括号，还是放入右括号。 条件。在这个例子中，选择是放入左括号，还是放入右括号，是有条件约束的，不是随便放的。而这个约束就是括号的数量。只有剩下的右括号比左括号多，才能放右括号。只有左括号数量大于0才能放入左括号。这里if的顺序会影响输出的顺序，但是不影响最终解。 结束。这里的结束条件很显然就是，左右括号都放完了。 对应回溯法递归函数参数设计： 用了一个空字符串来作为临时变量存储不完整解。 用了一个ArrayList results来存放符合要求的解。在后面可以看到，不一定要这样做，也可以直接打印结果。 把leftnum和rightnum传入给递归函数，这样可以用于判断结束条件。 这个例子不明显。但是事实上也符合这个条件。可以仔细观察代码，可以发现由于使用了两个if，所以当一次递归退出后，例如从第一个if退出，第二个递归直接递归的是leftnum-1和rightnum，这其实是已经恢复状态了（如果没有恢复状态，那就是leftnum, rightnum-1）。因此不需要人为让他恢复状态。但是恢复状态这点是很重要的，因为回溯法，顾名思义要回溯，不恢复状态，怎么回溯呢。 题目2：给出包含一个不重复且大于0数字的数组和一个目标，求数组中数的和等于 该目标的组合（数字不同组合顺序当做一个解）。12345678910111213141516171819202122232425262728293031public class BackTracking &#123; public static void main(String[] args)&#123; int[] num=new int[]&#123;2,3,7,6&#125;; int target=9; find(num, target, &quot;&quot;); &#125; public static void find(int[] num, int target, String temp)&#123; if(issolution(temp,target))&#123; System.out.println(temp); return; &#125; for(int i=0;i&lt;num.length;i++)&#123; if(num[i]!=-1)&#123;//如果取过这个数字了，就置为-1 int k=num[i]; num[i]=-1; find(num, target, temp+k); num[i]=k; //在递归后，必须把数组恢复。这也是参数的特征的第四点所说的内容 &#125; &#125;&#125; public static boolean issolution(String temp, int target)&#123; boolean result=false; int count=0; for(int i=0;i&lt;temp.length();i++)&#123; count=count+Integer.valueOf(temp.charAt(i)+&quot;&quot;); &#125; if(count==target) result=true; return result; &#125;&#125; 题目3：给一个字符串,字符不重复，给出他的所有排列12345678910111213141516public class BackTracking &#123; public static void main(String[] args)&#123; String s=&quot;abc&quot;; pailie(s,&quot;&quot;); &#125; public static void pailie(String s, String temp)&#123;//参数设计地尽量地简洁 if(s.length()==0)&#123; System.out.println(temp); return; &#125; for(int i=0;i&lt;s.length();i++)&#123; String news=s.substring(0, i)+s.substring(i+1,s.length());//去掉String中的某个字母 pailie(news, temp+s.charAt(i)); &#125; &#125;&#125; 题目4：五、贪心算法在对问题进行求解时，总是做出当前看来是最好的选择的一种方法，从而希望能够导致结果是最好或者最优的算法(可能是局部最优解也可能是全局最优解)。是动态规划的一种特例，能用贪心解决的问题，也可以用动态规划解决。 六、动态规划动态规划的实质是分治思想和解决冗余，是一种将问题实例分解为更小的、相似的子问题，求解每个子问题仅一次，并将其结果保存在一个表中，以后用到时直接存取，避免计算重复的子问题，以解决最优化问题的算法策略。（可分为多个相关子问题，子问题的解被重复使用）。 []: https://blog.csdn.net/cqfdcw/article/details/100063987","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"数据结构与算法---常见算法减治、分治、递归、迭代、回溯、动态规划、贪心的基本思想【转】","slug":"数据结构与算法-常见算法减治、分治、递归、迭代、回溯、动态规划、贪心的基本思想【转】","permalink":"https://tianxiafeiyu.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95%E5%87%8F%E6%B2%BB%E3%80%81%E5%88%86%E6%B2%BB%E3%80%81%E9%80%92%E5%BD%92%E3%80%81%E8%BF%AD%E4%BB%A3%E3%80%81%E5%9B%9E%E6%BA%AF%E3%80%81%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E3%80%81%E8%B4%AA%E5%BF%83%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3%E3%80%90%E8%BD%AC%E3%80%91/"}]},{"title":"火焰图怎么看","slug":"技术开发/grocery/火焰图怎么看","date":"2022-12-15T23:41:44.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/火焰图怎么看/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/%E7%81%AB%E7%84%B0%E5%9B%BE%E6%80%8E%E4%B9%88%E7%9C%8B/","excerpt":"","text":"y 轴表示调用栈，每一层都是一个函数。调用栈越深，火焰就越高，顶部就是正在执行的函数，下方都是它的父函数。 x 轴表示抽样数，如果一个函数在 x 轴占据的宽度越宽，就表示它被抽到的次数多，即执行的时间长。注意，x 轴不代表时间，而是所有的调用栈合并后，按字母顺序排列的。 火焰图就是看顶层的哪个函数占据的宽度最大。只要有 “平顶”（plateaus），就表示该函数可能存在性能问题。 y 轴表示调用栈，每一层都是一个函数。调用栈越深，火焰就越高，顶部就是正在执行的函数，下方都是它的父函数。 x 轴表示抽样数，如果一个函数在 x 轴占据的宽度越宽，就表示它被抽到的次数多，即执行的时间长。注意，x 轴不代表时间，而是所有的调用栈合并后，按字母顺序排列的。 火焰图就是看顶层的哪个函数占据的宽度最大。只要有 “平顶”（plateaus），就表示该函数可能存在性能问题。 颜色没有特殊含义，因为火焰图表示的是 CPU 的繁忙程度，所以一般选择暖色调。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"火焰图怎么看","slug":"火焰图怎么看","permalink":"https://tianxiafeiyu.github.io/tags/%E7%81%AB%E7%84%B0%E5%9B%BE%E6%80%8E%E4%B9%88%E7%9C%8B/"}]},{"title":"PriorityQueue-优先级队列","slug":"技术开发/java/PriorityQueue-优先级队列","date":"2022-12-15T23:41:31.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/PriorityQueue-优先级队列/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/PriorityQueue-%E4%BC%98%E5%85%88%E7%BA%A7%E9%98%9F%E5%88%97/","excerpt":"","text":"一、什么是优先级队列PriorityQueue类在Java1.5中引入。PriorityQueue是基于优先堆的一个无界队列，这个优先队列中的元素可以默认自然排序或者通过提供的Comparator（比较器）在队列实例化的时排序。要求使用Java Comparable和Comparator接口给对象排序，并且在排序时会按照优先级处理其中的元素。 优先级队列底层的数据结构其实是一棵二叉堆 二、使用1234567891011121314151617181920212223242526272829public class PriorityQueueTest &#123; public static void main(String[] args) &#123; // 不用比较器，默认升序排列，每次出列都是队列中最大元素，相当于小顶堆 Queue&lt;Integer&gt; minHeap = new PriorityQueue&lt;&gt;(); // 降序排列，每次出列都是队列中最小元素，相当于大顶堆 Queue&lt;Integer&gt; maxHeap1 = new PriorityQueue&lt;&gt;((a, b) -&gt; b - a); Queue&lt;Integer&gt; maxHeap2 = new PriorityQueue&lt;&gt;(new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o2 - o1; &#125; &#125;); int[] nums = &#123;1, 7, 3, 9, 5&#125;; for(int num : nums)&#123; minHeap.add(num); // 添加元素 maxHeap1.add(num); maxHeap2.add(num); &#125; int a = minHeap.peek(); // 获得队首元素，不出列 int b = minHeap.poll(); // 获得队首元素并出列，队列为空返回 null int c = minHeap.remove(); // 获得队首元素并出列, 队列为空报错 System.out.println(a + &quot;,&quot; + b + &quot;,&quot; + c); // 1,1,3 System.out.println(maxHeap1.peek() + &quot;,&quot; + maxHeap1.poll() + &quot;,&quot; + maxHeap1.remove()); // 9,9,7 &#125;&#125;","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"PriorityQueue-优先级队列","slug":"PriorityQueue-优先级队列","permalink":"https://tianxiafeiyu.github.io/tags/PriorityQueue-%E4%BC%98%E5%85%88%E7%BA%A7%E9%98%9F%E5%88%97/"}]},{"title":"实体类中用基本类型还是包装类","slug":"技术开发/java/实体类中用基本类型还是包装类","date":"2022-12-15T23:41:31.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/实体类中用基本类型还是包装类/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/%E5%AE%9E%E4%BD%93%E7%B1%BB%E4%B8%AD%E7%94%A8%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B%E8%BF%98%E6%98%AF%E5%8C%85%E8%A3%85%E7%B1%BB/","excerpt":"","text":"Java中基本类型： int、short、byte、long、float、double、char、boolean 对应的包装类： Integer 、Long、Short、Byte、Character、Double、Float、Boolean Java中基本类型 默认初始值 bit byte 0 8 short 0 16 int 0 32 long 0 64 float 0.0 32 double 0.0 64 char ‘ ‘ 16 boolean false 32 对应的包装类 默认初始值 bit Byte null Short null Integer null Long null Float null Double null Character null Boolean null 建模的时候用基本类型还是包装类型呢？个人认为还是包装类的好，原因有下： 数据库null问题，表字段都可能有null，包装类型默认值为null，基本类型不能为null 但是需要注意的是：Integer 的判断问题，需要使用 intValue 方法。 &#x3D;&#x3D; 判断可能会出现许多的问题。S","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"实体类中用基本类型还是包装类","slug":"实体类中用基本类型还是包装类","permalink":"https://tianxiafeiyu.github.io/tags/%E5%AE%9E%E4%BD%93%E7%B1%BB%E4%B8%AD%E7%94%A8%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B%E8%BF%98%E6%98%AF%E5%8C%85%E8%A3%85%E7%B1%BB/"}]},{"title":"混乱的Java版本命名","slug":"技术开发/java/混乱的Java版本命名","date":"2022-12-15T23:41:31.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/混乱的Java版本命名/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/%E6%B7%B7%E4%B9%B1%E7%9A%84Java%E7%89%88%E6%9C%AC%E5%91%BD%E5%90%8D/","excerpt":"","text":"转载自 https://www.cnblogs.com/biggw/p/11776294.html JDK版本与发行时间 版本 名称 发行日期 JDK 1.0 Oak(橡树) 1996-01-23 JDK 1.1 none（无） 1997-02-19 JDK 1.1.4 Sparkler（宝石） 1997-09-12 JDK 1.1.5 Pumpkin（南瓜） 1997-12-13 JDK 1.1.6 Abigail（阿比盖尔–女子名） 1998-04-24 JDK 1.1.7 Brutus（布鲁图–古罗马政治家和将军） 1998-09-28 JDK 1.1.8 Chelsea（切尔西–城市名） 1999-04-08 J2SE 1.2 Playground（运动场） 1998-12-04 J2SE 1.2.1 none（无） 1999-03-30 J2SE 1.2.2 Cricket（蟋蟀） 1999-07-08 J2SE 1.3 Kestrel（美洲红隼） 2000-05-08 J2SE 1.3.1 Ladybird（瓢虫） 2001-05-17 J2SE 1.4.0 Merlin（灰背隼） 2002-02-13 J2SE 1.4.1 grasshopper（蚱蜢） 2002-09-16 J2SE 1.4.2 Mantis（螳螂） 2003-06-26 Java SE 5.0 (1.5.0) Tiger（老虎） 2004-09-30 Java SE 6.0 (1.6.0) Mustang（野马） 2006-04 Java SE 7.0 (1.7.0) Dolphin（海豚） 2011-07-28 Java SE 8.0 (1.8.0) Spider（蜘蛛） 2014-03-18 Java SE 9.0 none（无） 2017-09-21 Java SE 10.0 none（无） 2018-03-21 Java SE 11.0 none（无） 2018-09-25 Java大体有3大类命名方式：JDK、J2SE、JAVA SE。 我们口中说的Java8、JDK8、JDK1.8都是一个东西，JDK(Java Development Kit) Java命名方式更改的事件原因1998年12月8日，Sun公司发布了第二代Java平台（简称为Java2）的3个版本：J2ME（Java2 Micro Edition，Java2平台的微型版），应用于移动、无线及有限资源的环境；J2SE（Java 2 Standard Edition，Java 2平台的标准版），应用于桌面环境；J2EE（Java 2Enterprise Edition，Java 2平台的企业版），应用于基于Java的应用服务器。 2004年9月30日，J2SE1.5发布。为了表示该版本的重要性，J2SE 1.5更名为Java SE 5.0（内部版本号1.5.0） 2005年6月，Java SE 6正式发布。此时，Java的各种版本已经更名，已取消其中的数字2（如J2EE更名为JavaEE，J2SE更名为JavaSE，J2ME更名为JavaME）。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"混乱的Java版本命名","slug":"混乱的Java版本命名","permalink":"https://tianxiafeiyu.github.io/tags/%E6%B7%B7%E4%B9%B1%E7%9A%84Java%E7%89%88%E6%9C%AC%E5%91%BD%E5%90%8D/"}]},{"title":"解读阿里巴巴 Java 代码规范","slug":"技术开发/java/解读阿里巴巴 Java 代码规范","date":"2022-12-15T23:41:31.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/解读阿里巴巴 Java 代码规范/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/%E8%A7%A3%E8%AF%BB%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%20Java%20%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/","excerpt":"","text":"转载自 https://developer.ibm.com/zh/articles/deconding-code-specification-part-1/ 前言2017 年阿里云栖大会，阿里发布了针对 Java 程序员的《阿里巴巴 Java 开发手册（终极版）》，这篇文档作为阿里数千位 Java 程序员的经验积累呈现给公众，并随之发布了适用于 Eclipse 和 Intellim 的代码检查插件。为了能够深入了解 Java 程序员编码规范，也为了深入理解为什么阿里这样规定，是否规定有误，本文以阿里发布的这篇文档作为分析起源，扩大范围至业界其他公司的规范，例如谷歌、FaceBook、微软、百度、华为，并搜索网络上技术大牛发表的技术文章，深入理解每一条规范的设计背景和目标。 由于解读文章仅有两篇，所以按照阿里的篇幅权重分为上篇仅针对 Java 语言本身的编码规约，下篇包含日志管理、异常处理、单元测试、MySQL 规范、工程规范等方面内容进行解读。本文是上篇，主要针对编码规约部分进行解读，由于篇幅限制，仅挑选一小部分进行解读，如果需要全篇，请联系本文作者。 一、编码规约命名风格1. 下划线或者美元符号阿里强制规定代码中的命名均不能以下划线或美元符号开始，也不能以下划线或美元符号结束。 反例：Java_name/__name/$Object/name_/name$/Object$ 我的理解： Oracle 官网建议不要使用$或者开始变量命名，并且建议在命名中完全不要使用”$”字符，原文是”The convention,however,is to always begin your variable names with a letter,not ‘$’ or ‘‘”。对于这一条，腾讯的看法是一样的，百度认为虽然类名可以支持使用”$”符号，但只在系统生成中使用（如匿名类、代理类），编码不能使用。 这类问题在 StackOverFlow 上有很多人提出，主流意见为人不需要过多关注，只需要关注原先的代码是否存在”“，如果存在就继续保留，如果不存在则尽量避免使用。也有一位提出尽量不适用”“的原因是低分辨率的显示器，肉眼很难区分”“（一个下划线）和”_“（两个下划线）。 我个人觉得可能是由于受 C 语言的编码规范所影响。因为在 C 语言里面，系统头文件里将宏名、变量名、内部函数名用开头，因为当你#include 系统头文件时，这些文件里的名字都有了定义，如果与你用的名字冲突，就可能引起各种奇怪的现象。综合各种信息，建议不要使用”“、”$”、空格作为命名开始，以免不利于阅读或者产生奇怪的问题。 2. 类命名阿里强制规定类名使用 UpperCamelCase 风格，必须遵从驼峰形式，但以下情形例外：DO&#x2F;BO&#x2F;DTO&#x2F;VO&#x2F;AO。 正例：MarcoPolo/UserDO/XmlService/TcpUdpDeal/TarPromotion 反例：macroPolo/UserDo/XMLService/TCPUDPD/TAPromotion 我的理解： 百度除了支持阿里的规范以外，规定虽然类型支持”$”符号，但只在系统生成中使用（如匿名类、代理类），编码中不能使用。 对于类名，俄罗斯 Java 专家 Yegor Bugayenko 给出的建议是尽量采用现实生活中实体的抽象，如果类的名字以”-er”结尾，这是不建议的命名方式。他指出针对这一条有一个例外，那就是工具类，例如 StringUtils、FileUtils、IOUtils。对于接口名称，不要使用 IRecord、IfaceEmployee、RedcordInterface，而是使用现实世界的实体命名。如清单 3 所示。 清单 3 示例 1234Class SimpleUser implements User&#123;&#125;;Class DefaultRecord implements Record&#123;&#125;;Class Suffixed implements Name&#123;&#125;;Class Validated implements Content&#123;&#125;; 3. 抽象类的命名阿里强制规定抽象类命名使用 Abstratc 或 Base 开头。 我的理解： Oracle 的抽象类和方法规范并没有要求必须采用 Abstract 或者 Base 开头命名，事实上官网上的示例没有这种命名规范要求，如清单 4 所示。 清单 4 示例： 12345public abstract class GraphicObject&#123; //declare fields //declare nonabstract methods abstract void draw();&#125; 我也查了一下 JDK，确实源码里很多类都是以这样的方式命名的，例如抽象类 java.util.AbstractList。 Stackoverflow 上对于这个问题的解释是，由于这些类不会被使用，一定会由其他的类继承并实现内部细节，所以需要明白地告诉读者这是一个抽象类，那以 Abstract 开头比较合适。 JoshuaBloch的理解是支持以 Abstract 开头。我的理解是不要以 Base 开头命名，因为实际的基类也以 Base 开头居多，这样意义有多样性，不够直观。 常量定义1. 避免魔法值的使用阿里强制规定不允许任何魔法值（未经定义的常量）直接出现在代码中。 反例： 12String key = &quot;Id#taobao_&quot; + tradeId；cache.put(key,value); 我的理解： 魔法值确实让你很疑惑，比如你看下面这个例子： int priceTable[] &#x3D; new int[16];&#x2F;&#x2F;这样定义错误；这个 16 究竟代表什么？ 正确的定义方式是这样的： static final int PRICE_TABLE_MAX &#x3D; 16; &#x2F;&#x2F;这样定义正确，通过使用完整英语单词的常量名明确定义 int price Table[] &#x3D; new int[PRICE_TABLE_MAX]; 魔法值会让代码的可读性大大降低，而且如果同样的数值多次出现时，容易出现不清楚这些数值是否代表同样的含义。另一方面，如果本来应该使用相同的数值，一旦用错，也难以发现。因此可以采用以下两点，极力避免使用魔法数值。 不适用魔法数值，使用带名字的 Static final 或者 enum 值； 原则上 0 不用于魔法值，这是因为 0 经常被用作数组的最小下标或者变量初始化的缺省值。 2. 变量值范围阿里推荐如果变量值仅在一个范围内变化，且带有名称之外的延伸属性，定义为枚举类。下面这个正例中的数字就是延伸信息，表示星期几。 正例： 1public Enum &#123;MONDAY(1),TUESDAY(2),WEDNESDAY(3),THURSDAY(4),FRIDAY(5),SATURDAY(6),SUNDAY(7);&#125; 我的理解： 对于固定并且编译时对象，如 Status、Type 等，应该采用 enum 而非自定义常量实现，enum 的好处是类型更清楚，不会再编译时混淆。这是一个建议性的试用推荐，枚举可以让开发者在 IDE 下使用更方便，也更安全。另外就是枚举类型是一种具有特殊约束的类类型，这些约束的存在使得枚举类本身更加简洁、安全、便捷。 代码格式1. 大括号的使用约定阿里强制规定如果是大括号为空，则简洁地写成{}即可，不需要换行；如果是非空代码块则遵循如下原则： 左大括号前不换行 左大括号后换行 右大括号前换行 右大括号后还有 else 等代码则不换行表示终止的右大括号后必须换行 正例： 1234567try&#123; // try to do...&#125;catch(Exception e)&#123; // do somthing...&#125;finally&#123; // do somthing...&#125; 我的理解： 阿里的这条规定应该是参照了 SUN 公司 1997 年发布的代码规范（SUN 公司是 JAVA 的创始者），Google 也有类似的规定，大家都是遵循 K&amp;R 风格（Kernighan 和 Ritchie），Kernighan 和 Ritchie 在《The C Programming Language》一书中推荐这种风格，JAVA 语言的大括号风格就是受到了 C 语言的编码风格影响。 注意，SUN 公司认为方法名和大括号之间不应该有空格。 2. 单行字符数限制阿里强制规定单行字符数限制不超过 120 个，超出需要换行，换行时遵循如下原则： 第二行相对第一行缩进 4 个空格，从第三行开始，不再继续缩进，参考示例。 运算符与下文一起换行。 方法调用的点符号与下文一起换行。 方法调用时，多个参数，需要换行时，在逗号后进行。 在括号前不要换行，见反例。 正例： 123456StringBuffer sb = new StringBuffer();//超过 120 个字符的情况下，换行缩进 4 个空格，点号和方法名称一起换行sb.append(&quot;zi&quot;).append(&quot;xin&quot;)... .append(&quot;huang&quot;)... .append(&quot;huang&quot;)... .append(&quot;huang&quot;)... 反例： 123456StringBuffer sb = new StringBuffer();//超过 120 个字符的情况下，不要在括号前换行sb.append(&quot;zi&quot;).append(&quot;xin&quot;).append(&quot;huang&quot;);//参数很多的方法调用可能超过 120 个字符，不要在逗号前换行method(args1,args2,args3,....,argsX); 我的理解：SUN 公司 1997 年的规范中指出单行不要超过 80 个字符，对于文档里面的代码行，规定不要超过 70 个字符单行。当表达式不能在一行内显示的时候，遵循以下原则进行切分： 在逗号后换行； 在操作符号前换行； 倾向于高级别的分割； 尽量以描述完整作为换行标准； 如果以下标准造成代码阅读困难，直接采用 8 个空格方式对第二行代码留出空白。 OOP 规约1. 静态变量及方法调用阿里强制规定代码中避免通过一个类的对象引用访问此类的静态变量或静态方法，无谓增加编译器解析成本，直接用类名来访问即可。 我的理解： 谷歌公司在代码规范中指出必须直接使用类名对静态成员进行引用。并同时举例说明，如清单 9 所示。 清单 9 示例： 1234Foo aFoo = …;Foo.aStaticMethod();//goodaFoo.aStaticMethod();//badsomethingThatYieldsAFoo().aStaticMethod();//very bad SUN 公司 1997 年发布的代码规范也做了类似的要求。 为什么需要这样做呢？因为被 static 修饰过的变量或者方法都是随着类的初始化产生的，在堆内存中有一块专门的区域用来存放，后续直接用类名访问即可，避免编译成本的增加和实例对象存放空间的浪费。 StackOverflow 上也有人提出了相同的疑问，网友较为精辟的回复是”这是由于生命周期决定的，静态方法或者静态变量不是以实例为基准的，而是以类为基准，所以直接用类访问，否则违背了设计初衷“。那为什么还保留了实例的访问方式呢？可能是因为允许应用方无污染修改吧。 2. 可变参数编程阿里强制规定相同参数类型、相同业务类型，才可以使用 Java 的可变参数，避免使用 Object，并且要求可变参数必须放置在参数列表的最后（提倡同学们尽量不用可变参数编程）。 我的理解：我们先来了解可变参数的使用方式： 在方法中定义可变参数后，我们可以像操作数组一样操作该参数。 如果该方法除了可变参数还有其他的参数，可变参数必须放到最后。 拥有可变参数的方法可以被重载，在被调用时，如果能匹配到参数定长的方法则优先调用参数定长的方法。 可变参数可以兼容数组参数，但数组参数暂时无法兼容可变参数。 至于为什么可变参数需要被放在最后一个，这是因为参数个数不定，所以当其后还有相同类型参数时，编译器无法区分传入的参数属于前一个可变参数还是后边的参数，所以只能让可变参数位于最后一项。 可变参数编程有一些好处，例如反射、过程建设、格式化等。对于阿里同学提出的尽量不使用可变参数编程，我猜测的原因是不太可控，比如 Java8 推出 Lambda 表达式之后，可变参数编程遇到了实际的实现困难。 并发处理1. 单例模式需要保证线程安全阿里强制要求获取单例对象需要保证线程安全，其中的方法也要保证线程安全，并进一步说明资源驱动类、工具类、单例工厂类都需要注意。 我的理解： 对于这一条规范是通识化规定，我这里进一步讲讲如何做好针对单例对象的线程安全，主要有以下几种方式： 1. 方法中申明 synchronized 关键字 出现非线程安全问题，是由于多个线程可以同时进入 getInstance()方法，那么只需要对该方法进行 synchronized 锁同步即可，如清单 15 所示。 12345678910111213141516171819 // 清单 15 synchronized 关键字方式 public class MySingleton&#123; private static MySingleton instance = null; private MySingleton()&#123;&#125; public synchronized static MySingleton getInstance()&#123; try&#123; if(instance != null)&#123;//懒汉式 &#125;else&#123; //创建实例之前可能会有一些准备性的耗时工作 Thread.sleep(500); Instance = new MySingleton(); &#125; &#125;catch(InterruptedException e)&#123; e.printStackTrace(); &#125; return instance; &#125;&#125; 从执行结果上来看，多线程访问的问题已经解决了，返回的是一个实例。但是这种实现方式的运行效率很低。我们接下来采用同步方法块实现。 2. 2. 同步方法块实现 1234567891011121314151617181920public class MySingleton &#123; private static MySingleton instance = null; private MySingleton()&#123;&#125; public static MySingleton getInstance() &#123; try &#123; synchronized (MySingleton.class) &#123; if(instance != null)&#123;//懒汉式 &#125;else&#123; //创建实例之前可能会有一些准备性的耗时工作 Thread.sleep(300); instance = new MySingleton(); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return instance; &#125; &#125; 这里的实现能够保证多线程并发下的线程安全性，但是这样的实现将全部的代码都被锁上了，同样的效率很低下。 3. 针对某些重要的代码来进行单独的同步: 针对某些重要的代码进行单独的同步，而不是全部进行同步，可以极大的提高执行效率。 1234567891011121314151617181920public class MySingleton &#123; private static MySingleton instance = null; private MySingleton()&#123;&#125; public static MySingleton getInstance() &#123; try &#123; if(instance != null)&#123;//懒汉式 &#125;else&#123; //创建实例之前可能会有一些准备性的耗时工作 Thread.sleep(300); synchronized (MySingleton.class) &#123; instance = new MySingleton(); &#125; &#125; &#125;catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return instance; &#125; &#125; 从运行结果来看，这样的方法进行代码块同步，代码的运行效率是能够得到提升，但是却没能保住线程的安全性。看来还得进一步考虑如何解决此问题。 4. 双检查锁机制（Double Check Locking） 为了达到线程安全，又能提高代码执行效率，我们这里可以采用 DCL 的双检查锁机制来完成。 1234567891011121314151617181920212223public class MySingleton &#123; //使用 volatile 关键字保其可见性 volatile private static MySingleton instance = null; private MySingleton()&#123;&#125; public static MySingleton getInstance() &#123; try &#123; if(instance != null)&#123;//懒汉式 &#125;else&#123; //创建实例之前可能会有一些准备性的耗时工作 Thread.sleep(300); synchronized (MySingleton.class) &#123; if(instance == null)&#123;//二次检查 instance = new MySingleton(); &#125; &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return instance; &#125; &#125; 这里在声明变量时使用了 volatile 关键字来保证其线程间的可见性；在同步代码块中使用二次检查，以保证其不被重复实例化。集合其二者，这种实现方式既保证了其高效性，也保证了其线程安全性。 5. 静态内置类方式 DCL 解决了多线程并发下的线程安全问题，其实使用其他方式也可以达到同样的效果 123456789101112public class MySingleton &#123; //内部类 private static class MySingletonHandler&#123; private static MySingleton instance = new MySingleton(); &#125; private MySingleton()&#123;&#125; public static MySingleton getInstance() &#123; return MySingletonHandler.instance; &#125; &#125; 6. 序列化与反序列化方式 静态内部类虽然保证了单例在多线程并发下的线程安全性，但是在遇到序列化对象时，默认的方式运行得到的结果就是多例的。 123456789101112131415import java.io.Serializable; public class MySingleton implements Serializable &#123; private static final long serialVersionUID = 1L; //内部类 private static class MySingletonHandler&#123; private static MySingleton instance = new MySingleton(); &#125; private MySingleton()&#123;&#125; public static MySingleton getInstance() &#123; return MySingletonHandler.instance; &#125; &#125; 7. 使用枚举数据类型方式 枚举 enum 和静态代码块的特性相似，在使用枚举时，构造方法会被自动调用，利用这一特性也可以实现单例。 1234567891011121314151617public enum EnumFactory&#123; singletonFactory; private MySingleton instance; private EnumFactory()&#123;//枚举类的构造方法在类加载是被实例化 instance = new MySingleton(); &#125; public MySingleton getInstance()&#123; return instance; &#125; &#125; class MySingleton&#123;//需要获实现单例的类，比如数据库连接 Connection public MySingleton()&#123;&#125; &#125; 这样写枚举类被完全暴露了，据说违反了”职责单一原则”，我们可以按照下面的代码改造。 12345678910111213141516171819202122public class ClassFactory&#123; private enum MyEnumSingleton&#123; singletonFactory; private MySingleton instance; private MyEnumSingleton()&#123;//枚举类的构造方法在类加载是被实例化 instance = new MySingleton(); &#125; public MySingleton getInstance()&#123; return instance; &#125; &#125; public static MySingleton getInstance()&#123; return MyEnumSingleton.singletonFactory.getInstance(); &#125; &#125; class MySingleton&#123;//需要获实现单例的类，比如数据库连接 Connection public MySingleton()&#123;&#125; &#125; 不太理解这种写法，为什么不直接把单例类改成枚举呢？？（2020.11.12） 1234567public enum MySingleton&#123; instance; private MySingleton()&#123; &#125; &#125; 控制语句1. Switch 语句的使用阿里强制规定在一个 switch 块内，每个 case 要么通过 break&#x2F;return 等来终止，要么注释说明程序将继续执行到哪一个 case 为止；在一个 switch 块内，都必须包含一个 default 语句并且放在最后，即使它什么代码也没有。 我的理解： 首先理解前半部分，”每个 case 要么通过 break&#x2F;return 等来终止，要么注释说明程序将继续执行到哪一个 case 为止”。因为这样可以比较清楚地表达程序员的意图，有效防止无故遗漏的 break 语句。default 语句里面也应该有 break&#x2F;return。 集合处理1. 集合转数组处理阿里强制规定使用集合转数组的方法，必须使用集合的 toArray(T[] arrays)，传入的是类型完全一样的数组，大小就是 list.size()。使用 toArray 带参方法，入参分配的数组空间不够大时，toArray 方法内部将重新分配内存空间，并返回新数组地址；如果数组元素大于实际所需，下标为[list.size()]的数组元素将被置为 null，其它数组元素保持原值，因此最好将方法入参数组大小定义与集合元素个数一致。正例如清单 25 所示。 清单 25 正例： 12345List&lt;String&gt; list = new ArrayList&lt;String&gt;(2);list.add(&quot;guan&quot;);list.add(&quot;bao&quot;);String[] array = new String[list.size()];array = list.toArray(array); 注释规约1. 方法注释要求阿里强制要求方法内部单行注释，在被注释语句上方另起一行，使用&#x2F;&#x2F;注释。方法内部多行注释使用&#x2F;**&#x2F;注释，注意与代码对照。 我的理解： 百度规定方法注释采用标准的 Javadoc 注释规范，注释中必须提供方法说明、参数说明及返回值和异常说明。腾讯规定采用 JavaDoc 文档注释，在方法定义之前应该对其进行注释，包括方法的描述、输入、输出以及返回值说明、抛出异常说明、参考链接等。 其他1. 数据结构初始化大小阿里推荐任何数据结构的构造或初始化，都应指定大小，避免数据结构暂时无限增长吃光内存。 我的理解： 首先明确一点，阿里这里指的大小具体是指数据结构的最大长度。大部分 Java 集合类在构造时指定的大小都是初始尺寸（initial Capacity），而不是尺寸上限（Capacity），只有几种队列除外，例如 ArrayBlockingQueue、LinkedBlockingQueue，它们在构造时可以指定队列的最大长度。阿里推荐的目的是为了合理规划内存，避免出现 OOM（Out of Memory）异常。 异常处理1. 不要捕获 RuntimeException阿里强制规定 Java 类库中的 RuntimeException 可以通过预先检查进行规避，而不应该通过 catch 来处理，例如 IndexOutOfBoundsException、NullPointerException 等。 我的理解： RuntimeException，也被称为运行时异常，通常是由于代码中的 bug 引起的，正确的处理方式是去检查代码，通过添加数据长度判断，判断对象是否为空等方法区规避，而不是靠捕获来规避这种异常。 2. 事务中的异常需要回滚阿里强制规定有 try 块放到了事务代码中，catch 异常后，如果需要回滚事务，一定要注意手动回滚事务。 我的理解： try catch 代码块中对异常的处理，可能会遗漏事务的一致性，当事务控制不使用其他框架管理时，事务需要手动回滚。实际使用如果引入第三方的框架对事务进行管理，比如 Spring，则根据第三方框架的实际实现情况，确定是否有必要手动回滚。当第三方事务管理框架本身就会对于异常进行抛出时需要做事务回滚。例如 Spring 在@Transactional 的 annotation 注解下，会默认开启运行时异常事务回滚。 3. 不能在 finally 块中使用 return阿里强制要求 finally 块中不使用 return，因为执行完该 return 后方法结束执行，不会再执行 try 块中的 return 语句。 我的理解： 在try-catch-finally中, 当return遇到finally，return对finally无效，即:1.在try catch块里return的时候，finally也会被执行。2.finally里的return语句会把try catch块里的return语句效果给覆盖掉。 return语句并不一定都是函数的出口，执行return时，只是把return后面的值复制了一份到返回值变量里去了。所以在finally有return时，会覆盖掉try-catch中的return。 finally语句是不是总会被执行？ 答案是否。以下情况finally语句不会执行： try语句没有被执行到，如在try语句之前return就返回了，这样finally语句就不会执行。这也说明了finally语句被执行的必要而非充分条件是：相应的try语句一定被执行到。 在try块|catch块中有System.exit(0);这样的语句。System.exit(0)是终止Java虚拟机JVM的，连JVM都停止了，所有都结束了，当然finally语句也不会被执行到。 日志规约1. 不可直接使用日志系统阿里强制规定应用中不可直接使用日志系统（Log4j、Logback）中的 API，而应依赖使用日志框架 SLF4J 中的 API，使用门面模式的日志框架，有利于维护和各个类的日志处理方式统一。 我的理解： SLF4J 即简单日志门面模式，不是具体的日志解决方案，它只服务于各种各样的日志系统。在使用 SLF4J 时不需要指定哪个具体的日志系统，只需要将使用到的具体日志系统的配置文件放到类路径下去。 正例代码： 123456789import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HelloWorld&#123; private static final Logger logger = LoggerFactory.getLogger(HelloWorld.class); public static void main(String[] args)&#123; logger.info(&quot;please use SLF4J,rather than logback or log4j&quot;); &#125;&#125; 反例代码： 12345678import org.apache.log4j.Logger;public class HelloWorld&#123; private static final Logger logger = LoggerFactory.getLogger(HelloWorld.class); public static void main(String[] args)&#123; logger.info(&quot;please use SLF4J,rather than logback or log4j&quot;); &#125;&#125; 2. 日志文件保留时间阿里强制规定日志文件至少保存 15 天，因为有些异常具备以”周”为频次发生的特点。 我的理解： 日志保留时间推荐 15 天以上，但是保留时间也不宜过长，一般不超过 21 天，否则造成硬盘空间的浪费。对于一些长周期性执行的逻辑，可以根据实际情况调整该保存时间，同时也需要保证日志能够监控到关键的应用。 对于长周期执行的逻辑，可以使用特定的 appender，并使用不同的日志清理规则，如时间、大小等。如一月执行一次的定时任务，可以将日志输出到新的日志文件，然后通过大小限定的规则进行清理，并不一定要使用时间清理的逻辑。 安全规约1. 权限控制校验阿里强制要求对于隶属于用户个人的页面或者功能必须进行权限控制校验。 我的理解： 涉及到对于数据的增删改查，必须有权限的控制和校验，要有一个黑白名单的控制，不能依赖于前台页面的简单控制，后台要有对于完整的权限控制的实现。这样就能尽可能地防治数据的错误修改。 2. 用户传入参数校验阿里强制要求用户请求传入的任何参数必须做有效校验。 我的理解： 对于用户输入的任何参数，前端页面上都必须要做一定的有效性校验，并且在数据发送至服务器的时候在页面上给出验证结果提示，那么在用户请求传入的任务参数，后台同样也要对其有效性进行验证，防止前端页面未能过滤或者暂时无法验证的错误参数。忽略参数的验证会导致的问题很多，page size 过大会导致内存溢出、SQL 溢出等，只有验证才能尽可能地减少这些问题的出现，进而减少错误的排查几率。 所以说在前端已经做了参数校验的情况下，后端也有必要做参数校验。 单元测试1. 单元测试应该自动执行阿里强制单元测试应该是全自动执行的，并且非交互式的。测试框架通常是定期执行的，执行过程必须完全自动化才有意义。输出结果需要人工检查的测试不是一个号的单元测试。单元测试中不准使用 System.out 来进行人肉验证，必须使用 assert 来验证。 我的理解： 这条原则比较容易理解。单元测试是整个系统的最小测试单元，针对的是一个类中一个方法的测试，如果这些测试的结果需要人工校验是否正确，那么对于验证人来说是一项痛苦而且耗时的工作。另外，单元测试作为系统最基本的保障，需要在修改代码、编译、打包过程中都会运行测试用例，保障基本功能，自动化的测试是必要条件。其实自动化测试不仅是单元测试特有的，包括集成测试、系统测试等，都在慢慢地转向自动化测试，以降低测试的人力成本。 2. 单元测试应该是独立的阿里强制保持单元测试的独立性。为了保证单元测试稳定可靠且便于维护，单元测试用例之间决不能互相调用，也不能依赖执行的先后次序。 反例：method2 需要依赖 method1 的执行，将执行结果作为 method2 的输入。 我的理解： 单元测试作为系统的最小测试单元，主要目的是尽可能早地测试编写的代码，降低后续集成测试期间的测试成本，以及在运行测试用例的时候能够快速地定位到对应的代码段并解决相关问题。 我们假设这么一个场景，method1 方法被 10 个其他 method 方法调用，如果 10 个 method 方法的测试用例都需要依赖 method1，那么当 methdo1 被修改导致运行出错的情况下，会导致 method1 以及依赖它的 10 个 method 的所有测试用例报错，这样就需要排查这 11 个方法到底哪里出了问题，这与单元测试的初衷不符，也会大大的增加排查工作量，所以单元测试必须是独立的，不会因为受到外部修改（这里的修改包括了依赖方法的修改以及外部环境的修改），编写单元测试时遇到的这类依赖可以使用 mock 来模拟输入和期望的返回，这样所以来的方法内部逻辑的变更就不会影响到外部的实现。 3. BCDE 原则阿里推荐编写单元测试代码遵守 BCDE 原则，以保证被测试模块的交付质量。 我的理解： BCDE 原则逐一解释如下： B（Border）：确保参数边界值均被覆盖。 例如：对于数字，测试负数、0、正数、最小值、最大值、NaN（非数字）、无穷大值等。对于字符串，测试空字符串、单字符、非 ASCII 字符串、多字节字符串等。对于集合类型，测试空、第一个元素、最后一个元素等。对于日期，测试 1 月 1 日、2 月 29 日、12 月 31 日等。被测试的类本身也会暗示一些特定情况下的边界值。对于边界情况的测试一定要详尽。 C（Connect）：确保输入和输出的正确关联性。 例如，测试某个时间判断的方法 boolean inTimeZone(Long timeStamp)，该方法根据输入的时间戳判断该事件是否存在于某个时间段内，返回 boolean 类型。如果测试输入的测试数据为 Long 类型的时间戳，对于输出的判断应该是对于 boolean 类型的处理。如果测试输入的测试数据为非 Long 类型数据，对于输出的判断应该是报错信息是否正确。 D（Design）：任务程序的开发包括单元测试都应该遵循设计文档。 E（Error）：单元测试包括对各种方法的异常测试，测试程序对异常的响应能力。 除了这些解释之外，《单元测试之道（Java 版）》这本书里面提到了关于边界测试的 CORRECT 原则： 一致性（Conformance）：值是否符合预期格式（正常的数据），列出所有可能不一致的数据，进行验证。 有序性（Ordering）：传入的参数的顺序不同的结果是否正确，对排序算法会产生影响，或者是对类的属性赋值顺序不同会不会产生错误。 区间性（Range）：参数的取值范围是否在某个合理的区间范围内。 引用&#x2F;耦合性（Reference）：程序依赖外部的一些条件是否已满足。前置条件：系统必须处于什么状态下，该方法才能运行。后置条件，你的方法将会保证哪些状态发生改变。 存在性（Existence）：参数是否真的存在，引用为 Null，String 为空，数值为 0 或者物理介质不存在时，程序是否能正常运行。 基数性（Cardinality）：考虑以”0-1-N 原则”，当数值分别为 0、1、N 时，可能出现的结果，其中 N 为最大值。 时间性（Time）：相对时间指的是函数执行的依赖顺序，绝对时间指的是超时问题、并发问题。 数据库表设计1. 建表的是与否规则阿里强制要求如果遇到需要表达是与否的概念时，必须使用 is_xxx 的方法命令，数据类型是 unsigned tinyint，1 表示是，0 表示否。 说明：任务字段如果为非负数，必须是 unsigned。 正例：表达逻辑删除的字段名 is_deleted，1 表示删除，0 表示未删除。 我的理解： 命名使用 is_xxx 第一个好处是比较清晰的，第二个好处是使用者根据命名就可以知道这个字段的取值范围，也方便做参数验证。 类型使用 unsigned 的好处是如果只存整数，unsigned 类型有更大的取值范围，可以节约磁盘和内存使用。 对于表的名字，MySQL 社区有自己推荐的命名规范： 表包含多个英文单词时，需要用下划线进行单词分割，这一点类似于 Java 类名的命名规范，例如 master_schedule、security_user_permission；由于 InnoDB 存储引擎本身是针对操作系统的可插拔设计的，所以原则上所有的表名组成全部由小写字母组成；不允许出现空格，需要分割一律采用下划线；名字不允许出现数字，仅包含英文字母；名字需要总长度少于 64 个字符。 2. 数据类型精度考量阿里强制要求存放小数时使用 decimal，禁止使用 float 和 double。 说明：float 和 double 在存储的时候，存在精度损失的问题，很可能在值的比较时，得到不正确的结果。如果存储的数据范围超过 decimal 的范围，建议将数据拆成整数和小数分开存储。 我的理解： 我们先来看看各个精度的范围。 Float：浮点型，4 字节数 32 位，表示数据范围-3.4E38~3.4E38 Double：双精度型，8 字节数 64 位，表示数据范围-1.7E308~1.7E308 Decimal：数字型，16 字节数 128 位，不存在精度损失，常用于银行账目计算 在精确计算中使用浮点数是非常危险的，在对精度要求高的情况下，比如银行账目就需要使用 Decimal 存储数据。 实际上，所有涉及到数据存储的类型定义，都会涉及数据精度损失问题。Java 的数据类型也存在 float 和 double 精度损失情况，阿里没有指出这条规约，就全文来说，这是一个比较严重的规约缺失。 Joshua Bloch（著名的 Effective Java 书作者）认为，float 和 double 这两个原生的数据类型本身是为了科学和工程计算设计的，它们本质上都采用单精度算法，也就是说在较宽的范围内快速获得精准数据值。但是，需要注意的是，这两个原生类型都不保证也不会提供很精确的值。单精度和双精度类型特别不适用于货币计算，因为不可能准确地表示 0.1（或者任何其他十的负幂）。 我们再来看一个实际的例子。假设你有 1 块钱，现在每次购买蛋糕的价格都会递增 0.10 元，为我们一共可以买几块蛋糕。口算一下，应该是 4 块（因为 0.1+0.2+0.3+0.4&#x3D;1.0），我们写个程序验证看看，如下所示。 1234567891011121314151617181920212223242526//错误的方式double funds1 = 1.00;int itemsBought = 0;for(double price = .10;funds&gt;=price;price+=.10)&#123; funds1 -=price; itemsBought++;&#125; System.out.println(itemsBought+&quot; items boughts.&quot;); System.out.println(&quot;Changes:&quot;+funds1); // 3 items boughts.// Changes:0.3999999999999999 //正确的方式 final BigDecimal TEN_CENTS = new BigDecimal(&quot;.10&quot;); itemsBought = 0; BigDecimal funds2 = new BigDecimal(&quot;1.00&quot;);for(BigDecimal price = TEN_CENTS;funds2.compareTo(price)&gt;0;price = price.add(TEN_CENTS))&#123; fund2 = fund2.substract(price); itemsBought++; &#125; System.out.println(itemsBought+&quot; items boughts.&quot;); System.out.println(&quot;Changes:&quot;+funds2);// 4 items boughts.// Changes:0.00 这里我们可以看到使用了 BigDecimal 解决了问题，实际上 int、long 也可以解决这类问题。采用 BigDecimal 有一个缺点，就是使用过程中没有原始数据这么方便，效率也不高。如果采用 int 方式，最好不要在有小数点的场景下使用，可以在 100、10 这样业务场景下选择使用。 3. 使用 Char阿里强制要求如果存储的字符串长度几乎相等，使用 Char 定长字符串类型。 我的理解： 从性能上分析，character(n)通常是最慢的，在大多数情况下，应该使用 text 或者 character varying。 工程结构1. 服务间依赖关系阿里推荐默认上层依赖于下层，箭头关系表示可直接依赖，如：Controller层可以依赖于 Web 层，也可以直接依赖于 Service 层。 我的理解： 《软件架构模式》一书中介绍了分层架构思想： 分层架构是一种很常见的架构模式，它也被叫做 N 层架构。这种架构是大多数 Java EE 应用的实际标准。许多传统 IT 公司的组织架构和分层模式十分的相似，所以它很自然地成为大多数应用的架构模式。 分层架构模式里的组件被分成几个平行的层次，每一层都代表了应用的一个功能（展示逻辑或者业务逻辑）。尽管分层架构没有规定自身要分成几层几种，大多数的结构都分成四个层次，即展示层、业务层、持久层和数据库层。业务层和持久层有时候可以合并成单独的一个业务层，尤其是持久层的逻辑绑定在业务层的组件当中。因此，有一些小的应用可能只有三层，一些有着更复杂的业务的大应用可能有五层甚至更多的层。 分层架构中的每一层都有着特定的角色和职能。举个例子，展示层负责所有的界面展示以及交互逻辑，业务层负责处理请求对应的业务。架构里的层次是具体工作的高度抽象，它们都是为了实现某种特定的业务请求。比如说展示层并不关心如何得到用户数据，它只需在屏幕上以特定的格式展示信息。业务层并不关心要展示在屏幕上的用户数据格式，也不关心这些用户数据从哪里来，它只需要从持久层得到数据，执行与数据有关的相应业务逻辑，然后把这些信息传递给展示层。 分层架构的一个突出特性地组件间关注点分离。一个层中的组件只会处理本层的逻辑。比如说，展示层的组件只会处理展示逻辑，业务层中的组件只会去处理业务逻辑。因为有了组件分离设计方式，让我们更容易构造有效的角色和强力的模型，这样应用变得更好开发、测试、管理和维护。 2. 高并发服务器 time_wait阿里推荐高并发服务器建议调小 TCP 协议的 time_wait 超时时间。 说明：操作系统默认 240 秒后才会关闭处于 time_wait 状态的连接，在高并发访问下，服务器端会因为处于 time_wait 的连接数太多，可能无法建立新的连接，所以需要在服务器上调小此等待值。 正例：在 Linux 服务器上通过变更&#x2F;etc&#x2F;sysctl.conf 文件去修改该缺省值（秒）：net.ipv4.tcp_fin_timeout&#x3D;30 我的理解： 服务器在处理完客户端的连接后，主动关闭，就会有 time_wait 状态。TCP 连接是双向的，所以在关闭连接的时候，两个方向各自都需要关闭。先发 FIN 包的一方执行的是主动关闭，后发 FIN 包的一方执行的是被动关闭。主动关闭的一方会进入 time_wait 状态，并且在此状态停留两倍的 MSL 时长。 主动关闭的一方收到被动关闭的一方发出的 FIN 包后，回应 ACK 包，同时进入 time_wait 状态，但是因为网络原因，主动关闭的一方发送的这个 ACK 包很可能延迟，从而触发被动连接一方重传 FIN 包。极端情况下，这一去一回就是两倍的 MSL 时长。如果主动关闭的一方跳过 time_wait 直接进入 closed，或者在 time_wait 停留的时长不足两倍的 MSL，那么当被动关闭的一方早于先发出的延迟包达到后，就可能出现类似下面的问题： 旧的 TCP 连接已经不存在了，系统此时只能返回 RST 包 新的 TCP 连接被建立起来了，延迟包可能干扰新的连接 不管是哪种情况都会让 TCP 不再可靠，所以 time_wait 状态有存在的必要性。 修改 net.ipv4.tcp_fin_timeout 也就是修改了 MSL 参数。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"解读阿里巴巴 Java 代码规范","slug":"解读阿里巴巴-Java-代码规范","permalink":"https://tianxiafeiyu.github.io/tags/%E8%A7%A3%E8%AF%BB%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4-Java-%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"}]},{"title":"TCP 协议灵魂 12 问 【转】","slug":"技术开发/os/TCP 协议灵魂 12 问 【转】","date":"2022-12-15T23:41:00.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/os/TCP 协议灵魂 12 问 【转】/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/os/TCP%20%E5%8D%8F%E8%AE%AE%E7%81%B5%E9%AD%82%2012%20%E9%97%AE%20%E3%80%90%E8%BD%AC%E3%80%91/","excerpt":"","text":"转载自 https://my.oschina.net/u/4192546/blog/4644900 01. 能不能说一说 TCP 和 UDP 的区别？基本区别： TCP是一个面向连接的、可靠的、基于字节流的传输层协议。 而UDP是一个面向无连接的传输层协议。(就这么简单，其它TCP的特性也就没有了)。 具体分析： 和 UDP 相比，TCP 有三大核心特性: 面向连接。所谓的连接，指的是客户端和服务器的连接，在双方互相通信之前，TCP 需要三次握手建立连接，而 UDP 没有相应建立连接的过程。 可靠性。TCP 花了非常多的功夫保证连接的可靠，这个可靠性体现在哪些方面呢？一个是有状态，另一个是可控制。TCP 会精准记录哪些数据发送了，哪些数据被对方接收了，哪些没有被接收到，而且保证数据包按序到达，不允许半点差错。这是有状态。当意识到丢包了或者网络环境不佳，TCP 会根据具体情况调整自己的行为，控制自己的发送速度或者重发。这是可控制。相应的，UDP 就是无状态, 不可控的。 面向字节流。UDP 的数据传输是基于数据报的，这是因为仅仅只是继承了 IP 层的特性，而 TCP 为了维护状态，将一个个 IP 包变成了字节流。 02. 说说 TCP 三次握手的过程？为什么是三次而不是两次、四次？TCP 的三次握手，目的是确认双方的两样能力: 发送的能力和接收的能力。 客户端：“喂，能听到我说话吗” 服务端：“我能听到，你能听到我吗” 客户端：“能听到” 从图中可以看出，SYN （同步序列标志 Synchronize Sequence Numbers）是需要消耗一个序列号的，下次发送对应的 ACK（确认标志 Acknowledgement Number） 序列号要加1，为什么呢？只需要记住一个规则: 凡是需要对端确认的，一定消耗TCP报文的序列号。 SYN 需要对端的确认， 而 ACK 并不需要，因此 SYN 消耗一个序列号而 ACK 不需要。 为什么不是两次？ 根本原因: 无法确认客户端的接收能力。 分析如下: 如果是两次，你现在发了 SYN 报文想握手，但是这个包滞留在了当前的网络中迟迟没有到达，TCP 以为这是丢了包，于是重传，两次握手建立好了连接。 看似没有问题，但是连接关闭后，如果这个滞留在网路中的包到达了服务端呢？这时候由于是两次握手，服务端只要接收到然后发送相应的数据包，就默认建立连接，但是现在客户端已经断开了。 看到问题的吧，这就带来了连接资源的浪费。 为什么不是四次？ 三次握手的目的是确认双方发送和接收的能力，那四次握手可以嘛？ 当然可以，100 次都可以。但为了解决问题，三次就足够了，再多用处就不大了。 三次握手过程中可以携带数据么？ 第三次握手的时候，可以携带。前两次握手不能携带数据。 如果前两次握手能够携带数据，那么一旦有人想攻击服务器，那么他只需要在第一次握手中的 SYN 报文中放大量数据，那么服务器势必会消耗更多的时间和内存空间去处理这些数据，增大了服务器被攻击的风险。 第三次握手的时候，客户端已经处于ESTABLISHED状态，并且已经能够确认服务器的接收、发送能力正常，这个时候相对安全了，可以携带数据。 03. 说说 TCP 四次挥手的过程 客户端：我好了。 服务端：收到。 服务端：我也好了。 客户端：收到。 需要注意的是，第4步客户端发送确认响应给服务端后，连接并不会马上断开。客户端需要等待足够长的时间，具体来说，是 2 个 MSL(Maximum Segment Lifetime，报文最大生存时间), 在这段时间内如果客户端没有收到服务端的重发请求，那么表示 ACK 成功到达，挥手结束，否则客户端重发 ACK。 等待2MSL的意义 如果不等待会怎样？ 如果不等待，客户端直接跑路，当服务端还有很多数据包要给客户端发，且还在路上的时候，若客户端的端口此时刚好被新的应用占用，那么就接收到了无用数据包，造成数据包混乱。所以，最保险的做法是等服务器发来的数据包都死翘翘再启动新的应用。 那，照这样说一个 MSL 不就不够了吗，为什么要等待 2 MSL? 1 个 MSL 确保四次挥手中主动关闭方最后的 ACK 报文最终能达到对端1 个 MSL 确保对端没有收到 ACK 重传的 FIN 报文可以到达 这就是等待 2MSL 的意义。为什么是四次挥手而不是三次？ 因为服务端在接收到FIN, 往往不会立即返回FIN, 必须等到服务端所有的报文都发送完毕了，才能发FIN。因此先发一个ACK表示已经收到客户端的FIN，延迟一段时间才发FIN。这就造成了四次挥手。 如果是三次挥手会有什么问题？ 等于说服务端将ACK和FIN的发送合并为一次挥手，这个时候长时间的延迟可能会导致客户端误以为FIN没有到达客户端，从而让客户端不断的重发FIN。 04. 说说半连接队列和 SYN Flood 攻击的关系三次握手前，服务端的状态从CLOSED变为LISTEN, 同时在内部创建了两个队列：半连接队列和全连接队列，即SYN队列和ACCEPT队列。 半连接队列 当客户端发送SYN到服务端，服务端收到以后回复ACK和SYN，状态由LISTEN变为SYN_RCVD，此时这个连接就被推入了SYN队列，也就是半连接队列。 全连接队列 当客户端返回ACK, 服务端接收后，三次握手完成。这个时候连接等待被具体的应用取走，在被取走之前，它会被推入另外一个 TCP 维护的队列，也就是全连接队列(Accept Queue)。 SYN Flood 攻击原理 SYN Flood 属于典型的 DoS&#x2F;DDoS 攻击。其攻击的原理很简单，就是用客户端在短时间内伪造大量不存在的 IP 地址，并向服务端疯狂发送SYN。对于服务端而言，会产生两个危险的后果: 处理大量的SYN包并返回对应ACK, 势必有大量连接处于SYN_RCVD状态，从而占满整个半连接队列，无法处理正常的请求。 由于是不存在的 IP，服务端长时间收不到客户端的ACK，会导致服务端不断重发数据，直到耗尽服务端的资源。 如何应对 SYN Flood 攻击？ 增加 SYN 连接，也就是增加半连接队列的容量。 减少 SYN + ACK 重试次数，避免大量的超时重发。 利用 SYN Cookie 技术，在服务端接收到SYN后不立即分配连接资源，而是根据这个SYN计算出一个Cookie，连同第二次握手回复给客户端，在客户端回复ACK的时候带上这个Cookie值，服务端验证 Cookie 合法之后才分配连接资源。 05. 介绍一下 TCP 报文头部的字段报文头部结构如下(单位为字节): 源端口、目标端口 如何标识唯一标识一个连接？答案是 TCP 连接的四元组——源 IP、源端口、目标 IP 和目标端口。 那 TCP 报文怎么没有源 IP 和目标 IP 呢？这是因为在 IP 层就已经处理了 IP 。TCP 只需要记录两者的端口即可。 序列号 即Sequence number, 指的是本报文段第一个字节的序列号。 从图中可以看出，序列号是一个长为 4 个字节，也就是 32 位的无符号整数，表示范围为 0 ~ 2^32 - 1。如果到达最大值了后就循环到0。 序列号在 TCP 通信的过程中有两个作用: 在 SYN 报文中交换彼此的初始序列号。保证数据包按正确的顺序组装。 ISN 即Initial Sequence Number（初始序列号）,在三次握手的过程当中，双方会用过SYN报文来交换彼此的 ISN。 ISN 并不是一个固定的值，而是每 4 ms 加一，溢出则回到 0，这个算法使得猜测 ISN 变得很困难。那为什么要这么做？ 如果 ISN 被攻击者预测到，要知道源 IP 和源端口号都是很容易伪造的，当攻击者猜测 ISN 之后，直接伪造一个 RST 后，就可以强制连接关闭的，这是非常危险的。 而动态增长的 ISN 大大提高了猜测 ISN 的难度。 确认号 即ACK(Acknowledgment number)。用来告知对方下一个期望接收的序列号，小于ACK的所有字节已经全部收到。 标记位 常见的标记位有SYN,ACK,FIN,RST,PSH。 SYN 和 ACK 已经在上文说过，后三个解释如下: FIN：即 Finish，表示发送方准备断开连接。 RST：即 Reset，用来强制断开连接。 PSH：即 Push, 告知对方这些数据包收到后应该马上交给上层的应用，不能缓存。 窗口大小 占用两个字节，也就是 16 位，但实际上是不够用的。因此 TCP 引入了窗口缩放的选项，作为窗口缩放的比例因子，这个比例因子的范围在 0 ~ 14，比例因子可以将窗口的值扩大为原来的 2 ^ n 次方。 校验和 占用两个字节，防止传输过程中数据包有损坏，如果遇到校验和有差错的报文，TCP 直接丢弃之，等待重传。 可选项 可选项的格式如下: 在这里插入图片描述 常用的可选项有以下几个: TimeStamp: TCP 时间戳，后面详细介绍。 MSS: 指的是 TCP 允许的从对方接收的最大报文段。 SACK: 选择确认选项。 Window Scale：窗口缩放选项。 06. 说说 TCP 快速打开的原理(TFO)第一节讲了 TCP 三次握手，可能有人会说，每次都三次握手好麻烦呀！能不能优化一点？ 可以啊。今天来说说这个优化后的 TCP 握手流程，也就是 TCP 快速打开(TCP Fast Open, 即TFO)的原理。 优化的过程是这样的，还记得我们说 SYN Flood 攻击时提到的 SYN Cookie 吗？这个 Cookie 可不是浏览器的Cookie, 用它同样可以实现 TFO。 TFO 流程 首轮三次握手 首先客户端发送SYN给服务端，服务端接收到。 注意哦！现在服务端不是立刻回复 SYN + ACK，而是通过计算得到一个SYN Cookie, 将这个Cookie放到 TCP 报文的 Fast Open选项中，然后才给客户端返回。 客户端拿到这个 Cookie 的值缓存下来。后面正常完成三次握手。 首轮三次握手就是这样的流程。而后面的三次握手就不一样啦！ 后面的三次握手 在后面的三次握手中，客户端会将之前缓存的 Cookie、SYN 和HTTP请求(是的，你没看错)发送给服务端，服务端验证了 Cookie 的合法性，如果不合法直接丢弃；如果是合法的，那么就正常返回SYN + ACK。 重点来了，现在服务端能向客户端发 HTTP 响应了！这是最显著的改变，三次握手还没建立，仅仅验证了 Cookie 的合法性，就可以返回 HTTP 响应了。 当然，客户端的ACK还得正常传过来，不然怎么叫三次握手嘛。 注意：客户端最后握手的 ACK 不一定要等到服务端的 HTTP 响应到达才发送，两个过程没有任何关系。 TFO 的优势 TFO 的优势并不在与首轮三次握手，而在于后面的握手，在拿到客户端的 Cookie 并验证通过以后，可以直接返回 HTTP 响应，充分利用了1 个RTT(Round-Trip Time，往返时延)的时间提前进行数据传输，积累起来还是一个比较大的优势。 07. 能不能说说TCP报文中时间戳的作用？timestamp是 TCP 报文首部的一个可选项，一共占 10 个字节，格式如下: kind(1 字节) + length(1 字节) + info(8 个字节) 其中 kind &#x3D; 8， length &#x3D; 10， info 有两部分构成: timestamp和timestamp echo，各占 4 个字节。 那么这些字段都是干嘛的呢？它们用来解决那些问题？ 接下来我们就来一一梳理，TCP 的时间戳主要解决两大问题: 计算往返时延 RTT(Round-Trip Time) 防止序列号的回绕问题: 序列号的范围其实是在0 ~ 2 ^ 32 - 1浮动，在一次传输中可能存在相同的序列号报文，这时可用时间戳区分。 08. TCP 的超时重传时间是如何计算的？TCP 具有超时重传机制，即间隔一段时间没有等到数据包的回复时，重传这个数据包。 那么这个重传间隔是如何来计算的呢？ … 09. 能不能说一说 TCP 的流量控制？对于发送端和接收端而言，TCP 需要把发送的数据放到发送缓存区, 将接收的数据放到接收缓存区。 而流量控制索要做的事情，就是在通过设置接收缓存区的大小，控制发送端的发送。如果对方的接收缓存区满了，就不能再继续发送了。 要具体理解流量控制，首先需要了解滑动窗口的概念。 TCP 滑动窗口 TCP 滑动窗口分为两种: 发送窗口和接收窗口。 流量控制过程 这里我们不用太复杂的例子，以一个最简单的来回来模拟一下流量控制的过程，方便大家理解。 首先双方三次握手，初始化各自的窗口大小，均为 200 个字节。 假如当前发送端给接收端发送 100 个字节，那么此时对于发送端而言，SND.NXT 当然要右移 100 个字节，也就是说当前的可用窗口减少了 100 个字节，这很好理解。 现在这 100 个到达了接收端，被放到接收端的缓冲队列中。不过此时由于大量负载的原因，接收端处理不了这么多字节，只能处理 40 个字节，剩下的 60 个字节被留在了缓冲队列中。 注意了，此时接收端的情况是处理能力不够用啦，你发送端给我少发点，所以此时接收端的接收窗口应该缩小，具体来说，缩小 60 个字节，由 200 个字节变成了 140 字节，因为缓冲队列还有 60 个字节没被应用拿走。 因此，接收端会在 ACK 的报文首部带上缩小后的滑动窗口 140 字节，发送端对应地调整发送窗口的大小为 140 个字节。 此时对于发送端而言，已经发送且确认的部分增加 40 字节，也就是 SND.UNA 右移 40 个字节，同时发送窗口缩小为 140 个字节。 这也就是流量控制的过程。尽管回合再多，整个控制的过程和原理是一样的。 10. 能不能说说 TCP 的拥塞控制？上一节所说的流量控制发生在发送端跟接收端之间，并没有考虑到整个网络环境的影响，如果说当前网络特别差，特别容易丢包，那么发送端就应该注意一些了。而这，也正是拥塞控制需要处理的问题。 对于拥塞控制来说，TCP 每条连接都需要维护两个核心状态: 拥塞窗口（Congestion Window，cwnd） 慢启动阈值（Slow Start Threshold，ssthresh） 涉及到的算法有这几个: 慢启动 拥塞避免 快速重传和快速恢复 接下来，我们就来一一拆解这些状态和算法。首先，从拥塞窗口说起。 拥塞窗口 拥塞窗口（Congestion Window，cwnd）是指目前自己还能传输的数据量大小。 那么之前介绍了接收窗口的概念，两者有什么区别呢？ 接收窗口(rwnd)是接收端给的限制 拥塞窗口(cwnd)是发送端的限制 限制谁呢？ 限制的是发送窗口的大小。 有了这两个窗口，如何来计算发送窗口？ 发送窗口大小 &#x3D; min(rwnd, cwnd) 取两者的较小值。而拥塞控制，就是来控制cwnd的变化。 慢启动 刚开始进入传输数据的时候，你是不知道现在的网路到底是稳定还是拥堵的，如果做的太激进，发包太急，那么疯狂丢包，造成雪崩式的网络灾难。 因此，拥塞控制首先就是要采用一种保守的算法来慢慢地适应整个网路，这种算法叫慢启动。运作过程如下: 首先，三次握手，双方宣告自己的接收窗口大小双方初始化自己的拥塞窗口(cwnd)大小在开始传输的一段时间，发送端每收到一个 ACK，拥塞窗口大小加 1，也就是说，每经过一个 RTT，cwnd 翻倍。如果说初始窗口为 10，那么第一轮 10 个报文传完且发送端收到 ACK 后，cwnd 变为 20，第二轮变为 40，第三轮变为 80，依次类推。难道就这么无止境地翻倍下去？当然不可能。它的阈值叫做慢启动阈值，当 cwnd 到达这个阈值之后，好比踩了下刹车，别涨了那么快了，老铁，先 hold 住！ 在到达阈值后，如何来控制 cwnd 的大小呢？ 这就是拥塞避免做的事情了。 拥塞避免 原来每收到一个 ACK，cwnd 加1，现在到达阈值了，cwnd 只能加这么一点: 1 &#x2F; cwnd。那你仔细算算，一轮 RTT（往返时延） 下来，收到 cwnd 个 ACK, 那最后拥塞窗口的大小 cwnd 总共才增加 1。 也就是说，以前一个 RTT 下来，cwnd翻倍，现在cwnd只是增加 1 而已。 当然，慢启动和拥塞避免是一起作用的，是一体的。 快速重传和快速恢复 快速重传 在 TCP 传输的过程中，如果发生了丢包，即接收端发现数据段不是按序到达的时候，接收端的处理是重复发送之前的 ACK。 比如第 5 个包丢了，即使第 6、7 个包到达的接收端，接收端也一律返回第 4 个包的 ACK。当发送端收到 3 个重复的 ACK 时，意识到丢包了，于是马上进行重传，不用等到一个 RTO 的时间到了才重传。 这就是快速重传，它解决的是是否需要重传的问题。 选择性重传 那你可能会问了，既然要重传，那么只重传第 5 个包还是第5、6、7 个包都重传呢？ 当然第 6、7 个都已经到达了，TCP 的设计者也不傻，已经传过去干嘛还要传？干脆记录一下哪些包到了，哪些没到，针对性地重传。 在收到发送端的报文后，接收端回复一个 ACK 报文，那么在这个报文首部的可选项中，就可以加上SACK这个属性，通过left edge和right edge告知发送端已经收到了哪些区间的数据报。因此，即使第 5 个包丢包了，当收到第 6、7 个包之后，接收端依然会告诉发送端，这两个包到了。剩下第 5 个包没到，就重传这个包。这个过程也叫做选择性重传(SACK，Selective Acknowledgment)，它解决的是如何重传的问题。 快速恢复 当然，发送端收到三次重复 ACK 之后，发现丢包，觉得现在的网络已经有些拥塞了，自己会进入快速恢复阶段。 在这个阶段，发送端如下改变： 拥塞阈值降低为 cwnd 的一半 cwnd 的大小变为拥塞阈值 cwnd 线性增加 以上就是 TCP 拥塞控制的经典算法: 慢启动、拥塞避免、快速重传和快速恢复。 11. 能不能说说 Nagle 算法和延迟确认？**Nagle 算法 ** 试想一个场景，发送端不停地给接收端发很小的包，一次只发 1 个字节，那么发 1 千个字节需要发 1000 次。这种频繁的发送是存在问题的，不光是传输的时延消耗，发送和确认本身也是需要耗时的，频繁的发送接收带来了巨大的时延。 而避免小包的频繁发送，这就是 Nagle 算法要做的事情。 具体来说，Nagle 算法的规则如下: 当第一次发送数据时不用等待，就算是 1byte 的小包也立即发送 后面发送满足下面条件之一就可以发了: 数据包大小达到最大段大小(Max Segment Size, 即 MSS) 之前所有包的 ACK 都已接收到 延迟确认 试想这样一个场景，当我收到了发送端的一个包，然后在极短的时间内又接收到了第二个包，那我是一个个地回复，还是稍微等一下，把两个包的 ACK 合并后一起回复呢？ 延迟确认(delayed ack)所做的事情，就是后者，稍稍延迟，然后合并 ACK，最后才回复给发送端。TCP 要求这个延迟的时延必须小于500ms，一般操作系统实现都不会超过200ms。 不过需要主要的是，有一些场景是不能延迟确认的，收到了就要马上回复: 接收到了大于一个 frame 的报文，且需要调整窗口大小 TCP 处于 quickack 模式（通过tcp_in_quickack_mode设置） 发现了乱序包 两者一起使用会怎样？ 前者意味着延迟发，后者意味着延迟接收，会造成更大的延迟，产生性能问题。 12. 如何理解 TCP 的 keep-alive？大家都听说过 http 的keep-alive, 不过 TCP 层面也是有keep-alive机制，而且跟应用层不太一样。 试想一个场景，当有一方因为网络故障或者宕机导致连接失效，由于 TCP 并不是一个轮询的协议，在下一个数据包到达之前，对端对连接失效的情况是一无所知的。 这个时候就出现了 keep-alive, 它的作用就是探测对端的连接有没有失效。 在 Linux 下，可以这样查看相关的配置: 12345678sudo sysctl -a | grep keepalive// 每隔 7200 s 检测一次net.ipv4.tcp_keepalive_time = 7200// 一次最多重传 9 个包net.ipv4.tcp_keepalive_probes = 9// 每个包的间隔重传间隔 75 snet.ipv4.tcp_keepalive_intvl = 75 不过，现状是大部分的应用并没有默认开启 TCP 的keep-alive选项，为什么？ 站在应用的角度: 7200s 也就是两个小时检测一次，时间太长 时间再短一些，也难以体现其设计的初衷, 即检测长时间的死连接 因此是一个比较尴尬的设计。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"os","slug":"技术开发/os","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/os/"}],"tags":[{"name":"TCP 协议灵魂 12 问 【转】","slug":"TCP-协议灵魂-12-问-【转】","permalink":"https://tianxiafeiyu.github.io/tags/TCP-%E5%8D%8F%E8%AE%AE%E7%81%B5%E9%AD%82-12-%E9%97%AE-%E3%80%90%E8%BD%AC%E3%80%91/"}]},{"title":"NaN代表什么意思","slug":"技术开发/grocery/NaN代表什么意思","date":"2022-12-15T23:40:42.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/NaN代表什么意思/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/NaN%E4%BB%A3%E8%A1%A8%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D/","excerpt":"","text":"简介NaN（Not a Number，非数）是计算机科学中数值数据类型的一类值，表示未定义或不可表示的值。常在浮点数运算中使用。首次引入NaN的是1985年的IEEE 754浮点数标准。 浮点数返回NaN的运算有如下三种： 至少有一个参数是NaN的运算 不定式 除法运算：0&#x2F;0、∞&#x2F;∞、∞&#x2F;−∞、−∞&#x2F;∞、−∞&#x2F;−∞ 乘法运算：0×∞、0×−∞ 加法运算：∞ + (−∞)、(−∞) + ∞ 减法运算：∞ - ∞、(−∞) - (−∞) 产生复数结果的实数运算。例如：对负数进行开偶次方的运算对负数进行对数运算对正弦或余弦到达域以外的数进行反正弦或反余弦运算。 整数 NaN 表示无效数据（超出表示范围、不是有效整数等） Perl的BigInt包用“NaN”来表示不含有效整数数据字符串的处理结果","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"NaN代表什么意思","slug":"NaN代表什么意思","permalink":"https://tianxiafeiyu.github.io/tags/NaN%E4%BB%A3%E8%A1%A8%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D/"}]},{"title":"jsonpath使用心得","slug":"技术开发/grocery/jsonpath使用心得","date":"2022-12-15T23:40:42.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/jsonpath使用心得/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/jsonpath%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/","excerpt":"","text":"JsonPath表达式通常是用来路径检索或设置Json的。其表达式可以接受“dot–notation”和“bracket–notation”格式，例如$.store.book[0].title、$[‘store’][‘book’][0][‘title’] 操作符 符号 说明 $ 查询的根节点对象，用于表示一个json数据，可以是数组或对象 @ 当前节点，类似于this * 通配符，可以表示一个名字或数字 . 表示一个子节点 .. 深度查询 [‘’ (, ‘’)] 一个或多个子节点 [ (, )] 一个或多个数组下标 [start:end] 数组片段，区间为[start,end),不包含end [?()] 过滤器表达式，表达式结果必须是boolean 函数可以在JsonPath表达式执行后进行调用，其输入值为表达式的结果。 名称 描述 输出 min() 获取数值类型数组的最小值 Double max() 获取数值类型数组的最大值 Double avg() 获取数值类型数组的平均值 Double stddev() 获取数值类型数组的标准差 Double length() 获取数值类型数组的长度 Integer 过滤器过滤器是用于过滤数组的逻辑表达式，一个通常的表达式形如：[?(@.age &gt; 18)]，可以通过逻辑表达式&amp;&amp;或||组合多个过滤器表达式，例如 [?(@.price &lt; 10 &amp;&amp; @.category == ‘fiction’)]，字符串必须用单引号或双引号包围，例如 [?(@.color == ‘blue’)] or [?(@.color == “blue”)]。 操作符 描述 &#x3D;&#x3D; 等于符号，但数字1不等于字符1(note that 1 is not equal to ‘1’) !&#x3D; 不等于符号 &lt; 小于符号 &lt;&#x3D; 小于等于符号 | 大于符号&#x3D; | 大于等于符号&#x3D;~ | 判断是否符合正则表达式，例如[?(@.name &#x3D;~ &#x2F;foo.*?&#x2F;i)]in | 所属符号，例如[?(@.size in [‘S’, ‘M’])]nin | 排除符号size | size of left (array or string) should match rightempty | 判空符号 注意：正则过滤 &#x3D;~，貌似是无效的 常见用法123456789101112131415161718&#123; &quot;count&quot;: 2, &quot;success&quot;: 1, &quot;data&quot;: [ &#123; &quot;name&quot;: &quot;xiaoxing-y9000p&quot;, &quot;cpu&quot;: &quot;i7 12700k&quot;, &quot;gpu&quot;: &quot;RTX3080&quot;, &quot;price&quot;: 9999 &#125;, &#123; &quot;name&quot;: &quot;xiaomi4&quot;, &quot;cpu&quot;: &quot;rz6800h&quot;, &quot;gpu&quot;: &quot;RTX3060&quot;, &quot;price&quot;: 6999, &#125; ]&#125; json数据是一条接口查询返回 $.count 获得数据条数 $.data.name 获取所有电脑名称 $.data[?(@.price)&gt;9000] 获取价格超过9000的电脑 python中使用过jsonpath获取json指定数据 12345678import jsonpathlaptop_json = &#x27;&#123;&quot;count&quot;:2,&quot;success&quot;:1,&quot;data&quot;:[&#123;&quot;name&quot;:&quot;xiaoxing-y9000p&quot;,&quot;cpu&quot;:&quot;i7 12700k&quot;,&quot;gpu&quot;:&quot;RTX3080&quot;,&quot;price&quot;:9999&#125;,&#123;&quot;name&quot;:&quot;xiaomi4&quot;,&quot;cpu&quot;:&quot;rz6800h&quot;,&quot;gpu&quot;:&quot;RTX3060&quot;,&quot;price&quot;:6999&#125;]&#125;&#x27;laptop_data= json.loads(laptop_json)names = jsonpath.jsonpath(laptop_data, &quot;$.data.name&quot;)# [&quot;xiaoxing-y9000p&quot;, &quot;name&quot;]","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"jsonpath使用心得","slug":"jsonpath使用心得","permalink":"https://tianxiafeiyu.github.io/tags/jsonpath%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/"}]},{"title":"k8s国际化实现","slug":"技术开发/grocery/k8s国际化实现","date":"2022-12-15T23:40:42.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/k8s国际化实现/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/k8s%E5%9B%BD%E9%99%85%E5%8C%96%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"k8s用的是 github.com&#x2F;gosexy&#x2F;gettext&#x2F;go-xgettext 翻译库 项目中提供shell脚本，通过翻译库自带的 go-xgettext 工具进行词条扫描，生成template.po文件 不支持增量扫描","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"k8s国际化实现","slug":"k8s国际化实现","permalink":"https://tianxiafeiyu.github.io/tags/k8s%E5%9B%BD%E9%99%85%E5%8C%96%E5%AE%9E%E7%8E%B0/"}]},{"title":"maven使用本地依赖","slug":"技术开发/java/maven使用本地依赖","date":"2022-12-15T23:40:30.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/maven使用本地依赖/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/maven%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0%E4%BE%9D%E8%B5%96/","excerpt":"","text":"1234567&lt;dependency&gt; &lt;groupId&gt;com.test&lt;/groupId&gt; &lt;artifactId&gt;core&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;systemPath&gt;$&#123;project.basedir&#125;/lib/jasperreports-html-component-6.5.0.jar&lt;/systemPath&gt;&lt;/dependency&gt;","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"maven使用本地依赖","slug":"maven使用本地依赖","permalink":"https://tianxiafeiyu.github.io/tags/maven%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0%E4%BE%9D%E8%B5%96/"}]},{"title":"Spring 注解","slug":"技术开发/java/Spring 注解","date":"2022-12-15T23:39:58.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Spring 注解/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Spring%20%E6%B3%A8%E8%A7%A3/","excerpt":"","text":"什么是注解？注解是JDK1.5版本开始引入的一个特性，用于对代码进行说明，可以对包、类、接口、字段、方法参数、局部变量等进行注解。 注解与什么用？ 生成文档，通过代码里标识的元数据生成javadoc文档。 编译检查，通过代码里标识的元数据让编译器在编译期间进行检查验证。 编译时动态处理，编译时通过代码里标识的元数据动态处理，例如动态生成代码。 运行时动态处理，运行时通过代码里标识的元数据动态处理，例如使用反射注入实例 注解和XML的区别： 注解：是一种分散式的元数据，与源代码紧绑定。 xml：是一种集中式的元数据，与源代码无绑定 怎么实现注解？1、使用 @interface 定义注解。 2、通过继承以下注解，实现功能： 元注解@Target,@Retention,@Documented,@Inherited 元注解： @Target 表示该注解用于什么地方，可能的 ElemenetType 参数包括： ElemenetType.CONSTRUCTOR 构造器声明 ElemenetType.FIELD 域声明（包括 enum 实例） ElemenetType.LOCAL_VARIABLE 局部变量声明 ElemenetType.METHOD 方法声明 ElemenetType.PACKAGE 包声明 ElemenetType.PARAMETER 参数声明 ElemenetType.TYPE 类，接口（包括注解类型）或enum声明 @Retention 表示在什么级别保存该注解信息。可选的 RetentionPolicy 参数包括： RetentionPolicy.SOURCE 注解将被编译器丢弃 RetentionPolicy.CLASS 注解在class文件中可用，但会被VM丢弃 RetentionPolicy.RUNTIME VM将在运行期也保留注释，因此可以通过反射机制读取注解的信息。 @Documented 将此注解包含在 javadoc 中 @Inherited 允许子类继承父类中的注解 注解工作过程以 spring 的 @controller 来当做示例: @Controller继承@Component注解的方法，将其以单例的形式放入spring容器，然后spring会通过配置文件中的context:component-scan的配置，进行如下操作： 使用asm技术扫描.class文件，并将包含@Component及元注解为@Component的注解@Controller、@Service、@Repository或者其他自定义的的bean注册到beanFactory中， 然后spring注册注解处理器。注解处理器是一个在javac编译期处理注解的工具，你可以创建注解处理器并注册，在编译期你创建的处理器以Java代码作为输入，生成文件.java文件作为输出。 实例化处理器，然后将其放到beanPostFactory中，然后我们就可以在类中进行使用了。 创建bean时，会自动调用相应的处理器进行处理。 spring @Controller源码： 12345678910111213141516171819package org.springframework.stereotype;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import org.springframework.core.annotation.AliasFor;@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Controller &#123; @AliasFor( annotation = Component.class ) String value() default &quot;&quot;;&#125; @AliasFor 表示别名，它可以注解到自定义注解的两个属性上，表示这两个互为别名，也就是说这两个属性其实同一个含义 @Component 123456789101112131415package org.springframework.stereotype;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Indexedpublic @interface Component &#123; String value() default &quot;&quot;;&#125; 每个注解里面都有一个默认的value()方法，为当前的注解声明一个名字，一般默认为类名","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Spring 注解","slug":"Spring-注解","permalink":"https://tianxiafeiyu.github.io/tags/Spring-%E6%B3%A8%E8%A7%A3/"}]},{"title":"SkyWalking—Java探针插件开发","slug":"技术开发/java/SkyWalking—Java探针插件开发","date":"2022-12-15T23:39:56.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/SkyWalking—Java探针插件开发/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/SkyWalking%E2%80%94Java%E6%8E%A2%E9%92%88%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/","excerpt":"","text":"SpanSpan 是分布式追踪系统中一个非常重要的概念，可以理解为一次方法调用、一个程序块的调用、一次 RPC 调用或者数据库访问。 SkyWalking 将 Span 粗略分为两类：LocalSpan 和 RemoteSpan。 LocalSpan 代表一次普通的 Java 方法调用，与跨进程无关。 RemoteSpan","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"SkyWalking—Java探针插件开发","slug":"SkyWalking—Java探针插件开发","permalink":"https://tianxiafeiyu.github.io/tags/SkyWalking%E2%80%94Java%E6%8E%A2%E9%92%88%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/"}]},{"title":"Skywalking数据库插件分析（废稿）","slug":"技术开发/java/Skywalking数据库插件分析（废稿）","date":"2022-12-15T23:39:56.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Skywalking数据库插件分析（废稿）/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Skywalking%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8F%92%E4%BB%B6%E5%88%86%E6%9E%90%EF%BC%88%E5%BA%9F%E7%A8%BF%EF%BC%89/","excerpt":"","text":"apm-mysql-8.x-plugin主要增强的功能有：123456789//mysql-8.x=org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.ConnectionImplCreateInstrumentation mysql-8.x=org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.ConnectionInstrumentationmysql-8.x=org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.CallableInstrumentationmysql-8.x=org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.PreparedStatementInstrumentationmysql-8.x=org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.StatementInstrumentationmysql-8.x=org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.PreparedStatementSetterInstrumentationmysql-8.x=org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.PreparedStatementNullSetterInstrumentationmysql-8.x=org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.PreparedStatementIgnoredSetterInstrumentation 源码分析ConnectionCreateInterceptor.class12345678910111213141516171819202122232425262728293031323334import com.mysql.cj.conf.HostInfo;import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.StaticMethodsAroundInterceptor;import org.apache.skywalking.apm.plugin.jdbc.connectionurl.parser.URLParser;import org.apache.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;import java.lang.reflect.Method;public class ConnectionCreateInterceptor implements StaticMethodsAroundInterceptor &#123; @Override public void beforeMethod(Class clazz, Method method, Object[] allArguments, Class&lt;?&gt;[] parameterTypes, MethodInterceptResult result) &#123; &#125; @Override public Object afterMethod(Class clazz, Method method, Object[] allArguments, Class&lt;?&gt;[] parameterTypes, Object ret) &#123; if (ret instanceof EnhancedInstance) &#123; final HostInfo hostInfo = (HostInfo) allArguments[0]; ConnectionInfo connectionInfo = URLParser.parser(hostInfo.getDatabaseUrl()); ((EnhancedInstance) ret).setSkyWalkingDynamicField(connectionInfo); &#125; return ret; &#125; @Override public void handleMethodException(Class clazz, Method method, Object[] allArguments, Class&lt;?&gt;[] parameterTypes, Throwable t) &#123; &#125;&#125; ConnectionCreateInterceptor实现了StaticMethodsAroundInterceptor接口， afterMethod方法提取com.mysql.cj.conf.HostInfo解析为org.apache.skywalking.apm.plugin.jdbc.trace.ConnectionInfo 设置给ret的skyWalkingDynamicField，记录连接信息 AbstractMysqlInstrumentation1234567891011121314151617181920212223242526272829package org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define;import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;import org.apache.skywalking.apm.agent.core.plugin.interceptor.StaticMethodsInterceptPoint;import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassEnhancePluginDefine;public abstract class AbstractMysqlInstrumentation extends ClassEnhancePluginDefine &#123; @Override public ConstructorInterceptPoint[] getConstructorsInterceptPoints() &#123; return null; &#125; @Override public StaticMethodsInterceptPoint[] getStaticMethodsInterceptPoints() &#123; return null; &#125; @Override public InstanceMethodsInterceptPoint[] getInstanceMethodsInterceptPoints() &#123; return null; &#125; @Override protected String[] witnessClasses() &#123; return new String[] &#123;Constants.WITNESS_MYSQL_8X_CLASS&#125;; &#125;&#125; AbstractMysqlInstrumentation继承了ClassEnhancePluginDefine，定义了构造器方法、静态方法、实例方法的拦截形式。 witnessClasses返回的是com.mysql.cj.interceptors.QueryInterceptor CallableInstrumentation123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define;import net.bytebuddy.description.method.MethodDescription;import net.bytebuddy.matcher.ElementMatcher;import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;import static net.bytebuddy.matcher.ElementMatchers.named;import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;public class CallableInstrumentation extends AbstractMysqlInstrumentation &#123; private static final String ENHANCE_CLASS = &quot;com.mysql.cj.jdbc.CallableStatement&quot;; private static final String SERVICE_METHOD_INTERCEPTOR = org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.PREPARED_STATEMENT_EXECUTE_METHODS_INTERCEPTOR; @Override public ConstructorInterceptPoint[] getConstructorsInterceptPoints() &#123; return new ConstructorInterceptPoint[0]; &#125; @Override public InstanceMethodsInterceptPoint[] getInstanceMethodsInterceptPoints() &#123; return new InstanceMethodsInterceptPoint[] &#123; new InstanceMethodsInterceptPoint() &#123; @Override public ElementMatcher&lt;MethodDescription&gt; getMethodsMatcher() &#123; return named(&quot;execute&quot;).or(named(&quot;executeQuery&quot;)).or(named(&quot;executeUpdate&quot;)); &#125; @Override public String getMethodsInterceptor() &#123; return SERVICE_METHOD_INTERCEPTOR; &#125; @Override public boolean isOverrideArgs() &#123; return false; &#125; &#125; &#125;; &#125; @Override protected ClassMatch enhanceClass() &#123; return byName(ENHANCE_CLASS); &#125;&#125; 增强com.mysql.cj.jdbc.CallableStatement类，即调用过程 定义该类实例方法的拦截形式，匹配“execute”或“executeQuery”或“executeUpdate”方法 指定该实例方法的拦截器org.apache.skywalking.apm.plugin.jdbc.mysql.PreparedStatementExecuteMethodsInterceptor 不重写实例方法参数 PreparedStatementExecuteMethodsInterceptor123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package org.apache.skywalking.apm.plugin.jdbc.mysql;import java.lang.reflect.Method;import org.apache.skywalking.apm.agent.core.context.ContextManager;import org.apache.skywalking.apm.agent.core.context.tag.Tags;import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;import org.apache.skywalking.apm.plugin.jdbc.JDBCPluginConfig;import org.apache.skywalking.apm.plugin.jdbc.PreparedStatementParameterBuilder;import org.apache.skywalking.apm.plugin.jdbc.define.StatementEnhanceInfos;import org.apache.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.SQL_PARAMETERS;public class PreparedStatementExecuteMethodsInterceptor implements InstanceMethodsAroundInterceptor &#123; @Override public final void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class&lt;?&gt;[] argumentsTypes, MethodInterceptResult result) &#123; StatementEnhanceInfos cacheObject = (StatementEnhanceInfos) objInst.getSkyWalkingDynamicField(); /** * For avoid NPE. In this particular case, Execute sql inside the &#123;@link com.mysql.jdbc.ConnectionImpl&#125; constructor, * before the interceptor sets the connectionInfo. * When invoking prepareCall, cacheObject is null. Because it will determine procedures&#x27;s parameter types by executing sql in mysql * before the interceptor sets the statementEnhanceInfos. * @see JDBCDriverInterceptor#afterMethod(EnhancedInstance, Method, Object[], Class[], Object) */ if (cacheObject != null &amp;&amp; cacheObject.getConnectionInfo() != null) &#123; ConnectionInfo connectInfo = cacheObject.getConnectionInfo(); AbstractSpan span = ContextManager.createExitSpan( buildOperationName(connectInfo, method.getName(), cacheObject .getStatementName()), connectInfo.getDatabasePeer()); Tags.DB_TYPE.set(span, &quot;sql&quot;); Tags.DB_INSTANCE.set(span, connectInfo.getDatabaseName()); Tags.DB_STATEMENT.set(span, cacheObject.getSql()); span.setComponent(connectInfo.getComponent()); if (JDBCPluginConfig.Plugin.MySQL.TRACE_SQL_PARAMETERS) &#123; final Object[] parameters = cacheObject.getParameters(); if (parameters != null &amp;&amp; parameters.length &gt; 0) &#123; int maxIndex = cacheObject.getMaxIndex(); String parameterString = getParameterString(parameters, maxIndex); SQL_PARAMETERS.set(span, parameterString); &#125; &#125; SpanLayer.asDB(span); &#125; &#125; @Override public final Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class&lt;?&gt;[] argumentsTypes, Object ret) &#123; StatementEnhanceInfos cacheObject = (StatementEnhanceInfos) objInst.getSkyWalkingDynamicField(); if (cacheObject != null &amp;&amp; cacheObject.getConnectionInfo() != null) &#123; ContextManager.stopSpan(); &#125; return ret; &#125; @Override public final void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments, Class&lt;?&gt;[] argumentsTypes, Throwable t) &#123; StatementEnhanceInfos cacheObject = (StatementEnhanceInfos) objInst.getSkyWalkingDynamicField(); if (cacheObject != null &amp;&amp; cacheObject.getConnectionInfo() != null) &#123; ContextManager.activeSpan().errorOccurred().log(t); &#125; &#125; private String buildOperationName(ConnectionInfo connectionInfo, String methodName, String statementName) &#123; return connectionInfo.getDBType() + &quot;/JDBI/&quot; + statementName + &quot;/&quot; + methodName; &#125; private String getParameterString(Object[] parameters, int maxIndex) &#123; return new PreparedStatementParameterBuilder() .setParameters(parameters) .setMaxIndex(maxIndex) .setMaxLength(JDBCPluginConfig.Plugin.MySQL.SQL_PARAMETERS_MAX_LENGTH) .build(); &#125;&#125; beforeMethod：创建ExitSpan，记录DB_TYPE、DB_INSTANCE、DB_STATEMENT等信息 如果开启参数追踪，记录参数信息 afterMethod：结束此Span追踪 handleMethodException：当前方法出现异常，将堆栈信息存入此Span ConnectionImplCreateInstrumentation12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define;import net.bytebuddy.description.method.MethodDescription;import net.bytebuddy.matcher.ElementMatcher;import org.apache.skywalking.apm.agent.core.plugin.interceptor.StaticMethodsInterceptPoint;import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;import java.util.Properties;import static net.bytebuddy.matcher.ElementMatchers.named;import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;/** * interceptor the method &#123;@link com.mysql.cj.jdbc.ConnectionImpl#getInstance(com.mysql.cj.conf.HostInfo)&#125; instead of * &#123;@link com.mysql.cj.jdbc.Driver#connect(String, Properties)&#125; */public class ConnectionImplCreateInstrumentation extends AbstractMysqlInstrumentation &#123; private static final String JDBC_ENHANCE_CLASS = &quot;com.mysql.cj.jdbc.ConnectionImpl&quot;; private static final String CONNECT_METHOD = &quot;getInstance&quot;; @Override public StaticMethodsInterceptPoint[] getStaticMethodsInterceptPoints() &#123; return new StaticMethodsInterceptPoint[] &#123; new StaticMethodsInterceptPoint() &#123; @Override public ElementMatcher&lt;MethodDescription&gt; getMethodsMatcher() &#123; return named(CONNECT_METHOD); &#125; @Override public String getMethodsInterceptor() &#123; return &quot;org.apache.skywalking.apm.plugin.jdbc.mysql.v8.ConnectionCreateInterceptor&quot;; &#125; @Override public boolean isOverrideArgs() &#123; return false; &#125; &#125; &#125;; &#125; @Override protected ClassMatch enhanceClass() &#123; return byName(JDBC_ENHANCE_CLASS); &#125;&#125; 增强com.mysql.cj.jdbc.ConnectionImpl类 指定增强该类的getInstance静态方法 指定静态方法拦截器org.apache.skywalking.apm.plugin.jdbc.mysql.v8.ConnectionCreateInterceptor 不重写方法参数 ConnectionCreateInterceptor123456789101112131415161718192021222324252627282930313233343536package org.apache.skywalking.apm.plugin.jdbc.mysql.v8;import com.mysql.cj.conf.HostInfo;import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.StaticMethodsAroundInterceptor;import org.apache.skywalking.apm.plugin.jdbc.connectionurl.parser.URLParser;import org.apache.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;import java.lang.reflect.Method;public class ConnectionCreateInterceptor implements StaticMethodsAroundInterceptor &#123; @Override public void beforeMethod(Class clazz, Method method, Object[] allArguments, Class&lt;?&gt;[] parameterTypes, MethodInterceptResult result) &#123; &#125; @Override public Object afterMethod(Class clazz, Method method, Object[] allArguments, Class&lt;?&gt;[] parameterTypes, Object ret) &#123; if (ret instanceof EnhancedInstance) &#123; final HostInfo hostInfo = (HostInfo) allArguments[0]; ConnectionInfo connectionInfo = URLParser.parser(hostInfo.getDatabaseUrl()); ((EnhancedInstance) ret).setSkyWalkingDynamicField(connectionInfo); &#125; return ret; &#125; @Override public void handleMethodException(Class clazz, Method method, Object[] allArguments, Class&lt;?&gt;[] parameterTypes, Throwable t) &#123; &#125;&#125; afterMethod：方法执行完成后，记录当前方法的数据库连接信息 ConnectionInstrumentation123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113package org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define;import net.bytebuddy.description.method.MethodDescription;import net.bytebuddy.matcher.ElementMatcher;import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;import static net.bytebuddy.matcher.ElementMatchers.named;import static net.bytebuddy.matcher.ElementMatchers.takesArguments;import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;public class ConnectionInstrumentation extends AbstractMysqlInstrumentation &#123; @Override public ConstructorInterceptPoint[] getConstructorsInterceptPoints() &#123; return new ConstructorInterceptPoint[0]; &#125; @Override public InstanceMethodsInterceptPoint[] getInstanceMethodsInterceptPoints() &#123; return new InstanceMethodsInterceptPoint[] &#123; new InstanceMethodsInterceptPoint() &#123; @Override public ElementMatcher&lt;MethodDescription&gt; getMethodsMatcher() &#123; return named(org.apache.skywalking.apm.plugin.jdbc.define.Constants.PREPARE_STATEMENT_METHOD_NAME); &#125; @Override public String getMethodsInterceptor() &#123; return org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.CREATE_PREPARED_STATEMENT_INTERCEPTOR; &#125; @Override public boolean isOverrideArgs() &#123; return false; &#125; &#125;, new InstanceMethodsInterceptPoint() &#123; @Override public ElementMatcher&lt;MethodDescription&gt; getMethodsMatcher() &#123; return named(org.apache.skywalking.apm.plugin.jdbc.define.Constants.PREPARE_CALL_METHOD_NAME); &#125; @Override public String getMethodsInterceptor() &#123; return org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.CREATE_CALLABLE_STATEMENT_INTERCEPTOR; &#125; @Override public boolean isOverrideArgs() &#123; return false; &#125; &#125;, new InstanceMethodsInterceptPoint() &#123; @Override public ElementMatcher&lt;MethodDescription&gt; getMethodsMatcher() &#123; return named(org.apache.skywalking.apm.plugin.jdbc.define.Constants.CREATE_STATEMENT_METHOD_NAME).and(takesArguments(2)); &#125; @Override public String getMethodsInterceptor() &#123; return org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.CREATE_STATEMENT_INTERCEPTOR; &#125; @Override public boolean isOverrideArgs() &#123; return false; &#125; &#125;, new InstanceMethodsInterceptPoint() &#123; @Override public ElementMatcher&lt;MethodDescription&gt; getMethodsMatcher() &#123; return named(org.apache.skywalking.apm.plugin.jdbc.define.Constants.COMMIT_METHOD_NAME).or(named(org.apache.skywalking.apm.plugin.jdbc.define.Constants.ROLLBACK_METHOD_NAME)) .or(named(org.apache.skywalking.apm.plugin.jdbc.define.Constants.CLOSE_METHOD_NAME)) .or(named(org.apache.skywalking.apm.plugin.jdbc.define.Constants.RELEASE_SAVE_POINT_METHOD_NAME)); &#125; @Override public String getMethodsInterceptor() &#123; return org.apache.skywalking.apm.plugin.jdbc.define.Constants.SERVICE_METHOD_INTERCEPT_CLASS; &#125; @Override public boolean isOverrideArgs() &#123; return false; &#125; &#125;, new InstanceMethodsInterceptPoint() &#123; @Override public ElementMatcher&lt;MethodDescription&gt; getMethodsMatcher() &#123; return named(&quot;setCatalog&quot;); &#125; @Override public String getMethodsInterceptor() &#123; return org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.SET_CATALOG_INTERCEPTOR; &#125; @Override public boolean isOverrideArgs() &#123; return false; &#125; &#125; &#125;; &#125; @Override protected ClassMatch enhanceClass() &#123; return byName(&quot;com.mysql.cj.jdbc.ConnectionImpl&quot;); &#125;&#125; 指定要增强的类com.mysql.cj.jdbc.ConnectionImpl 定义构造方法的拦截形式 定义实例方法的拦截形式： 拦截prepareStatement方法 指定拦截器org.apache.skywalking.apm.plugin.jdbc.mysql.CreatePreparedStatementInterceptor 不重写方法参数 拦截prepareCall方法 指定拦截器org.apache.skywalking.apm.plugin.jdbc.mysql.CreateCallableStatementInterceptor 不重写方法参数 拦截createStatement方法 指定拦截器org.apache.skywalking.apm.plugin.jdbc.mysql.CreateStatementInterceptor 不重写方法参数 拦截commit或rollback或close或releaseSavepoint方法 指定拦截器org.apache.skywalking.apm.plugin.jdbc.ConnectionServiceMethodInterceptor 不重写方法参数 拦截setCatalog方法 指定拦截器org.apache.skywalking.apm.plugin.jdbc.mysql.SetCatalogInterceptor 不重写参数 CreatePreparedStatementInterceptor1234567891011121314151617181920212223242526272829303132package org.apache.skywalking.apm.plugin.jdbc.mysql;import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;import org.apache.skywalking.apm.plugin.jdbc.define.StatementEnhanceInfos;import org.apache.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;import java.lang.reflect.Method;public class CreatePreparedStatementInterceptor implements InstanceMethodsAroundInterceptor &#123; @Override public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class&lt;?&gt;[] argumentsTypes, MethodInterceptResult result) throws Throwable &#123; &#125; @Override public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class&lt;?&gt;[] argumentsTypes, Object ret) throws Throwable &#123; if (ret instanceof EnhancedInstance) &#123; // allArguments[0]为要执行的sql，设置到ret的SkyWalkingDynamicField ((EnhancedInstance) ret).setSkyWalkingDynamicField(new StatementEnhanceInfos((ConnectionInfo) objInst.getSkyWalkingDynamicField(), (String) allArguments[0], &quot;PreparedStatement&quot;)); &#125; return ret; &#125; @Override public void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments, Class&lt;?&gt;[] argumentsTypes, Throwable t) &#123; &#125;&#125; afterMethod：实例方法结束后，创建StatementEnhanceInfos","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Skywalking数据库插件分析（废稿）","slug":"Skywalking数据库插件分析（废稿）","permalink":"https://tianxiafeiyu.github.io/tags/Skywalking%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8F%92%E4%BB%B6%E5%88%86%E6%9E%90%EF%BC%88%E5%BA%9F%E7%A8%BF%EF%BC%89/"}]},{"title":"Spring的单例模式与线程安全","slug":"技术开发/java/Spring的单例模式与线程安全","date":"2022-12-15T23:39:56.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Spring的单例模式与线程安全/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Spring%E7%9A%84%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/","excerpt":"","text":"Spring的单例模式与线程安全前言spring 管理的bean（@Component类注解标记的类并且由IOC容器注入），默认是单例的。声明为单例的bean，在spring容器中只会有一个实例化对象，存储在全局的map中，处理请求时，会先从缓存（map）中寻找对象，如果不存在才实例化一个对象并且缓存起来。也就是说，在处理多个请求中，使用的都是同一个对象。 Spring提供了5种scope分别是singleton（单例）、prototype（原型）、request、session、global session。 单例bean的优势 减少了新生成实例的消耗 新生成实例消耗包括两方面，第一，spring会通过反射或者cglib（动态代理）来生成bean实例这都是耗性能的操作，其次给对象分配内存也会涉及复杂算法。 减少jvm垃圾回收 由于不会给每个请求都生成新的bean实例，所以自然回收的对象少了。 可以快速获取到bean 单例bean除了第一次需要实例化外其余都是从缓存中获取，速度自然快。 单例bean的劣势单例的bean一个很大的劣势就是他不能做到线程安全，由于所有请求都共享一个bean实例，所以这个bean要是有状态的一个bean的话可能在并发场景下出现问题，而原型的bean则不会有这样问题（但也有例外，比如他被单例bean依赖），因为给每个请求都新创建实例。 什么是有状态对象？什么是无状态对象？ 有状态对象：有实例变量可以标志其对象所处的状态。（有实例变量的对象，有存储数据能力）- 白话：有属性的对象 无状态对象：无实例变量可以标志其对象所处的状态。（无实例变量的对象，无存储数据能力）- 白话：无属性的对象 结论在编码时，需要注意把contoller,service等类设计成无状态的，不要随便把类交由spring管理（@Component注解）。 spring多例的设置前面有提到， Spring提供了5种scope分别是singleton、prototype、request、session、global session。可以添加类注解 @Scope(prototype) 来声明该类使用原型模式（每次调用都生成新实例）。 但是这个注解并不好用。 如果父类声明了原型模式，子类是单例模式，那么子类中的父类也是只有一个实例； 如果类的属性是原型模式，类是单例模式，那么该属性也会只有一个实例。 注意因为spring管理bean是单例的特性，在操作外部资源时需要注意及时释放资源，否则资源将会长时间按得不到释放。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Spring的单例模式与线程安全","slug":"Spring的单例模式与线程安全","permalink":"https://tianxiafeiyu.github.io/tags/Spring%E7%9A%84%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"}]},{"title":"skywalking Jdbc插件分析","slug":"技术开发/java/skywalking Jdbc插件分析","date":"2022-12-15T23:39:56.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/skywalking Jdbc插件分析/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/skywalking%20Jdbc%E6%8F%92%E4%BB%B6%E5%88%86%E6%9E%90/","excerpt":"","text":"mysql-8.x-plugin 拦截形式 增强的类 增强方法 类型 方法说明 拦截器 执行前 执行后 报错 org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.CallableInstrumentation com.mysql.cj.jdbc.CallableStatement execute、executeQuery、executeUpdate 实例方法 调用存储过程类增强，拦截存储过程的执行方法 org.apache.skywalking.apm.plugin.jdbc.mysql.PreparedStatementExecuteMethodsInterceptor 创建ExitSpan，追踪本次数据库调用 ContextManager.stopSpan()，结束追踪 ContextManager.activeSpan().errorOccurred().log(t)，记录异常堆栈 org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.ConnectionImplCreateInstrumentation com.mysql.cj.jdbc.ConnectionImpl getInstance 静态方法 拦截获取数据库连接方法 org.apache.skywalking.apm.plugin.jdbc.mysql.v8.ConnectionCreateInterceptor 记录数据库连接信息connectionInfo (dbType,dbName,dbPeer...) org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.ConnectionInstrumentation com.mysql.cj.jdbc.ConnectionImpl prepareStatement 实例方法 创建一个PreparedStatement对象，该对象用于预编译和发送sql,获得执行结果 org.apache.skywalking.apm.plugin.jdbc.mysql.CreatePreparedStatementInterceptor 记录statement信息StatementEnhanceInfos（connectionInfo,statementName,sql...） org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.ConnectionInstrumentation com.mysql.cj.jdbc.ConnectionImpl prepareCall 实例方法 创建一个CallableStatement。此对象用于调用数据库存储过程 org.apache.skywalking.apm.plugin.jdbc.mysql.CreateCallableStatementInterceptor 记录statement信息StatementEnhanceInfos（connectionInfo,statementName,sql...） org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.ConnectionInstrumentation com.mysql.cj.jdbc.ConnectionImpl createStatement,参数数量为2 实例方法 创建一个Statement对象，Statement用于发送sql语句到数据库和获得返回结果 org.apache.skywalking.apm.plugin.jdbc.mysql.CreateStatementInterceptor 记录statement信息StatementEnhanceInfos（connectionInfo,statementName...） org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.ConnectionInstrumentation com.mysql.cj.jdbc.ConnectionImpl commit、rollback、close、releaseSavepoint 实例方法 事务相关操作 org.apache.skywalking.apm.plugin.jdbc.ConnectionServiceMethodInterceptor 创建ExitSpan，追踪本次数据库调用 ContextManager.stopSpan()，结束追踪 ContextManager.activeSpan().errorOccurred().log(t)，记录异常堆栈 org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.ConnectionInstrumentation com.mysql.cj.jdbc.ConnectionImpl setCatalog 实例方法 设置给定目录名称，以便选择要在其中进行工作的此 Connection 对象数据库的子空间 org.apache.skywalking.apm.plugin.jdbc.mysql.SetCatalogInterceptor 获取connectionInfo，调用setDatabaseName(),记录目录名称catalog org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.PreparedStatementInstrumentation com.mysql.cj.jdbc.ClientPreparedStatement、com.mysql.cj.jdbc.ServerPreparedStatement execute、executeQuery、executeUpdate、executeLargeUpdate 实例方法 ClientPreparedStatement是PreparedStatement接口的实现类，StatementImpl的子类；ServerPreparedStatement是ClientPreparedStatement的子类，预编译和发送sql的类 org.apache.skywalking.apm.plugin.jdbc.mysql.PreparedStatementExecuteMethodsInterceptor 创建ExitSpan，追踪本次数据库调用 ContextManager.stopSpan()，结束追踪 ContextManager.activeSpan().errorOccurred().log(t)，记录异常堆栈 org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.PreparedStatementIgnoredSetterInstrumentation com.mysql.cj.jdbc.ClientPreparedStatement、com.mysql.cj.jdbc.ServerPreparedStatement setAsciiStream, setBinaryStream, setBlob, setBytes, setCharacterStream, setClob, setNCharacterStream, setNClob, setRef, setSQLXML, setUnicodeStream 实例方法 参数绑定（长文本） org.apache.skywalking.apm.plugin.jdbc.JDBCPreparedStatementIgnorableSetterInterceptor statementEnhanceInfos.setParameter(index, \"?\")，记录参数信息，避免数据太大，用”?“代替 org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.PreparedStatementNullSetterInstrumentation com.mysql.cj.jdbc.ClientPreparedStatement、com.mysql.cj.jdbc.ServerPreparedStatement setNull 实例方法 参数绑定（null） org.apache.skywalking.apm.plugin.jdbc.JDBCPreparedStatementNullSetterInterceptor statementEnhanceInfos.setParameter(index, \"NULL\")，记录参数信息 org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.PreparedStatementSetterInstrumentation com.mysql.cj.jdbc.ClientPreparedStatement、com.mysql.cj.jdbc.ServerPreparedStatement setArray, setBigDecimal, setBoolean, setByte, setDate, setDouble, setFloat, setInt, setLong, setNString, setObject, setRowId, setShort, setString, setTime, setTimestamp, setURL 实例方法 参数绑定 org.apache.skywalking.apm.plugin.jdbc.JDBCPreparedStatementSetterInterceptor statementEnhanceInfos.setParameter(index, parameter)，记录参数信息 org.apache.skywalking.apm.plugin.jdbc.mysql.v8.define.StatementInstrumentation com.mysql.cj.jdbc.StatementImpl execute、executeQuery、executeUpdate、executeLargeUpdate、executeBatchInternal、executeUpdateInternal、executeQuery、executeBatch 实例方法 StatementImpl是Statement接口的实现类，用于发送sql命令，获得查询结果。 org.apache.skywalking.apm.plugin.jdbc.mysql.StatementExecuteMethodsInterceptor 创建ExitSpan，追踪本次数据库调用 ContextManager.stopSpan()，结束追踪 ContextManager.activeSpan().errorOccurred().log(t)，记录异常堆栈 postgresql-8.x-plugin 拦截形式 增强的类 增强方法 类型 方法说明 拦截器 执行前 执行后 报错 AbstractJdbc2StatementInstrumentation org.postgresql.jdbc2.AbstractJdbc2Statement（发行版中该类已废弃） 无参的execute，executeQuery，executeUpdate 实例方法 sql语句执行方法 org.apache.skywalking.apm.plugin.jdbc.postgresql.PreparedStatementExecuteMethodsInterceptor 创建ExitSpan，追踪本次数据库调用 结束追踪 记录错误堆栈 入参数目为1的execute，executeQuery，executeUpdate 实例方法 sql语句执行方法 org.apache.skywalking.apm.plugin.jdbc.postgresql.StatementExecuteMethodsInterceptor 同上 同上 同上 ConnectionInstrumentation \"org.postgresql.jdbc.PgConnection， org.postgresql.jdbc42.Jdbc42Connection（已废弃）， org.postgresql.jdbc3g.Jdbc3gConnection（已废弃）， org.postgresql.jdbc4.Jdbc4Connection（已废弃） \" 入参数目为4的prepareStatement 实例方法 创建一个PgPreparedStatement对象，该对象用于预编译和发送sql,获得执行结果 org.apache.skywalking.apm.plugin.jdbc.postgresql.CreatePreparedStatementInterceptor 记录statement信息StatementEnhanceInfos（connectionInfo,statementName,sql...） 第二个参数类型为String[]的prepareStatement 实例方法 同上 org.apache.skywalking.apm.plugin.jdbc.postgresql.JDBCPrepareStatementWithStringArrayInterceptor 记录statement信息StatementEnhanceInfos（connectionInfo,statementName,sql...） 入参数目为4的prepareCall 实例方法 创建一个CPgCallableStatement。此对象用于调用数据库存储过程 org.apache.skywalking.apm.plugin.jdbc.postgresql.CreateCallableStatementInterceptor 创建PreparedStatement的代理SWPreparedStatement，记录（connectionInfo,statementName,sql...） 入参数目为3的createStatement 实例方法 创建一个PgStatement，该对象用于预编译和发送sql,获得执行结果 org.apache.skywalking.apm.plugin.jdbc.postgresql.CreateStatementInterceptor 记录statement信息StatementEnhanceInfos（connectionInfo,statementName,sql...） commit,rollback,close,releaseSavepoint 实例方法 数据库事务相关方法 org.apache.skywalking.apm.plugin.jdbc.ConnectionServiceMethodInterceptor 创建ExitSpan，追踪本次数据库调用 结束追踪 记录错误堆栈 Jdbc3ConnectionInstrumentation org.postgresql.jdbc3.Jdbc3Connection（已废弃） 同ConnectionInstrumentation,应该是重复的 实例方法 Jdbc4ConnectionInstrumentation org.postgresql.jdbc4.Jdbc4Connection（已废弃） 同上 实例方法 PgCallableStatementInstrumentation org.postgresql.jdbc.PgCallableStatement \"第一个参数为int的executeWithFlags， executeUpdate\" 实例方法 执行sql方法 org.apache.skywalking.apm.plugin.jdbc.postgresql.PreparedStatementExecuteMethodsInterceptor 创建ExitSpan，追踪本次数据库调用 结束追踪 记录错误堆栈 PgPreparedStatementInstrumentation org.postgresql.jdbc.PgPreparedStatement \"第一个参数为string的execute， 第一个参数为int的executeWithFlags, executeQuery, executeUpdate \" 实例方法 执行sql方法 同上 创建ExitSpan，追踪本次数据库调用 结束追踪 记录错误堆栈 PgPreparedStatementSetterInstrumentation org.postgresql.jdbc.PgPreparedStatement setAsciiStream, setBinaryStream, setBlob, setBytes, setCharacterStream, setClob, setNCharacterStream, setNClob, setRef, setSQLXML, setUnicodeStream 实例方法 参数绑定（长文本） org.apache.skywalking.apm.plugin.jdbc.JDBCPreparedStatementIgnorableSetterInterceptor statementEnhanceInfos.setParameter(index, \"?\")，记录参数信息，避免数据太大，用”?“代替 PgStatementInstrumentation org.postgresql.jdbc.PgStatement \"第一个参数为stirng或string[]的execute， executeQuery， 第一个参数为stirng或string[]的executeUpdate， executeLargeUpdate，\" 实例方法 执行sql方法 org.apache.skywalking.apm.plugin.jdbc.postgresql.StatementExecuteMethodsInterceptor 创建ExitSpan，追踪本次数据库调用 结束追踪 记录错误堆栈","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"skywalking Jdbc插件分析","slug":"skywalking-Jdbc插件分析","permalink":"https://tianxiafeiyu.github.io/tags/skywalking-Jdbc%E6%8F%92%E4%BB%B6%E5%88%86%E6%9E%90/"}]},{"title":"RESTful API格式规范","slug":"技术开发/grocery/RESTful API格式规范","date":"2022-12-15T23:39:41.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/RESTful API格式规范/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/RESTful%20API%E6%A0%BC%E5%BC%8F%E8%A7%84%E8%8C%83/","excerpt":"","text":"1 RESTful风格RESTful是一种API的设计风格，他和GraphQL ，JSON-RPC，WebService类似，用于定义在CS、BS架构下暴露服务端接口。此次设计对接规范，将使用RESTful作为标准。 1.1 特征RESTful风格的特点是： 1）URI资源化即，URI代表的是资源，而不包含动作。比如，一个班级，有很多学生，我们可以这样表示：&#x2F;class&#x2F;students 2）动作由HTTP头里的方法决定。比如，我们想新增一个学生，我们可以用POST方法： POST &#x2F;class&#x2F;students{“name”: “Jake”,“age” : 18}我们想查看当前有哪些学生，可以用GET方法： GET &#x2F;class&#x2F;students 我们想查看某学生的具体信息，可以用路径指定到某一个ID： GET &#x2F;class&#x2F;students&#x2F;1 我们想要开除id为1的学生，可以用DELETE方法： DELETE &#x2F;class&#x2F;students&#x2F;1 HTTP头里面的方法决定了动作后，后端实现也应该严格根据动作来，比如，GET请求不应该对数据造成任何更改，如此，我们对权限控制便非常方便，例如，如果是访客，我们可以只开放GET方法，而对于ADMIN，我们可以开放GET,POST,DELETE等方法。 大多数就是做CRUD，用HTTP头部动作，可以很好满足。 3）资源的表现由Content-Type决定HTTP请求的头信息中Accept和Content-Type字段，是对资源的表现描述。例如，指定是JSON格式，还是HTML格式。 4）无状态无状态是指客户端无状态，例如，你不应该在客户端使用类似的逻辑： if (hasStudent(“Jake”)) {getStudentInfo(“Jake”);}因为，hasStudent和getStudentInfo调用之间，可能别人已经将Jake删除了，你的状态维护不一定准确。 你可以直接getStudentInfo(“Jake”)，没有则返回失败即可。 服务端可以维护一些状态，但最好不要维护太多，例如，HTTP登录状态，是应该维护的，但是，记录并强制要求用户A是否请求过某个URL再请求另一个URL，这种设计就不应该了。 5）数据安全使用HTTPS协议，加密数据。 我们对接统一采用RESTful方式的HTTPS（为了加密）请求，内容为JSON格式，其中，安全、幂等性、无状态之类的约束，请产品线严格按照Restful规定设计。 1.2 优点1）减少沟通成本。API是开放给别人使用的，由于有既有的约定，会让沟通成本大大减少，这是API提供者最应该考虑的。 2）能够接纳多种客户端(适用于大多数CS BS架构程序)不止是web程序，基本上的CS架构程序，都可以使用RESTful提供API，这样，不论是WEB Client还是Windows APP还是，Mobile APP，都可以轻松使用服务端的API。 由Facebook开放的GraphQL 等也可能在今后流行，不过当前主流的还是RESTful。 3）思维方式转换为以资源为中心传统的方式是以操作为中心，例如create_user, query_students。 类似于面向对象以对象为中心，RESTful推崇以资源为中心，说不上绝对好，但的确会引导大家考虑资源本身，关注内聚性，关注权限，关注资源间关联。 4）扩展方便无状态设计对横向扩展非常方便，因为API之间解耦比较好，资源解耦也比较好。 还有一个叫 hypertext-driven 的东西，类似于自描述，但是用起来也不方便，在CodeReview工具提供的API便是这种方式，优点是服务端可以随意更换URL，缺点是请求前要去查询一下该请求什么路径。例如github的参考https://api.github.com/ 5）建立在HTTP协议基础之上HTTP协议里面规定的东西很多，例如，缓存，压缩，代理，加密，穿透，等等，都已经让HTTP帮忙完成了，给很多实现减负。 1.3 动作GET获取资源 幂等 举例：获取学生Jake的信息。 GET &#x2F;class&#x2F;students?name&#x3D;”Jake” POST创建资源，不会指定资源ID，但创建完成后，通常会返回资源的ID，这样后续可以通过资源ID操作此资源。 非幂等 举例：创建学生。POST &#x2F;class&#x2F;students{“name”: “Jake”, “age” : 18, “score”: 0} PUT整体(Entire Resource)替换。为了定位资源，要求路径上有资源的唯一ID。 幂等 举例：替换ID为2的学生的信息为如下新信息。 PUT &#x2F;class&#x2F;students&#x2F;2{“name”: “Jim”,”age”: 19} 此操作将原本ID为2的学生的所有属性冲掉了，替换后，ID为2的学生整体内部数据结构变为： {“id”: 2, “name”: “Jim”,”age”: 19} 异常： 1.如果Playload为空，返回失败。 2.如果Playload为{}，是正确的，表示清空（重置），例如上述示例内部数据结构将变为：{“id”: 2} PATCH部分(Part Resource)替换。 幂等 为了定位资源，要求路径上有资源的唯一ID。 举例：更新ID为2的学生的年龄从之前的18岁更新为20岁。PATCH &#x2F;class&#x2F;students&#x2F;2{“age”: 20} 这里，ID为2的学生的其他属性保留，整体内部数据结构变成： {“id”: 2, “name”: “Jake”, “age” : 20, “score”: 0} 异常： 1.如果Playload为空或{}，返回失败。 2.对于嵌套的结构，如果是正常书写，表示整体替换；如果是点分结构，表示部分更新。比如： {“id”: 2, “name”: “Jake”, “age” : 20, “score”: {“English”: 86, “Chinese”:88, “math”:99}} 2.1子结构替换： PATCH &#x2F;class&#x2F;students&#x2F;2 {“score”: {“math”:100}} 替换后为： {“id”: 2, “name”: “Jake”, “age” : 20, “score”: {“math”:100}} 2.2 子结构更新： PATCH &#x2F;class&#x2F;students&#x2F;2 {“score.math”: 100} 替换后为： {“id”: 2, “name”: “Jake”, “age” : 20, “score”: {“English”: 86, “Chinese”:88, “math”:100}} 3.对于数组，标准用法是表示整体替换，而不能增删。比如： {“id”: 2, “name”:”Jake”, “friends”: [“Jim”, “Marry”, “Jake”]} 3.1 执行整体替换： PATCH /class/students/2 &#123;&quot;friends&quot;: [&quot;Bob&quot;]&#125; 替换后为： &#123;&quot;id&quot;: 2, &quot;name&quot;:&quot;Jake&quot;, &quot;friends&quot;: [&quot;Bob&quot;]&#125; 3.2 扩展语法，为了支持增加和删除功能，参考rfc6902（我们修改一下使得一致性更好），我们在URL参数上，附带_arrayop&#x3D;[add,remove]，用于表示增删数组，例如： PATCH /class/students/2?_arrayop=add &#123;&quot;friends&quot;: [&quot;Bob&quot;]&#125; 增加后为： &#123;&quot;id&quot;: 2, &quot;name&quot;:&quot;Jake&quot;, &quot;friends&quot;: [&quot;Jim&quot;, &quot;Marry&quot;, &quot;Jake&quot;, &quot;Bob&quot;]&#125; PATCH /class/students/2?_arrayop=remove &#123;&quot;friends&quot;: [&quot;Jim&quot;]&#125; 删除后为： &#123;&quot;id&quot;: 2, &quot;name&quot;:&quot;Jake&quot;, &quot;friends&quot;: [&quot;Marry&quot;, &quot;Jake&quot;]&#125; 这种做法的缺陷是，一个_arrayop控制了整个Playload的array动作，所以，同一Playload如果需要多种动作的情况，请拆分为多次请求。 DELETE删除资源。 幂等 DELETE里面能不能带payload，这个RFC 7231 “Hypertext Transfer Protocol (HTTP&#x2F;1.1): Semantics and Content”是这么规定的： A payload within a DELETE request message has no defined semantics; sending a payload body on a DELETE request might cause some existing implementations to reject the request. 所以，并没有禁止，是否支持依赖于服务端实现，比如某些版本的Tomcat或 Jetty就会忽略payload。 而OpenAPI3.0定义里面描述为： The request body applicable for this operation. The requestBody is only supported in HTTP methods where the HTTP 1.1 specification RFC7231 has explicitly defined semantics for request bodies. In other cases where the HTTP spec is vague, requestBody SHALL be ignored by consumers. 说明，对OpenAPI规范而言，这种模棱两可的描述，是明确要ignored的。 经过我们的实践，发现DELETE带payload需求很多，所以，我们明确一下，支持DELETE带payload的行为，假如遇到实现不支持时，请使用DELETE Over POST实现。 举例： 删除ID为2的学生。DELETE &#x2F;class&#x2F;students&#x2F;2 删除有Jim这个朋友的所有学生。 DELETE &#x2F;class&#x2F;students {“friends”: [“Jim”]} 或表达为DELETE Over POST： POST &#x2F;class&#x2F;students?_method&#x3D;DELETE {“friends”: [“Jim”]} HEAD获取资源元信息。只有HTTP头，不包含数据。 幂等 举例：查看学生Jake是否存在。 HEAD &#x2F;class&#x2F;students?name&#x3D;”Jake” OPTIONS获取资源选项。例如获取服务端支持的方法子集，HTTP版本等。 幂等 举例：获取当前学生API是否支持POST方法。 OPTIONS &#x2F;class&#x2F;student 返回值中有Allow字段，标明支持的方法，Responses to this method are not cacheable. TRACE服务器端loop back消息。 幂等 对RESTful来说基本没用。 CONNECT代理时使用 幂等 对RESTful来说基本没用。 在实际资源操作中，总会有一些不符合 CRUD（Create-Read-Update-Delete） 的情况，处理方法为使用POST加上endpoint, 比如 POST &#x2F;mail&#x2F;:id&#x2F;resend表示重发邮件，建议在资源的基础上加入动作endpoint。 如果参数里面带有_method参数，那_method参数将override掉HTTP协议头里面的动作，用于扩展某些难以支持HTTP头部修改的场景、某些关键字如DELETE无法附带正文内容的问题、某些类防火墙系统截拦PUT等关键字场景。 2 命名规范2.1 关于URL中的横线和下划线先说结论：URL中使用横线“-”或下划线“_”各有利弊，本规范中即不使用横线也不使用下划线。 关于横线和下划线的讨论，如有兴趣可参见：关于URL里面使用下划线还是横线的理由.doc 2.2 URL命名规范规范：全部使用小写字母，如果有多个单词，那么单词之间不需要使用任何分隔符（即不使用下划线，也不使用横线），直接将所有单词拼接在一起即可。 例如，即不使用user-name，也不使用user_name，而是直接使用username。 URL命名规则可用正则描述：&#x2F;^[0-9a-z]+$&#x2F; 举例子：&#x2F;api&#x2F;v1&#x2F;mailsetting&#x2F;testemail 讨论：有人提出疑问“很多时候单词长度查不多时，不分隔一下估计都很难知道是那两个单词”，这个需要再收集一下大家的意见，看是否需要把规划放宽松一些。 2.3 变量命名规范——驼峰法（camel case）变量是指URL查询参数（Query String）和请求体中json字段的名字。 规范：强制新代码使用驼峰法命名，大小写敏感。例如userName。不允许使用下划线或横线来连接单词。 目的：减少了下划线带来的字符长度增加，减少了纠结是使用下划线还是横线的情况，是很多种语言的默认风格（JAVA,C#,GO,SWIFT等新派语言代表）。 特殊场景：允许在变量开头加上一个下划线，用于防止和产品线的关键字冲突，例如：_queryMethod 和 _cache 变量命名规则可用正则描述：&#x2F;^_?[a-z][0-9A-Za-z]*$&#x2F; 举例子：&#x2F;api&#x2F;v1&#x2F;mailsetting&#x2F;testemail?userName&#x3D;zhangsan&amp;_enableAuth&#x3D;1&amp;_cache&#x3D;false POST json数据举例：{“userName”: “zhangsan”, “_enableAuth”: 1, “_cache”: false} 最关键的设计约定是：所有命名尽可能使用单一名称涵盖你要表达的意义，不到万不得已，不要用多个词连接。 2.4 历史版本可选命名规则-蛇形法（snake case）由于有的产品线，例如AD，内部一致使用下划线方式，对转换为驼峰法抗议较多，这里新增一种命名规则，适应这些产品线。 目前发现，使用下划线风格的部门，很难融入整体的驼峰风格，有的规范定义后，显得格格不入，总体规范不会为某个部门单独开一套风格的API。 对接无法保证对端是什么语言，比如是PYTHON、PHP、PERL、JAVASCRIPT，JAVA，GO，不要因为自己的语言习惯下划线而选择下滑线风格。大家不是历史原因万不得已，不要选择这种风格。 所有涉及的参数名称、JSON名称等，都遵循如下命名规范： 1）URL，大小写无感知，user name 使用横线连在一起，写成user-name。 &#x2F;^[0-9a-z][0-9-a-z]*[0-9a-z]$&#x2F; 2）变量，只能出现小写，user name写成user_name。 &#x2F;^[_a-z][_0-9a-z]*$&#x2F; 3 URI格式https://host:port{/separatePath}/{product}/{version}/{resourceURI} 例如： https://200.200.88.88:443/open/api/sip/v1/log/security https://200.200.88.88:443/doc/acloud/v3/keystone https://200.200.88.88:443/api/sangforinter/v1/ 1）separatePath隔离路径因为我们的产品，基本上没有域名，只提供IP访问，导致没办法做子域名，所以，一般的URI隔离，就用路径表示，我们将隔离路径表示为separatePath，其功能类似于子域名，上例中open&#x2F;api就是separatePath。 对于支持域名的产品线（例如云脑），可以将separatePath和product移到子域名。 2）product产品每个部门，有自己不同的产品，例如vt的acloud，本规范主要是用于全公司产品之间互通，product名称叫sangforinter，此处也可以当成模块名称，比如appstore表示app应用商店模块。 3）version版本号每个产品可能会定义不同版本的规范，所有这里有版本号。 我们的sangforinter产品，当前版本号为v1。 关于版本号的位置，虽然HTTP头部的Accept: version&#x3D;1.1里面可以指定version，但是，不太方便操作，不少设计是指定在路径上，例如 &#x2F;v2&#x2F;class&#x2F;students。 4）resourceURIresourceURI为具体的资源URI，这里可以有resource的嵌套。 例如，用WordPress写文章，就会出现Posts和Comments的关系： 有人认为，Comments应该独立于Posts存在，类似： GET &#x2F;api&#x2F;comments?postId&#x3D;XXXX GET &#x2F;api&#x2F;comments&#x2F;:commentsId POST &#x2F;api&#x2F;comments 也有人认为，Comments是依赖于Posts的，类似： GET&#x2F;POST &#x2F;api&#x2F;posts&#x2F;:postId&#x2F;comments 如果是后者，则出现了posts和comments两种资源的嵌套。 4 GET请求GET相关文档请参考https://www.w3.org/2001/tag/doc/get7 4.1 GET OVER POST由于有的部门，GET请求参数过于复杂，或者GET请求要发送很长的URL列表，所以，我们建议，对于比较长（超过几百字符）或比较复杂（有嵌套OBJECT或ARRAY）的情况，使用GET OVER POST方式，即上面讲的，使用POST 发送请求，但是参数里面_method&#x3D;GET的方式。 4.2 GET语义转变从语义上，将GET请求资源的概念转换为POST新增一个请求资源的task，也是比较适合的一种转换方式，不需要GET OVER POST。 例如，获取几百条URL的风险状态，可以转换为，新增一个获取几百条URL的风险状态任务，异步情况下，服务器会返回一个任务ID，供下次查询，同步情况下，服务器直接返回数据TASK执行结果也是可以的。其示例如下。 原本： GET &#x2F;status&#x2F;url?list&#x3D;url1,url2,url3 语义转变后： POST &#x2F;status&#x2F;url&#x2F;task?_method&#x3D;GET { [ &quot;url1&quot;, &quot;url2&quot;, &quot;url3&quot; ] } 4.3 GET传统方式如果不是上面说的，GET请求参数特别复杂的情况，建议使用传统方式。 1）请求参数的最大长度。 GET请求参数放在了URL里面，有最长限制，RFC7230也并没有强制规定，只是建议： at a minimum, request-line lengths of 8000 octets. 目前看，2000字节以内才是安全长度，参考“What is the maximum length of a URL in different browsers?” 参考What is the maximum length of a URL in different browsers? 如果请求参数过长，服务器必须返回414 (Request-URI Too Long) HTTP状态码。 2）请求参数的风格 a) 多参数风格： 建议使用 &#x2F;cars&#x2F;?color&#x3D;blue&amp;type&#x3D;sedan&amp;doors&#x3D;4。 不推荐使用&#x2F;cars&#x2F;color:blue&#x2F;type:sedan&#x2F;doors:4。 b) 数组表示风格： 建议使用&#x2F;appointments?users&#x3D;[id1,id2]。 不推荐使用&#x2F;appointments?users&#x3D;id1,id2。虽然这种方式各位简洁，但是下面我们还要表示对象，需统一风格。 c) 对象表示风格： 建议使用&#x2F;appointments?params&#x3D;{users:[id1,id2], age:18}。 3）URL编码。 URL参数为key&#x3D;value形式，key规定为驼峰命名的纯英文+数组+下划线组合，不能出现中文或其他特殊符号，正则规则为：&#x2F;[_A-Za-z][0-9A-Za-z]*&#x2F; value部分，由于不同的浏览器和html编码设置差异比较大，参见《关于URL编码》为了统一，我们以rfc3986 为标准（主要是中文必须是UTF-8编码而非其他编码）对value做encode。 JS里面对value做encode&#x2F;decode的函数为：encodeURIComponent()&#x2F;decodeURIComponent() PHP里面对value做encode&#x2F;decode的函数为（必须关闭magic_quotes_gpc）：rawurlencode()&#x2F;rawurldecode() 5 批量处理接口1）URI相同的操作，RESTFUL本身就支持BATCH操作，只需要将参数改为数组即可。 比如添加学生，添加一个学生为： POST /class/students {“data”:{“name”:”Jake”, “age”:18}} 添加多个学生（批）为： POST /class/students {“data”:[{“name”:”Jake”, “age”:18},{“name”:”Jakson”, “age”:19}]} 2）URI不同，可以写一个READ ONLY的BATCH接口，不涉及任何WRITE。 某些产品线有这种需求，例如首页有很多URL GET请求，可以合并。 再例如，我们想要同时获取之前三个接口提供的统计信息，可以这样写： POST &#x2F;status&#x2F;batch?_method&#x3D;GET{“items”:[{“path”:”status&#x2F;cpu”,“param” :{“max” : 90}},{“path”:”status&#x2F;memory”},{“path”:”status&#x2F;disk”}]} 3）URI不同，不支持BATCH WRITE操作。 某些产品线有这类需求，但是不建议大家这么设计，原因是很难做到原子操作，会残留中间状态，而且错误处理比较麻烦，幂等性之类的RESTFUL标准也无法满足。 5.1 返回结果子项的格式请参考“回复消息格式”小节。 批量处理，返回结果有三种方式，建议支持第三种返回结果。 1）返回整体错误描述。例如： {“code”: 0,“message”: “success”}2）返回具体的每项错误描述（返回错误数组的顺序和发送时的数组顺序必须一一对应）。例如： [{“code” : 0,“message” : “success”,“data” : {“id” : 1}}, {“code” : 22,“message” : “invalid param”}]3） 返回整体错误描述加具体的每项错误描述（返回错误数组的顺序和发送时的数组顺序必须一一对应），全部成功返回0，部分失败或者全部失败返回错误码57（57本来是EBADSLT(Invalid slot)的意思，取其有的slot有错误的含义，用来表示部分或全部失败）。 {“code” : 57,“message” : “Part failed”,“items” : [{“code” : 0,“message” : “success”,“data” : {“id” : 1}}, {“code” : 22,“message” : “invalid param”}]} 关于HTTP状态码在Restful API里应该如何结合使用，网上争论激烈，到底应该用状态码来表示错误，还是应该在JSON里面填写errorCode。比如这里： https://stackoverflow.com/questions/942951/rest-api-error-return-good-practices/34324179#34324179 https://stackoverflow.com/questions/2380554/rest-mapping-application-errors-to-http-status-codes?noredirect=1&amp;lq=1 我们可以看到，不少厂商，其实结合了两者同时使用，比如IBM的API规范定义如下： 上面，他不仅支持Http Response Code，还将Http Response Code放到JSON块里面返回，目的是为了方便获取Http Response Code，不过有些多此一举，他的错误码，会有一个映射关系，比如404下，有code 1002, 1003分别代表什么含义。这种方式并没有什么问题，而且主流的API管理工具，也支持Http Response Code含义区分。常见的错误码含义： 类型 错误码GET返回值200 - 请求成功。 206 - 请求成功，但只返回了部分（分页场景）。 POST返回值201 - 同步创建成功。 202 - 接收成功，将进行异步处理。 PUT返回值200 - 同步更新成功（原资源已存在）。 201 - 同步创建成功（原资源不存在，和POST类似）。 202 - 接收成功，将进行异步处理。 PATCH返回值200 - 同步更新成功（原资源存在）。 202 - 接收成功，将进行异步处理。 DELETE返回值200 - 同步删除成功。 202 - 接收成功，将进行异步处理。 HEAD返回值 404 - 表示不存在。 通过多方考察和分析，包括Google和Facebook的使用来看，我们得出一个结论，将Http Response Code当成HTTP层的错误码，而errorCode当成应用层的错误码，这样一个划分逻辑更清晰。 所以，只要是到应用层处理逻辑获取到了请求数据，并且不需要状态码协同配合的情况，都应该使用状态码200，然后内部再返回code错误。 举例1，状态码使用场景。 我们收到一个请求&#x2F;users?token&#x3D;xxxx，如果是&#x2F;users这个资源在Apache里面配置为没不具备访问权限，则此时应该由Apache直接返回，此时就是HTTP层错误，返回HTTP Response Code 401。 举例2，错误码使用场景。 我们收到一个请求&#x2F;users?token&#x3D;xxxx，如果是&#x2F;users这个资源具备访问权限，并且进入到了PHP框架代码，框架代码校验token不通过，此时应该返回HTTP Response Code为200，同时附带错误消息： {“code” : 13,“message” : “Token校验失败！”}所以，基本上，我们做API的时候，基本不需要考虑状态码的情况，因为我们全在应用层，如此设计，旨在简化我们的逻辑，对于有的场景，确实需要联动HTTP Response Code的，可以联动，比如上述，也可以返回HTTP Response Code为401，并附带errorCode错误码13。 状态码的具体含义参考： https://www.codetinkerer.com/2015/12/04/choosing-an-http-status-code.html https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html 状态码的RFC参考： https://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml 7 错误码应用层错误码，其意义在于精确定位错误类型，例如5和3表示不同含义，调用端可以根据不同错误码，做更进一步处理，假设只有message（message变动可能性大，而且国际化导致更改），程序很难对错误做进一步处理，一般只能做错误传递。 错误码为数字的原因： 1）数字是所有语言的内置类型，存储不需要额外开辟对象或者堆空间；错误码通过函数参数等方式传递的时候，也不需要考虑类似谁分配谁释放的问题。 2）数字的比较是非常简单的操作(比如有的语言switch case不支持字符串，但是支持数字，字符串需要if else if else方式去比较)，不消耗多少CPU。 3）数字也可以做一些有具体含义的编码，例如HTTP RESPONSE CODE，用4xx和2xx表示不同含义。 4）数字还可以做范围比较，例如 1000 &lt; errno &lt; 10005 这一段表示某一类型错误。 5）数字的errno如果是连续的，用errno对应“错误描述”时可以不使用hash表，而用array即可做translate。例如 en[1] &#x3D; “param invalid”; zh[1] &#x3D; “参数错误”; 6）数字可以兼容C语言系列的API errno直接转换。 为了提高可读写，建议产品线根据语言将errno定义成类似的宏或者常量（不使用原始的数字），例如，如果要写: printf(&quot;&#123;\\&quot;code\\&quot;: %d&#125;&quot;, 1); 这样一个回复，在c语言里面应该是写为： 12printf(&quot;&#123;\\&quot;code\\&quot;: %d&#125;&quot;, EPERM); 9 编码模式REST API支持多种Encoding schemes，用的比较多的是JSON和XML，其次还有CSV，ROW格式等，为了对接不同类型的客户端，特别是在联动外部客户设备的时候，编码模式就会显示出他的价值。 理论上，数据构造层是不需要考虑编码模式的，应由专门的编码模式转换层来根据client的请求转换编码模式。 比如，请求为JSON：Content-Type: application&#x2F;json {“id”: 0,“userName”: “string”,“email”: “string”}请求为XML：Content-Type: application&#x2F;xml &lt;?xml version&#x3D;”1.0” encoding&#x3D;”UTF-8”?&gt; &lt;User&gt; &lt;id&gt;0&lt;&#x2F;id&gt; &lt;userName&gt;string&lt;&#x2F;userName&gt; &lt;email&gt;string&lt;&#x2F;email&gt;&lt;&#x2F;User&gt;之所以要说明编码模式，是今后在设计API底层框架的时候，应该要支持encoding schemes之间的转换。 10 缓存设计很多耗时操作，后端会提前做好缓存，请求时直接返回cache。 如果用户不想获取缓存数据（获取实时数据），可以禁用cache。我们统一定义这类需求，只需要在GET参数里面带_cache&#x3D;0即表示cache disable； _cache&#x3D;1表示cache enable，其他的取值，暂时保留，产品线不能自行定义使用意义（如果有需求，请组织讨论）。 11 异步原则有人提出单独说一下异步消息的处理，这个其实没什么特别的，通用设计是先PUT、POST、DELETE一个异步任务，在返回值里带上后端异步任务的ID，前端间隙GET此异步任务ID，来获取最终的进度。 例如，我们准被创建一个虚拟机，异步请求定义为： POST &#x2F;api&#x2F;vm{“name”: “MySQL Server”,“cpu” : 2,“memory” : 1024}返回值为： HTTP &#x2F; 1.1 200 OK{“code”:0,“message” : “VM is creating!”,“data” :{“id”: string, &#x2F;&#x2F; 例如返回id&#x3D;”2018031420080001”“timeout”: int, &#x2F;&#x2F; 例如180，表示最多检查180s}}客户端再根据返回的id，再次查询进度： GET &#x2F;api&#x2F;vm&#x2F;:id 返回当前更新进度值： HTTP &#x2F; 1.1 200 OK{“code”:0, &#x2F;&#x2F;如果找不到此任务id，code为2，ENOENT“message” : “step 2: copy images!”,“data” :{“percent”: int, &#x2F;&#x2F;完成度，取值范围为[0, 100]，例如90表示完成90%}} 12 国际化所有字符串，全部采用UTF-8编码，禁止采用任何其他编码，对于ANSI表里面可显示字符[0x20,0x80)之外的字符，全部采用Unicode code point，即\\uxxx方式编码： &#x2F;[\\u0009\\u000A\\u000D\\u0020-\\uFFFF]&#x2F; 转换Unicode code point的时候注意，对于超过0xFFFF的部分，以UTF-16的编码代理方式(surrogate pair)表示，即将Unicode code point以两个code unit表示。 UNICODE参考：http://unicode.org/standard/standard.html 同时，所有API请求，必须在头部附带如下固定Content-Type： Content-Type:application&#x2F;json;charset&#x3D;UTF-8 其中charset如果不指定，默认表示UTF-8。 转换示例代码： CMP &gt; RESTful API格式规范v2.4（公司规范） &gt; image2020-7-28_9-21-27.png 请处理好字符串截断，不能包含截断后的UTF8字符！给一段截断示例代码： int Utf8CharLength(const char* start, int length){if (NULL &#x3D;&#x3D; start || length &lt;&#x3D; 0){&#x2F;&#x2F;invalid paramreturn -1;} int firstChar = (unsigned char)(*start); //这是单字节情况：0xxxxxxx -&gt; [0b00000000(0x00), 0b10000000(0x80)) if (firstChar &lt; 0x80) &#123; return 1; //1字节 &#125; //这是follow字节：10xxxxxx -&gt; [0b10000000(0x80), 0b11000000(0xC0)) if (firstChar &lt; 0xC0)// &#123; return 0; //0表示follow字节 &#125; // 0000 0080 - 0000 07FF | 110xxxxx 10xxxxxx // 这是双字节：110xxxxx -&gt; [0b11000000(0xC0), 0b11100000(0xE0)) if (firstChar &lt; 0xE0) &#123; return (length &gt;= 2) ? 2 : -2; &#125; // 0000 0800 - 0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx // 这是三字节：1110xxxx -&gt; [0b11100000(0xE0), 0b11110000(0xF0)) if (firstChar &lt; 0xF0) &#123; return (length &gt;= 3) ? 3 : -3; &#125; // 0001 0000 - 0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx // 这是四字节：11110xxx -&gt; [0b11110000(0xF0), 0b11111000(0xF8)) if (firstChar &lt; 0xF8) &#123;//四字节的时候，我们还应该判断是否Codepoint &lt; 0x10FFFF，这里省略了。 return (length &gt;= 4) ? 4 : -4; &#125; // invalid char return -1; } int Utf8RoundCut(char* str, int* plength){if (NULL &#x3D;&#x3D; str || NULL &#x3D;&#x3D; plength || *plength &lt; 0){return -1;} int length = *plength; if (0 == length) &#123; return 0; &#125; int offset = (length &lt;= 4) ? 0 : (length - 4), chMaxLen, chLen; while (offset &lt; length) &#123; chMaxLen = length - offset; chLen = Utf8CharLength(&amp;str[offset], chMaxLen); if (chLen &lt; 0) &#123; str[offset] = &#39;\\0&#39;; *plength = offset; return chMaxLen; &#125; else &#123;// == 0 || &gt; 0 offset += ((0 == chLen)?1:chLen); //check next &#125; &#125; return 0; } 12.2 Language定义复用HTTP协议头部信息定义，国际化所需语言，直接在HTTP头部定义，例如： Accept-Language:zh-CN 请求英文，头部定义为： Accept-Language:en-US 如果参数里面定义了lang，则参数里面的lang会override掉Accept-Language动作，用于扩展支持某些场景，无法修改HTTP头部的情况。同时，在一些具备让用户下拉选择国际化的设计中，用lang参数可能会比Accept-Language来得方便一些。 12.3 时间格式建议尽量传 UTC seconds，就是c语言中的time(NULL)返回的秒数。 time() returns the time since the Epoch (00:00:00 UTC, January 1, 1970), measured in seconds. 如果觉得可视方面不便，可以采用ISO 8601标准：”yyyy-MM-dd’T’HH:mm:ss.SSS’Z’”，例如，将本地时间”Thu Sep 27 2012 11:00:00 GMT+0800” 转换为 “2012-09-27T03:00:00Z”，对于有毫秒的情况，在Z前添加毫秒，如：”2012-09-27T03:00:00.300Z”，不到万不得已不要用这种方案。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"RESTful API格式规范","slug":"RESTful-API格式规范","permalink":"https://tianxiafeiyu.github.io/tags/RESTful-API%E6%A0%BC%E5%BC%8F%E8%A7%84%E8%8C%83/"}]},{"title":"mysql常用函数汇总","slug":"技术开发/database/mysql常用函数汇总","date":"2022-12-15T23:39:27.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/database/mysql常用函数汇总/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/mysql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E6%B1%87%E6%80%BB/","excerpt":"","text":"转载自 https://www.cnblogs.com/panchanggui/p/10652322.html MySQL函数包括数学函数、字符串函数、日期和时间函数、条件判断函数、系统信息函数、加密函数、格式化函数等。MySQL提供了众多功能强大、方便易用的函数，使用这些函数，可以极大地提高用户对于数据库的管理效率，从而更加灵活地满足不同用户的需求 数学函数 ABS(x)返回x的绝对值 PI()返回圆周率π，默认显示6位小数 SQRT(x)返回非负数的x的二次方根 MOD(x,y)返回x被y除后的余数 CEIL(x)、CEILING(x)返回不小于x的最小整数，即向上取整 FLOOR(x)返回不大于x的最大整数，即向下取整 ROUND(x)、ROUND(x,y)前者返回最接近于x的整数，即对x进行四舍五入；后者返回最接近x的数，其值保留到小数点后面y位，若y为负值，则将保留到x到小数点左边y位 SIGN(x)返回参数x的符号，-1表示负数，0表示0，1表示正数 POW(x,y)和、POWER(x,y)返回x的y次乘方的值 EXP(x)返回e的x乘方后的值 LOG(x)返回x的自然对数，x相对于基数e的对数 LOG10(x)返回x的基数为10的对数 RADIANS(x)返回x由角度转化为弧度的值 DEGREES(x)返回x由弧度转化为角度的值 SIN(x)、ASIN(x)前者返回x的正弦，其中x为给定的弧度值；后者返回x的反正弦值，x为正弦 COS(x)、ACOS(x)前者返回x的余弦，其中x为给定的弧度值；后者返回x的反余弦值，x为余弦 TAN(x)、ATAN(x)前者返回x的正切，其中x为给定的弧度值；后者返回x的反正切值，x为正切 COT(x)返回给定弧度值x的余切 字符串函数 CHAR_LENGTH(str)计算字符串字符个数 CONCAT(s1,s2，…)返回连接参数产生的字符串，一个或多个待拼接的内容，任意一个为NULL则返回值为NULL CONCAT_WS(x,s1,s2,…)返回多个字符串拼接之后的字符串，每个字符串之间间隔为x INSERT(s1,x,len,s2)返回字符串s1，其子字符串起始于位置x，被字符串s2取代len个字符 LOWER(str)和LCASE(str)将str中的字母全部转换成小写 UPPER(str)和UCASE(str)将字符串中的字母全部转换成大写 LEFT(s,n)、RIGHT(s,n) 前者返回字符串s从最左边开始的n个字符，后者返回字符串s从最右边开始的n个字符 LPAD(s1,len,s2)、RPAD(s1,len,s2) 前者返回s1，其左边由字符串s2填补到len字符长度，假如s1的长度大于len，则返回值被缩短至len字符；后者返回s1，其右边由字符串s2填补到len字符长度，假如s1的长度大于len，则返回值被缩短至len字符 LTRIM(s)、RTRIM(s) 前者返回字符串s，其左边所有空格被删除；后者返回字符串s，其右边所有空格被删除 TRIM(s)返回字符串s删除了两边空格之后的字符串 TRIM(s1 FROM s)删除字符串s两端所有子字符串s1，未指定s1的情况下则默认删除空格 REPEAT(s,n)返回一个由重复字符串s组成的字符串，字符串s的数目等于n SPACE(n)返回一个由n个空格组成的字符串 REPLACE(s,s1,s2)返回一个字符串，用字符串s2替代字符串s中所有的字符串s1 STRCMP(s1,s2)若s1和s2中所有的字符串都相同，则返回0；根据当前分类次序，第一个参数小于第二个则返回-1，其他情况返回1 SUBSTRING(s,n,len)、MID(s,n,len)两个函数作用相同，从字符串s中返回一个第n个字符开始、长度为len的字符串 LOCATE(str1,str)、POSITION(str1 IN str)、INSTR(str,str1)三个函数作用相同，返回子字符串str1在字符串str中的开始位置（从第几个字符开始） REVERSE(s)将字符串s反转 ELT(N,str1,str2,str3,str4,…)返回第N个字符串 日期和时间函数 CURDATE()、CURRENT_DATE()将当前日期按照”YYYY-MM-DD”或者”YYYYMMDD”格式的值返回，具体格式根据函数用在字符串或是数字语境中而定 CURRENT_TIMESTAMP()、LOCALTIME()、NOW()、SYSDATE()这四个函数作用相同，返回当前日期和时间值，格式为”YYYY_MM-DD HH:MM:SS”或”YYYYMMDDHHMMSS”，具体格式根据函数用在字符串或数字语境中而定 UNIX_TIMESTAMP()、UNIX_TIMESTAMP(date)前者返回一个格林尼治标准时间1970-01-01 00:00:00到现在的秒数，后者返回一个格林尼治标准时间1970-01-01 00:00:00到指定时间的秒数 FROM_UNIXTIME(date)和UNIX_TIMESTAMP互为反函数，把UNIX时间戳转换为普通格式的时间 UTC_DATE()和UTC_TIME()前者返回当前UTC（世界标准时间）日期值，其格式为”YYYY-MM-DD”或”YYYYMMDD”，后者返回当前UTC时间值，其格式为”YYYY-MM-DD”或”YYYYMMDD”。具体使用哪种取决于函数用在字符串还是数字语境中 MONTH(date)和MONTHNAME(date)前者返回指定日期中的月份，后者返回指定日期中的月份的名称 DAYNAME(d)、DAYOFWEEK(d)、WEEKDAY(d)DAYNAME(d)返回d对应的工作日的英文名称，如Sunday、Monday等；DAYOFWEEK(d)返回的对应一周中的索引，1表示周日、2表示周一；WEEKDAY(d)表示d对应的工作日索引，0表示周一，1表示周二 WEEK(d)、WEEKOFYEAD(d)前者计算日期d是一年中的第几周，后者计算某一天位于一年中的第几周 DAYOFYEAR(d)、DAYOFMONTH(d)前者返回d是一年中的第几天，后者返回d是一月中的第几天 YEAR(date)、QUARTER(date)、MINUTE(time)、SECOND(time)YEAR(date)返回指定日期对应的年份，范围是19702069；QUARTER(date)返回date对应一年中的季度，范围是14；MINUTE(time)返回time对应的分钟数，范围是0~59；SECOND(time)返回制定时间的秒值 EXTRACE(type FROM date)从日期中提取一部分，type可以是YEAR、YEAR_MONTH、DAY_HOUR、DAY_MICROSECOND、DAY_MINUTE、DAY_SECOND TIME_TO_SEC(time)返回以转换为秒的time参数，转换公式为”3600小时 + 60分钟 + 秒” SEC_TO_TIME()和TIME_TO_SEC(time)互为反函数，将秒值转换为时间格式 DATE_ADD(date,INTERVAL expr type)、ADD_DATE(date,INTERVAL expr type)返回将起始时间加上expr type之后的时间，比如DATE_ADD(‘2010-12-31 23:59:59’, INTERVAL 1 SECOND)表示的就是把第一个时间加1秒 DATE_SUB(date,INTERVAL expr type)、SUBDATE(date,INTERVAL expr type)返回将起始时间减去expr type之后的时间 ADDTIME(date,expr)、SUBTIME(date,expr)前者进行date的时间加操作，后者进行date的时间减操作 条件判断函数 IF(expr,v1,v2)如果expr是TRUE则返回v1，否则返回v2 IFNULL(v1,v2)如果v1不为NULL，则返回v1，否则返回v2 CASE expr WHEN v1 THEN r1 [WHEN v2 THEN v2] [ELSE rn] END如果expr等于某个vn，则返回对应位置THEN后面的结果，如果与所有值都不想等，则返回ELSE后面的rn 系统信息函数 VERSION()查看MySQL版本号 CONNECTION_ID()查看当前用户的连接数 USER()、CURRENT_USER()、SYSTEM_USER()、SESSION_USER()查看当前被MySQL服务器验证的用户名和主机的组合，一般这几个函数的返回值是相同的 CHARSET(str)查看字符串str使用的字符集 COLLATION()查看字符串排列方式 加密函数 PASSWORD(str)从原明文密码str计算并返回加密后的字符串密码，注意这个函数的加密是单向的（不可逆），因此不应将它应用在个人的应用程序中而应该只在MySQL服务器的鉴定系统中使用 MD5(str)为字符串算出一个MD5 128比特校验和，改值以32位十六进制数字的二进制字符串形式返回 ENCODE(str, pswd_str)使用pswd_str作为密码，加密str DECODE(crypt_str,pswd_str)使用pswd_str作为密码，解密加密字符串crypt_str，crypt_str是由ENCODE函数返回的字符串 其他函数 FORMAT(x,n)将数字x格式化，并以四舍五入的方式保留小数点后n位，结果以字符串形式返回 CONV(N,from_base,to_base)不同进制数之间的转换，返回值为数值N的字符串表示，由from_base进制转换为to_base进制 INET_ATON(expr)给出一个作为字符串的网络地址的点地址表示，返回一个代表该地址数值的整数，地址可以使4或8比特 INET_NTOA(expr)给定一个数字网络地址（4或8比特），返回作为字符串的该地址的点地址表示 BENCHMARK(count,expr)重复执行count次表达式expr，它可以用于计算MySQL处理表达式的速度，结果值通常是0（0只是表示很快，并不是没有速度）。另一个作用是用它在MySQL客户端内部报告语句执行的时间 CONVERT(str USING charset)使用字符集charset表示字符串str","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"database","slug":"技术开发/database","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/"}],"tags":[{"name":"mysql常用函数汇总","slug":"mysql常用函数汇总","permalink":"https://tianxiafeiyu.github.io/tags/mysql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E6%B1%87%E6%80%BB/"}]},{"title":"mysql联合索引","slug":"技术开发/database/mysql联合索引","date":"2022-12-15T23:39:27.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/database/mysql联合索引/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/mysql%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95/","excerpt":"","text":"sqlalchemy 创建联合索引，报索引超长问题: DBError: (pymysql.err.InternalError) (1071, u&#39;Specified key was too long; max key length is 3072 bytes&#39;) mysql联合索引最大长度为3072，这个长度是怎么计算的呢？ 索引限制12345(5.6里面默认不能超过767bytes，5.7不超过3072bytes)：起因是256×3-1=767。这个3是字符最大占用空间（utf8）。但是在5.5以后，开始支持4个字节的uutf8。255×4&gt;767, 于是增加了一个参数叫做 innodb_large_prefix# 256的由来： 只是因为char最大是255，所以以前的程序员以为一个长度为255的index就够用了，所以设置这个256.历史遗留问题。 --- by 阿里-丁奇 字段1字符长度 * 字符最大占用空间 + 字段2字符长度 * 字符最大占用空间 + … 这个字符最大占用空间取决于编码格式，utf8为3，utf8mb4为4 外键约束CASCADE：对父表进行delete，update操作时，子表也会delete，update掉关联的记录。更新&#x2F;删除主表中记录时自动更新&#x2F;删除子表中关联记录。 RESTRICT：如果想要删除&#x2F;更新父表的记录时，而子表中有关联该父表的记录，则不允许删除&#x2F;更新父表中的记录 SET NULL：对父表进行delete，updat操作时，会将子表中关联的记录外键所在列设置为null，在设置时该列应设置为可以为nullNO ACTION：同 RESTRICT，立即检查外键约束 外键约束作用的是主表，所以对子表做删除、更新、删表等操作，都不影响。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"database","slug":"技术开发/database","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/"}],"tags":[{"name":"mysql联合索引","slug":"mysql联合索引","permalink":"https://tianxiafeiyu.github.io/tags/mysql%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95/"}]},{"title":"Linux shell 各种符号的意义","slug":"技术开发/os/Linux shell 各种符号的意义","date":"2022-12-15T23:39:11.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/os/Linux shell 各种符号的意义/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/os/Linux%20shell%20%E5%90%84%E7%A7%8D%E7%AC%A6%E5%8F%B7%E7%9A%84%E6%84%8F%E4%B9%89/","excerpt":"","text":"一、小括号，圆括号（）1、单小括号 ()①命令组。括号中的命令将会新开一个子shell顺序执行，所以括号中的变量不能够被脚本余下的部分使用。括号中多个命令之间用分号隔开，最后一个命令可以没有分号，各命令和括号之间不必有空格。 ②命令替换。等同于cmd，shell扫描一遍命令行，发现了结构，便将(cmd)结构，便将(cmd)中的cmd执行一次，得到其标准输出，再将此输出放到原来命令。有些shell不支持，如tcsh。 ③用于初始化数组。如：array&#x3D;(a b c d) 2、双小括号 (( ))①整数扩展。这种扩展计算是整数型的计算，不支持浮点型。((exp))结构扩展并计算一个算术表达式的值，如果表达式的结果为0，那么返回的退出状态码为1，或者 是”假”，而一个非零值的表达式所返回的退出状态码将为0，或者是”true”。若是逻辑判断，表达式exp为真则为1,假则为0。 ②只要括号中的运算符、表达式符合C语言运算规则，都可用在((exp))中，甚至是三目运算符。作不同进位(如二进制、八进制、十六进制)运算时，输出结果全都自动转化成了十进制。如：echo((16#5f)) 结果为95 (16进位转十进制) ③单纯用 (( )) 也可重定义变量值，比如 a&#x3D;5; ((a++)) 可将 $a 重定义为6 ④常用于算术运算比较，双括号中的变量可以不使用符号前缀。括号内支持多个表达式用逗号分开。只要括号中的表达式符合C语言运算规则,比如可以直接使用for((i&#x3D;0;i&lt;5;i++)),如果不使用双括号,则为foriin‘seq04‘或者foriin0..4。再如可以直接使用if((i&lt;5)), 如果不使用双括号, 则为if [ $i -lt 5 ]。 二、中括号，方括号[]1、单中括号 []①bash 的内部命令，[和test是等同的。如果我们不用绝对路径指明，通常我们用的都是bash自带的命令。if&#x2F;test结构中的左中括号是调用test的命令标识，右中括号是关闭条件判断的。这个命令把它的参数作为比较表达式或者作为文件测试，并且根据比较的结果来返回一个退出状态码。if&#x2F;test结构中并不是必须右中括号，但是新版的Bash中要求必须这样。 ②Test和[]中可用的比较运算符只有&#x3D;&#x3D;和!&#x3D;，两者都是用于字符串比较的，不可用于整数比较，整数比较只能使用-eq，-gt这种形式。无论是字符串比较还是整数比较都不支持大于号小于号。如果实在想用，对于字符串比较可以使用转义形式，如果比较”ab”和”bc”：[ ab &lt; bc ]，结果为真，也就是返回状态为0。[ ]中的逻辑与和逻辑或使用-a 和-o 表示。 ③字符范围。用作正则表达式的一部分，描述一个匹配的字符范围。作为test用途的中括号内不能使用正则。 ④在一个array 结构的上下文中，中括号用来引用数组中每个元素的编号。 2、双中括号[[ ]]①[[是 bash 程序语言的关键字。并不是一个命令，[[ ]] 结构比[ ]结构更加通用。在[[和]]之间所有的字符都不会发生文件名扩展或者单词分割，但是会发生参数扩展和命令替换。 ②支持字符串的模式匹配，使用&#x3D;~操作符时甚至支持shell的正则表达式。字符串比较时可以把右边的作为一个模式，而不仅仅是一个字符串，比如[[ hello &#x3D;&#x3D; hell? ]]，结果为真。[[ ]] 中匹配字符串或通配符，不需要引号。 ③使用[[ … ]]条件判断结构，而不是[ … ]，能够防止脚本中的许多逻辑错误。比如，&amp;&amp;、||、&lt;和&gt; 操作符能够正常存在于[[ ]]条件判断结构中，但是如果出现在[ ]结构中的话，会报错。比如可以直接使用if [[ $a !&#x3D; 1 &amp;&amp; $a !&#x3D; 2 ]], 如果不适用双括号, 则为if [ $a -ne 1] &amp;&amp; [ $a !&#x3D; 2 ]或者if [ $a -ne 1 -a $a !&#x3D; 2 ]。 ④bash把双中括号中的表达式看作一个单独的元素，并返回一个退出状态码。 例子： 123456789if ($i&lt;5) if [ $i -lt 5 ] if [ $a -ne 1 -a $a != 2 ] if [ $a -ne 1] &amp;&amp; [ $a != 2 ] if [[ $a != 1 &amp;&amp; $a != 2 ]] for i in $(seq 0 4);do echo $i;donefor i in `seq 0 4`;do echo $i;donefor ((i=0;i&lt;5;i++));do echo $i;donefor i in &#123;0..4&#125;;do echo $i;done 三、大括号、花括号 {}1、常规用法①大括号拓展。(通配(globbing))将对大括号中的文件名做扩展。在大括号中，不允许有空白，除非这个空白被引用或转义。第一种：对大括号中的以逗号分割的文件列表进行拓展。如 touch {a,b}.txt 结果为a.txt b.txt。第二种：对大括号中以点点（..）分割的顺序文件列表起拓展作用，如：touch {a..d}.txt 结果为a.txt b.txt c.txt d.txt 123456# ls &#123;ex1,ex2&#125;.sh ex1.sh ex2.sh # ls &#123;ex&#123;1..3&#125;,ex4&#125;.sh ex1.sh ex2.sh ex3.sh ex4.sh # ls &#123;ex[1-3],ex4&#125;.sh ex1.sh ex2.sh ex3.sh ex4.sh ②代码块，又被称为内部组，这个结构事实上创建了一个匿名函数 。与小括号中的命令不同，大括号内的命令不会新开一个子shell运行，QQ号码买卖即脚本余下部分仍可使用括号内变量。括号内的命令间用分号隔开，最后一个也必须有分号。{}的第一个命令和左括号之间必须要有一个空格。 2、几种特殊的替换结构${var:-string},${var:+string},${var:&#x3D;string},${var:?string} ①${var:-string}和${var:&#x3D;string}:若变量var为空，则用在命令行中用string来替换${var:-string}，否则变量var不为空时，则用变量var的值来替换${var:-string}；对于${var:&#x3D;string}的替换规则和${var:-string}是一样的，所不同之处是${var:&#x3D;string}若var为空时，用string替换${var:&#x3D;string}的同时，把string赋给变量var：${var:&#x3D;string}很常用的一种用法是，判断某个变量是否赋值，没有的话则给它赋上一个默认值。 ② ${var:+string}的替换规则和上面的相反，即只有当var不是空的时候才替换成string，若var为空时则不替换或者说是替换成变量 var的值，即空值。(因为变量var此时为空，所以这两种说法是等价的) ③${var:?string}替换规则为：若变量var不为空，则用变量var的值来替换${var:?string}；若变量var为空，则把string输出到标准错误中，并从脚本中退出。我们可利用此特性来检查是否设置了变量的值。 补充扩展：在上面这五种替换结构中string不一定是常值的，可用另外一个变量的值或是一种命令的输出。 3、四种模式匹配替换结构模式匹配记忆方法： #是去掉左边(在键盘上#在$之左边) %是去掉右边(在键盘上%在$之右边) #和%中的单一符号是最小匹配，两个相同符号是最大匹配。 ${var%pattern},${var%%pattern},${var#pattern},${var##pattern}第一种模式：${variable%pattern}，这种模式时，shell在variable中查找，看它是否一给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最短的匹配模式 第二种模式：${variable%%pattern}，这种模式时，shell在variable中查找，看它是否一给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最长的匹配模式 第三种模式：${variable#pattern} 这种模式时，shell在variable中查找，看它是否一给的模式pattern开始，如果是，就从命令行把variable中的内容去掉左边最短的匹配模式 第四种模式：${variable##pattern} 这种模式时，shell在variable中查找，看它是否一给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最长的匹配模式 这四种模式中都不会改变variable的值，其中，只有在pattern中使用了匹配符号时，%和%%，#和##才有区别。结构中的pattern支持通配符，表示零个或多个任意字符，?表示仅与一个任意字符匹配，[…]表示匹配中括号里面的字符，[!…]表示不匹配中括号里面的字符。 123456789101112131415161718# var=testcase # echo $var testcase # echo $&#123;var%s*e&#125; testca # echo $var testcase # echo $&#123;var%%s*e&#125; te # echo $&#123;var#?e&#125; stcase # echo $&#123;var##?e&#125; stcase # echo $&#123;var##*e&#125;# echo $&#123;var##*s&#125; e # echo $&#123;var##test&#125; case 4、字符串提取和替换${var:num},${var:num1:num2},${var&#x2F;pattern&#x2F;pattern},${var&#x2F;&#x2F;pattern&#x2F;pattern} 第一种模式：${var:num}，这种模式时，shell在 var中提取第num个字符到末尾的所有字符。若num为正数，从左边0处开始；若num为负数，从右边开始提取字串，但必须使用在冒号后面加空格或一个数字或整个num加上括号，如${var: -2}、${var:1-3}或${var:(-2)}。 第二种模式：${var:num1:num2}，num1是位置，num2是长度。表示从$var字符串的第$num1个位置开始提取长度为$num2的子串。不能为负数。 第三种模式：${var&#x2F;pattern&#x2F;pattern}表示将var字符串的第一个匹配的pattern替换为另一个pattern。 第四种模式：${var&#x2F;&#x2F;pattern&#x2F;pattern}表示将var字符串中的所有能匹配的pattern替换为另一个pattern。 123456789101112131415[root@centos ~]# var=/home/centos [root@centos ~]# echo $var /home/centos[root@centos ~]# echo $&#123;var:5&#125; /centos[root@centos ~]# echo $&#123;var: -6&#125; centos [root@centos ~]# echo $&#123;var:(-6)&#125; centos [root@centos ~]# echo $&#123;var:1:4&#125; home [root@centos ~]# echo $&#123;var/o/h&#125; /hhme/centos[root@centos ~]# echo $&#123;var//o/h&#125; /hhme/cenths 四、符号$后的括号（1）${a} 变量a的值, 在不引起歧义的情况下可以省略大括号。 （2）$(cmd) 命令替换，和cmd效果相同，结果为shell命令cmd的输，过某些Shell版本不支持$()形式的命令替换, 如tcsh。 （3）$((expression)) 和exprexpression效果相同, 计算数学表达式exp的数值, 其中exp只要符合C语言的运算规则即可, 甚至三目运算符和逻辑表达式都可以计算。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"os","slug":"技术开发/os","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/os/"}],"tags":[{"name":"Linux shell 各种符号的意义","slug":"Linux-shell-各种符号的意义","permalink":"https://tianxiafeiyu.github.io/tags/Linux-shell-%E5%90%84%E7%A7%8D%E7%AC%A6%E5%8F%B7%E7%9A%84%E6%84%8F%E4%B9%89/"}]},{"title":"Linux常用命令","slug":"技术开发/os/Linux常用命令","date":"2022-12-15T23:39:11.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/os/Linux常用命令/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/os/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"远程文件拷贝123456789101112131415//从远程主机拷贝文件到当前目录scp root@172.23.4.112:/opt/test.txt .//从远程主机拷贝文件夹到当前目录scp -r root@172.23.4.112:/opt/test/ .//拷贝文件到远程主机scp /opt/test.txt root@172.23.4.112:/opt//拷贝文夹件到远程主机scp -r /opt/test/ root@172.23.4.112:/opt//指定端口scp -P 22345 ... 性能问题排除1234567891011121314// 查看cpu使用情况top// 查看内存使用情况free -m// 查看内存占用前20进程ps aux | head -1;ps aux |grep -v PID |sort -rn -k +4 | head -20// 查看磁盘使用情况df -h// 查看当前目录下的所有一级子目录和文件的磁盘使用情况du -sh * vi&#x2F;vim使用关键字查询命令模式下，输入： &#x2F; + &lt;关键字&gt; + 回车 （从开头查找） ? + &lt;关键字&gt; + 回车 （从末尾行查找） n（小写）查看下一个匹配 N(大写）查看上一个匹配 命令模式，: + noh&#x2F;set-noh (nohlsearch或者set nohlsearch) 复制粘贴删除两种模式，快速模式和命令模式 快速模式从当前光标作为锚点 yy &#x2F;&#x2F; 复制当前行8yy &#x2F;&#x2F; 从当前光标所在的行开始复制8行 dd &#x2F;&#x2F; 剪切当前行 8dd &#x2F;&#x2F; 从当前光标所在的行开始剪切8行 p &#x2F;&#x2F; 在光标下一行粘贴 : + 1,8d + 回车 &#x2F;&#x2F; 剪切1-8行 ：+ 1,,$d + 回车 &#x2F;&#x2F; 剪切全部 : + 1,8y + 回车 &#x2F;&#x2F; 复制1-8行 ：+ 1,,$y + 回车 &#x2F;&#x2F; 复制全部 行号: + set number + 回车 &#x2F;&#x2F; 显示行号 : + set nonumber + 回车 &#x2F;&#x2F; 隐藏行号 : + n &#x2F;&#x2F; 跳转到n行 : + ,$ &#x2F;&#x2F; 跳转到文件末尾 vim +n filename &#x2F;&#x2F; &#x2F;&#x2F; 打开文件然后跳转到n行 ip&amp;dns配置1234567vi /etc/sysconfig/network-scripts/ifcfg-ens32 // 查看配置cat /etc/resolv.confnameserver 114.114.114.114//查看配置nslookup 127.0.0.1 | grep Server journalctl常用命令 12345678910111213141516171819202122232425262728293031323334353637复制代码# 以flow形式查看日志$ journalctl -f# 查看内核日志$ journalctl -k# 查看指定服务日志$ journalctl -u docker.serivce# 查看指定日期日志$ journalctl --since=&quot;2018-09-21 10:21:00&quot; -u docker$ journalctl --since=&quot;2018-09-21 10:21:00&quot; --until=&quot;2018-09-21 10:22:00&quot; -u docker# 查看指定级别日志$ journalctl -p 3 -u docker.service操作系统提供了从0 (emerg) 到 7 (debug) 一共7个级别的日志，7个级别的含义为： 0: emerg 1: alert 2: crit 3: err 4: warning 5: notice 6: info 7: debug # 查看日志占用的磁盘空间$ journalctl --disk-usage# 设置日志占用的空间$ journalctl --vacuum-size=500M# 设置日志保存的时间$ journalctl --vacuum-time=1month# 检查日志文件一致性$ journalctl –-verify 创建软连接ln -sfn &#x2F;sf&#x2F;etc&#x2F;n9e&#x2F; etc 查看进程所在路径ps aux | grep [name]ll &#x2F;proc&#x2F;{pid} 如何让linux打满 cpu加压：for i in seq 1 $(cat /proc/cpuinfo |grep &quot;physical id&quot; |wc -l); do cpu_test if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;&#x2F;dev&#x2F;null &amp; done 恢复：ps aux | grep cpu_test | awk ‘{print $2}’ | xargs kill -9 查看占用端口的进程 先根据进程名查看进程idps aux | grep 进程名(或者ps -ef | grep 进程名) 通过进程id查看占用的端口netstat -nap | grep 进程id 通过端口号查看占用的进程idnetstat -nap | grep 端口号 iptables1、查看所有规则 iptables -nvL –line-number -L 查看当前表的所有规则，默认查看的是filter表，如果要查看NAT表，可以加上-t NAT参数-n 不对ip地址进行反查，加上这个参数显示速度会快很多-v 输出详细信息，包含通过该规则的数据包数量，总字节数及相应的网络接口–-line-number 显示规则的序列号，这个参数在删除或修改规则时会用到 3w命令123456who #查询系统中的用户(登陆的用户)whoami #查看系统当前用户名whereis #查看系统安装的某个软件的路径which #查找软件的可执行文件路径 whereis python #查看python的安装路径which python #查看python可执行文件路径 命令行获取和修改文本123456789101112// 获取第一列第一行cut -f 1 -d . version | sed -n &#x27;1p&#x27;// 获取指定行awk -F &quot; = &quot; &#x27;NR==2&#123;printf $1 &quot;_suffix&quot;&#125;&#x27; envpasswd.confawk -F &quot;&lt;分隔符&gt;&quot; &#x27;&lt;运算&gt;&#123;printf &lt;列&gt; &quot;&lt;连接符&gt;&quot;&#125;&#x27; &lt;指定文件&gt;sed -i &#x27;s/\\/home\\/bow/\\/user\\/bw/g&#x27; 6.txtsed -i &#x27;s/&lt;匹配内容&gt;/&lt;替换内容&gt;/g&#x27; &lt;指定文件&gt; rpm操作查看某个项目所属的rpm包 rpm -qf 模糊搜索rpm包 rpm -qa | grep 查看rpm包所有文件 rpm -ql 查看系统服务启动顺序及耗时systemd-analyze blame systemd-analyze plot &gt; a.svg（输出到文件，可直接用chrome打开）","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"os","slug":"技术开发/os","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/os/"}],"tags":[{"name":"Linux常用命令","slug":"Linux常用命令","permalink":"https://tianxiafeiyu.github.io/tags/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"}]},{"title":"Java中无处不在的坑","slug":"技术开发/java/Java中无处不在的坑","date":"2022-12-15T23:38:01.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Java中无处不在的坑/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Java%E4%B8%AD%E6%97%A0%E5%A4%84%E4%B8%8D%E5%9C%A8%E7%9A%84%E5%9D%91/","excerpt":"","text":"关于Integer12345678public static void main(String[] args) &#123; Integer a = 1; Integer b = 1; Integer c = 2000; Integer d = 2000; System.out.println(a==b); //true System.out.println(c==d); //false&#125; 原因是自动装箱时调用了Integer.valueOf()这个方法，当值在-128到127之间时从缓存里面拿出来的，超出后会new一个对象 所以Integer的比较要用a.intValue()&#x3D;&#x3D;b.intValue() 或者调用equals方法。Long也有类似的特性。 Java的包装类都不能直接用 &#x3D;&#x3D; 比较。封箱和拆箱在下面的场景中才会存在： 关于Arrays.asList12345public static void main(String[] args) &#123; String[] strings = &#123;&quot;zhao&quot;,&quot;qian&quot;,&quot;sun&quot;&#125;; List&lt;String&gt; list = Arrays.asList(strings); list.add(&quot;li&quot;); // java.lang.UnsupportedOperationException &#125; Arrays.asList() 返回的是java.util.Arrays.ArrayList;不是java.util.ArrayList。 源码中： 12345678910111213141516171819202122232425public class Arrays &#123; public static &lt;T&gt; List&lt;T&gt; asList(T... a) &#123; return new ArrayList&lt;&gt;(a); &#125; /** * @serial include */ private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements RandomAccess, java.io.Serializable &#123; private static final long serialVersionUID = -2764017481108945198L; private final E[] a; ArrayList(E[] array) &#123; a = Objects.requireNonNull(array); &#125; @Override public int size() &#123; return a.length; &#125; ... &#125;&#125; java.util.Arrays.ArrayList 只是Arrays的一个静态内部类，只实现了 get、set、forEach等方法，没有add、remove等方法，无法改变集合大小。 重载函数传入 null123456789101112131415161718192021222324public class Test &#123; public void func1(String param) &#123; System.out.println(&quot;Param type is String&quot;); &#125; public void func1(Object param) &#123; System.out.println(&quot;Param type is Object&quot;); &#125; public void func2( Double param) &#123; System.out.println(&quot;Param type is Double&quot;); &#125; public void func2(Integer param) &#123; System.out.println(&quot;Param type is Integer&quot;); &#125; public static void main(String[] args) &#123; Test test = new Test(); test.func1(null); //Param type is String test.func2(null); //编译不通过 &#125;&#125; 重载函数传入 null: 此时如果参数存在继承关系的话，走的是 类型参数是子类的方法（更具体） 如果参数类型不存在继承关系的话，程序不知道要调哪一个方法，编译报错 关于继承强转的问题java中子类强转父类,实际上依然是子类，该引用只能调用父类中定义的方法和变量； 如果子类中重写了父类中的一个方法，那么在调用这个方法的时候，将会调用子类中的这个方法； 可以认为子类强转父类就是在子类的基础上，照着父类的模版削减自身，只留下父类中存在的方法和属性。 父类是不能强转子类的，除非当前父类是子类装 (new) 出来的，可以转回真正的子类身份。 12List list1 = new ArrayList();ArrayList list2 = (ArrayList) list1; HashSet的问题12345678910111213141516171819202122232425262728293031323334public class Person &#123; public int age; public String name; //注意此处重写了hashCode方法 @Override public int hashCode() &#123; return Objects.hash(age, name); &#125; @Override public String toString() &#123; return &quot;Person&#123;&quot; + &quot;age=&quot; + age + &quot;, name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125; public Person(int age, String name) &#123; this.age = age; this.name = name; &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; Person person1 = new Person(25, &quot;xiaoming&quot;); Person person2 = new Person(32, &quot;xiaohong&quot;); HashSet&lt;Person&gt; hashSet = new HashSet&lt;&gt;(); hashSet.add(person1); hashSet.add(person2); person1.age = 18; hashSet.remove(person1); Iterator&lt;Person&gt; iterator= hashSet.iterator(); while (iterator.hasNext())&#123; System.out.println(iterator.next()); &#125; &#125;&#125; 控制台打印结果：Person{age&#x3D;18, name&#x3D;‘xiaoming’}Person{age&#x3D;32, name&#x3D;‘xiaohong’}可发现 xiaoming 并没有被删除掉 是因为age改成18以后 hashcode值改变了。 ArrayList遍历删除的问题123456789101112public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;a&quot;); list.add(&quot;b&quot;); list.add(&quot;b&quot;); list.add(&quot;c&quot;); for (int i = 0; i &lt; list.size(); i++) &#123; if (&quot;b&quot;.equals(list.get(i))) &#123; list.remove(list.get(i)); &#125; &#125; &#125; 结果错误，因为 remove 会导致下标的改变。针对这种情况可以用倒序删除的方式来避免，数组倒序遍历时即使发生元素删除也不影响后序元素遍历。 123456789101112public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;a&quot;); list.add(&quot;b&quot;); list.add(&quot;b&quot;); list.add(&quot;c&quot;); for(int i=list.size()-1;i&gt;=0;i--)&#123; if(&quot;b&quot;.equals(list.get(i)))&#123; list.remove(list.get(i)); &#125; &#125; &#125; 123456789101112public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;a&quot;); list.add(&quot;b&quot;); list.add(&quot;b&quot;); list.add(&quot;c&quot;); for (String item:list) &#123; if (&quot;b&quot;.equals(item)) &#123; list.remove(item); &#125; &#125; &#125; 上面的程序抛出了java.util.ConcurrentModificationException异常。 正确写法： 12345678910111213public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;a&quot;); list.add(&quot;b&quot;); list.add(&quot;b&quot;); list.add(&quot;c&quot;); Iterator&lt;String&gt; iterator = list.iterator(); while (iterator.hasNext()) &#123; if (&quot;b&quot;.equals(iterator.next())) &#123; iterator.remove(); &#125; &#125;&#125; 使用 String.compareTo() 注意问题java8 源码： 123456789101112131415161718public int compareTo(String anotherString) &#123; int len1 = value.length; int len2 = anotherString.value.length; int lim = Math.min(len1, len2); char v1[] = value; char v2[] = anotherString.value; int k = 0; while (k &lt; lim) &#123; char c1 = v1[k]; char c2 = v2[k]; if (c1 != c2) &#123; return c1 - c2; &#125; k++; &#125; return len1 - len2;&#125; 对于两个比较的字符串： 从左到右最多取 min(len1, len2) 个字符做比较。在比较中，若字符不相等，则返回该位置的字符的ASCII码的差值。 如果比较中的字符都相等，则返回 长度的差值 所以在做数字用的字符串中，整型数据可以使用 compareTo 比较，小数则不应该使用 compareTo 判断大小。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Java中无处不在的坑","slug":"Java中无处不在的坑","permalink":"https://tianxiafeiyu.github.io/tags/Java%E4%B8%AD%E6%97%A0%E5%A4%84%E4%B8%8D%E5%9C%A8%E7%9A%84%E5%9D%91/"}]},{"title":"Java优雅的关闭连接资源","slug":"技术开发/java/Java优雅的关闭连接资源","date":"2022-12-15T23:38:01.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Java优雅的关闭连接资源/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Java%E4%BC%98%E9%9B%85%E7%9A%84%E5%85%B3%E9%97%AD%E8%BF%9E%E6%8E%A5%E8%B5%84%E6%BA%90/","excerpt":"","text":"背景在Java中，如果打开了外部资源（文件、数据库连接、网络连接等），因为外部资源不由JVM管理，无法享用JVM的垃圾回收机制，我们必须在这些外部资源使用完毕后，手动关闭它们。如果我们不在编程时确保在正确的时机关闭外部资源，就会导致外部资源泄露，紧接着就会出现文件被异常占用，数据库连接过多导致连接池溢出等诸多很严重的问题。 传统关闭方式 try-catch-finally1234567891011121314151617181920212223242526272829303132333435363738394041424344 public Object add(User user) &#123; String sql = &quot;insert into user values(?, ?)&quot;; Connection connection = null; PreparedStatement pstm = null; try&#123; connection = defaultConnection(); pstm = connection.prepareStatement(sql); pstm.setString(1, user.getName()); pstm.setString(2, user.getAge()); pstm.executeUpdate(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; if(pstm != null)&#123; try &#123; pstm.close(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; if(connection != null)&#123; try &#123; connection.close(); &#125;catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125; return user; &#125;private Connection defaultConnection()&#123; Connection connection = null; try &#123; Class.forName(driverClassName); return DriverManager.getConnection(url, username, password); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; return connection;&#125; 这一连串的 try-catch-finally 简直是噩梦。。。 优雅释放资源 try-with-resourcetry-with-resource 是 Java7 新增的语法糖，可以省略很多模板化的代码。在 try() 括号中定义的资源将会在 try 语句执行完毕后释放。 使用try-with-resource的前提： JDK1.7及以上的版本 资源必须实现AutoClosable接口（基本都会实现） 12345678910111213141516171819202122232425public Object add(User user) &#123; String sql = &quot;insert into user values(?, ?)&quot;; try ( Connection connection = defaultConnection(); PreparedStatement pstm = connection.prepareStatement(sql) ) &#123; pstm.setString(1, user.getName()); pstm.setString(2, user.getAge()); pstm.executeUpdate(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; return user;&#125;private Connection defaultConnection()&#123; Connection connection = null; try &#123; Class.forName(driverClassName); return DriverManager.getConnection(url, username, password); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; return connection;&#125; 单例模式","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Java优雅的关闭连接资源","slug":"Java优雅的关闭连接资源","permalink":"https://tianxiafeiyu.github.io/tags/Java%E4%BC%98%E9%9B%85%E7%9A%84%E5%85%B3%E9%97%AD%E8%BF%9E%E6%8E%A5%E8%B5%84%E6%BA%90/"}]},{"title":"Java保留小数点后几位","slug":"技术开发/java/Java保留小数点后几位","date":"2022-12-15T23:38:00.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Java保留小数点后几位/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Java%E4%BF%9D%E7%95%99%E5%B0%8F%E6%95%B0%E7%82%B9%E5%90%8E%E5%87%A0%E4%BD%8D/","excerpt":"","text":"1. 使用 Math.round()12float totalPrice = 11.21212float num = (float)(Math.round(totalPrice*100)/100);//如果要求精确4位就*10000然后/10000 2. 使用 DecimalFormat123float price = 1.2;DecimalFormat decimalFormat = new DecimalFormat(&quot;.00&quot;);//构造方法的字符格式这里如果小数不足2位,会以0补足.String p = decimalFomat.format(price);//format 返回的是字符串","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Java保留小数点后几位","slug":"Java保留小数点后几位","permalink":"https://tianxiafeiyu.github.io/tags/Java%E4%BF%9D%E7%95%99%E5%B0%8F%E6%95%B0%E7%82%B9%E5%90%8E%E5%87%A0%E4%BD%8D/"}]},{"title":"Java对象循环引用解法","slug":"技术开发/java/Java对象循环引用解法","date":"2022-12-15T23:38:00.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Java对象循环引用解法/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Java%E5%AF%B9%E8%B1%A1%E5%BE%AA%E7%8E%AF%E5%BC%95%E7%94%A8%E8%A7%A3%E6%B3%95/","excerpt":"","text":"前言循环引用，或者说循环依赖，对象 A 持有对象 B 的引用，对象 B 又持有 A, 两个对象相互引用，或者多个对象形成引用环路。 序列化：对象转字节序列（toJson）。 反序列化：字节对象转对象（fromJson）。 在对象序列化的时候，循环引用会出现堆栈溢出的错误，因为字段将会无限的延伸，比如序列化对象 A 时候： 12345678910111213&#123; A&#123; B&#123; A&#123; B&#123; A&#123; ... &#125; &#125; &#125; &#125; &#125;&#125; 要解决循环引用的问题，就需要打断环。最好是在建模的时候就避免循环引用，当然，有时候循环引用是客观存在的，比如在父子关系的结构中。那么，在序列化的时候，就需要进行断环。 解决方案1. @JsonIgnore@JsonIgnore标注在属性上时候，直接忽略该属性，以断开无限递归，序列化或反序列化均忽略。当然如果标注在get、set方法中，则可以分开控制，序列化对应的是get方法，反序列化对应的是set方法。 123456789101112131415161718class aDTO&#123; //1. 直接忽略属性 @JsonIgnore private B b; //2. 序列化时候忽略属性 @JsonIgnore public B getB()&#123; return b; &#125; //3. 反序列化时候忽略属性 @JsonIgnore public void setB(B b)&#123; this.b = b; &#125;&#125; 注意：当使用@JsonIgnore控制属性的序列化和反序列时，需要与@JsonProperty配合使用，比如要在序列化时忽略属性，在get方法上添加了@JsonIgnore注解，在set方法上添加@JsonProperty注解。否则，在反序列化时候也会被忽略。 2. @JsonBackReference和@JsonManagedReference这两个注解通常配对使用，在父子结构中。 序列化(serialization) @JsonBackReference标注的属性在序列化（serialization，即将对象转换为json数据）时，会被忽略（即结果中的json数据不包含该属性的内容） @JsonManagedReference标注的属性则会被序列化。在序列化时，@JsonBackReference的作用相当于@JsonIgnore，此时可以没有@JsonManagedReference。 反序列化（deserialization） 如果没有@JsonManagedReference，则不会自动注入@JsonBackReference标注的属性（被忽略的父或子） 如果有@JsonManagedReference，则会自动注入自动注入@JsonBackReference标注的属性。 3. @JsonIgnoreProperties@JsonIgnoreProperties(“xxx”)标注在属性或对应的get（序列化）、set（反序列化）方法上,忽略被标对象的某个属性。 4. @JsonIdentityInfo@JsonIdentityInfo(generator&#x3D;ObjectIdGenerators.IntSequenceGenerator.class, property&#x3D;”id”) generator:唯一标识的类型 Property 对象的唯一标识 ，无特殊需求的，一般都是对象的主键 jackson从2.0 增加注解@JsonIdentityInfo解决无限递归的问题,这种方法是，如果发现循环引用，在形成环的最后一步，会将被引用的对象置空，序列化后的结果可能会缺失一部分数据，导致数据不完整。如A-&gt;B-&gt;A , 最后返回的结果是中，A-B-&gt;null。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Java对象循环引用解法","slug":"Java对象循环引用解法","permalink":"https://tianxiafeiyu.github.io/tags/Java%E5%AF%B9%E8%B1%A1%E5%BE%AA%E7%8E%AF%E5%BC%95%E7%94%A8%E8%A7%A3%E6%B3%95/"}]},{"title":"Jpa还是Mybatis？","slug":"技术开发/java/Jpa还是Mybatis？","date":"2022-12-15T23:38:00.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Jpa还是Mybatis？/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Jpa%E8%BF%98%E6%98%AFMybatis%EF%BC%9F/","excerpt":"","text":"转自 https://www.zhihu.com/question/356307466 绝大部分一般要求的业务需求项目，数据量不大，并发压力也不大，他们两个的效率比直接用JDBC的查询效率损失都可以忽略不计。这些项目包括：并发不大，查询一次记录50ms还是150ms其实没什么区别，也不会有很复杂的多个超大表的组合、聚合、子查询这类复杂操作，这时候其实用哪个都还好。如果硬说区别： 1、jpa+hibernate，开发速度快，搞cqrs什么的也方便，对于对开发速度有要求的项目，非常不错。不要迷信换框架，或者换数据库类型，基本上没这个操作，去IOE也就是大公司有那么一两次机会。大家对数据库的依赖程度高到骨头里，轻易不会换的。jpa+hibernate其实也能原生sql，就算是复杂点的sql，hibernate自己也能处理。大家觉得之前用hibernate不爽的可能是hql的不透明，导致不好去针对性优化，对于简单业务其实问题也不大。现在特别提倡全栈、devops，对于一杆子通到底的系统开发，jpa+hibernate是利器。同时hibernate封装了一些dialect的最佳实践，简单的分页之类，可以限制新手写错了，提高了效率。。。总之越简单越小白的系统，越推荐。对了，搞DDD的业务系统开发，也推荐。 2、mybatis，有一定规模的大的系统、数据量很大、并发也大的，对性能有很高要求的，这类系统很少，但是比较推荐用mybatis，大家说的性能其实是次要的，主要是规范管理+方便调优。mybatis是针对DBA友好的，可能很多人意识不到，大公司的开发人员写的SQL是不能直接上线的，一定需要经过DBA去review，这样一个项目把这次修改的所有代码提交，代码的diff自动通过工具提交到了资源开发或架构师那边去review，而mapper文件里的这些SQL的变动会到DBA这边来review，这是非常关键的。开发人员可能并不清楚改动的SQL会对线上造成什么影响，也没有机会让开发人员去线上试验。而DBA可以给出意见，或者修订这些提交的SQL，甚至让开发人员修改或拆分SQL，比如加上一些hint，这个操作用jpa貌似就不好办了。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Jpa还是Mybatis？","slug":"Jpa还是Mybatis？","permalink":"https://tianxiafeiyu.github.io/tags/Jpa%E8%BF%98%E6%98%AFMybatis%EF%BC%9F/"}]},{"title":"java多线程核心技术梳理","slug":"技术开发/java/java多线程核心技术梳理【转】","date":"2022-12-15T23:38:00.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/java多线程核心技术梳理【转】/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E6%A2%B3%E7%90%86%E3%80%90%E8%BD%AC%E3%80%91/","excerpt":"","text":"一、基础知识 创建线程的两种方式： 继承 Thread 类 实现 Runnable 接口 一些基本 API：isAlive(),sleep(),getId(),yield() 等。 isAlive() 测试线程是否处于活动状态 sleep() 让“正在执行的线程”休眠 getId() 取得线程唯一标识 yield() 放弃当前的CPU资源 弃用的 API:stop(),suspend(),resume() 等，已经弃用了，因为可能产生数据不同步等问题。 停止线程的几种方式： 使用退出标识，使线程正常退出，即 run 方法完成。 使用 interrupt 方法中断线程 线程的优先级特性:继承性，规则性，随机性 线程的优先级具有继承性. 如,线程A启动线程B，则B和A优先级一样 线程的优先级具有规则性. CPU尽量倾向于把资源分配给优先级高的线程 线程的优先级具有随机性. 优先级不等同于执行顺序，二者关系不确定 java中的两种线程：用户线程和守护(Daemon)线程。 守护线程：进程中不存在非守护线程时，守护线程自动销毁。典型例子如垃圾回收线程。 二、比较和辨析 某个线程与当前线程：当前线程则是指正在运行的那个线程，可由 currentThread() 方法返回值确定。例如，直接在 main 方法里调用 run 方法，和调用线程的 start 方法，打印出的当前线程结果是不同的。 interrupted() 和 isInterrupted() interrupted() 是类的静态方法，测试当前线程是否已经是中断状态，执行后具有将状态标志清除为false的功能。 isInterrupted() 是类的实例方法，测试Thread对象是否已经是中断状态，但不清楚状态标志。 sleep()和wait()区别： sleep() 是 Thread 类的 static (静态)的方法；wait() 方法是 Object 类里的方法。 sleep() 睡眠时，保持对象锁，仍然占有该锁；wait() 睡眠时，释放对象锁。 在 sleep() 休眠时间期满后，该线程不一定会立即执行，这是因为其它线程可能正在运行而且没有被调度为放弃执行，除非此线程具有更高的优先级；wait() 使用 notify 或者 notifyAlll 或者指定睡眠时间来唤醒当前等待池中的线程。 wait() 必须放在 synchronized block 中，否则会在 runtime 时抛出 java.lang.IllegalMonitorStateException 异常。 方法 是否释放锁 备注 wait 是 wait 和 notify&#x2F;notifyAll 是成对出现的, 必须在 synchronize 块中被调用 sleep 否 可使低优先级的线程获得执行机会 yield 否 yield 方法使当前线程让出 CPU 占有权, 但让出的时间是不可设定的 三、对象及变量的并发访问 synchronized 关键字 调用用关键字 synchronized 声明的方法是排队运行的。但假如线程A持有某对象的锁，那线程B异步调用非 synchronized 类型的方法不受限制。 synchronized 锁重入:一个线程得到对象锁后，再次请求此对象锁时是可以得到该对象的锁的。同时，子类可通过“可重入锁”调用父类的同步方法。 同步不具有继承性。 synchronized 使用的“对象监视器”是一个，即必须是同一个对象 synchronized 同步方法和 synchronized 同步代码块。 对其他 synchronized 同步方法或代码块调用呈阻塞状态。 同一时间只有一个线程可执行 synchronized 方法&#x2F;代码块中的代码。 synchronized(非 this 对象 x)，将 x 对象作为“对象监视器”。 当多个线程同时执行 synchronized(x){} 同步代码块时呈同步效果。 当其他线程执行 x 对象中 synchronizd 同步方法时呈同步效果。 当其他线程执行 x 对象方法里的 synchronized(this) 代码块时呈同步效果。 静态同步 synchronized 方法与 synchronized(class) 代码块：对当前对应的 class 类进行持锁。 volatile 关键字：主要作用是使变量在多个线程间可见。加 volatile 关键字可强制性从公共堆栈进行取值,而不是从线程私有数据栈中取得变量的值。 在方法中 while 循环中设置状态位(不加 volatile 关键字)，在外面把状态位置位并不可行，循环不会停止，比如 JVM 在 -server 模式。因为私有堆栈中的值和公共堆栈中的值不同步。 volatile 增加了实例变量在多个线程间的可见性，但不支持原子性。 原子类:一个原子类型就是一个原子操作可用的类型，可在没有锁的情况下做到线程安全。但原子类也不是完全安全，虽然原子操作是安全的，可方法间的调用却不是原子的，需要用同步。 synchronized 静态方法与非静态方法： synchronized 关键字加 static 静态方法上是给 Class 类上锁，可以对类的所有实例对象起作用。 synchronized 关键字加到非 static 静态方法上是给对象上锁，对该对象起作用。 synchronized 和volatile 比较 ： 关键字 volatile 是线程同步的轻量级实现，性能比 synchronized 好，且 volatile 只能修饰变量，synchronized 可修饰方法和代码块。 多线程访问 volatile 不会发生阻塞，synchronized 会出现阻塞。 volatile 能保证数据可见性，不保证原子性；synchronized 可以保证原子性，也可以间接保证可见性，因为** synchronized 会将私有内存和公共内存中的数据做同步**。 volatile 解决的是变量在多个线程间的可见性，synchronized 解决的是多个线程访问资源的同步性。 String 常量池特性，故大多数情况下，synchronized 代码块都不适用 String 作为锁对象。 多线程死锁。使用JDK自带工具，jps 命令 + jstack 命令监测是否有死锁。 一个线程出现异常时，其所持有的锁会自动释放。 四、线程间通信 等待&#x2F;通知机制：wait()和notify()&#x2F;notifyAll()。wait使线程停止运行，notify使停止的线程继续运行。 wait()：将当前执行代码的线程进行等待，置入”预执行队列”。 在调用wait()之前，线程必须获得该对象的对象级别锁； 执行wait()方法后，当前线程立即释放锁； 从wait()返回前，线程与其他线程竞争重新获得锁； 当线程呈wait()状态时，调用线程的interrup()方法会出现InterrupedException异常； wait(long)是等待某一时间内是否有线程对锁进行唤醒，超时则自动唤醒。 notify()：通知可能等待该对象的对象锁的其他线程。随机挑选一个呈wait状态的线程，使它等待获取该对象的对象锁。 在调用notify()之前，线程必须获得该对象的对象级别锁； 执行完notify()方法后，不会马上释放锁，要直到退出synchronized代码块，当前线程才会释放锁； notify()一次只随机通知一个线程进行唤醒。 notifyAll()和notify()差不多，只不过是使所有正在等待队中等待同一共享资源的“全部”线程从等待状态退出，进入可运行状态。 每个锁对象有两个队列：就绪队列和阻塞队列。 就绪队列：存储将要获得锁的线程 阻塞队列：存储被阻塞的的线程 生产者&#x2F;消费者模式 “假死”：线程进入WAITING等待状态，呈假死状态的进程中所有线程都呈WAITING状态。 假死的主要原因：有可能连续唤醒同类。notify唤醒的不一定是异类，也许是同类，如“生产者”唤醒“生产者”。 解决假死：将notify()改为notifyAll()。 wait条件改变，可能出现异常，需要将if改成while。 通过管道进行线程间通信：一个线程发送数据到输出管道，另一个线程从输入管道读数据。 字节流：PipedInputStream和PipedOutputStream。 字符流：PipedReader和PipedWriter。 join()：等待线程对象销毁，具有使线程排队运行的作用。 join()与interrupt()方法彼此遇到会出现异常。 join(long)可设定等待的时间。 join与synchronized的区别：join在内部使用wait()方法进行等待;synchronized使用的是“对象监视器”原理作为同步。 join(long)与sleep(long)的区别：join(long)内部使用wait(long)实现，所以join(long)具有释放锁的特点;Thread.sleep(long)不释放锁。 ThreadLocal类：每个线程绑定自己的值 。 覆写该类的initialValue()方法可以使变量初始化，从而解决get()返回null的问题。 InheritableThreadLocal类可在子线程中取得父线程继承下来的值。 五、Lock的使用 ReentrantLock类：实现线程之间的同步互斥，比synchronized更灵活 lock()，调用了的线程就持有了“对象监视器”，效果和synchronized一样 使用Condition实现等待&#x2F;通知：比wait()和notify()&#x2F;notyfyAll()更灵活，比如可实现多路通知。 调用condition.await()前须先调用lock.lock()获得同步监视器。 Object与Condition方法对比 Object Conditon wait() await() wait(long timeout) await(long time,TimeUnit unit) notify() signal() notifyAll() signalAll() Condition API 方法 说明 int getHoldCount() 查询当前线程保持此锁定的个数，即调用lock()方法的次数 int getQueueLength() 返回正在等待获取此锁定的线程估计数 int getWaitQueueLength(Condition condition) 返回等待与此锁定相关的给定条件Conditon的线程估计数 boolean hasQueueThread(Thread thread) 查询指定的线程是否正在等待获取此锁定 boolean hasQueueThreads() 查询是否有线程正在等待获取此锁定 boolean hasWaiters(Condition) 查询是否有线程正在等待与此锁定有关的condition条件 boolean isFair() 判断是不是公平锁 boolean isHeldByCurrentThread() 查询当前线程是否保持此锁定 boolean isLocked() 查询此锁定是否由任意线程保持 void lockInterruptibly() 如果当前线程未被中断，则获取锁定，如果已经被中断则出现异常 boolean tryLock() 仅在调用时锁定未被另一个线程保持的情况下，才获取该锁定 boolean tryLock(long timeout,TimeUnit unit) 如果锁定在给定等待时间内没有被另一个线程保持，且当前线程未被中断，则获取该锁定 公平锁与非公平锁 公平锁表示线程获取锁的顺序是按照加锁的顺序来分配的，即FIFO先进先出。 非公平锁是一种获取锁的抢占机制，随机获得锁。 ReentrantReadWriteLock类 读读共享 写写互斥 读写互斥 写读互斥 六、定时器 schedule API 方法 说明 schedule(TimerTask task, Date time) 在指定的日期执行某一次任务 scheduleAtFixedRate(TimerTask task, Date firstTime, long period) 在指定的日期之后按指定的间隔周期，无限循环的执行某一任务 schedule(TimerTask task, long delay) 以执行此方法的当前时间为参考时间，在此时间基础上延迟指定的毫秒数后执行一次TimerTask任务 schedule(TimerTask task, long delay, long period) 以执行此方法的当前时间为参考时间，在此时间基础上延迟指定的毫秒数，再以某一间隔时间无限次数地执行某一TimerTask任务 schedule和scheduleAtFixedRate的区别:schedule不具有追赶执行性;scheduleAtFixedRate具有追赶执行性。 七、单例与多线程 立即加载&#x2F;“饿汉模式”：调用方法前，实例已经被创建了。通过静态属性new实例化实现的。 延迟加载&#x2F;“懒汉模式”：调用get()方法时实例才被创建。最常见的实现办法是在get()方法中进行new实例化 。 缺点：多线程环境中，会出问题。 解决方法 ： 声明synchronized关键字，但运行效率非常低下 同步代码块，效率也低 针对某些重要代码(实例化语句)单独同步，效率提升，但会出问题 使用DCL双检查锁 使用enum枚举数据类型实现单例模式 七、补充 线程的状态：Thread.State枚举类 BLOCKED 阻塞态 NEW 创建态 RUNNABLE 运行态 TERMINATED 结束态 TIMED_WAITING 指定时间休眠态 WAITING 休眠态 线程组：线程组中可以有线程对象，也可以有线程组，组中还可以有线程。可批量管理线程或线程组对象。 SimpleDateFormat非线程安全，解决办法有： 创建多个SimpleDateFormat类的实例 使用ThreadLocal类 线程组出现异常的处理 setUncaughtExceptionHandler() 给指定线程对线设置异常处理器 setDefaultUncaughtExceptionHandler() 对所有线程对象设置异常处理器 转载自 https://blog.csdn.net/h3243212/article/details/51180173","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"java多线程核心技术梳理【转】","slug":"java多线程核心技术梳理【转】","permalink":"https://tianxiafeiyu.github.io/tags/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E6%A2%B3%E7%90%86%E3%80%90%E8%BD%AC%E3%80%91/"}]},{"title":"AI视频处理软件","slug":"技术开发/grocery/AI视频处理软件","date":"2022-12-15T23:37:48.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/AI视频处理软件/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/AI%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86%E8%BD%AF%E4%BB%B6/","excerpt":"","text":"这么一款视频处理软件： 提高码率，最高支持8k视频输出 提高帧率 降低噪点 10m左右的480视频，输出为1080p，大概耗时1h （1660s） 图像处理确实是一个费时费力的过程 通过自己的工具从不知名网站下载 m3u8 视频，都是一些码率很低，清晰度很差的视频 通过ai视频工具，明显提高视频码率，就是大小也明显增长，99M的20分钟左右视频，升码到1080，大小变为1.6G，耗时 3h","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"AI视频处理软件","slug":"AI视频处理软件","permalink":"https://tianxiafeiyu.github.io/tags/AI%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86%E8%BD%AF%E4%BB%B6/"}]},{"title":"FTP、FTPS和SFTP都是啥","slug":"技术开发/grocery/FTP、FTPS和SFTP都是啥","date":"2022-12-15T23:37:48.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/FTP、FTPS和SFTP都是啥/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/FTP%E3%80%81FTPS%E5%92%8CSFTP%E9%83%BD%E6%98%AF%E5%95%A5/","excerpt":"","text":"FTP、FTPS和SFTP简介 FTP FTP 即 文件传输协议（英语：File Transfer Protocol 的缩写）是一个用于计算机网络上在客户端和服务器之间进行文件传输的应用层协议。完整的 FTP 是由 FTP 服务器 和 FTP 客户端组成的，客户端可以将本地的文件通过 FTP 协议上传到服务器，也可以将服务器的文件下载到本地。它是当今使用的最古老的文件传输协议之一，是一种非常便捷的移动文件的方式。 FTP 的工作原理 FTP 连接需要 FTP 服务器和客户端两方在网络上建立通信。建立 FTP 连接时会有两个不同的通信通道。一个被称为命令通道，它的作用是发出和响应指令。另一个为数据通道，用于客户端和服务器端进行数据交互。 使用 FTP 传输文件时，用户需要通过向 FTP 服务器提供凭据来获得文件传输许可。当然某些公共 FTP 服务器可能不需要凭据即可访问其文件，但是无法保证数据传输的安全性，任何未加密公共网络上的数据发送都是非常危险的，所以为了保护传输数据的安全，由 FTP 衍生而出的就是下面的两种协议：FTPS 与 SFTP。 FTPS 一种多传输协议，相当于加密版的FTP。当你在FTP服务器上收发文件的时候，你面临两个风险。第一个风险是在上载文件的时候为文件加密。第二个风险是，这些文件在你等待接收方下载的时候将停留在FTP服务器上，这时你如何保证这些文件的安全。你的第二个选择（创建一个支持SSL的FTP服务器）能够让你的主机使用一个FTPS连接上载这些文件。这包括使用一个在FTP协议下面的SSL层加密控制和数据通道。一种替代FTPS的协议是安全文件传输协议(SFTP)。这个协议使用SSH文件传输协议加密从客户机到服务器的FTP连接。 FTPS是在安全套接层使用标准的FTP协议和指令的一种增强型FTP协议，为FTP协议和数据通道增加了SSL安全功能。FTPS也称作“FTP-SSL”和“FTP-over-SSL”。SSL是一个在客户机和具有SSL功能的服务器之间的安全连接中对数据进行加密和解密的协议。 和sftp连接方法类似，在windows中可以使用FileZilla等传输软件来连接FTPS进行上传，下载文件，建立，删除目录等操作,在FileZilla连接时，有显式和隐式TLS&#x2F;SSL连接之分，连接时也有指纹提示。 SFTPSftp是(Secure File Transfer Protocol)的缩写，安全文件传送协议。可以为传输文件提供一种安全的加密方法。sftp 与 ftp 有着几乎一样的语法和功能。SFTP 为 SSH的一部分，是一种传输档案至 Blogger 服务器的安全方式。其实在SSH软件包中，已经包含了一个叫作SFTP(Secure File Transfer Protocol)的安全文件传输子系统，SFTP本身没有单独的守护进程，它必须使用sshd守护进程（端口号默认是22）来完成相应的连接操作，所以从某种意义上来说，SFTP并不像一个服务器程序，而更像是一个客户端程序。SFTP同样是使用加密传输认证信息和传输的数据，所以，使用SFTP是非常安全的。但是，由于这种传输方式使用了加密&#x2F;解密技术，所以传输效率比普通的FTP要低得多，如果您对网络安全性要求更高时，可以使用SFTP代替FTP。 SFTP 和FTPS的区别 SFTP 和FTPS都是为ftp连接加密，协议非常相似。 一个时借助ssh加密，一个是借助ssl协议加密。 ssl是为http&#x2F;smtp等加密设计的，ssh是为telnet&#x2F;ftp等加密、建立传输通道而设计的。 其实ssh建立传输通道就是为了加密和传输，而且这个通道是可以用来远程登录。如果只说它们的功能，通俗的讲，ssh就像铺管子，ssl就像打包裹，铺管子和打包裹都会使数据安全，都是一个制作密钥的过程，而因为ssh是一个管子所以它很适合ftp的安全传输。 简单的讲：sftp协议是ssh中的一条独立的协议，利用sftp服务器就可以传输数据。而ftps是ftp-over-ssl的意思，即ftp借助ssl协议加密传输，不但要用ftp服务器还要用ssl协议加密。（如果是ftp-over-ssh，就是完全不同于sftp的传输方式了，就是利用ftp服务器和ssh协议加密传输数据。 ） FTP和SFTP的区别 文件传送协议FTP(File Transfer Protocol)是TCP&#x2F;IP协议簇中的一个成员，也是现在因特网上最广泛的文件传送协议。FTP协议包括两个部分，一个是FTP客户端，另一个是FTP服务器。当然，FTP服务器是用来存储文件资源的，FTP客户端通过访问FTP服务器来获得资源的。 一般情况下，当使用FTP服务的时候，我们都知道默认是21号端口，其实还有一个20号端口。FTP使用两个TCP连接，21号端口负责控制连接，20号端口负责数据连接，这样才不会混乱，是FTP可以更好的为我们服务。FTP协议的工作方式可以分为主动方式和被动方式两种，主动是指FTP客户端发送PORT命令连接FTP服务器，被动是FTP客户端发送PASV命令连接FTP服务器。 主动方式：在通过21号端口连接好控制通道后，客户端发送给服务器PORT命令，就是给服务器说咱们俩通信你可以在那个端口进行，于是服务器打开20号端口，连接上客户端的指定的端口进行连接，传送数据。需要创建一个新的连接。 被动方式：在通过21号端口连接好控制通道后，客户端发送给服务器PASV命令，就是给服务器说咱们俩通信的端口号你选择，然后服务器随机选择一个端口（大于1024）,FTP客户端连接至此端口，进行通信。不需要创建一个新的连接。 安全文件传送协议SFTP(Secure File Transfer Protocol)可以为文件传送提供安全的加密&#x2F;解密技术。基本语法和FTP差不多。SFTP是SSH的一部分，在SSH软件包中，已经包含了一个SFTP(Secure File Transfer Protocol)的安全文件传输子系统，SFTP本身没有单独的守护进程，它必须使用sshd守护进程（端口号默认是22）来完成相应的连接操作。由于这种传输方式使用了加密&#x2F;解密技术，文件传送相对来说是很安全的，但是是有代价的，它的传输效率比FTP要低得多。 SSL证书是HTTP明文协议升级HTTPS加密协议的重要渠道，是网络安全传输的加密到通道。关于更多SSL证书的资讯，请关注GDCA（数安时代）。GDCA致力于网络信息安全，已通过WebTrust 的国际认证，是全球可信任的证书签发机构。GDCA专业技术团队将根据用户具体情况为其提供最优的产品选择建议，并针对不同的应用或服务器要求提供专业对应的HTTPS解决方案。————————————————版权声明：本文为CSDN博主「Flynn up！」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/Mr_Fan97/article/details/119539189","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"FTP、FTPS和SFTP都是啥","slug":"FTP、FTPS和SFTP都是啥","permalink":"https://tianxiafeiyu.github.io/tags/FTP%E3%80%81FTPS%E5%92%8CSFTP%E9%83%BD%E6%98%AF%E5%95%A5/"}]},{"title":"github添加ssh方法","slug":"技术开发/grocery/github添加ssh方法","date":"2022-12-15T23:37:48.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/github添加ssh方法/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/github%E6%B7%BB%E5%8A%A0ssh%E6%96%B9%E6%B3%95/","excerpt":"","text":"Windows生成一个新的SSH key打开 git bash 输入 ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot; 输入一个文件名，默认是id_rsa，该步骤可直接选择默认即可。（多用户的可能要设置另一个名字，以防止冲突） 输入密码，同上可以选择默认即可。 将新生成的SSH key添加到github复制key到粘贴板 github设置中添加ssh key Linux生成密钥ssh-keygen -t rsa -C &quot;11706@sangfor.com&quot; 根据提示完成下一步 添加 SSH key到 ssh-agenteval $(ssh-agent -s) 确保ssh-agent工作 ssh-add ~/.ssh/id_rsa 将 ssh 私钥添加到 ssh 代理中 将新生成的SSH key添加到github复制key到粘贴板 github设置中添加ssh key 连接测试ssh -T git@github.com 12$ ssh -T git@github.comHi xxx! You&#x27;ve successfully authenticated, but GitHub does not provide shell access. 如果某天突然报错 123kex_exchange_identification: Connection closed by remote hostConnection closed by 20.205.243.166 port 22fatal: Could not read from remote repository. 可以尝试重新运行一次 ssh -T git@github.com 命令","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"github添加ssh方法","slug":"github添加ssh方法","permalink":"https://tianxiafeiyu.github.io/tags/github%E6%B7%BB%E5%8A%A0ssh%E6%96%B9%E6%B3%95/"}]},{"title":"git—合并不同仓库的项目代码","slug":"技术开发/grocery/git—合并不同仓库的项目代码","date":"2022-12-15T23:37:48.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/git—合并不同仓库的项目代码/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/git%E2%80%94%E5%90%88%E5%B9%B6%E4%B8%8D%E5%90%8C%E4%BB%93%E5%BA%93%E7%9A%84%E9%A1%B9%E7%9B%AE%E4%BB%A3%E7%A0%81/","excerpt":"","text":"转载自 https://www.cnblogs.com/phpper/p/8391607.html git合并两个不同的仓库目前开发是2个仓库，线上仓库online_a（对应的branch分支为online）,测试环境online_b（对应的branch分支为demo），测试环境需要时刻保持onine_a上的最新稳定稳定代码同步过来。如何合并呢？特此记录下：在测试仓库onine_b 上执行： 测试仓库添加远程生产仓库(切换到自己的测试仓库下执行以下命令，比如我的当期测试online_b.git) git remote add online_a &#103;&#105;&#x74;&#x40;&#x67;&#x69;&#x74;&#x68;&#117;&#x62;&#46;&#x63;&#x6f;&#x6d;:fantasy&#x2F;online_a.git &#x2F;&#x2F;将online_a作为远程仓库，添加到online_b中，设置别名为online_a(自定义，这里我是为了方便区分仓库名) 从远程仓库下载，这时我们弄个新的 $ git fetch online-aremote: Counting objects: 21744, done.remote: Compressing objects: 100% (7380&#x2F;7380), done.remote: Total 21744 (delta 15332), reused 20415 (delta 14323)Receiving objects: 100% (21744&#x2F;21744), 2.44 MiB | 214.00 KiB&#x2F;s, done.Resolving deltas: 100% (15332&#x2F;15332), completed with 201 local objects.From &#103;&#x69;&#x74;&#64;&#x67;&#105;&#x74;&#104;&#x75;&#x62;&#x2e;&#99;&#x6f;&#109;:fantasy&#x2F;online_a.git* [new branch] demo -&gt; online-backend&#x2F;demo [new branch] online -&gt; online-backend&#x2F;online [new tag] demo-last-bad -&gt; demo-last-bad [new tag] demo-last-ok -&gt; demo-last-ok [new tag] v2.0-beta -&gt; v2.0-beta [new tag] v2.1-days -&gt; v2.1-days [new tag] v2.1-dist -&gt; v2.1-dist [new tag] v2.2-dist -&gt; v2.2-dist [new tag] v2.2-nosmartbid -&gt; v2.2-nosmartbid [new tag] v2.2demo -&gt; v2.2demo [new tag] v2.3-bad-smartbid -&gt; v2.3-bad-smartbid [new tag] demo-no-score -&gt; demo-no-score [new tag] tmp-repay-v1 -&gt; tmp-repay-v1 [new tag] tmp-repay-v2 -&gt; tmp-repay-v2 [new tag] transfer-dep-last -&gt; transfer-dep-last [new tag] transfer-dep-ok -&gt; transfer-dep-ok 3.将online_a仓库抓去的online分支作为新分支checkout到本地，新分支名设定为online_repo1 $ git checkout -b online_repo1 online-a/online //注意这里也是别名online_a Switched to a new branch &#39;online_repo1&#39; Branch &#39;online_repo1&#39; set up to track remote branch &#39;online&#39; from &#39;online-a&#39;. 4.切换回本地测试的online_b的demo分支 $ git checkout demo Switched to branch &#39;demo&#39; Your branch is up to date with &#39;origin/demo&#39;. 5.将online_repo1合并入demo分支 git merge online_repo1 6.解决冲突 git add . git commit -m &quot;合并&quot; git push online_repo1 online_a:online //上传到远程库 git checkout demo git merge online_repo1 git branch -d online_repo1 总结 大致思路是伪造远程的repo1仓库为repo2的一个分支，然后合并进来； 若是文件有冲突、或要建立子目录，建议在repo1中先解决，再进行如上操作。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"git—合并不同仓库的项目代码","slug":"git—合并不同仓库的项目代码","permalink":"https://tianxiafeiyu.github.io/tags/git%E2%80%94%E5%90%88%E5%B9%B6%E4%B8%8D%E5%90%8C%E4%BB%93%E5%BA%93%E7%9A%84%E9%A1%B9%E7%9B%AE%E4%BB%A3%E7%A0%81/"}]},{"title":"git仓库第一次提交时失败问题记录","slug":"技术开发/grocery/git仓库第一次提交时失败问题记录","date":"2022-12-15T23:37:48.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/git仓库第一次提交时失败问题记录/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/git%E4%BB%93%E5%BA%93%E7%AC%AC%E4%B8%80%E6%AC%A1%E6%8F%90%E4%BA%A4%E6%97%B6%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/","excerpt":"","text":"问题： 本地初始化 git 仓库，并且进行了 add 和 commit 操作。 github 上新建 git 仓库。 本地仓库添加了github上的git仓库作为远程仓库，起名origin。$git remote add origin https://github.com/… 本地仓库在想做同步远程仓库到本地为之后本地仓库推送到远程仓库做准备时报错：fatal: refusing to merge unrelated histories（拒绝合并不相关的历史） 解决：出现这个问题的最主要原因还是在于本地仓库和远程仓库实际上是独立的两个仓库。假如我之前是直接clone的方式在本地建立起远程github仓库的克隆本地仓库就不会有这问题了。 查阅了一下资料，发现可以在pull命令后紧接着使用–allow-unrelated-history选项来解决问题（该选项可以合并两个独立启动仓库的历史）。 命令： $git pull origin master --allow-unrelated-histories 以上是将远程仓库的文件拉取到本地仓库了。紧接着将本地仓库的提交推送到远程github仓库上，使用的命令是： $ git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; 也就是 $git push origin master:master 提交成功。 其实在github创建空的仓库时候，就已经功能给出仓库初始提交的提示，注意网页上的提示。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"git仓库第一次提交时失败问题记录","slug":"git仓库第一次提交时失败问题记录","permalink":"https://tianxiafeiyu.github.io/tags/git%E4%BB%93%E5%BA%93%E7%AC%AC%E4%B8%80%E6%AC%A1%E6%8F%90%E4%BA%A4%E6%97%B6%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"}]},{"title":"数据库之脏读、幻读、不可重复读","slug":"技术开发/database/数据库之脏读、幻读、不可重复读","date":"2022-12-15T23:37:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/database/数据库之脏读、幻读、不可重复读/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8B%E8%84%8F%E8%AF%BB%E3%80%81%E5%B9%BB%E8%AF%BB%E3%80%81%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB/","excerpt":"","text":"1. 事务数据库事务，是由有限的数据库操作序列组成的逻辑执行单元，这一系列操作要么全部执行，要么全部放弃执行。 在MySQL里，事务是在引擎层面实现，比如MyIsam不支持，InnoDB支持 2. ACID 原子性( Atomicity)：事务中的全部操作在数据库中是不可分割的，要么全部完成，要么均不执行。 一致性( Consistency)：几个并行执行的事务，其执行结果必须与按某一顺序串行执行的结果相一致。 隔离性( Isolation)：多个事务并发执行时，一个事务的执行不应影响其他事务的执行 持久性( Durability)：对于任意已提交事务，系统必须保证该事务对数据库的改变不被丢失。 3. 脏读（Read Uncommitted）通俗的讲，一个事务在处理过程中读取了另外一个事务未提交的数据。 4. 幻读（Phantom Read）查询数据库时候没找到指定数据，但是在中间过程中插入了这条数据，对这条“不存在”的数据的更新等操作都是成功的，很“玄幻”。 5. 不可重复读（Non-repeatable Read）通俗的讲，一个事务范围内，多次查询某个数据，却得到不同的结果。 与脏读的区别：脏读是读到未提交的数据，而不可重复读读到的却是已经提交的数据，但实际上是违反了事务的一致性原则。 解决脏读、幻读、不可重复读最简单粗暴的做法是加锁，在对资源对象做事务操作时锁住资源，不让其它事务操作它。那么就一定是安全的。但是数据库的性能会大大降低。 针对上面的三个问题，数据库提出四大隔离级别： read uncommitted——不作任何隔离，具有脏读、不可重复读、幻读问题 read committed——可防止脏读，不能防止不可重复读和幻读问题 repeatable read——可以防止脏读、不可重复读，不能防止幻读问题（mysql默认是这个隔离级别） serializable——数据库运行在串行化，上述问题都可以防止，只是性能非常低 MySql 设置隔离级别的语句: 123set [session/global] transaction isolation level ...; // 修改隔离级别 select @@tx_isolation; // 查询当前数据库的隔离级别","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"database","slug":"技术开发/database","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/"}],"tags":[{"name":"数据库之脏读、幻读、不可重复读","slug":"数据库之脏读、幻读、不可重复读","permalink":"https://tianxiafeiyu.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8B%E8%84%8F%E8%AF%BB%E3%80%81%E5%B9%BB%E8%AF%BB%E3%80%81%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB/"}]},{"title":"一次apisix问题排查过程","slug":"技术开发/grocery/一次apisix问题排查过程","date":"2022-12-15T23:36:21.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/一次apisix问题排查过程/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/%E4%B8%80%E6%AC%A1apisix%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E8%BF%87%E7%A8%8B/","excerpt":"","text":"问题描述用户登录有时接口会报500的错误，”Network connection error occurred. Please try again later.” 分析过程查看接口的具体服务，没有相关的报错信息，应该是发生在网关层的报错。 不是必现的问题，一时也摸不着头脑 开始还安慰自己是环境问题，因为其他的环境确实没有反馈有这个问题 但是过了好几天，这个报错还时不时出现，看来是真的有问题了 好吧，只能硬着头皮排查了 排查问题三板斧：复现2问题，分析日志，定位问题 首先是怎么让报错必现，发现，在长时间不登录系统后，第一次登录时，批量下发的接口中，会有几个接口报这个错误 难道是并发问题？这才几个并发，直接否决 从apisix中抓取日志，发现接口的报错如下： 12022/09/01 19:09:27 [error] 44#44: *941885 [lua] init.lua:689: phase_func(): failed to acquire the lock: timeout, client: 172.23.12.158, server: _, request: &quot;GET /aops/overview?sf_cloud_id=5719605851&amp; HTTP/1.1&quot;, host: &quot;10.113.2.101:4430&quot;, referrer: &quot;https://10.113.2.101:4430/index.html&quot; 度娘了一把，在apisix github的issue倒是找到一个类似的问题，但是最后也没有具体的解决方法，而且问题和我这个也不太一样，放弃 难道要从apisix源码入手？这个我一开始是拒绝的，因为我完全不熟悉apisix，何况它还是用lua写的，难办 但是问题得解决啊，只能硬着头皮搞了。查看环境的apisix是2.11.0版本，github上下了对应版本的apisix源码，看了几篇apisix博客，看了一点lua语法，整呗 定位报错位置，是在请求一个缓存时，由于没有找到，使用 resty_lock 加锁，然后巴拉巴拉一堆看不懂，猜测应该是要写共享缓存，所以加锁了 度娘一下 resty_lock ，默认超时时间 5s，我看报错的接口，刚好都是5s左右超时的，看来问题就在这里了 为啥会超时呢？apisix一直都是这样用的，性能这么差的吗？问了几个人，无果，还得自己看 因为是缓存导致的超时，所以也找到了问题必现的方法，就是重启apisix，缓存会清空，这时候，登录用户一定有接口报这个错误 不知道lua该怎么调试，直接用原始的方法，打日志，把所有可能的流程和加锁、解锁的地方都加上标志打印 触发报错，查看流程，确实是一个接口在获得锁后，长达8s时间后才释放锁，这8s时间都干了啥？而且前面有的接口加锁释放锁很快就结束了，为啥咧？ 根据打印的信息和代码推断，这是在加载第三方插件，这里从缓存中拿的应该是插件实例，在没有缓存的时候，就要去实例化插件，不过这实例化过程居然要这么久，肯定有问题 又去看了一些apisix插件相关的资料，发现这一块是加载其他语言的扩展插件，目前平台使用的主要就是权限认证插件iam_policy，难怪有些接口可以通过，那些都是免认证的接口，不会去实例化认证插件。 又结合之前在日志中发现的插件报错 123456789022/09/01 19:09:31 [warn] 50#50: *109 [lua] init.lua:753: 2022-09-01T19:09:31.253+0800 ERROR common/util.go:33 failed to send http request, url: http://xaas-fees.bss:13003/v1/api-assets, err: Get &quot;http://xaas-fees.bss:13003/v1/api-assets&quot;: dial tcp: lookup xaas-fees.bss on 10.43.0.10:53: server misbehaving mq.code.sangfor.org/CMP/SCC/Infrastructure/GW/sf-apisix-plugins/apisix-go-plugin-runner/cmd/go-runner/plugins/iam_policy/pkg/common.HttpRequest /home/go/src/mq.code.sangfor.org/CMP/SCC/Infrastructure/GW/sf-apisix-plugins/apisix-go-plugin-runner/cmd/go-runner/plugins/iam_policy/pkg/common/util.go:33 mq.code.sangfor.org/CMP/SCC/Infrastructure/GW/sf-apisix-plugins/apisix-go-plugin-runner/cmd/go-runner/plugins/iam_policy/internal/policy.getServerRoute /home/go/src/mq.code.sangfor.org/CMP/SCC/Infrastructure/GW/sf-apisix-plugins/apisix-go-plugin-runner/cmd/go-runner/plugins/iam_policy/internal/policy/route.go:90 mq.code.sangfor.org/CMP/SCC/Infrastructure/GW/sf-apisix-plugins/apisix-go-plugin-runner/cmd/go-runner/plugins/iam_policy/internal/policy.GetServerRouteInfo /home/go/src/mq.code.sangfor.org/CMP/SCC/Infrastructure/GW/sf-apisix-plugins/apisix-go-plugin-runner/cmd/go-runner/plugins/iam_policy/internal/policy/route.go:52 mq.code.sangfor.org/CMP/SCC/Infrastructure/GW/sf-apisix-plugins/apisix-go-plugin-runner/cmd/go-runner/plugins/iam_policy/internal/policy.GetServersRouteInfo.func1 /home/go/src/mq.code.sangfor.org/CMP/SCC/Infrastructure/GW/sf-apisix-plugins/apisix-go-plugin-runner/cmd/go-runner/plugins/iam_policy/internal/policy/route.go:35 之前还觉得不相关的，现在看来很特么相关，问题就在这里 查看 iam_policy 源码，在实例化插件的时候，向所有配置的服务都会调用一次请求，获取服务器的路由信息；这里配置了bss相关的路由，但是实际环境并没有运行bss服务，所以一定会超时失败（10s）,这就是为什么注册插件会花费10s之多！ 删除配置中的bss相关路由，重新生成配置文件，重启apisix，相关报错不再出现。 完结撒花。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"一次apisix问题排查过程","slug":"一次apisix问题排查过程","permalink":"https://tianxiafeiyu.github.io/tags/%E4%B8%80%E6%AC%A1apisix%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E8%BF%87%E7%A8%8B/"}]},{"title":"一次python代码混淆问题排查","slug":"技术开发/grocery/一次python代码混淆问题排查","date":"2022-12-15T23:36:21.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/一次python代码混淆问题排查/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/%E4%B8%80%E6%AC%A1python%E4%BB%A3%E7%A0%81%E6%B7%B7%E6%B7%86%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/","excerpt":"","text":"问题描述： 部署加密版本的容器后，有一个容器启动过程失败 aops-api-permission-sync ，该容器是服务启动前做初始化配置，容器启动失败，导致服务也启动失败 正常的日志： 123456789101112131415161718Config file not found, using default configs.2022-09-06 22:01:27.196 6 INFO /usr/lib/python2.7/site-packages/sf_libs/utils/encryption_lib.py:55:get_confuse_aes_key() [-] encryption key is not confused2022-09-06 22:01:27.250 6 INFO /usr/lib/python2.7/site-packages/migrate/versioning/api.py:348:_migrate() [-] 0 -&gt; 1...2022-09-06 22:01:27.261 6 INFO /usr/lib/python2.7/site-packages/migrate/versioning/api.py:367:_migrate() [-] done2022-09-06 22:01:29,695 - /usr/lib/python2.7/site-packages/medusaclient/script/permission_model_sync.py[line:364] - INFO: start processing sync script, data file: /sf/etc/aops-api/iam-policy.yaml2022-09-06 22:01:29,918 - /usr/lib/python2.7/site-packages/medusaclient/script/permission_model_sync.py[line:184] - INFO: success to parser yaml file: /sf/etc/aops-api/iam-policy.yaml2022-09-06 22:01:29,919 - /usr/lib/python2.7/site-packages/medusaclient/script/permission_model_sync.py[line:210] - INFO: start to sync OC model data2022-09-06 22:01:31,488 - /usr/lib/python2.7/site-packages/medusaclient/script/permission_model_sync.py[line:162] - INFO: start to compare &#x27;OC.actions.md5&#x27; whether md5 has changed2022-09-06 22:01:31,493 - /usr/lib/python2.7/site-packages/medusaclient/script/permission_model_sync.py[line:167] - INFO: cacheKey &#x27;OC.actions.md5&#x27; old md5:371f3488d2eac117b111484d995d6eba new md5:371f3488d2eac117b111484d995d6eba2022-09-06 22:01:31,493 - /usr/lib/python2.7/site-packages/medusaclient/script/permission_model_sync.py[line:317] - INFO: app OC actions is not changed, no need to sync2022-09-06 22:01:31,495 - /usr/lib/python2.7/site-packages/medusaclient/script/permission_model_sync.py[line:162] - INFO: start to compare &#x27;OC.action_groups.md5&#x27; whether md5 has changed2022-09-06 22:01:31,498 - /usr/lib/python2.7/site-packages/medusaclient/script/permission_model_sync.py[line:167] - INFO: cacheKey &#x27;OC.action_groups.md5&#x27; old md5:80271c64213658b301632b551b7168ba new md5:80271c64213658b301632b551b7168ba2022-09-06 22:01:31,498 - /usr/lib/python2.7/site-packages/medusaclient/script/permission_model_sync.py[line:317] - INFO: app OC action_groups is not changed, no need to sync2022-09-06 22:01:31,501 - /usr/lib/python2.7/site-packages/medusaclient/script/permission_model_sync.py[line:162] - INFO: start to compare &#x27;OC.policies.md5&#x27; whether md5 has changed2022-09-06 22:01:31,503 - /usr/lib/python2.7/site-packages/medusaclient/script/permission_model_sync.py[line:167] - INFO: cacheKey &#x27;OC.policies.md5&#x27; old md5:35adbb04e2bf38d2fc7437fc89df0bc6 new md5:35adbb04e2bf38d2fc7437fc89df0bc62022-09-06 22:01:31,503 - /usr/lib/python2.7/site-packages/medusaclient/script/permission_model_sync.py[line:317] - INFO: app OC policies is not changed, no need to sync2022-09-06 22:01:31,505 - /usr/lib/python2.7/site-packages/medusaclient/script/permission_model_sync.py[line:371] - INFO: success to sync permission model, file: /sf/etc/aops-api/iam-policy.yamlNone 异常日志： 12345678910111213141516171819202122232425Config file not found, using default configs.2022-09-07 14:23:40.251 6 INFO &lt;frozen utils.encryption_lib&gt;:55:get_confuse_aes_key() [-] encryption key is not confused2022-09-07 14:23:40.336 6 INFO /usr/lib/python2.7/site-packages/migrate/versioning/api.py:348:_migrate() [-] 0 -&gt; 1...2022-09-07 14:23:40.356 6 INFO /usr/lib/python2.7/site-packages/migrate/versioning/api.py:367:_migrate() [-] done2022-09-07 14:23:42,763 - &lt;frozen script.permission_model_sync&gt;[line:364] - INFO: start processing sync script, data file: /sf/etc/aops-api/iam-policy.yaml2022-09-07 14:23:42,991 - &lt;frozen script.permission_model_sync&gt;[line:184] - INFO: success to parser yaml file: /sf/etc/aops-api/iam-policy.yaml2022-09-07 14:23:42,992 - &lt;frozen script.permission_model_sync&gt;[line:210] - INFO: start to sync OC model data2022-09-07 14:23:44,540 - &lt;frozen script.permission_model_sync&gt;[line:355] - ERROR: get aops_api failedTraceback (most recent call last):File &quot;&lt;frozen script.permission_model_sync&gt;&quot;, line 353, in _get_routers_infoFile &quot;&lt;frozen common.utils&gt;&quot;, line 870, in get_routersFile &quot;/usr/lib64/python2.7/importlib/__init__.py&quot;, line 37, in import_module__import__(name)File &quot;&lt;/usr/lib/python2.7/site-packages/aops_api/app/region/routers.py&gt;&quot;, line 1, in &lt;module&gt;RuntimeError: Marshal loads failedTraceback (most recent call last):File &quot;./medusa&quot;, line 10, in &lt;module&gt;sys.exit(main())File &quot;&lt;frozen shell&gt;&quot;, line 46, in mainFile &quot;&lt;frozen shell&gt;&quot;, line 318, in runFile &quot;&lt;frozen commands.iam&gt;&quot;, line 290, in cmd_permission_syncFile &quot;&lt;frozen script.permission_model_sync&gt;&quot;, line 370, in permission_syncFile &quot;&lt;frozen script.permission_model_sync&gt;&quot;, line 225, in do_synchronizationFile &quot;&lt;frozen script.permission_model_sync&gt;&quot;, line 356, in _get_routers_infoException: get_routers_info(aops_api) failed 容器启动命令 123456- command: - /bin/sh - -c - /sf/bin/aops-manage --config-file /sf/etc/aops-api/aops-api.conf db_sync;source /sf/bin/keystonerc_admin;cd /sf/bin/;./medusa permission-sync --data-file /sf/etc/aops-api/iam-policy.yaml 得知，后台手动同步权限命令 123source /sf/bin/keystonerc_admincd /sf/bin/./medusa permission-sync --data-file /sf/etc/aops-api/iam-policy.yaml 使用镜像启动容器 docker run -it docker.sangfor.com/scc-docker-history/aops-api:v2.1.1_EN.stable.20220907111917.encrypt 1234567891011121314151617Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; from aops_api.app.agent import controllersTraceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; File &quot;&lt;/usr/lib/python2.7/site-packages/aops_api/app/agent/__init__.py&gt;&quot;, line 1, in &lt;module&gt; File &quot;&lt;frozen app.agent&gt;&quot;, line 17, in &lt;module&gt; File &quot;&lt;/usr/lib/python2.7/site-packages/aops_api/app/agent/provider.py&gt;&quot;, line 1, in &lt;module&gt; File &quot;&lt;frozen app.agent.provider&gt;&quot;, line 20, in &lt;module&gt; File &quot;&lt;/usr/lib/python2.7/site-packages/phoenix/common/manager.py&gt;&quot;, line 1, in &lt;module&gt; File &quot;&lt;frozen common.manager&gt;&quot;, line 22, in &lt;module&gt; File &quot;&lt;/usr/lib/python2.7/site-packages/phoenix/common/wsgi.py&gt;&quot;, line 1, in &lt;module&gt; File &quot;&lt;frozen common.wsgi&gt;&quot;, line 37, in &lt;module&gt; File &quot;/usr/lib/python2.7/site-packages/rpdb/__init__.py&quot;, line 9, in &lt;module&gt; import pdb File &quot;/usr/lib64/python2.7/pdb.py&quot;, line 59, in &lt;module&gt; class Pdb(bdb.Bdb, cmd.Cmd):AttributeError: &#x27;module&#x27; object has no attribute &#x27;Cmd&#x27; 其他容器的镜像同步权限没有问题 12345678910&gt;&gt;&gt; import importlib&gt;&gt;&gt; module = importlib.import_module(&quot;aops_api.app.agent.routers&quot;)&gt;&gt;&gt; module = importlib.import_module(&quot;aops_api.app.region.routers&quot;)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; File &quot;/usr/lib64/python2.7/importlib/__init__.py&quot;, line 37, in import_module __import__(name) File &quot;&lt;/usr/lib/python2.7/site-packages/aops_api/app/region/routers.py&gt;&quot;, line 1, in &lt;module&gt;RuntimeError: Marshal loads failed&gt;&gt;&gt; 其他app导入正常，看来问题就在这里 替换容器内的 &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages&#x2F;aops_api&#x2F;app&#x2F;region&#x2F;routers.py 文件 再执行以上命令，不报错！ 看来就是这个routers.py加密文件有问题 容器内运行代码失败，报错： 1234567891011122022-09-08 11:50:29.299 155 WARNING &lt;frozen version.service&gt;:65:wrapper() [-] &#x27;local conf&#x27; from PasteDeploy INI is being ignored.2022-09-08 11:50:29.336 155 ERROR &lt;frozen version.service&gt;:52:wrapper() [-] Marshal loads failed: RuntimeError: Marshal loads failed2022-09-08 11:50:29.336 155 ERROR phoenix.version.service Traceback (most recent call last):2022-09-08 11:50:29.336 155 ERROR phoenix.version.service File &quot;&lt;frozen version.service&gt;&quot;, line 49, in wrapper2022-09-08 11:50:29.336 155 ERROR phoenix.version.service File &quot;&lt;frozen version.service&gt;&quot;, line 67, in wrapper2022-09-08 11:50:29.336 155 ERROR phoenix.version.service File &quot;&lt;frozen version.service&gt;&quot;, line 108, in public_app_factory2022-09-08 11:50:29.336 155 ERROR phoenix.version.service File &quot;/usr/lib64/python2.7/importlib/__init__.py&quot;, line 37, in import_module2022-09-08 11:50:29.336 155 ERROR phoenix.version.service __import__(name)2022-09-08 11:50:29.336 155 ERROR phoenix.version.service File &quot;&lt;/usr/lib/python2.7/site-packages/aops_api/app/region/routers.py&gt;&quot;, line 1, in &lt;module&gt;2022-09-08 11:50:29.336 155 ERROR phoenix.version.service RuntimeError: Marshal loads failed2022-09-08 11:50:29.336 155 ERROR phoenix.version.service2022-09-08 11:50:29.338 155 CRITICAL &lt;frozen version.service&gt;:55:wrapper() [-] Marshal loads failed: RuntimeError: Marshal loads failed 查看pyarmor版本 1234Sangfor:SCC/scc-fefcfe86b56e /sf/data/local/test/usr/lib/python2.7/site-packages x pyarmor -vPyArmor Version 6.4.2Registration Code: pyarmor-vax-000713Because of internet exception, could not query registration information. 容器上的和打包环境的一致 从制品库下载rpm，替换环境代码，报错 本地环境加密代码，替换，无报错 问题出在 流水线打rpm加密包 Python 版本不一致？ 查看打包镜像 docker.sangfor.com&#x2F;cicd_2336&#x2F;scc-docker-base&#x2F;cmp-builder-rpm-q 的 python 12345[root@5bcb6cfeeb1f /]# pythonPython 2.7.5 (default, Nov 16 2020, 22:23:17)[GCC 4.8.5 20150623 (Red Hat 4.8.5-44)] on linux2Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; 一模一样 咋整啊，僵住了 实在没招了，看代码，找不同！ region.routers 12345678910111213class Routers(wsgi.RoutersBase): &quot;&quot;&quot;API for the aops_api region.&quot;&quot;&quot; def append_routers(self, mapper, routers): self._controllers = controllers.Controller() self._add_resource( mapper, self._controllers, path=&quot;/regions&quot;, get_action=&#x27;list_regions&#x27;, rel=json_home.build_resource_relation(&#x27;list_regions&#x27;), iam_action=OCRegionAction(action=&#x27;list_regions&#x27;) ) 其中self._controllers &#x3D; controllers.Controller()这里IDE会提示 “Instance attribute _controllers defined outside init“ 这里的写法和其他的routers都不同，缺失__init__函数，在方法中增加对象属性，会不会是这个问题呢，python写法问题 其他的routers class Routers(wsgi.RoutersBase): def __init__(self): super(Routers, self).__init__() self._controllers = controllers.Controller() def append_routers(self, mapper, routers): self._add_admin_routers(mapper) self._add_tenant_routers(mapper) self._add_msp_routers(mapper) # 获取agent列表 self._add_resource( mapper, self._controllers, path=&quot;/agent/host-agent-list&quot;, get_action=&#39;list_agent&#39;, rel=json_home.build_resource_relation(&#39;list_agent&#39;), iam_action=OCAgentAction(action=&#39;list_agent&#39;) ) 修改代码，流水线打出rpm包，然后替换，居然没报错了！问题就出在这里！！！ 问题算是解决了，但是，为什么会这样呢？","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"一次python代码混淆问题排查","slug":"一次python代码混淆问题排查","permalink":"https://tianxiafeiyu.github.io/tags/%E4%B8%80%E6%AC%A1python%E4%BB%A3%E7%A0%81%E6%B7%B7%E6%B7%86%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"}]},{"title":"一种将文本转换为图表的现代图表脚本语言","slug":"技术开发/grocery/一种将文本转换为图表的现代图表脚本语言","date":"2022-12-15T23:36:21.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/一种将文本转换为图表的现代图表脚本语言/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/%E4%B8%80%E7%A7%8D%E5%B0%86%E6%96%87%E6%9C%AC%E8%BD%AC%E6%8D%A2%E4%B8%BA%E5%9B%BE%E8%A1%A8%E7%9A%84%E7%8E%B0%E4%BB%A3%E5%9B%BE%E8%A1%A8%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/","excerpt":"","text":"d2上线一周就获得 5k+ star，火爆程度可见一斑；项目规范、文档齐全，有ber而来~ GitHub 地址→https://github.com/terrastruct/d2 官网文档： https://d2lang.com/tour/intro 我感觉是好用的，用代码的形式描述图表 格式化 易扩展 易归档 有时间研究一下~","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"一种将文本转换为图表的现代图表脚本语言","slug":"一种将文本转换为图表的现代图表脚本语言","permalink":"https://tianxiafeiyu.github.io/tags/%E4%B8%80%E7%A7%8D%E5%B0%86%E6%96%87%E6%9C%AC%E8%BD%AC%E6%8D%A2%E4%B8%BA%E5%9B%BE%E8%A1%A8%E7%9A%84%E7%8E%B0%E4%BB%A3%E5%9B%BE%E8%A1%A8%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/"}]},{"title":"为什么好的开源软件多是基础架构层","slug":"技术开发/grocery/为什么好的开源软件多是基础架构层","date":"2022-12-15T23:36:21.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/为什么好的开源软件多是基础架构层/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A5%BD%E7%9A%84%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%A4%9A%E6%98%AF%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E5%B1%82/","excerpt":"","text":"为什么好的开源软件多是基础架构层？像操作系统、数据库、Web 中间件这样，使用量都是以 “亿” 为单位的，工程师在这里写下的代码发挥的杠杆作用最高，基础架构软件工程师可以为了情怀而写下优美的代码。基础架构层的软件面向机器世界，而机器世界的约束边界多属于已知的边界，在已知的边界里寻找最优解会更容易、更清晰，一个领域发展到最后，可能只会剩下几个最好的产品。等下一个技术变革或者商业格局剧变的时候，才会出现新的发展窗口期。 基础架构层的软件是面向机器世界的，而应用软件是面向组织社会的。机器世界的规则在全世界都是通用的，产品优劣很容易评判。而应用是面向人和社会的，规则在不同的国家、不同的地区、不同的文化和不同的组织之间都有非常大的差异。在应用软件层，经常要面临大量的定制化开发和需求变动，并不是最贵最流行的软件就会适用你的场景。文无第一，武无第二，跟基础软件和应用软件的比较很类似。也有言论称，信息化是面向人的，数字化是面向机器的，如果从这个角度来看的话，做好信息化比做好数字化可要难多了。 应用软件的使用量很难达到基础软件那样的规模，大家写下的代码可能很快就被修改或者弃用，所以应用软件比较难吸引优秀的工程师全身心投入。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"为什么好的开源软件多是基础架构层","slug":"为什么好的开源软件多是基础架构层","permalink":"https://tianxiafeiyu.github.io/tags/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A5%BD%E7%9A%84%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%A4%9A%E6%98%AF%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E5%B1%82/"}]},{"title":"延时、丢包、抖动——术语解释","slug":"技术开发/grocery/延时、丢包、抖动——术语解释","date":"2022-12-15T23:36:21.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/延时、丢包、抖动——术语解释/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/%E5%BB%B6%E6%97%B6%E3%80%81%E4%B8%A2%E5%8C%85%E3%80%81%E6%8A%96%E5%8A%A8%E2%80%94%E2%80%94%E6%9C%AF%E8%AF%AD%E8%A7%A3%E9%87%8A/","excerpt":"","text":"延时、丢包、抖动——术语解释转载自 https://zhuanlan.zhihu.com/p/21968527 前言互联网大概可以算是最近几十年人类最重要的发明之一。最早人们用互联网发送电子邮件，接着普及了网页浏览，后来又流行即时文字聊天，人们工作生活的方式在这写年里发生了巨大的变化。可是当人们想更进一步实现实时音视频通话时，却发现互联网有点不给力了。卡顿、掉线、延时太高等等，这些问题始终伴阻碍实时音视频通话的发展。而这根本上的原因是，互联网一开始并不是针对实时通信而设计的。 人们常把互联网比喻成“信息高速公路”，其实更确切的比喻应该是“信息公路网”。互联网就像现实中的路网一样交错复杂，有像连接两地的高速公路一样快速的骨干网，也有像是难走的崎岖山路一样糟糕的网络环境。而在互联网上传输数据就像是从一个地方开车到另一个地方一样。 现在我们就借这个比喻来解释一下互联网传输的三个非常重要的特点：延时、丢包、抖动。 正文假设我们现在有一百辆车从北京鸟巢开往上海东方明珠，并且每隔一分钟出发一辆。 延时“延时”指的是每辆车从鸟巢开到东方明珠花的平均时间。显然，车队走高速公路肯定要比走各种小公路快很多，而且从鸟巢出发沿着怎样的路线开上高速公路也有很大影响，万一堵在了三环可就要多花好几个小时了。所以这个值和车队选择的行驶路线有关。互联网传输也是一样的道理，需要传输数据的两点之间经常是有很多可选路径的，而这些路径的延时往往相差很大。 丢包“丢包”指的是有的车无法在有效时间内无法达到终点，甚至可能永远也到不了终点。有的车可能永远堵在北京的三环上了，有的车可能中途出了车祸。假如我们的一百辆车里有五辆车因为各种原因没能按时到达上海，我们这次车队传输的“丢包率”就是5%。是的，互联网传输也一样，它并不是百分百可靠的，总有数据无法按时传输到目的地。 抖动“抖动”指的是车子到达的顺序、间隔和出发时的差异。虽然我们的一百辆车在北京是等间隔的一分钟一辆出发的，但是它们到达上海时却并不是按顺序一分钟一辆到达的，甚至可能有晚出发的车比早出发的车先到的情况。互联网传输也一样，如果简单地按照收到的音视频数据顺序直接播放出来，就会出现失真的现象。 延时、丢包、抖动是互联网这个信息公路网无法避免的三个特点。以前电子邮件、网页浏览、文字聊天的场景下，这三个特点并不是太大的问题，毕竟人们可以接受电子邮件晚几分钟到达对方的邮箱。但在实时音视频通信的场景下，不要说几分钟，就算只有几秒钟的延迟，音视频交流的体验就会大打折扣。 优化方案最近接入当车队从鸟巢出发的时候，调度中心首先给出一条从鸟巢通往高速公路入口的最优路径，让车队尽快离开拥挤的市区，这就叫做“就近接入”。 动态路由当我们的车队上了高速公路后，理想情况下只要沿着最短路线向上海行驶就可以了。但现实情况是，在最短路线上可能会有路段在维修无法通行，会有路段车辆太多非常拥堵，会有路段收费站太多通行效率低下等等情况。调度中心会根据实时的全国路况，给车队规划高速公路上的行驶路径，保证车队以最快的速度到达上海的高速公路出口。同样的，骨干网络也会有线路暂时不可用，线路拥堵，跨运营商线路质量差等情况，调度中心为需要传输的音视频数据包实时规划传输路径，这就叫做“动态路由”。 丢包重传“延时”的问题解决了，“丢包”怎么办呢？假设正好遇到上下班高峰，北京的路况非常糟糕，即使调度中心规划了最优的离开北京的线路，100辆车里也只有80辆按时到达了高速公路入口，“丢包率”达到了20%。在这种情况下调度中心的办法是，通知鸟巢再补发20辆车出来！即使这20辆车仍然有20%(4辆)无法离开北京，最终也能有总共96辆车驶上高速公路，最终的丢包率从20%降到了4%。这就是丢包重传”，无论是从用户到接入点，还是我们的服务器之间，还是最终从接入点到用户，丢失的数据包都有机会通过重传机制得到及时的恢复。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"延时、丢包、抖动——术语解释","slug":"延时、丢包、抖动——术语解释","permalink":"https://tianxiafeiyu.github.io/tags/%E5%BB%B6%E6%97%B6%E3%80%81%E4%B8%A2%E5%8C%85%E3%80%81%E6%8A%96%E5%8A%A8%E2%80%94%E2%80%94%E6%9C%AF%E8%AF%AD%E8%A7%A3%E9%87%8A/"}]},{"title":"css知识点","slug":"技术开发/html/css知识点","date":"2022-12-15T23:25:17.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/html/css知识点/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/html/css%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"css调整元素位置https://blog.csdn.net/dyk11111/article/details/126666975 属性声明顺序选择器中属性数量较多时，将相关的属性声明放在一起，并按以下顺序排列： 定位相关，如 position、top&#x2F;bottom&#x2F;left&#x2F;right、z-index 等 盒模型相关，如 display、float、margin、width&#x2F;height 等 排版相关，如 font、color、line-height 等 可视相关，如 background、color 等 其他，如 opacity、animation 等 建议：在属性数量较多时可以参考这 5 个类别归类排列。 1234567891011121314151617181920212223/* 定位相关 */position: absolute;top: 0;right: 0;bottom: 0;left: 0;z-index: 100;/* 盒模型相关 */display: block;float: right;width: 100px;height: 100px;/* 排版相关 */font: normal 13px &quot;Helvetica Neue&quot;, sans-serif;line-height: 1.5;color: #333;text-align: center;/* 可视相关 */background-color: #f5f5f5;border: 1px solid #e5e5e5;border-radius: 3px;/* 其他 */opacity: 1; 元素的 id 和 class 属性在 HTML 中，id 和 class 是用于标识和描述元素的属性。 id 属性用于唯一标识一个元素。每个 id 属性的值在文档中必须是唯一的，不能重复。可以使用 id 属性来为元素创建锚点，或者使用 JavaScript 来操作特定的元素。 例如，以下代码为一个段落元素添加了一个唯一的 id 属性： 1&lt;p id=&quot;my-paragraph&quot;&gt;这是一个段落。&lt;/p&gt; class 属性用于描述元素的类别。一个元素可以有多个 class 属性，每个 class 属性的值可以是相同的或不同的。可以使用 class 属性来为元素应用样式，或者使用 JavaScript 来选择一组元素。 例如，以下代码为一个段落元素添加了一个 class 属性： 1&lt;p class=&quot;important&quot;&gt;这是一个重要的段落。&lt;/p&gt; 总的来说，id 属性用于唯一标识一个元素，而 class 属性用于描述元素的类别。在 CSS 中，可以使用 # 符号来选择 id 属性，使用 . 符号来选择 class 属性。在 JavaScript 中，可以使用 getElementById() 方法来选择 id 属性，使用 getElementsByClassName() 方法来选择 class 属性。 id 选择器的优先级比 class 选择器的优先级更高。这意味着，如果一个元素同时具有 id 和 class 属性，并且这两个属性都有相应的 CSS 规则，那么 id 属性的 CSS 规则将覆盖 class 属性的 CSS 规则。 CSS常用属性 color：用于设置文本颜色，可以使用颜色名称、十六进制值、RGB值等方式来指定颜色。 font-size：用于设置字体大小，可以使用像素、百分比、em等单位来指定大小。 font-family：用于设置字体系列，可以指定多个字体，如果第一个字体不可用，则会尝试使用下一个字体。 font-weight：用于设置字体粗细，可以设置为normal、bold、bolder、lighter或者数字值。 text-align：用于设置文本对齐方式，可以设置为left、right、center、justify等。 background-color：用于设置背景颜色，可以使用颜色名称、十六进制值、RGB值等方式来指定颜色。 background-image：用于设置背景图片，可以指定图片的URL地址。 background-position：用于设置背景图片位置，可以指定像素值、百分比等方式来指定位置。 background-repeat：用于设置背景图片重复方式，可以设置为repeat、repeat-x、repeat-y、no-repeat等。 border：用于设置边框样式、宽度和颜色，可以分别指定边框样式、宽度和颜色，也可以使用简写方式指定。 padding：用于设置元素的内边距，可以指定像素值、百分比等方式来指定内边距。 margin：用于设置元素的外边距，可以指定像素值、百分比等方式来指定外边距。 display：用于设置元素的显示方式，可以设置为block、inline、inline-block、none等。 position：用于设置元素的定位方式，可以设置为static、relative、absolute、fixed等。 top、right、bottom、left：用于设置元素的定位位置，可以指定像素值、百分比等方式来指定位置。 float：用于设置元素的浮动方式，可以设置为left、right、none等。 clear：用于清除浮动，可以设置为left、right、both、none等。 width、height：用于设置元素的宽度和高度，可以指定像素值、百分比等方式来指定大小。 line-height：用于设置行高，可以指定像素值、百分比等方式来指定行高。 text-decoration：用于设置文本装饰效果，如下划线、删除线等。 text-transform：用于设置文本大小写转换方式，可以设置为uppercase、lowercase、capitalize等。 text-indent：用于设置文本缩进，可以指定像素值、em等单位来指定缩进大小。 white-space：用于设置空白符处理方式，可以设置为normal、nowrap、pre、pre-wrap等。 opacity：用于设置元素透明度，可以指定0到1之间的值，0表示完全透明，1表示完全不透明。 z-index：用于设置元素的堆叠顺序，可以指定正整数值，值越大，元素越靠前。 text-align-last：用于设置最后一行文本的对齐方式，可以设置为left、right、center、justify等。 text-justify：用于设置文本对齐方式，可以设置为auto、inter-word、inter-character、distribute等。 text-shadow：用于设置文本阴影效果，可以指定阴影的颜色、位置、模糊半径等属性。 box-shadow：用于设置盒子阴影效果，可以指定阴影的颜色、位置、模糊半径、扩展半径等属性。 border-radius：用于设置边框圆角效果，可以指定四个角的半径值，也可以指定单个角的半径值。 box-sizing：用于设置盒子模型的计算方式，可以设置为content-box、border-box等。 overflow：用于设置元素内容溢出时的处理方式，可以设置为visible、hidden、scroll、auto等。 text-overflow：用于设置文本溢出时的处理方式，可以设置为clip、ellipsis等。 word-wrap：用于设置长单词或URL地址的换行方式，可以设置为normal、break-word等。 cursor：用于设置鼠标指针的样式，可以设置为default、pointer、text等。 background-size：用于设置背景图片的大小，可以指定像素值、百分比等方式来指定大小。 background-attachment：用于设置背景图片的滚动方式，可以设置为scroll、fixed等。 transition：用于设置元素的过渡效果，可以指定过渡的属性、时间、延迟时间、过渡方式等属性。 transform：用于设置元素的变形效果，可以指定旋转、缩放、平移、倾斜等变形效果。 animation：用于设置元素的动画效果，可以指定动画的名称、时间、延迟时间、动画方式等属性。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"html","slug":"技术开发/html","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/html/"}],"tags":[{"name":"css知识点","slug":"css知识点","permalink":"https://tianxiafeiyu.github.io/tags/css%E7%9F%A5%E8%AF%86%E7%82%B9/"}]},{"title":"tops","slug":"技术开发/python/tops","date":"2022-12-15T23:23:38.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/python/tops/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/tops/","excerpt":"","text":"所谓 tips 记录，就是在实际工作学习中需要上网查找资料，得到满意答案后的记录，避免经常重复查询。 记录原则，精简有效，只记录满意的答案，尽量不要发散 1. os.path.basename、 os.path.dirname获取路径的文件名，文件夹 os.path.basename(&quot;/tmp/test/test.txt&quot;) # test.txt os.path.dirname(&quot;/tmp/test/test.txt&quot;) # /tmp/test sqlalchemy更新1234567891011121) for c in session.query(Stuff).all(): c.foo += 1 session.commit()2) session.query().\\ update(&#123;&quot;foo&quot;: (Stuff.foo + 1)&#125;) session.commit()3) conn = engine.connect() stmt = Stuff.update().\\ values(Stuff.foo = (Stuff.foo + 1)) conn.execute(stmt)","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"技术开发/python","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/"}],"tags":[{"name":"tops","slug":"tops","permalink":"https://tianxiafeiyu.github.io/tags/tops/"}]},{"title":"Python高级编程技巧","slug":"技术开发/python/Python高级编程技巧","date":"2022-12-15T23:22:29.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/python/Python高级编程技巧/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/Python%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/","excerpt":"","text":"推导式(Comprehensions)列表推导(list comprehensions)123456num = [1, 4, -5, 10, -7, 2, 3, -1]filtered_and_squared = [ x**2 for x in num if x &gt; 0]# 等效于 filtered_and_squared = map(lambda x: x ** 2, filter(lambda x: x &gt; 0, num))print filtered_and_squared # [1, 16, 100, 4, 9] 整个列表必须一次性加载于内存之中 生成器推导(Generatorst comprehensions)12345678910num = [1, 4, -5, 10, -7, 2, 3, -1]filtered_and_squared = ( x**2 for x in num if x &gt; 0 )print filtered_and_squared # &lt;generator object &lt;genexpr&gt; at 0x00583E18&gt; for item in filtered_and_squared: print item # 1, 16, 100 4,9 每次遍历加载一个列表元素 装饰器(Decorators)装饰器是一个包装了另一个函数的特殊函数：主函数被调用，并且其返回值将会被传给装饰器，接下来装饰器将返回一个包装了主函数的替代函数， 1234567891011# 统计运行时间装饰器def print_runtime(func): @wraps(func) def wrap(*args, **kwargs): t1 = time.time() func(*args, **kwargs) t2 = time.time() print &#x27;%s方法运行时间：%s s&#x27; % (func.__name__, t2 - t1) return wrap 类成员变量初始化建议所有变量初始化在__init()__方法下进行，且可变类型的变量不可以设置默认函数参数，否则也会导致共享变量。 123456789101112131415161718192021222324class Node(object): parents = [] # 危险操作1：init方法外定义可变类型变量 def __init__(self, children=[]): # 危险操作2：init方法内定义但设置了函数默认参数 self.children = childrenif __name__ == &#x27;__main__&#x27;: n1 = Node() n2 = Node() n1.parents.append(&#x27;parent for n1&#x27;) n1.children.append(&#x27;child for n1&#x27;) print &#x27;n1 parents: id: &#123;&#125;, value: &#123;&#125;&#x27;.format(id(n1.parents), n1.parents) print &#x27;n2 parents: id: &#123;&#125;, value: &#123;&#125;&#x27;.format(id(n2.parents), n2.parents) print print &#x27;n1 children: id: &#123;&#125;, value: &#123;&#125;&#x27;.format(id(n1.children), n1.children) print &#x27;n2 children: id: &#123;&#125;, value: &#123;&#125;&#x27;.format(id(n2.children), n2.children)# n1 parents: id: 40216072, value: [&#x27;parent for n1&#x27;]# n2 parents: id: 40216072, value: [&#x27;parent for n1&#x27;]# # n1 children: id: 40159112, value: [&#x27;child for n1&#x27;]# n2 children: id: 40159112, value: [&#x27;child for n1&#x27;] 函数式编程Lambda我们可以在 Python 中使用 lambda 关键字来定义此类函数。示例如下： 12mult = lambda x, y: x * ymult(1, 2) #returns 2 该 mult 函数的行为与使用传统 def 关键字定义函数的行为相同。 注意：lambda 函数必须为单行，且不能包含程序员写的返回语句。 事实上，它们通常具备隐式的返回语句（在上面的示例中，函数想表达 return x * y，不过我们省略了 lambda 函数中的显式返回语句）。 lambda 函数更加强大和精准，因为我们还可以构建匿名函数（即没有名称的函数）： 1(lambda x, y: x * y)(9, 10) #returns 90 当我们只需要一次性使用某函数时，这种方法非常方便。例如，当我们想填充字典时： 123import collectionspre_fill = collections.defaultdict(lambda: (0, 0))#all dictionary keys and values are set to 0 Mapmap 函数基于指定过程（函数）将输入集转换为另一个集合。这类似于上文提到的 iterate_custom 函数。例如： 12345def multiply_by_four(x): return x * 4scores = [3, 6, 8, 3, 5, 7]modified_scores = list(map(multiply_by_four, scores))#modified scores is now [12, 24, 32, 12, 20, 28] 在 Python 3 中，map 函数返回的 map 对象可被类型转换为 list，以方便使用。现在，我们无需显式地定义 multiply_by_four 函数，而是定义 lambda 表达式： 1modified_scores = list(map(lambda x: 4 * x, scores)) 当我们想对集合内的所有值执行某项操作时，map 函数很有用。 Filter就像名称所显示的那样，filter 函数可以帮助筛除不想要的项。例如，我们想要去除 scores 中的奇数，那么我们可以使用 filter： 12even_scores = list(filter(lambda x: True if (x % 2 == 0) else False, scores))#even_scores = [6, 8] 由于提供给 filter 的函数是逐个决定是否接受每一个项的，因此该函数必须返回 bool 值，且该函数必须是一元函数（即只使用一个输入参数）。 Reducereduce 函数用于「总结」或「概述」数据集。例如，如果我们想要计算所有分数的总和，就可以使用 reduce： 12sum_scores = reduce((lambda x, y: x + y), scores)#sum_scores = 32 这要比写循环语句简单多了。注意：提供给 reduce 的函数需要两个参数：一个表示正在接受检查的项，另一个表示所用运算的累积结果。 参考资料https://www.cnblogs.com/ajianbeyourself/p/3970508.html","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"技术开发/python","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/"}],"tags":[{"name":"Python高级编程技巧","slug":"Python高级编程技巧","permalink":"https://tianxiafeiyu.github.io/tags/Python%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"}]},{"title":"python list()和[],dict()和{}","slug":"技术开发/python/python list()和[],dict()和{}","date":"2022-12-15T23:22:29.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/python/python list()和[],dict()和{}/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/python%20list()%E5%92%8C[],dict()%E5%92%8C%7B%7D/","excerpt":"","text":"参考资料： https://www.cnblogs.com/wlfya/p/13856482.html Python疑难问题：[] 与 list() 哪个快？为什么快？快多少呢？ 在日常使用 Python 时，我们经常需要创建一个列表，相信大家都很熟练了吧？ 12345# 方法一：使用成对的方括号语法list_a = []# 方法二：使用内置的 list()list_b = list() 结论：[] 是 list() 的三倍快2、list() 比 [] 执行步骤多那么，我们继续来分析一下第二个问题：为什么 [] 会更快呢？ 这一次我们可以使用dis模块的 dis() 函数，看看两者执行的字节码有何差别： 123&gt;&gt;&gt; from dis import dis&gt;&gt;&gt; dis(&quot;[]&quot;)&gt;&gt;&gt; dis(&quot;list()&quot;) 结果 1234567&gt;&gt;&gt; dis(&quot;[1]&quot;) 0 DELETE_NAME 23857 (23857)&gt;&gt;&gt; dis(&quot;list(1)&quot;) 0 IMPORT_NAME 29545 (29545) 3 LOAD_GLOBAL 12584 (12584) 6 STORE_SLICE+1&gt;&gt;&gt; 前者明显少了步骤 12345678&gt;&gt;&gt; from dis import dis&gt;&gt;&gt; dis(&quot;&#123;1&#125;&quot;) 0 &lt;123&gt; 32049&gt;&gt;&gt; dis(&quot;dict(1)&quot;) 0 LOAD_CONST 25449 (25449) 3 LOAD_GLOBAL 12584 (12584) 6 STORE_SLICE+1&gt;&gt;&gt; {}初始化，只需要通过一次常量指令即可完成dict()，需要执行CALL_FUNCTION指令","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"技术开发/python","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/"}],"tags":[{"name":"python list()和[],dict()和{}","slug":"python-list-和-dict-和","permalink":"https://tianxiafeiyu.github.io/tags/python-list-%E5%92%8C-dict-%E5%92%8C/"}]},{"title":"python入门","slug":"技术开发/python/python入门","date":"2022-12-15T23:22:29.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/python/python入门/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/python%E5%85%A5%E9%97%A8/","excerpt":"","text":"腾讯课堂地址https://ke.qq.com/webcourse/404949/100482926#taid=3241897150000597&amp;vid=5285890793484703736 python起源人生苦短，我用pyrhon 编译器与解释器 将程序语言翻译成机器语言的工具，称之为编译器。翻译有两种方式，编译和解释。以解释方式运行的编译器也叫解释器。 编译：源码–&gt;编译器–&gt;最终可执行文件（机器码）–&gt;操作系统–&gt;cpu 解释：源码–&gt;解释器逐行解释–&gt;操作系统–&gt;cpu python特点 完全面向对象 强大的标准库 活跃的社区和第三方模块 第一个python程序","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"技术开发/python","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/"}],"tags":[{"name":"python入门","slug":"python入门","permalink":"https://tianxiafeiyu.github.io/tags/python%E5%85%A5%E9%97%A8/"}]},{"title":"python单例模式实现","slug":"技术开发/python/python单例模式实现","date":"2022-12-15T23:22:29.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/python/python单例模式实现/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/python%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"装饰器1234567891011121314151617181920212223242526from functools import wrapsimport threadinglock = threading.Lock()def singleton(cls): instances = &#123;&#125; @wraps(cls) def wrapper(*args, **kwargs): with lock: if cls not in instances: instances[cls] = cls(*args, **kwargs) return instances[cls] return wrapper@singletonclass MyClass: def __init__(self, *args, **kwargs): print(&#x27;MyClass.__init__ called.&#x27;) self.args = args self.kwargs = kwargs @classmethod def cls_method(cls, *args, **kwargs): print(&#x27;Myclass classmethod called.&#x27;) 测试一下： 12345678910111213In [2]: a = MyClass(1, 2)MyClass.__init__ called.In [3]: b = MyClass(3,4,5)In [4]: a is bOut[4]: TrueIn [5]: a.__dict__Out[5]: &#123;&#x27;args&#x27;: (1, 2), &#x27;kwargs&#x27;: &#123;&#125;&#125;In [6]: b.__dict__Out[6]: &#123;&#x27;args&#x27;: (1, 2), &#x27;kwargs&#x27;: &#123;&#125;&#125; 可见a和b两个实例其实是一个对象，Myclass只被调用了一次。加锁的目的是为了达到线程安全，防止在操作instances字典的时候被其他线程抢占到时间片执行而重复创建实例。这种方式确实实现了单例模式，但是MyClass现在变成一个函数了，所以不能直接用MyClass调用cls_method了，只能通过实例调用… 12345678910In [7]: MyClass.cls_method()---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-7-7bcbf0e7bf90&gt; in &lt;module&gt;()----&gt; 1 MyClass.cls_method()TypeError: &#x27;classmethod&#x27; object is not callableIn [8]: a.cls_method()Myclass classmethod called.COPY 模块导入第二种方法是在一个独立模块中创建好实例后导入，由于Python不会重复导入已经导入的对象，因此这样也能实现单例模式: 123456789101112131415161718# one.pyprint(&#x27;one.py imported by others.&#x27;)class Foobar: def __init__(self, *args, **kwargs): self.args = args self.kwargs = kwargsfoo = Foobar(1, &#x27;2&#x27;, x=3)# two.pyfrom one import fooprint(id(foo))from one import fooprint(id(foo)) 运行two.py: 1234❯ python3 two.py one.py imported by others.140485279112104140485279112104COPY 这样做的优点是简单，缺点和装饰器一样，只能通过实例来调用classmethod. new第三种，改写__new__方法: 123456789101112131415import threadingclass Singleton: instances = &#123;&#125; lock = threading.Lock() def __new__(cls, *args, **kwargs): with cls.lock: if cls not in cls.instances: cls.instances[cls] = super().__new__(cls) return cls.instances[cls] def __init__(self, *args, **kwargs): self.args = args self.kwargs = kwargsCOPY 测试： 123456789101112131415161718In [2]: a = Singleton(1, &#x27;2&#x27;, x=3)In [3]: b = Singleton(3, &#x27;4&#x27;, y=5)In [4]: a is bOut[4]: TrueIn [5]: aOut[5]: &lt;one.Singleton at 0x7f7132af6550&gt;In [6]: bOut[6]: &lt;one.Singleton at 0x7f7132af6550&gt;In [7]: a.__dict__Out[7]: &#123;&#x27;args&#x27;: (3, &#x27;4&#x27;), &#x27;kwargs&#x27;: &#123;&#x27;y&#x27;: 5&#125;&#125;In [8]: b.__dict__Out[8]: &#123;&#x27;args&#x27;: (3, &#x27;4&#x27;), &#x27;kwargs&#x27;: &#123;&#x27;y&#x27;: 5&#125;&#125; 前后两个实例是同一个，这点证明确实是单例模式了，但为什么a的属性变了？这个问题，在第四种方法中一并解释。这种方法的缺点是，如果子类改写了__new__方法，那么单例模式就失效了，比如： 1234567891011121314151617181920212223import threadingclass Singleton: instances = &#123;&#125; lock = threading.Lock() def __new__(cls, *args, **kwargs): if cls not in cls.instances: cls.instances[cls] = super().__new__(cls) return cls.instances[cls] def __init__(self, *args, **kwargs): self.args = args self.kwargs = kwargsclass Subclass(Singleton): def __new__(cls, *args, **kwargs): return object.__new__(cls) def __init__(self, *args, **kwargs): self.args = args self.kwargs = kwargs 测试： 123456789101112In [2]: a = Subclass(1, &#x27;2&#x27;, x=3)In [3]: b = Subclass(3, &#x27;4&#x27;, y=5)In [4]: aOut[4]: &lt;one.Subclass at 0x7fe97ad65e80&gt;In [5]: bOut[5]: &lt;one.Subclass at 0x7fe97add2a20&gt;In [6]: a is bOut[6]: False metaclass第四种方法，使用元类： 1234567891011121314151617import threadingclass Meta(type): instances = &#123;&#125; lock = threading.Lock() def __call__(cls, *args, **kwargs): with cls.lock: if cls not in cls.instances: cls.instances[cls] = super().__call__(*args, **kwargs) return cls.instances[cls]class Singleton(metaclass=Meta): def __init__(self, *args, **kwargs): self.args = args self.kwargs = kwargs 测试： 123456789101112In [2]: a = Singleton(1, &#x27;2&#x27;, x=3)In [3]: b = Singleton(3, &#x27;4&#x27;, y=5)In [4]: a is bOut[4]: TrueIn [5]: a.__dict__Out[5]: &#123;&#x27;args&#x27;: (1, &#x27;2&#x27;), &#x27;kwargs&#x27;: &#123;&#x27;x&#x27;: 3&#125;&#125;In [6]: b.__dict__Out[6]: &#123;&#x27;args&#x27;: (1, &#x27;2&#x27;), &#x27;kwargs&#x27;: &#123;&#x27;x&#x27;: 3&#125;&#125; 可以看到，a和b是同一个对象，确实是单例模式，但是跟第三种方法不同的是，实例属性是以第一次调用为准，为什么呢？ 实例完整的创建过程是这样的： 1.调用Metaclass.call 2.Metaclass.__call__调用Class.__new__创建instance 3.Metaclass.__call__以instance和其他参数去调用Class.__init__进行初始化 4.Metaclass.__call__返回instance在第四种方法，实例已经创建后，就不会再去调用Class.__new__创建实例和Class.__init__进行初始化了，因此实例属性由第一次创建决定。而第三种方法，虽然Class.__new__不会重复创建实例，但是Class.__init__还是会被调用，因此属性随最后一次而定。使用元类的好处是，元类会附着到子类上，单例模式不会因为继承而失效： 12345678910class Meta(type): passclass SupClass(metaclass=Meta): passclass SubClass(SupClass): passprint(type(SupClass), type(SubClass)) 运行结果： 1&lt;class &#x27;__main__.Meta&#x27;&gt; &lt;class &#x27;__main__.Meta&#x27;&gt; 因此，以上四种方法，元类的解决方案是最好的！","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"技术开发/python","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/"}],"tags":[{"name":"python单例模式实现","slug":"python单例模式实现","permalink":"https://tianxiafeiyu.github.io/tags/python%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%AE%9E%E7%8E%B0/"}]},{"title":"python多进程与多线程","slug":"技术开发/python/python多进程与多线程","date":"2022-12-15T23:22:29.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/python/python多进程与多线程/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/python%E5%A4%9A%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"关于进程与线程把进程比作一列火车，线程比作火车的一节车厢 线程在进程下行进（单纯的车厢无法运行） 一个进程可以包含多个线程（一辆火车可以有多个车厢） 不同进程间数据很难共享（一辆火车上的乘客很难换到另外一辆火车，比如站点换乘） 同一进程下不同线程间数据很易共享（A车厢换到B车厢很容易） 进程要比线程消耗更多的计算机资源（采用多列火车相比多个车厢更耗资源） 进程间不会相互影响，一个线程挂掉将导致整个进程挂掉（一列火车不会影响到另外一列火车，但是如果一列火车上中间的一节车厢着火了，将影响到所有车厢） 进程可以拓展到多机，进程最多适合多核（不同火车可以开在多个轨道上，同一火车的车厢不能在行进的不同的轨道上） 进程使用的内存地址可以上锁，即一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。（比如火车上的洗手间）－”互斥锁” 进程使用的内存地址可以限定使用量（比如火车上的餐厅，最多只允许多少人进入，如果满了需要在门口等，等有人出来了才能进去）－“信号量” 这里有几个知识点要重点记录一下 单个CPU在任一时刻只能执行单个线程，只有多核CPU才能真正做到多个线程同时运行 一个进程包含多个线程，这些线程可以分布在多个CPU上 多核CPU同时运行的线程可以属于单个进程或不同进程 所以，在大多数编程语言中因为切换消耗的资源更少，多线程比多进程效率更高 坏消息，Python是个特例！ GIL锁python始于1991年，创立初期对运算的要求不高，为了解决多线程共享内存的数据安全问题，引入了GIL锁，全称为Global Interpreter Lock，也就是全局解释器锁。 GIL规定，在一个进程中每次只能有一个线程在运行。这个GIL锁相当于是线程运行的资格证，某个线程想要运行，首先要获得GIL锁，然后遇到IO或者超时的时候释放GIL锁，给其余的线程去竞争，竞争成功的线程获得GIL锁得到下一次运行的机会。 正是因为有GIL的存在，python的多线程其实是假的，所以才有人说python的多线程非常鸡肋。但是虽然每个进程有一个GIL锁，进程和进程之前还是不受影响的。 GIL是个历史遗留问题，过去的版本迭代都是以GIL为基础来的，想要去除GIL还真不是一件容易的事，所以我们要做好和GIL长期面对的准备。 多进程 vs 多线程那么是不是意味着python中就只能使用多进程去提高效率，多线程就要被淘汰了呢？ 那也不是的。 这里分两种情况来讨论，CPU密集型操作和IO密集型操作。针对前者，大多数时间花在CPU运算上，所以希望CPU利用的越充分越好，这时候使用多进程是合适的，同时运行的进程数和CPU的核数相同；针对后者，大多数时间花在IO交互的等待上，此时一个CPU和多个CPU是没有太大差别的，反而是线程切换比进程切换要轻量得多，这时候使用多线程是合适的。 所以有了结论： CPU密集型操作使用多进程比较合适，例如海量运算 IO密集型操作使用多线程比较合适，例如爬虫，文件处理，批量ssh操作服务器等等&amp;#x20; 代码实现待执行函数 1234def func(): print(&#x27;process &#123;&#125; starts&#x27;.format(os.getpid())) time.sleep(2) print(&#x27;process &#123;&#125; ends&#x27;.format(os.getpid())) 多进程做为对比，首先来看看顺序执行两遍函数的情况 123456789if __name__ == &#x27;__main__&#x27;: print(&#x27;main process is &#123;&#125;&#x27;.format(os.getpid())) start_time = time.time() ### single process func() func() end_time = time.time() print(&#x27;total time is &#123;&#125;&#x27;.format(str(end_time - start_time))) 打印结果如下 123456main process is 24308process 24308 startsprocess 24308 endsprocess 24308 startsprocess 24308 endstotal time is 4.001222372055054 可以看到，这里是单个进程先后顺序执行了两遍函数，共耗时约4秒。 下面来看看多进程的情况 1234567891011121314if __name__ == &#x27;__main__&#x27;: print(&#x27;main process is &#123;&#125;&#x27;.format(os.getpid())) start_time = time.time() ### multiprocess from multiprocessing import Process p1 = Process(target=func) p2 = Process(target=func) p1.start() p2.start() p1.join() p2.join() end_time = time.time() print(&#x27;total time is &#123;&#125;&#x27;.format(str(end_time - start_time))) 从主进程创建新的进程使用的是Process类，该类在实例化时通常接两个参数 target - 新的进程执行的函数的函数名args - 函数的参数，元组格式传入这里因为func函数没有参数需要传递，所以args没有赋值。 创建完Process对象以后通过start()方法来启动该进程，同时如果想让某个进程阻塞主进程，可以执行该进程的join()方法。正常情况下创建完子进程以后主进程会继续向下执行直到结束，如果有子进程阻塞了主进程则主进程会等待该子进程执行完以后才向下执行。这里主进程会等待p1和p2两个子进程都执行完毕才计算结束时间。 打印结果如下 123456main process is 33536process 25764 startsprocess 11960 startsprocess 25764 endsprocess 11960 endstotal time is 2.3870742321014404 可以看到，创建的子进程和主进程的进程ID是不一样的，说明此时一共有三个进程在同时跑。最后的用时为2.387秒，几乎降到了顺序执行一半的程度，当然比单个函数执行的时间还是慢了点，说明进程的创建和停止还是需要耗时的。 进程池从上面的例子可以看出，进程的创建和停止都是消耗资源的，所以进程绝不是越多越好。因为单个CPU核某时刻只能执行单个进程，所以最好的情况是将进程数量与CPU核数相等，这样可以最大化利用CPU。 这时就有一个问题出现了，进程数少还好说，进程数多了的话如何自动去维持一个固定的进程数目呢，这时候就要用到进程池了。进程池就是规定一个可容纳最大进程数目的池子，当池子中进程数目不足时自动添加新进程，从而将同时运行的进程数目维持在一个上限之内。这里的上限就应该是CPU的核数。 1234567891011121314if __name__ == &#x27;__main__&#x27;: from multiprocessing import Process, cpu_count, Pool print(&#x27;main process is &#123;&#125;&#x27;.format(os.getpid())) print(&#x27;core number is &#123;&#125;&#x27;.format(cpu_count())) # 8 start_time = time.time() ### multiprocess pool p = Pool(8) for i in range(14): p.apply_async(func) p.close() p.join() end_time = time.time() print(&#x27;total time is &#123;&#125;&#x27;.format(str(end_time - start_time))) 这里我首先利用cpu_count()方法计算了一下我这台电脑的CPU核数，8核，所以进程池的最大进程数目设定为8。 这里利用Pool类来创建进程池，传递一个参数是最大进程数。利用Pool对象的apply_async()方法往进程池中添加待执行的任务（注意不是进程，只是任务），这里也可以利用map_async(func,iterable)来添加，用来类似于内建的map()方法，不过需要待执行的函数带参数，类似下面这样 123456789101112def func(n): print(&#x27;process &#123;&#125; starts&#x27;.format(os.getpid())) time.sleep(n) print(&#x27;process &#123;&#125; ends&#x27;.format(os.getpid())) ### multiprocess pool p = Pool(8) # for i in range(14): # p.apply_async(func) p.map_async(func,range(14)) p.close() p.join() 然后是close()方法，进程池不再接受新的任务（注意不是进程），以及terminate()方法，关闭主进程，此时未开始的子进程都不会执行了。同样的，想要让进程池去阻塞主进程可以用join()方法。注意join()一定要在close()或者terminate()之后。 上面的程序执行结果如下 12345678910111213141516171819202122232425262728293031main process is 12860core number is 8process 11956 startsprocess 34224 startsprocess 10596 startsprocess 20596 startsprocess 27668 startsprocess 15604 startsprocess 10820 startsprocess 16632 startsprocess 11956 endsprocess 11956 startsprocess 34224 endsprocess 34224 startsprocess 10596 endsprocess 10596 startsprocess 20596 endsprocess 20596 startsprocess 27668 endsprocess 27668 startsprocess 15604 endsprocess 15604 startsprocess 10820 endsprocess 16632 endsprocess 11956 endsprocess 34224 endsprocess 10596 endsprocess 20596 endsprocess 27668 endsprocess 15604 endstotal time is 5.258298635482788 一共14个任务，在最大数目为8的进程池里面至少要执行两轮，同时加上进程启动和停止的消耗，最后用时5.258秒。 进程间通讯前面说到进程间是相互独立的，不共享内存空间，所以在一个进程中声明的变量在另一个进程中是看不到的(包括全局变量)。这时候就要借助一些工具来在两个进程间进行数据传输了，其中最常见的就是队列了。 队列（queue）在生产消费者模型中很常见，生产者进程在队列一端写入，消费者进程在队列另一端读取。 首先创建两个函数，分别扮演生产者和消费者 1234567891011def write_to_queue(queue): for index in range(5): print(&#x27;write &#123;&#125; to &#123;&#125;&#x27;.format(str(index), queue)) queue.put(index) time.sleep(1)def read_from_queue(queue): while True: result = queue.get(True) print(&#x27;get &#123;&#125; from &#123;&#125;&#x27;.format(str(result), queue)) 这两个函数都接受一个队列作为参数然后利用put()方法往其中写入或者get()方法来读取。生产者会连续写入5个数字，每次间隔1秒，消费者则会一直尝试读取。 12345678910111213141516if __name__ == &#x27;__main__&#x27;: from multiprocessing import Process, cpu_count, Pool print(&#x27;main process is &#123;&#125;&#x27;.format(os.getpid())) print(&#x27;core number is &#123;&#125;&#x27;.format(cpu_count())) # 8 start_time = time.time() ### multiprocess queue from multiprocessing import Queue queue = Queue() pw = Process(target=write_to_queue, args=(queue,)) pr = Process(target=read_from_queue, args=(queue,)) pw.start() pr.start() pw.join() pr.terminate() end_time = time.time() print(&#x27;total time is &#123;&#125;&#x27;.format(str(end_time - start_time))) 注意这里在创建子进程的时候就用元组的形式传递了参数，如果元组只有一个元素，记住添加逗号，否则会被认为是单个元素而不是元组。同时这里因为消费者是死循环，所以只是将生产者加入了阻塞，生产者进程执行完毕以后停止消费者进程。 最后打印结果如下 12345678910111213main process is 28268core number is 8write 0 to &lt;multiprocessing.queues.Queue object at 0x0000023C6B25BF88&gt;get 0 from &lt;multiprocessing.queues.Queue object at 0x000002EF410B1C88&gt;write 1 to &lt;multiprocessing.queues.Queue object at 0x0000023C6B25BF88&gt;get 1 from &lt;multiprocessing.queues.Queue object at 0x000002EF410B1C88&gt;write 2 to &lt;multiprocessing.queues.Queue object at 0x0000023C6B25BF88&gt;get 2 from &lt;multiprocessing.queues.Queue object at 0x000002EF410B1C88&gt;write 3 to &lt;multiprocessing.queues.Queue object at 0x0000023C6B25BF88&gt;get 3 from &lt;multiprocessing.queues.Queue object at 0x000002EF410B1C88&gt;write 4 to &lt;multiprocessing.queues.Queue object at 0x0000023C6B25BF88&gt;get 4 from &lt;multiprocessing.queues.Queue object at 0x000002EF410B1C88&gt;total time is 5.603313446044922 多线程首先创建一个函数用于测试 123456import threadingdef func2(n): print(&#x27;thread &#123;&#125; starts&#x27;.format(threading.current_thread().name)) time.sleep(2) print(&#x27;thread &#123;&#125; ends&#x27;.format(threading.current_thread().name)) return n 多线程使用的是threading.Thread类 123456789101112if __name__ == &#x27;__main__&#x27;: print(&#x27;main thread is &#123;&#125;&#x27;.format(threading.current_thread().name)) start_time = time.time() ### multithread t1 = threading.Thread(target=func2, args=(1,)) t2 = threading.Thread(target=func2, args=(2,)) t1.start() t2.start() t1.join() t2.join() end_time = time.time() print(&#x27;total time is &#123;&#125;&#x27;.format(str(end_time - start_time))) 基本用法和上面进程的Process差不多，打印的结果如下&#96;&#96;main thread is MainThreadthread Thread-1 startsthread Thread-2 startsthread Thread-1 endsthread Thread-2 endstotal time is 2.002077341079712 12345678910111213141516171819对比前面多进程的2.38秒，这里还是快了不少的。### [线程池](https://so.csdn.net/so/search?q=%E7%BA%BF%E7%A8%8B%E6%B1%A0\\&amp;spm=1001.2101.3001.7020)和进程一样，通常是使用线程池来完成自动控制线程数量的目的。但是这里就没有一个推荐的上限数量了，毕竟因为GIL的存在不管怎么样每次都只有一个线程在跑。同时threading模块是不支持线程池的，python3.4以后官方推出了concurrent.futures模块来统一进程池和线程池的接口，这里关注一下线程池。```pythonfrom concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETEDif __name__ == &#x27;__main__&#x27;: print(&#x27;main thread is &#123;&#125;&#x27;.format(threading.current_thread().name)) start_time = time.time() ### threadpool executor = ThreadPoolExecutor(5) all_tasks = [executor.submit(func2, i) for i in range(8)] wait(all_tasks, return_when=ALL_COMPLETED) end_time = time.time() print(&#x27;total time is &#123;&#125;&#x27;.format(str(end_time - start_time))) 这里利用ThreadPoolExecutor()创建一个线程池，最大上限为5，然后利用submit()方法往线程池中添加任务（注意是任务，不是线程），submit方法会返回一个future对象，注意这里我将创建的任务放进了一个列表中。 如果要阻塞主线程，不能用join方法了，需要用到wait()方法，该方法接受三个参数，第一个参数是一个future对象的列表，第二个参数是超时时间，这里放空，第三个参数是在什么时候结束阻塞，默认是ALL_COMPLETED表示全部任务结束之后，也可以设定为FIRST_COMPLETED表示第一个任务结束以后。 打印结果如下 123456789101112131415161718main thread is MainThreadthread ThreadPoolExecutor-0_0 startsthread ThreadPoolExecutor-0_1 startsthread ThreadPoolExecutor-0_2 startsthread ThreadPoolExecutor-0_3 startsthread ThreadPoolExecutor-0_4 startsthread ThreadPoolExecutor-0_0 endsthread ThreadPoolExecutor-0_0 startsthread ThreadPoolExecutor-0_2 endsthread ThreadPoolExecutor-0_2 startsthread ThreadPoolExecutor-0_1 endsthread ThreadPoolExecutor-0_1 startsthread ThreadPoolExecutor-0_3 endsthread ThreadPoolExecutor-0_4 endsthread ThreadPoolExecutor-0_0 endsthread ThreadPoolExecutor-0_2 endsthread ThreadPoolExecutor-0_1 endstotal time is 4.003619432449341 最后的结果也是接近两倍的函数耗时4秒，比进程池快了不止一点点。 map这里需要额外提一下多线程中的map方法。 多进程中的map_async()方法和多线程中的map()方法除了将任务加入线程池，还会按添加的顺序返回每个线程的执行结果，这个执行结果也很特殊，是一个生成器 1234567891011from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETEDif __name__ == &#x27;__main__&#x27;: print(&#x27;main thread is &#123;&#125;&#x27;.format(threading.current_thread().name)) start_time = time.time() ### map executor = ThreadPoolExecutor(5) all_results = executor.map(func2, range(8)) # map返回的是线程执行的结果的生成器对象 for result in all_results: print(result) end_time = time.time() print(&#x27;total time is &#123;&#125;&#x27;.format(str(end_time - start_time))) 这里的all_results是一个生成器，可以通过for循环来按顺序获取每个线程的返回结果。同时值得注意的是map方法并不会阻塞主线程，也没法使用wait方法，只能通过获取生成器的结果来阻塞主线程了。 执行结果如下 1234567891011121314151617181920212223242526main thread is MainThreadthread ThreadPoolExecutor-0_0 startsthread ThreadPoolExecutor-0_1 startsthread ThreadPoolExecutor-0_2 startsthread ThreadPoolExecutor-0_3 startsthread ThreadPoolExecutor-0_4 startsthread ThreadPoolExecutor-0_0 endsthread ThreadPoolExecutor-0_0 starts0thread ThreadPoolExecutor-0_1 endsthread ThreadPoolExecutor-0_1 startsthread ThreadPoolExecutor-0_2 ends1thread ThreadPoolExecutor-0_2 starts2thread ThreadPoolExecutor-0_3 ends3thread ThreadPoolExecutor-0_4 ends4thread ThreadPoolExecutor-0_0 ends5thread ThreadPoolExecutor-0_1 ends6thread ThreadPoolExecutor-0_2 ends7total time is 4.004628419876099 异步想要不用map方法又要异步获取线程的返回值，还可以用as_completed()方法 12345678910from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED, as_completedif __name__ == &#x27;__main__&#x27;: print(&#x27;main thread is &#123;&#125;&#x27;.format(threading.current_thread().name)) start_time = time.time() executor = ThreadPoolExecutor(5) all_tasks = [executor.submit(func2, i) for i in range(8)] for future in as_completed(all_tasks): print(future.result()) end_time = time.time() print(&#x27;total time is &#123;&#125;&#x27;.format(str(end_time - start_time))) 1234567891011121314151617181920212223242526main thread is MainThreadthread ThreadPoolExecutor-0_0 startsthread ThreadPoolExecutor-0_1 startsthread ThreadPoolExecutor-0_2 startsthread ThreadPoolExecutor-0_3 startsthread ThreadPoolExecutor-0_4 startsthread ThreadPoolExecutor-0_0 endsthread ThreadPoolExecutor-0_1 endsthread ThreadPoolExecutor-0_1 starts1thread ThreadPoolExecutor-0_2 endsthread ThreadPoolExecutor-0_2 starts2thread ThreadPoolExecutor-0_0 startsthread ThreadPoolExecutor-0_3 endsthread ThreadPoolExecutor-0_4 ends034thread ThreadPoolExecutor-0_1 ends5thread ThreadPoolExecutor-0_0 ends7thread ThreadPoolExecutor-0_2 ends6total time is 4.003146648406982 这里的线程结果就不是按照就不是按照添加任务的顺序，而是按照返回的先后顺序打印的。 所以，想要获取多线程的返回结果，按照添加顺序就用map方法，按照返回的先后顺序就用as_completed方法。 想要更深入了解python中的futures模块，可以参考下面的文章学习下源码分析 https://www.jianshu.com/p/b9b3d66aa0be 同时python中还有专门做异步编程的asyncio模块，以后有时间再专门写文章说明。 线程间通讯与多进程的内存独立不同，多线程间可以共享内存，所以同一个变量是可以被多个线程共享的，不需要额外的插件。想要让多个线程能同时操作某变量，要么将该变量作为参数传递到线程中（必须是可变变量，例如list和dict），要么作为全局变量在线程中用global关键字进行声明。 因为有GIL的存在，每次只能有一个线程在对变量进行操作，有人就认为python不需要互斥锁了。但是实际情况却和我们想的相差很远，先看下面这个例子: 12345678910111213141516171819202122232425262728293031def increase(var): global total_increase_times for i in range(1000000): var[0] += 1 total_increase_times += 1def decrease(var): global total_decrease_times for i in range(1000000): var[0] -= 1 total_decrease_times += 1 if __name__ == &#x27;__main__&#x27;: print(&#x27;main thread is &#123;&#125;&#x27;.format(threading.current_thread().name)) start_time = time.time() var = [5] total_increase_times = 0 total_decrease_times = 0 t1 = threading.Thread(target=increase, args=(var,)) t2 = threading.Thread(target=decrease, args=(var,)) t1.start() t2.start() t1.join() t2.join() print(var) print(&#x27;total increase times: &#123;&#125;&#x27;.format(str(total_increase_times))) print(&#x27;total decrease times: &#123;&#125;&#x27;.format(str(total_decrease_times))) end_time = time.time() print(&#x27;total time is &#123;&#125;&#x27;.format(str(end_time - start_time))) 这里首先定义了两个函数，分别对传进来的list的第一个元素进行加一和减一操作，重复多遍。这里之所以使用list因为要满足可变变量的要求，对于python中变量和传参不熟悉的朋友可以参考另一篇博客《python3中各类变量的内存堆栈分配和函数传参区别实例详解》。 然后在主线程中创建两个子线程分别运行，同时创建两个全局变量total_increase_times和total_decrease_times分别来统计对变量进行加值和减值的次数，为了防止可能由于操作次数不一致导致的错误。 打印结果如下 12345main thread is MainThread[281970]total increase times: 1000000total decrease times: 1000000total time is 0.7370336055755615 很奇怪，对变量值增加和减少同样的次数，最后的结果却和原先的值不一致。而且如果将该程序重复运行多次，每次得到的最终值都不同，有正有负。 这是为什么呢？ 这是因为某些在我们看来是原子操作的，例如+或者-，在python看来不是的。例如执行a+&#x3D;1操作，在python看来其实是三步：获取a的值，将值加1，将新的值赋给a。在这三步中的任意位置，该线程都有可能被暂停，然后让别的线程先运行。这时候就有可能出现如下的局面: 123456线程1获取了a的值为10，被暂停线程2获取了a的值为10线程2将a的值赋值为9，被暂停线程1将a的值赋值为11，被暂停线程2获取了a的值为11... 这样线程1就将线程2的操作全部覆盖了，这也就是为什么最后的结果有正有负。 那么如何处理这种情况呢？ 需要用到互斥锁。 互斥锁线程1在操作变量a的时候就给a上一把锁，别的线程看到变量有锁就不会去操作该变量，一直到线程1再次获得GIL之后继续操作将锁释放，别的线程才有机会对该变量进行操作。 修改下上面的代码 123456789101112131415161718192021222324252627282930313233343536def increase(var, lock): global total_increase_times for i in range(1000000): if lock.acquire(): var[0] += 1 lock.release() total_increase_times += 1def decrease(var, lock): global total_decrease_times for i in range(1000000): if lock.acquire(): var[0] -= 1 lock.release() total_decrease_times += 1 if __name__ == &#x27;__main__&#x27;: print(&#x27;main thread is &#123;&#125;&#x27;.format(threading.current_thread().name)) start_time = time.time() lock = threading.Lock() var = [5] total_increase_times = 0 total_decrease_times = 0 t1 = threading.Thread(target=increase, args=(var, lock)) t2 = threading.Thread(target=decrease, args=(var, lock)) t1.start() t2.start() t1.join() t2.join() print(var) print(&#x27;total increase times: &#123;&#125;&#x27;.format(str(total_increase_times))) print(&#x27;total decrease times: &#123;&#125;&#x27;.format(str(total_decrease_times))) end_time = time.time() print(&#x27;total time is &#123;&#125;&#x27;.format(str(end_time - start_time))) 这里创建了一个全局锁lock并传递给两个线程，利用acquire()方法获取锁，如果没有获取到锁该线程会一直卡在这，并不会继续循环，操作完毕用release()方法释放锁。 打印结果如下 main thread is MainThread [5] total increase times: 1000000 total decrease times: 1000000 total time is 2.1161584854125977 最终的结果不管执行多少次都没有问题，但是因为前面说的等待锁的过程会造成大量时间的浪费，这里耗时2.116秒比前面的0.737秒要慢了3倍。 这里不能像进程中那样用terminate方法停止一个线程，需要用setDaemon方法。 打印结果如下 123456789101112main thread is MainThreadwrite 0 to &lt;queue.Queue object at 0x000001E3DACD21C8&gt;get 0 from &lt;queue.Queue object at 0x000001E3DACD21C8&gt;write 1 to &lt;queue.Queue object at 0x000001E3DACD21C8&gt;get 1 from &lt;queue.Queue object at 0x000001E3DACD21C8&gt;write 2 to &lt;queue.Queue object at 0x000001E3DACD21C8&gt;get 2 from &lt;queue.Queue object at 0x000001E3DACD21C8&gt;write 3 to &lt;queue.Queue object at 0x000001E3DACD21C8&gt;get 3 from &lt;queue.Queue object at 0x000001E3DACD21C8&gt;write 4 to &lt;queue.Queue object at 0x000001E3DACD21C8&gt;get 4 from &lt;queue.Queue object at 0x000001E3DACD21C8&gt;total time is 5.00357986831665 扩展多进程间的变量共享也可以用类似多线程那样传递变量或者全局变量的方式，限于篇幅这里没有展开说，感兴趣的朋友可以参考知乎上一篇不错的文章https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;68828849 multiprocessing中的共享变量总结总结下文章中涉及的知识点 CPU密集型使用多进程，IO密集型使用多线程 查看进程ID和线程ID的命令分别是os.getpid()和threading.current_thread() 多进程使用multiprocessing就可以了，通常使用进程池来完成操作，阻塞主进程使用join方法 多线程使用threading模块，线程池使用concurrent.futures模块，同时主线程的阻塞方法有多种 不管多进程还是多线程，生产消费模型都可以用队列来完成，如果要用多线程操作同一变量记得加锁 参考资料 https://blog.csdn.net/Victor2code/article/details/109005171 https://www.zhihu.com/question/25532384/answer/411179772","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"技术开发/python","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/"}],"tags":[{"name":"python多进程与多线程","slug":"python多进程与多线程","permalink":"https://tianxiafeiyu.github.io/tags/python%E5%A4%9A%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"python知识点","slug":"技术开发/python/python知识点","date":"2022-12-15T23:22:29.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/python/python知识点/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/python%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"实在是对python没有好感，但是还在吃这口饭，姑且还是要提升自己的。 Python的优势1、Python 易于学习; 2、用少量的代码构建出很多功能（高效的高级数据结构） 3、Python 拥有海量全面的库 4、Python完全支持面向对象 5、Python 是跨平台且开源的 6、动态类型 解释型和编译型编程语言解释型 python javascript php matlab 边解释边执行，将源代码解释成机器码，然后才能够执行 编译型 c c++ go 编译后再执行，一次将源代码编译成机器语言文件，之后执行不需要再编译 Java语言既具有编译语言的特征又具有解释语言的特征 Python的解释器种类以及相关特点CPython 使用C语言开发，官方版本的解释器， IPython 基于CPython之上的一个交互式解释器 支持变量自动补全，自动缩进，支持bash shell命令 PE8规范PEP8是Python的官方文档中提供的代码规范 12345678910111213141516171819202122231、使用4个空格而不是tab键进行缩进。2、每行长度不能超过793、使用空行来间隔函数和类，以及函数内部的大块代码4、必要时候，在每一行下写注释5、使用文档注释，写出函数注释6、在操作符和逗号之后使用空格，但是不要在括号内部使用7、命名类和函数的时候使用一致的方式，比如使用CamelCase来命名类，使用lower_case_with_underscores来命名函数和方法8、在类中总是使用self来作为默认9、尽量不要使用魔法方法10、默认使用UTF-8，甚至ASCII作为编码方式11、换行可以使用反斜杠，最好使用圆括号。12、不要在一句import中多个库，13、空格的使用： 各种右括号前不要加空格。 逗号、冒号、分号前不要加空格。 函数的左括号前不要加空格。如Func(1) 序列的左括号前不要加空格。如list[2] 操作符左右各加一个空格，不要为了对齐增加空格 函数默认参数使用的赋值符左右省略空格 14、不要将多句语句写在同一行，尽管使用‘；’允许15、if/for/while语句中，即使执行语句只有一句，也必须另起一行16、函数命名使用全部小写的方式，常量命名使用大写，类属性（方法和变量）使用小写17、类的命名首字母大写 进制之间转换12345678910111213141516171819202122232425262728293031# 二进制转换成十进制--&gt;intv = &quot;0b1111011&quot;b = int(v,2)print(b) # 123# 十进制转换成二进制---&gt;binv2 = 18print(bin(int(v2)))# 0b10010# ob是python的概念，代表这是一个二进制数，同理 0o 八进制，0x 十六进制# 八进制转换成十进制v3 = &quot;011&quot;print(int(v3))# 11# 十进制转换成八进制：---&gt; octv4 = 30print(oct(int(v4)))# 0o36# 十六进制转换成十进制：v5 = &quot;0x12&quot;print(int(v5,16))# 18# 十进制转换成十六进制：---&gt; hexv6 = 87print(hex(int(v6)))# 0x57 六大基本数据类型Python 类型检查要查看变量的数据类型，可以使用type()函数使用：type(变量名，或者直接写变量值) &amp;#x20;数字整型(int) - 通常被称为是整型或整数，是正或负整数，不带小数点。Python3 整型是没有限制大小的，可以当作 Long 类型使用，所以 Python3 没有 Python2 的 Long 类型。布尔(bool)是整型的子类型。 浮点型(float) - 浮点型由整数部分与小数部分组成，浮点型也可以使用科学计数法表示（2.5e2 &#x3D; 2.5 x 102 &#x3D; 250） 整数进制 十进制：不能以0开头&amp;#x20; 二进制：以0b开头&amp;#x20; 八进制：以0o开头&amp;#x20; 十六进制：以0x开头 字符串字符串是 Python 中最常用的数据类型。我们可以使用引号( ’ 或 “ )来创建字符串。 Python 格式化符号 %s 字符串 %d 有符号的十进制整数；%0nd 代表位数不足用0代替 n:代表几位数 %f 浮点数（默认保留6位小数；%.nf .代表小数点 n代表.后面保留几位数 list(列表)什么是列表？ 用来装载不同数据类型的数据集结构 列表的特点？ 有序的 - 可以装载任意数据类型&amp;#x20; 可以更改的 如何表示list？ 12345# 通过list()新建一个列表list(&quot;hello world&quot;)# 通过[]声明一个列表a = [1, 2, 3] tuple(元组)什么是元组? 可以简单地认为, 元组就是不可修改的列表, 常用来表示记录. 元组的特点? 有序的可以装载任意数据类型不可更改 如何表示tuple 123456# 通过tuple()新建一个元组tuple(&quot;hello&quot;)# 通过(,)来声明一个元组a = (1, 2, 3)# 声明单个元素的元组, 要添加逗号a = (1, ) dict(字典)什么是字典? 字典也叫hashtable, 通过hash(散列)函数将传入的key值生成地址来查找value key -&gt; hash函数 -&gt; 返回了value的地址 -&gt; 通过地址返回value值 字典的特点? 无序的 python3.6是有序的… 字典中的key必须是可hash的, 也就是不可更改的, 唯一的 可以更改的 如何表示字典？ 12345# 通过dict()来创建字典dict(a=2)# 通过&#123;&#125;来声明一个字典a = &#123;&quot;a&quot;: 2&#125; set(集合)什么是set？ set其实是没有value的字典 集合的特点？ 无序的&amp;#x20; 集合中的key必须是可hash的 可以更改的 元素是唯一的&amp;#x20; 如何表示set？？ 12345# 通过set()来创建集合set([1,2,2])# 通过&#123;&#125;来表示&#123;1, 2, 3&#125; 文本编码格式python2内容进行编码（默认ascii），python3对内容进行编码的默认为utf-8。 ascii 最多只能用8位来表示（一个字节），即：2**8 &#x3D; 256，所以，ASCII码最多只能表示 256 个符号。 unicode 万国码，任何一个字符等于两个字节 utf-8 万国码的升级版 一个中文字符等于三个字节 英文是一个字节 欧洲的是 2个字节 gbk 国内版本 一个中文字符等于2个字节 ，英文是一个字节，gbk 转 utf-8 需通过媒介 unicode &amp;#x20;机器码与字节码 机器码 学名机器语言指令，有时也被称为原生码，是电脑的CPU可直接解读的数据。 字节码 是一种中间状态（中间码）的二进制代码（文件）。需要直译器转译后才能成为机器码。 &amp;#x20;小数据池代码块Python程序是由代码块构造的。块是一个python程序的文本，他是作为一个单元执行的。 代码块：一个模块，一个函数，一个类，一个文件等都是一个代码块。 而作为交互方式输入的每个命令都是一个代码块，如命令行终端。 代码块的缓存机制Python在执行同一个代码块的初始化对象的命令时，会检查是否其值是否已经存在，如果存在，会将其重用。换句话说：执行同一个代码块时，遇到初始化对象的命令时，他会将初始化的这个变量与值存储在一个字典中，在遇到新的变量时，会先在字典中查询记录，如果有同样的记录那么它会重复使用这个字典中的之前的这个值。 代码块的缓存机制的适用范围： int(float):任何数字在同一代码块下都会复用。 bool:True和False在字典中会以1，0方式存在，并且复用。 str：几乎所有的字符串都会符合缓存机制。 &amp;#x20;小数据池小数据池，也称为小整数缓存机制，或者称为驻留机制 小数据池也是只针对 int(float)，str，bool，是针对不同代码块之间的缓存机制。 Python的一种优化机制，对一些常见数据进行缓存，当需要使用这个数据时，直接从池中获取，不会重复创建对象。 int(float): -5~256 的整数 进行了缓存，当你将这些整数赋值给变量时，并不会重新创建对象，而是使用已经创建好的缓存对象。 字符串 &amp;#x20; 1.字符串的长度为0或者1，默认都采用了驻留机制（小数据池）。 &amp;#x20; 2.字符串的长度&gt;1,且只含有大小写字母，数字，下划线时，才会默认驻留。 &amp;#x20; 3. 乘法运算的字符串，当，乘数&gt;&#x3D;2时：仅含大小写字母，数字，下划线，总长度&lt;&#x3D;20，默认驻留。 bool：True，False，无论你创建多少个变量指向True，False，那么他在内存中只存在一个 总结如果在同一代码块下，则采用同一代码块下的换缓存机制。 如果是不同代码块，则采用小数据池的驻留机制。 缓存机制适用的是未运算的变量，如果变量是经过 + - % &#x2F; 计算的，不适用缓存机制。 id, is，&#x3D;&#x3D;Python中，id是内存地址，比如你利用id()内置函数去查询一个数据的内存地址。 =&#x3D; 是比较的两边的数值是否相等，而 is 是比较的两边的内存地址是否相等。&amp;#x20; 要注意 is 进行比较带来的坑* * Python3和Python2的区别12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152531：打印时，py2需要可以不需要加括号，py3 需要python 2 ：print (&#x27;lili&#x27;) , print &#x27;lili&#x27;python 3 : print (&#x27;lili&#x27;) python3 必须加括号exec语句被python3废弃，统一使用exec函数2：内涵Python2：1，臃肿，源码的重复量很多。 2，语法不清晰。Python3：几乎是重构后的源码，规范，清晰，优美。3、默认字符编码python2中默认使用ascii,python3中默认使用utf-8python2：要输出中文 需加 # -*- encoding:utf-8 -*-Python3 ： 直接搞4：input不同python2 ：raw_inputpython3 ：input 统一使用input函数5：指定字节python2在编译安装时，可以通过参数-----enable-unicode=ucs2 或-----enable-unicode=ucs4分别用于指定使用2个字节、4个字节表示一个unicode；python3无法进行选择，默认使用 ucs4查看当前python中表示unicode字符串时占用的空间：impor sysprint（sys.maxunicode）#如果值是65535，则表示使用usc2标准，即：2个字节表示#如果值是1114111，则表示使用usc4标准，即：4个字节表示6：py2：xrange rangepy3：range 统一使用range，Python3中range的机制也进行修改并提高了大数据集生成效率7：在包的知识点里包：一群模块文件的集合 + __init__区别：py2 ： 必须有__init__ py3：不是必须的了8：不相等操作符&quot;&lt;&gt;&quot;被Python3废弃，统一使用&quot;!=&quot;9：long整数类型被Python3废弃，统一使用int10：迭代器iterator的next()函数被Python3废弃，统一使用next(iterator)11：异常StandardError 被Python3废弃，统一使用Exception12：字典变量的has_key函数被Python废弃，统一使用in关键词13：file函数被Python3废弃，统一使用open来处理文件，可以通过io.IOBase检查文件类型 &amp;#x20;字符串、列表、元组、字典每个常用的5个方法？12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364字符串：字符串用单引号(&#x27;)或双引号(&quot;)括起来，不可变1，find通过元素找索引，可切片，找不到返回-12，index，找不到报错。3，split 由字符串分割成列表，默认按空格。4，captalize 首字母大写，其他字母小写。5，upper 全大写。6，lower 全小写。7，title，每个单词的首字母大写。8，startswith 判断以什么为开头，可以切片，整体概念。9，endswith 判断以什么为结尾，可以切片，整体概念。10，format格式化输出#format的三种玩法 格式化输出res=&#x27;&#123;&#125; &#123;&#125; &#123;&#125;&#x27;.format(&#x27;egon&#x27;,18,&#x27;male&#x27;) ==&gt; egon 18 maleres=&#x27;&#123;1&#125; &#123;0&#125; &#123;1&#125;&#x27;.format(&#x27;egon&#x27;,18,&#x27;male&#x27;) ==&gt; 18 egon 18res=&#x27;&#123;name&#125; &#123;age&#125; &#123;sex&#125;&#x27;.format(sex=&#x27;male&#x27;,name=&#x27;egon&#x27;,age=18)11,strip 默认去掉两侧空格，有条件， 12，lstrip,rstrip 14,center 居中，默认空格。 15，count查找元素的个数，可以切片，若没有返回0 16，expandtabs 将一个tab键变成8个空格，如果tab前面的字符长度不足8个，则补全8个， 17，replace（old，new,次数） 18，isdigit 字符串由字母或数字组成 isalpha, 字符串只由字母组成 isalnum 字符串只由数字组成 19,swapcase 大小写翻转 20，for i in 可迭代对象。 字典：1无序（不能索引）2：数据关联性强3:键值对，键值对。唯一一个映射数据类型。#字典的键必须是可哈希的 不可变类型。在同一个字典中，键(key)必须是唯一的。列表是有序的对象集合，字典是无序的对象集合。两者之间的区别在于：字典当中的元素是通过键来存取的，而不是通过偏移存取key： 输出所有的键clear：清空 dic：删除的键如果没有则报错pop：键值对删，有返回，没有原来的键会报错（自行设置返回键就不会报错）popitem：随机删键值对del：删除的键如果没有则报错改 update查 用get时。不会报错# 没有可以返回设定的返回值 注意：1、字典是一种映射类型，它的元素是键值对。2、字典的关键字必须为不可变类型，且不能重复。3、创建空字典使用 &#123; &#125;。列表：索引，切片，加，乘，检查成员。增加：有三种，append：在后面添加。Insert按照索引添加，expend：迭代着添加。list.extend(seq) - 在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表）pop 删除 (pop 有返回值)remove 可以按照元素去删clear 清空列表del 1、可以按照索引去删除 2、切片 3、步长（隔着删）改 1、索引 2、切片：先删除，再迭代着添加list.count(obj) - 统计某个元素在列表中出现的次数list.index(obj) - 从列表中找出某个值第一个匹配项的索引位置list.reverse() - 反向列表中元素list.sort([func]) - 对原列表进行排序注意：1、List写在方括号之间，元素用逗号隔开。2、和字符串一样，list可以被索引和切片。3、List可以使用+操作符进行拼接。4、List中的元素是可以改变的。元组：（）元组的元素不能修改1、cmp(tuple1, tuple2)：比较两个元组元素。2、len(tuple)：计算元组元素个数。3、max(tuple)：返回元组中元素最大值。4、min(tuple)：返回元组中元素最小值。5、tuple(seq)：将列表转换为元组。注意1、与字符串一样，元组的元素不能修改。2、元组也可以被索引和切片，方法一样。3、注意构造包含0或1个元素的元组的特殊语法规则。4、元组也可以使用+操作符进行拼接。Set（集合）：集合（set）是一个无序不重复元素的序列。可以使用大括号 &#123; &#125; 或者 set() 函数创建集合，注意：创建一个空集合必须用 set() 而不是 &#123; &#125;，因为 &#123; &#125; 是用来创建一个空字典。 lambda表达式123456789函数名 = lambda 参数 ：返回值#参数可以有多个，用逗号隔开#匿名函数不管逻辑多复杂，只能写一行，且逻辑执行结束后的内容就是返回值#返回值和正常的函数一样可以是任意数据类型lambda 表达式temp = lambda x,y:x+yprint(temp(4,10)) # 14 转载自 https://www.cnblogs.com/JetpropelledSnake/p/9396511.html","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"技术开发/python","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/"}],"tags":[{"name":"python知识点","slug":"python知识点","permalink":"https://tianxiafeiyu.github.io/tags/python%E7%9F%A5%E8%AF%86%E7%82%B9/"}]},{"title":"python编程技巧","slug":"技术开发/python/python编程技巧","date":"2022-12-15T23:22:29.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/python/python编程技巧/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/python%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/","excerpt":"","text":"避免过多的if else表驱动方法编程（Table-Driven Methods）是一种编程模式,适用场景:消除代码中频繁的if else或switch case的逻辑结构代码,使代码更加直白. 1234567891011121314151617181920212223242526def response(method): &#x27;&#x27;&#x27;if 语句 黄哥Python培训 黄哥所写&#x27;&#x27;&#x27; if method == &quot;POST&quot;: return &quot;/post&quot; elif method == &quot;GET&quot;: return &quot;/get&quot; elif method == &quot;HEAD&quot;: return &quot;/head&quot; return &quot;/&quot;def resposne_by_dict(method_dict, method): &#x27;&#x27;&#x27;用字典代替if 语句 黄哥Python培训 黄哥所写 &#x27;&#x27;&#x27; return method_dict.get(method, &quot;/&quot;)if __name__ == &#x27;__main__&#x27;: method_dict = &#123; &quot;POST&quot;: &quot;/post&quot;, &quot;GET&quot;: &quot;/get&quot;, &quot;HEAD&quot;: &quot;/head&quot;, &#125; method = &quot;POST&quot; print(response(method)) print(resposne_by_dict(method_dict, method)) 12345678假设让你实现一个返回每个月天数的函数（为简单起见不考虑闰年）。static int monthDays[12] = &#123;31,28,31,30,31,30,31,31,30,31,30,31&#125;;public static int getDayByMonth(int month)&#123; if(month&lt;1|| month&gt;12)&#123; throw new RuntimeException(&quot;month invalid parameter:&quot;+month); &#125; return monthDays[(month- 1)]; &#125;","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"技术开发/python","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/"}],"tags":[{"name":"python编程技巧","slug":"python编程技巧","permalink":"https://tianxiafeiyu.github.io/tags/python%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"}]},{"title":"python脚本接收参数的几种实现方式","slug":"技术开发/python/python脚本接收参数的几种实现方式","date":"2022-12-15T23:22:29.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/python/python脚本接收参数的几种实现方式/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/python%E8%84%9A%E6%9C%AC%E6%8E%A5%E6%94%B6%E5%8F%82%E6%95%B0%E7%9A%84%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/","excerpt":"","text":"sys.argvsys.argv[] 可以接收脚本的参数，得到一个列表类型，列表第一个元素是脚本名称。 import sys arg1 = sys.argv[0] arg2 = sys.argv[1] arg4 = sys.argv[2] # e.g. # python test_func.py test_arg1 test_arg2 # arg1: test_func.py # arg1: test_arg1 # arg1: test_arg2 argparsepython专门用于处理命令行参数的标准库 import argparse if __name__ == &#39;__main__&#39;: parser = argparse.ArgumentParser( prog=&#39;cmdb_mock&#39;, description=&#39;mock tool for cmdb&#39;, formatter_class=argparse.ArgumentDefaultsHelpFormatter) parser.add_argument(&#39;action&#39;) parser.add_argument(&#39;-size&#39;, dest=&#39;size&#39;, type=int, default=10, help=u&#39;number of resource mock&#39;) args = parser.parse_args() actiom = args.action size = args.size # python cmdb_mock.py create -size 100","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"技术开发/python","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/"}],"tags":[{"name":"python脚本接收参数的几种实现方式","slug":"python脚本接收参数的几种实现方式","permalink":"https://tianxiafeiyu.github.io/tags/python%E8%84%9A%E6%9C%AC%E6%8E%A5%E6%94%B6%E5%8F%82%E6%95%B0%E7%9A%84%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/"}]},{"title":"变量及方法前后下划线的含义","slug":"技术开发/python/变量及方法前后下划线的含义","date":"2022-12-15T23:22:29.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/python/变量及方法前后下划线的含义/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/%E5%8F%98%E9%87%8F%E5%8F%8A%E6%96%B9%E6%B3%95%E5%89%8D%E5%90%8E%E4%B8%8B%E5%88%92%E7%BA%BF%E7%9A%84%E5%90%AB%E4%B9%89/","excerpt":"","text":"单下划线和双下划线在Python变量名和方法名中都有各自的含义。有些仅仅是作为约定，用于提示开发人员；而另一些则对Python解释器有特殊含义。 总的来说有一下几种情况： 前置单下划线：_var 后置单下划线：var_ 前置双下划线：__var 前后双下划线：var 单下划线：_ 1. 前置单下划线：_var“单下划线 “ 开始的成员变量相当于私有变量，也叫做保护变量，意思是只有类实例和子类实例能访问到这些变量，需通过类提供的接口进行访问（可以定义有点像java中的getter、setter方法，借助方法访问，而不是直接对变量动刀子）；不能用’from module import *‘导入。其实，Python并没有真正的私有化支持，用下划线得到的是伪私有，也就是说如果你强行要用也是可以的，但不符合python的规范。我们应该尽量避免重新定义以下划线开头的变量。 2. 后置单下划线：var_有时，某个变量最合适的名称已被Python语言中的关键字占用。因此，诸如class或def的名称不能用作Python中的变量名。在这种情况下，可以追加一个下划线来绕过命名冲突。 例如：sqlalchemy的查询 session.query(model).filter(model.name.in_(names), model.age.is_(None)) 总之，用一个后置单下划线来避免与Python关键字的命名冲突是一个约定。 3. 前置双下划线：__var类中的私有变量&#x2F;方法名 （Python的函数也是对象，所以成员方法称为成员变量也行得通）。” 双下划线 “ 开始的是私有成员，意思是只有类对象自己能访问，连子类对象也不能访问到这个数据。可以理解为Java上真正的私有变量。 123456789101112131415161718192021222324252627class A(object): _num = 0 # 可以访问 num_ = 0 # 可以访问 __num = 0 # 只有类内可以访问 __num__ = 0 # 可以访问 def __method(self): print(&#x27;I am method A&#x27;) def method(self): # 只允许类内调用， a = A(); a.__method()报错； return self.__method()class B(A): def __method(self): # 子类无法重写__method()函数 print(&#x27;I am method B&#x27;)if __name__ == &#x27;__main__&#x27;: a = A() a.method() b = B() b.method() 输出： I am method A I am method A 4. 前后双下划线：var系统定义名字，前后均有一个“双下划线” 代表python里特殊方法专用的标识，如 init（）代表类的构造函数。类似__xxx__这样的变量是特殊变量，可以被直接引用，但是有特殊用途，比如一个模块的__author__，__name__就是特殊变量，模块定义的文档注释（就是模块开头的字符串）也可以用特殊变量__doc__访问，我们自己的变量一般不要用这种变量名，以避免与将来Python语言的变化产生冲突。 5. 单下划线：_按照习惯，有时候单个独立下划线是用作一个名字，来表示某个变量是临时的或无关紧要的。通常被称为丢弃变量","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"技术开发/python","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/"}],"tags":[{"name":"变量及方法前后下划线的含义","slug":"变量及方法前后下划线的含义","permalink":"https://tianxiafeiyu.github.io/tags/%E5%8F%98%E9%87%8F%E5%8F%8A%E6%96%B9%E6%B3%95%E5%89%8D%E5%90%8E%E4%B8%8B%E5%88%92%E7%BA%BF%E7%9A%84%E5%90%AB%E4%B9%89/"}]},{"title":"cmdb_mock","slug":"技术开发/python/Script/cmdb_mock","date":"2022-12-15T23:22:29.000Z","updated":"2022-12-16T21:37:31.000Z","comments":true,"path":"2022/12/15/技术开发/python/Script/cmdb_mock/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/Script/cmdb_mock/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780#!/usr/bin/python# -*- coding: utf-8 -*-&quot;&quot;&quot;用于在批量创建cmdb数据1.创建资源python cmdb_mock.py -action create -type plat -size 102. 清理资源python cmdb_mock.py -action delete -type plat&quot;&quot;&quot;import argparseimport loggingimport osimport randomimport uuidfrom oslo_config import cfgfrom oslo_utils import uuidutilsfrom pymongo import MongoClientfrom aops_api.common.client import Clientfrom sf_libs.utils.mongodb_lib import get_mongodb_client_auth_dictfrom sf_libselect import libselect_MONGODB_HOST = &#x27;mongodb.cloud.vt&#x27;_MONGODB_PORT = 27017_MONGODB_MAX_POOL_SIZE = 256_MONGODB_DB_NAME = &#x27;cmdb&#x27;_MONGODB_USER = &#x27;aops&#x27;PROJECT = &#x27;sync_scp_host&#x27;CONF = cfg.CONFLOG_FILE_NAME = &#x27;/sf/log/today/%s.log&#x27; % os.path.basename(__file__)logging.basicConfig(level=logging.INFO, format=&#x27;%(asctime)s %(filename)s[line:%(lineno)d] &#x27; &#x27;%(levelname)s %(message)s&#x27;, datefmt=&#x27;%Y-%m-%d %H:%M:%S&#x27;, filename=LOG_FILE_NAME)# mock资源名称的前缀，方便清理MOCK_NAME_PREFIX = &#x27;mock-resource&#x27;LOG = logging.getLogger(__name__)class MongoManager(object): def __init__(self, pool_size, host, port, db): self.cachedb = self._get_mongo_client(pool_size, host, port, db) def _get_mongo_client(self, pool_size, host, port, db): return libselect.Libselect(pool_size=pool_size, host=host, port=port, db=db).get_mongodb() def list_scp(self): scps = self.cachedb[&#x27;sf_scp&#x27;].find() return scps def get_host(self, vmid): filters = &#123; &#x27;host.sf_uuid&#x27;: vmid &#125; hosts = self.cachedb[&#x27;host&#x27;].find(filters) hosts = [host for host in hosts] return hosts[0] if hosts else None def get_user(self, username): filters = dict(name=username) users = self.cachedb[&#x27;user&#x27;].find(filters) users = [user for user in users] return users[0] if users else Noneclass CmdbManager(object): def __init__(self): self.client = Client.cmdb_no_auth() self.mongo_db = self.get_mongodb() @staticmethod def get_mongodb(): &quot;&quot;&quot;获取mongo客户端&quot;&quot;&quot; auth_dict = get_mongodb_client_auth_dict(_MONGODB_USER) client = MongoClient(maxPoolSize=_MONGODB_MAX_POOL_SIZE, **auth_dict) mongo_db = client.get_database(_MONGODB_DB_NAME) return mongo_db def create_scp_host(self, scp_manage_ip, vmid, project_id): host = &#123; &quot;host_info&quot;: &#123; &quot;0&quot;: &#123; &quot;bk_host_type&quot;: &quot;1&quot;, &quot;bk_host_name&quot;: &quot;SCP_&quot; + scp_manage_ip, &quot;bk_host_innerip&quot;: &quot;127.0.0.1&quot;, &quot;bk_uuid&quot;: vmid, &quot;bk_project_id&quot;: project_id &#125; &#125; &#125; try: self.client.hosts.add_host(host) except Exception: LOG.exception(&quot;Failed to create scp host: %s.&quot;, host) return LOG.info(&quot;Succeeded to create scp host: %s.&quot;, host) def create_all(self, size=1): &quot;&quot;&quot;所有类型资源都mock一份&quot;&quot;&quot; for inst_type in INST_TYPE_SET: func_name = &#x27;create_&#123;type&#125;&#x27;.format(type=inst_type) if getattr(self, func_name, None) is not None: getattr(self, func_name)(size) def create_plat(self, size=1): &quot;&quot;&quot;批量添加数据中心&quot;&quot;&quot; documents = [] for i in range(0, size): temp_plat = PLAT_TEMPLATE.copy() temp_plat[&#x27;bk_cloud_name&#x27;] = rand_name(MOCK_NAME_PREFIX, &#x27;&#x27;) temp_plat[&#x27;bk_cloud_id&#x27;] = rand_int_id() documents.append(temp_plat) self.mongo_db[&#x27;cc_PlatBase&#x27;].insert_many(documents) EMPLATE, size) def create_host(self, size=1): &quot;&quot;&quot;批量添加机房&quot;&quot;&quot; self._create_host(SERVER_TEMPLATE, size) def _create_instance(self, template, size): &quot;&quot;&quot;批量添加实例&quot;&quot;&quot; documents = [] for i in range(0, size): temp_inst = template.copy() temp_inst[&#x27;bk_inst_name&#x27;] = rand_name(MOCK_NAME_PREFIX, &#x27;&#x27;) temp_inst[&#x27;bk_inst_id&#x27;] = rand_int_id() documents.append(temp_inst) self.mongo_db[&#x27;cc_ObjectBase&#x27;].insert_many(documents) def create_sf_room(self, size=1): &quot;&quot;&quot;批量添加机房&quot;&quot;&quot; self._create_instance(ROOM_TEMPLATE, size) def create_sf_rack(self, size=1): &quot;&quot;&quot;批量添加机房&quot;&quot;&quot; self._create_instance(RACK_TEMPLATE, size) def create_sf_switch(self, size=1): &quot;&quot;&quot;批量添加机房&quot;&quot;&quot; self._create_instance(SWITCH_TEMPLATE, size) def create_sf_az(self, size=1): &quot;&quot;&quot;批量添加资源池&quot;&quot;&quot; self._create_instance(AZ_TEMPLATE, size) def create_cluster(self, size=1): &quot;&quot;&quot;批量添加集群&quot;&quot;&quot; self._create_instance(CLUSTER_TEMPLATE, size) def create_sf_line_type(self, size=1): &quot;&quot;&quot;批量添加线路&quot;&quot;&quot; self._create_instance(LINE_TYPE_TEMPLATE, size) def create_sf_oracle(self, size=1): &quot;&quot;&quot;批量添加线路&quot;&quot;&quot; self._create_instance(ORACLE_TEMPLATE, size) def create_sf_sqlserver(self, size=1): &quot;&quot;&quot;批量添加线路&quot;&quot;&quot; self._create_instance(SQLSERVER_TEMPLATE, size) def delete_all(self): &quot;&quot;&quot;清理所有mock出来的数据&quot;&quot;&quot; for inst_type in INST_TYPE_SET: func_name = &#x27;delete_&#123;type&#125;&#x27;.format(type=inst_type) if getattr(self, func_name, None) is not None: getattr(self, func_name)() def delete_plat(self): &quot;&quot;&quot;批量添加数据中心&quot;&quot;&quot; condition = &#123; &#x27;bk_cloud_name&#x27;: &#123; &#x27;$regex&#x27;: &#x27;^&#123;prefix&#125;&#x27;.format( prefix=MOCK_NAME_PREFIX)&#125;&#125; self.mongo_db[&#x27;cc_PlatBase&#x27;].delete_many(condition) def _delete_host(self, inst_type): &quot;&quot;&quot;批量删除实例&quot;&quot;&quot; type_map = &#123; &quot;sf_server&quot;: &quot;2&quot;, &quot;host&quot;: &quot;1&quot; &#125; condition = &#123; &#x27;bk_host_type&#x27;: type_map[inst_type], &#x27;bk_host_name&#x27;: &#123; &#x27;$regex&#x27;: &#x27;^&#123;prefix&#125;&#x27;.format(prefix=MOCK_NAME_PREFIX) &#125; &#125; self.mongo_db[&#x27;cc_ObjectBase&#x27;].delete_many(condition) def delete_sf_server(self): &quot;&quot;&quot;批量删除机房&quot;&quot;&quot; self._delete_instance(&#x27;sf_server&#x27;) def delete_host(self): &quot;&quot;&quot;批量删除机房&quot;&quot;&quot; self._delete_instance(&#x27;host&#x27;) def _delete_instance(self, inst_type): &quot;&quot;&quot;批量删除实例&quot;&quot;&quot; condition = &#123; &#x27;bk_obj_id&#x27;: inst_type, &#x27;bk_inst_name&#x27;: &#123; &#x27;$regex&#x27;: &#x27;^&#123;prefix&#125;&#x27;.format(prefix=MOCK_NAME_PREFIX) &#125; &#125; self.mongo_db[&#x27;cc_ObjectBase&#x27;].delete_many(condition) def delete_sf_room(self): &quot;&quot;&quot;批量删除机房&quot;&quot;&quot; self._delete_instance(&#x27;sf_room&#x27;) def delete_sf_rack(self): &quot;&quot;&quot;批量删除机架&quot;&quot;&quot; self._delete_instance(&#x27;sf_rack&#x27;) def delete_sf_switch(self): &quot;&quot;&quot;批量删除交换机&quot;&quot;&quot; self._delete_instance(&#x27;sf_switch&#x27;) def delete_sf_az(self): &quot;&quot;&quot;批量删除机房&quot;&quot;&quot; self._delete_instance(&#x27;sf_az&#x27;) def delete_cluster(self): &quot;&quot;&quot;批量删除机架&quot;&quot;&quot; self._delete_instance(&#x27;sf_cluster&#x27;) def delete_sf_line_type(self): &quot;&quot;&quot;批量删除交换机&quot;&quot;&quot; self._delete_instance(&#x27;sf_line_type&#x27;) def delete_sf_oracle(self): &quot;&quot;&quot;批量删除交换机&quot;&quot;&quot; self._delete_instance(&#x27;sf_oracle&#x27;) def delete_sf_sqlserver(self): &quot;&quot;&quot;批量删除交换机&quot;&quot;&quot; self._delete_instance(&#x27;sf_sql_server&#x27;)def mock_cmdb_data(action, inst_type, size): cmdb_manager = CmdbManager() func_name = &#x27;&#123;action&#125;_&#123;type&#125;&#x27;.format(action=action, type=inst_type) func_inst = getattr(cmdb_manager, func_name) if action == &#x27;create&#x27;: func_inst(size) elif action == &#x27;delete&#x27;: func_inst()# =============================================================================# 数据模板# =============================================================================PLAT_TEMPLATE = &#123; &quot;bk_project_id&quot;: &quot;9119535f9c544115bc9fba43ed24734f&quot;, &quot;create_time&quot;: &quot;2021-10-26T09:37:51.734Z&quot;, &quot;bk_business_contact&quot;: &quot;dalin2&quot;, &quot;bk_duty_officer&quot;: &quot;dalin1&quot;, &quot;bk_location&quot;: &quot;&quot;, &quot;bk_supplier_account&quot;: &quot;0&quot;, &quot;creator&quot;: &quot;e901f2c93c34465181353921cab3ef7e&quot;, &quot;bk_duty_phone&quot;: &quot;13444444444&quot;, &quot;bk_open_time&quot;: &quot;2021-05-28 00:00:00&quot;, &quot;bk_region_name&quot;: &quot;&quot;, &quot;bk_region_maintainer&quot;: None, &quot;bk_business_contact_phone&quot;: &quot;13444444444&quot;, &quot;bk_comment&quot;: &quot;mark&quot;, &quot;last_time&quot;: &quot;2021-10-26T09:37:51.734Z&quot;, &quot;modifier&quot;: &quot;e901f2c93c34465181353921cab3ef7e&quot;&#125;ROOM_TEMPLATE = &#123; &quot;bk_column&quot;: 10, &quot;bk_row&quot;: 10, &quot;bk_supplier_account&quot;: &quot;0&quot;, &quot;bk_cloud_id&quot;: 0, &quot;region_id&quot;: &quot;&quot;, &quot;create_time&quot;: &quot;2021-10-14T01:11:08.087Z&quot;, &quot;modifier&quot;: &quot;e901f2c93c34465181353921cab3ef7e&quot;, &quot;creator&quot;: &quot;e901f2c93c34465181353921cab3ef7e&quot;, &quot;bk_obj_id&quot;: &quot;sf_room&quot;, &quot;bk_project_id&quot;: &quot;9119535f9c544115bc9fba43ed24734f&quot;, &quot;bk_serial_num&quot;: &quot;1&quot;, &quot;bk_floor&quot;: 1, &quot;last_time&quot;: &quot;2021-11-05T02:27:04.918Z&quot;, &quot;bk_comment&quot;: &quot;&quot;&#125;RACK_TEMPLATE = &#123; &quot;bk_open_time&quot;: &quot;2021-10-28 00:00:00&quot;, &quot;bk_project_id&quot;: &quot;9119535f9c544115bc9fba43ed24734f&quot;, &quot;bk_serial_num&quot;: &quot;1&quot;, &quot;bk_u_position&quot;: 1, &quot;modifier&quot;: &quot;e901f2c93c34465181353921cab3ef7e&quot;, &quot;creator&quot;: &quot;e901f2c93c34465181353921cab3ef7e&quot;, &quot;bk_obj_id&quot;: &quot;sf_rack&quot;, &quot;bk_supplier_account&quot;: &quot;0&quot;, &quot;bk_comment&quot;: &quot;zxcz123123&quot;, &quot;region_id&quot;: &quot;&quot;, &quot;last_time&quot;: &quot;2021-11-05T02:27:04.918Z&quot;, &quot;bk_column&quot;: 10, &quot;create_time&quot;: &quot;2021-10-28T03:50:57.452Z&quot;, &quot;bk_cloud_id&quot;: 584346202, &quot;bk_row&quot;: 10, &quot;bk_electric_limit&quot;: 4, &quot;bk_close_time&quot;: &quot;2021-10-29 00:00:00&quot;,&#125;SWITCH_TEMPLATE = &#123; &quot;bk_obj_id&quot;: &quot;sf_switch&quot;, &quot;bk_device_runtime&quot;: 464400, &quot;bk_device_web_version&quot;: &quot;&quot;, &quot;bk_asset_num&quot;: &quot;2&quot;, &quot;bk_used_by&quot;: &quot;&quot;, &quot;bk_u_position&quot;: 12, &quot;bk_project_id&quot;: &quot;&quot;, &quot;bk_uuid&quot;: &quot;192.200.112.253&quot;, &quot;create_time&quot;: &quot;2021-08-31T01:46:21.300Z&quot;, &quot;bk_device_mac&quot;: &quot;&quot;, &quot;bk_supplier_account&quot;: &quot;0&quot;, &quot;bk_device_type&quot;: &quot;0&quot;, &quot;bk_u_position_num&quot;: 2, &quot;bk_password&quot;: &quot;&quot;, &quot;bk_comment&quot;: &quot;123&quot;, &quot;region_id&quot;: &quot;&quot;, &quot;modifier&quot;: &quot;e901f2c93c34465181353921cab3ef7e&quot;, &quot;creator&quot;: &quot;cc_collector&quot;, &quot;bk_device_master&quot;: &quot;physics&quot;, &quot;bk_device_model&quot;: &quot;aSW1100&quot;, &quot;bk_device_status&quot;: &quot;0&quot;, &quot;bk_agreement&quot;: &quot;&quot;, &quot;bk_cloud_id&quot;: 0, &quot;user_id&quot;: &quot;&quot;, &quot;last_time&quot;: &quot;2021-11-09T06:38:34.761Z&quot;, &quot;bk_device_brand&quot;: &quot;2&quot;, &quot;bk_device_os_soft_version&quot;: &quot;11&quot;, &quot;bk_account&quot;: &quot;&quot;, &quot;bk_device_patch&quot;: &quot;&quot;, &quot;bk_put_on_time&quot;: &quot;2021-11-01&quot;, &quot;bk_device_serial_num&quot;: &quot;222222&quot;, &quot;bk_device_stack&quot;: &quot;&quot;, &quot;bk_device_cascade&quot;: &quot;&quot;, &quot;bk_device_ip&quot;: &quot;192.200.112.253&quot;, &quot;bk_device_start_time&quot;: 1633651200, &quot;bk_device_fan_status&quot;: &quot;0&quot;&#125;AZ_TEMPLATE = &#123; &quot;creator&quot;: &quot;cc_cloudsync&quot;, &quot;bk_scp_id&quot;: None, &quot;bk_type&quot;: &quot;1&quot;, &quot;bk_uuid&quot;: &quot;515881e1-1825-400e-861e-93ce4ef59ae2&quot;, &quot;bk_supplier_account&quot;: &quot;0&quot;, &quot;last_time&quot;: &quot;2021-11-04T07:52:32.363Z&quot;, &quot;bk_cloud_id&quot;: 0, &quot;bk_total_mem&quot;: 0, &quot;bk_obj_id&quot;: &quot;sf_az&quot;, &quot;modifier&quot;: &quot;cc_collector&quot;, &quot;region_id&quot;: &quot;dffff2398540418cab1575d480bea8a4&quot;, &quot;create_time&quot;: &quot;2021-10-26T13:01:17.665Z&quot;, &quot;bk_total_core&quot;: 10, &quot;bk_comment&quot;: &quot;&quot;&#125;CLUSTER_TEMPLATE = &#123; &quot;bk_az_id&quot;: &quot;8af74a76-f822-4bb3-b512-8ebd34c6c23b&quot;, &quot;bk_uuid&quot;: &quot;04a2b635-feb8-4a8a-8624-272df2f785a7&quot;, &quot;version&quot;: &quot;6.2.0&quot;, &quot;create_time&quot;: &quot;2021-10-26T13:01:15.885Z&quot;, &quot;last_time&quot;: &quot;2021-11-04T07:42:02.784Z&quot;, &quot;bk_scp_id&quot;: None, &quot;type&quot;: &quot;1&quot;, &quot;user_id&quot;: &quot;&quot;, &quot;bk_comment&quot;: &quot;&quot;, &quot;modifier&quot;: &quot;cc_collector&quot;, &quot;bk_cloud_id&quot;: 0, &quot;region_id&quot;: &quot;dffff2398540418cab1575d480bea8a4&quot;, &quot;status&quot;: &quot;3&quot;, &quot;bk_supplier_account&quot;: &quot;0&quot;, &quot;pwd&quot;: &quot;&quot;, &quot;project_id&quot;: &quot;&quot;, &quot;bk_obj_id&quot;: &quot;cluster&quot;, &quot;import_from&quot;: &quot;0&quot;, &quot;ip&quot;: &quot;10.134.82.35&quot;, &quot;port&quot;: 443, &quot;username&quot;: &quot;&quot;, &quot;creator&quot;: &quot;cc_cloudsync&quot;&#125;# 服务器模板SERVER_TEMPLATE = &#123; &quot;bk_raid&quot;: &quot;&quot;, &quot;hugepage&quot;: False, &quot;last_time&quot;: &quot;2022-01-13T03:57:29.571Z&quot;, &quot;bk_cloud_id&quot;:0, &quot;bk_sla&quot;: None, &quot;bk_disk&quot;: None, &quot;bk_slot_num&quot;: None, &quot;bk_mem&quot;: None, &quot;bk_mem_max_size&quot;: None, &quot;invtsc&quot;: False, &quot;bk_host_type&quot;: &quot;2&quot;, &quot;bk_u_position&quot;: None, &quot;bk_outer_mac&quot;: &quot;&quot;, &quot;bk_mem_used_num&quot;: None, &quot;creator&quot;: &quot;cc_cloudsync&quot;, &quot;bk_cpu&quot;: 16, &quot;operator&quot;: [], &quot;bk_bak_operator&quot;: [], &quot;bk_province_name&quot;: None, &quot;bk_model_number&quot;: &quot;&quot;, &quot;bk_idle_percent&quot;: None, &quot;disk_preallocate_full&quot;: False, &quot;bk_project_id&quot;: &quot;&quot;, &quot;bk_runtime&quot;: None, &quot;bk_scp_uuid&quot;: &quot;&quot;, &quot;cmdline&quot;: &quot;&quot;, &quot;bk_sn&quot;: &quot;&quot;, &quot;bk_asset_belong&quot;: None, &quot;bk_cpu_physical_cores&quot;: None, &quot;bk_last_monitor_time&quot;: None, &quot;bk_mem_info&quot;: None, &quot;disk_cache_real_direct_sync&quot;: False, &quot;vmnics_attribute&quot;: &quot;&quot;, &quot;bk_mem_num&quot;: None, &quot;bk_cpu_over_commit&quot;: None, &quot;pid&quot;: &quot;&quot;, &quot;bk_host_id&quot;: 584368814, &quot;bk_host_name&quot;: &quot;10.134.91.66&quot;, &quot;bk_os_version&quot;: &quot;&quot;, &quot;bk_device_type&quot;: None, &quot;bk_brand&quot;: None, &quot;bk_collect_status&quot;: &quot;2&quot;, &quot;bk_host_turbo&quot;: False, &quot;disk_preallocate_metadata&quot;: False, &quot;bk_uuid&quot;: &quot;host-0cc47a6c5bea&quot;, &quot;disk_vs&quot;: False, &quot;net0_info&quot;: &quot;&quot;, &quot;mtu&quot;: None, &quot;bk_az_id&quot;: &quot;35ab7223-93d9-47d2-b26e-616c1107945b&quot;, &quot;bk_host_outerip&quot;: [], &quot;docker_server_version&quot;: &quot;&quot;, &quot;bk_server_id&quot;: &quot;&quot;, &quot;bk_u_position_num&quot;: 1, &quot;bk_snmp_port&quot;: &quot;&quot;, &quot;bk_asset_num&quot;: &quot;&quot;, &quot;schedopt&quot;: False, &quot;bk_rated_power&quot;: &quot;&quot;, &quot;bk_scp_id&quot;: 584368694, &quot;bk_os_type&quot;: None, &quot;bk_idle_evidence&quot;: &quot;&quot;, &quot;host_cpu&quot;: False, &quot;bk_host_status&quot;: &quot;running&quot;, &quot;bk_service_term&quot;: None, &quot;bk_hci_id&quot;: None, &quot;modifier&quot;: &quot;cc_collector&quot;, &quot;docker_client_version&quot;: &quot;&quot;, &quot;bk_bios_version&quot;: &quot;&quot;, &quot;bk_az_name&quot;: &quot;10.134.90.63&quot;, &quot;bk_host_innerip&quot;: [ &quot;10.134.91.66&quot; ], &quot;bk_asset_id&quot;: &quot;&quot;, &quot;bk_os_name&quot;: &quot;&quot;, &quot;bk_cpu_module&quot;: &quot;&quot;, &quot;bk_raid_info&quot;: &quot;&quot;, &quot;bk_mem_card&quot;: False, &quot;disk_cdrom&quot;: False, &quot;bk_cpu_mhz&quot;: None, &quot;bk_business_module&quot;: &quot;&quot;, &quot;bk_server_type&quot;: &quot;1&quot;, &quot;bk_mem_over_commit&quot;: None, &quot;bk_server_status&quot;: None, &quot;bk_serial_num&quot;: &quot;&quot;, &quot;region_id&quot;: &quot;3f8da76540a34ea0a02dcb9f7ee7dce8&quot;, &quot;bk_mac&quot;: &quot;&quot;, &quot;bk_nic_type&quot;: &quot;&quot;, &quot;bk_idle_status&quot;: &quot;0&quot;, &quot;using_hugepage&quot;: False, &quot;bk_network_type&quot;: &quot;1&quot;, &quot;bk_state_name&quot;: None, &quot;create_time&quot;: &quot;2021-12-29T02:07:25.663Z&quot;, &quot;bk_disk_info&quot;: &quot;&quot;, &quot;bk_comment&quot;: &quot;&quot;, &quot;bk_vtool_installed&quot;: None, &quot;numa&quot;: False, &quot;bk_bmc_ip&quot;: &quot;&quot;, &quot;bk_put_on_time&quot;: &quot;&quot;, &quot;hci_dp_info&quot;: &quot;&quot;, &quot;cpu_microcode&quot;: &quot;&quot;, &quot;bk_boot_time&quot;: None, &quot;bk_hyper_threading&quot;: False, &quot;bk_cpu_num&quot;: 2, &quot;bk_os_bit&quot;: &quot;&quot;, &quot;bk_single_power&quot;: False, &quot;bk_server_name&quot;: &quot;&quot;, &quot;bk_project_name&quot;: &quot;&quot;, &quot;bk_isp_name&quot;: None, &quot;bk_vhost_type&quot;: &quot;1&quot;, &quot;import_from&quot;: &quot;2&quot;, &quot;bk_supplier_account&quot;: &quot;0&quot;, &quot;bk_state&quot;: None&#125;# 云主机模板HOST_TEMPLATE = &#123; &quot;bk_raid&quot;: &quot;&quot;, &quot;hugepage&quot;: False, &quot;last_time&quot;: &quot;2022-01-13T03:57:29.571Z&quot;, &quot;bk_cloud_id&quot;: 0, &quot;bk_sla&quot;: None, &quot;bk_disk&quot;: None, &quot;bk_slot_num&quot;: None, &quot;bk_mem&quot;: None, &quot;bk_mem_max_size&quot;: None, &quot;invtsc&quot;: False, &quot;bk_host_type&quot;: &quot;2&quot;, &quot;bk_u_position&quot;: None, &quot;bk_outer_mac&quot;: &quot;&quot;, &quot;bk_mem_used_num&quot;: None, &quot;creator&quot;: &quot;cc_cloudsync&quot;, &quot;bk_cpu&quot;: 16, &quot;operator&quot;: [], &quot;bk_bak_operator&quot;: [], &quot;bk_province_name&quot;: None, &quot;bk_model_number&quot;: &quot;&quot;, &quot;bk_idle_percent&quot;: None, &quot;disk_preallocate_full&quot;: False, &quot;bk_project_id&quot;: &quot;&quot;, &quot;bk_runtime&quot;: None, &quot;bk_scp_uuid&quot;: &quot;&quot;, &quot;cmdline&quot;: &quot;&quot;, &quot;bk_sn&quot;: &quot;&quot;, &quot;bk_asset_belong&quot;: None, &quot;bk_cpu_physical_cores&quot;: None, &quot;bk_last_monitor_time&quot;: None, &quot;bk_mem_info&quot;: None, &quot;disk_cache_real_direct_sync&quot;: False, &quot;vmnics_attribute&quot;: &quot;&quot;, &quot;bk_mem_num&quot;: None, &quot;bk_cpu_over_commit&quot;: None, &quot;pid&quot;: &quot;&quot;, &quot;bk_host_id&quot;: 584368814, &quot;bk_host_name&quot;: &quot;10.134.91.66&quot;, &quot;bk_os_version&quot;: &quot;&quot;, &quot;bk_device_type&quot;: None, &quot;bk_brand&quot;: None, &quot;bk_collect_status&quot;: &quot;2&quot;, &quot;bk_host_turbo&quot;: False, &quot;disk_preallocate_metadata&quot;: False, &quot;bk_uuid&quot;: &quot;host-0cc47a6c5bea&quot;, &quot;disk_vs&quot;: False, &quot;net0_info&quot;: &quot;&quot;, &quot;mtu&quot;: None, &quot;bk_az_id&quot;: &quot;35ab7223-93d9-47d2-b26e-616c1107945b&quot;, &quot;bk_host_outerip&quot;: [], &quot;docker_server_version&quot;: &quot;&quot;, &quot;bk_server_id&quot;: &quot;&quot;, &quot;bk_u_position_num&quot;: 1, &quot;bk_snmp_port&quot;: &quot;&quot;, &quot;bk_asset_num&quot;: &quot;&quot;, &quot;schedopt&quot;: False, &quot;bk_rated_power&quot;: &quot;&quot;, &quot;bk_scp_id&quot;: 584368694, &quot;bk_os_type&quot;: None, &quot;bk_idle_evidence&quot;: &quot;&quot;, &quot;host_cpu&quot;: False, &quot;bk_host_status&quot;: &quot;running&quot;, &quot;bk_service_term&quot;: None, &quot;bk_hci_id&quot;: None, &quot;modifier&quot;: &quot;cc_collector&quot;, &quot;docker_client_version&quot;: &quot;&quot;, &quot;bk_bios_version&quot;: &quot;&quot;, &quot;bk_az_name&quot;: &quot;10.134.90.63&quot;, &quot;bk_host_innerip&quot;: [ &quot;10.134.91.66&quot; ], &quot;bk_asset_id&quot;: &quot;&quot;, &quot;bk_os_name&quot;: &quot;&quot;, &quot;bk_cpu_module&quot;: &quot;&quot;, &quot;bk_raid_info&quot;: &quot;&quot;, &quot;bk_mem_card&quot;: False, &quot;disk_cdrom&quot;: False, &quot;bk_cpu_mhz&quot;: None, &quot;bk_business_module&quot;: &quot;&quot;, &quot;bk_server_type&quot;: &quot;1&quot;, &quot;bk_mem_over_commit&quot;: None, &quot;bk_server_status&quot;: None, &quot;bk_serial_num&quot;: &quot;&quot;, &quot;region_id&quot;: &quot;3f8da76540a34ea0a02dcb9f7ee7dce8&quot;, &quot;bk_mac&quot;: &quot;&quot;, &quot;bk_nic_type&quot;: &quot;&quot;, &quot;bk_idle_status&quot;: &quot;0&quot;, &quot;using_hugepage&quot;: False, &quot;bk_network_type&quot;: &quot;1&quot;, &quot;bk_state_name&quot;: None, &quot;create_time&quot;: &quot;2021-12-29T02:07:25.663Z&quot;, &quot;bk_disk_info&quot;: &quot;&quot;, &quot;bk_comment&quot;: &quot;&quot;, &quot;bk_vtool_installed&quot;: None, &quot;numa&quot;: False, &quot;bk_bmc_ip&quot;: &quot;&quot;, &quot;bk_put_on_time&quot;: &quot;&quot;, &quot;hci_dp_info&quot;: &quot;&quot;, &quot;cpu_microcode&quot;: &quot;&quot;, &quot;bk_boot_time&quot;: None, &quot;bk_hyper_threading&quot;: False, &quot;bk_cpu_num&quot;: 2, &quot;bk_os_bit&quot;: &quot;&quot;, &quot;bk_single_power&quot;: False, &quot;bk_server_name&quot;: &quot;&quot;, &quot;bk_project_name&quot;: &quot;&quot;, &quot;bk_isp_name&quot;: None, &quot;bk_vhost_type&quot;: &quot;1&quot;, &quot;import_from&quot;: &quot;2&quot;, &quot;bk_supplier_account&quot;: &quot;0&quot;, &quot;bk_state&quot;: None&#125;# 线路模板LINE_TYPE_TEMPLATE = &#123; &quot;region_id&quot;: &quot;&quot;, &quot;bk_bandwidth&quot;: 1000, &quot;last_time&quot;: &quot;2021-11-09T04:50:08.426Z&quot;, &quot;bk_ip_sections&quot;: &quot;[&#123;\\&quot;port_ids\\&quot;: [584345359], \\&quot;cidr\\&quot;: \\&quot;10.134.88.1/24\\&quot;, \\&quot;switch_ids\\&quot;: [584345369]&#125;]&quot;, &quot;bk_ip_total&quot;: 256, &quot;bk_supplier_account&quot;: &quot;0&quot;, &quot;user_id&quot;: &quot;&quot;, &quot;modifier&quot;: &quot;e901f2c93c34465181353921cab3ef7e&quot;, &quot;bk_obj_id&quot;: &quot;sf_line_type&quot;, &quot;bk_cloud_id&quot;: 0, &quot;bk_comment&quot;: &quot;111&quot;, &quot;create_time&quot;: &quot;2021-11-01T03:03:10.280Z&quot;, &quot;creator&quot;: &quot;e901f2c93c34465181353921cab3ef7e&quot;&#125;# oracle服务ORACLE_TEMPLATE = &#123; &quot;create_time&quot;: &quot;2021-12-10T10:07:11.806Z&quot;, &quot;last_time&quot;: &quot;2021-12-10T10:07:11.806Z&quot;, &quot;bk_cluster_hosts&quot;: &quot;5.096611959E+09&quot;, &quot;bk_cluster_ip&quot;: None, &quot;bk_run_host_uuid&quot;: &quot;7979718770500&quot;, &quot;bk_obj_id&quot;: &quot;sf_oracle&quot;, &quot;bk_supplier_account&quot;: &quot;0&quot;, &quot;modifier&quot;: &quot;cc_collector&quot;, &quot;bk_inst_name&quot;: &quot;oracle-127.0.0.1:1433&quot;, &quot;creator&quot;: &quot;cc_collector&quot;&#125;# sqlserver服务SQLSERVER_TEMPLATE = &#123; &quot;create_time&quot;: &quot;2021-12-10T10:07:11.806Z&quot;, &quot;last_time&quot;: &quot;2021-12-10T10:07:11.806Z&quot;, &quot;bk_cluster_hosts&quot;: &quot;5.096611959E+09&quot;, &quot;bk_cluster_ip&quot;: None, &quot;bk_run_host_uuid&quot;: &quot;7979718770500&quot;, &quot;bk_obj_id&quot;: &quot;sf_sqlserver&quot;, &quot;bk_supplier_account&quot;: &quot;0&quot;, &quot;modifier&quot;: &quot;cc_collector&quot;, &quot;bk_inst_name&quot;: &quot;sqlserver-127.0.0.1:1433&quot;, &quot;creator&quot;: &quot;cc_collector&quot;&#125;TEMPLATE_SET = [ PLAT_TEMPLATE, ROOM_TEMPLATE, RACK_TEMPLATE, SWITCH_TEMPLATE, AZ_TEMPLATE, CLUSTER_TEMPLATE, SERVER_TEMPLATE, HOST_TEMPLATE, LINE_TYPE_TEMPLATE, ORACLE_TEMPLATE, SQLSERVER_TEMPLATE,]INST_TYPE_SET = [ &#x27;plat&#x27;, &#x27;sf_room&#x27;, &#x27;sf_rack&#x27;, &#x27;sf_switch&#x27;, &#x27;sf_az&#x27;, &#x27;cluster&#x27;, &#x27;sf_server&#x27;, &#x27;host&#x27;, &#x27;sf_line_type&#x27;, &#x27;sf_oracle&#x27;, &#x27;sf_sqlserver&#x27;]# =============================================================================# 工具方法# =============================================================================def rand_uuid(): &quot;&quot;&quot;Generate a random UUID string :return: a random UUID (e.g. &#x27;1dc12c7d-60eb-4b61-a7a2-17cf210155b6&#x27;) :rtype: string &quot;&quot;&quot; return uuidutils.generate_uuid()def rand_uuid_hex(): &quot;&quot;&quot;Generate a random UUID hex string :return: a random UUID (e.g. &#x27;0b98cf96d90447bda4b46f31aeb1508c&#x27;) :rtype: string &quot;&quot;&quot; return uuid.uuid4().hexdef rand_name(name=&#x27;&#x27;, prefix=&#x27;unit&#x27;): &quot;&quot;&quot;Generate a random name that includes a random number :param str name: The name that you want to include :param str prefix: The prefix that you want to include :return: a random name. The format is &#x27;&lt;prefix&gt;-&lt;name&gt;-&lt;random number&gt;&#x27;. (e.g. &#x27;prefixfoo-namebar-154876201&#x27;) :rtype: string &quot;&quot;&quot; rand_name = str(random.randint(1, 0x7fffffff)) if name: rand_name = name + &#x27;-&#x27; + rand_name if prefix: rand_name = prefix + &#x27;-&#x27; + rand_name return rand_namedef rand_int_id(start=0, end=0x7fffffff): &quot;&quot;&quot;Generate a random integer value :param int start: The value that you expect to start here :param int end: The value that you expect to end here :return: a random integer value :rtype: int &quot;&quot;&quot; return random.randint(start, end)if __name__ == &#x27;__main__&#x27;: parser = argparse.ArgumentParser( prog=&#x27;cmdb_mock&#x27;, description=&#x27;mock tool for cmdb&#x27;, formatter_class=argparse.ArgumentDefaultsHelpFormatter) parser.add_argument(&#x27;-action&#x27;, required=True, dest=&#x27;action&#x27;, type=str, help=u&#x27;[create, delete]&#x27;) parser.add_argument( &#x27;-type&#x27;, required=True, dest=&#x27;inst_type&#x27;, type=str, help=u&#x27;[all, plat, sf_room, sf_rack, sf_switch, sf_az, cluster, sf_line_type]&#x27;, choices=INST_TYPE_SET) parser.add_argument(&#x27;-size&#x27;, dest=&#x27;size&#x27;, type=int, default=10, help=u&#x27;number of resource mock&#x27;) args = parser.parse_args() ACTION = args.action INST_TYPE = args.inst_type SIZE = args.size mock_cmdb_data(ACTION, INST_TYPE, SIZE)","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"技术开发/python","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/"},{"name":"Script","slug":"技术开发/python/Script","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/Script/"}],"tags":[{"name":"cmdb_mock","slug":"cmdb-mock","permalink":"https://tianxiafeiyu.github.io/tags/cmdb-mock/"}]},{"title":"push_cmdb_data","slug":"技术开发/python/Script/push_cmdb_data","date":"2022-12-15T23:22:29.000Z","updated":"2022-12-16T21:37:31.000Z","comments":true,"path":"2022/12/15/技术开发/python/Script/push_cmdb_data/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/Script/push_cmdb_data/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220#!/usr/bin/python# -*- coding: utf-8 -*-import osimport jsonimport loggingimport requestsimport signalimport threadingimport timeu&quot;&quot;&quot;向环境上的所有服务器推送cmdb采集数据&quot;&quot;&quot;LOG_FORMAT = &quot;%(asctime)s - %(levelname)s - %(message)s&quot;logging.basicConfig(filename=&#x27;push.log&#x27;, level=logging.DEBUG, format=LOG_FORMAT)# scc ipSCC_HOST = &#x27;10.134.47.25&#x27;TRANSFER_GATEWAY_HOST = &#x27;10.134.47.25&#x27;# 页面登录用户名USERNAME = &#x27;admin&#x27;# 加密后的密码PWD = &#x27;6707361739e5ca18002bcb05d464d033da1a499ed5fdf660fadd35e250f518f97da0fa884b079b6193f93ed68040e91ea86be547b7a82d0cf3245c01ca2bb20fd7bbadb937103898b00e47c605226fbaeb13a0348762e8dede31d5b570dc07d4c8e7b5308d531158c672d94204c73a972585ef816c87aaadc2778b40d96c24c45d82b2e6da58aded4bdd30b57a2f49b5e08dc189776ee53c92926be0ee3e25512558ccca953b603fcb9153c94a579c257d0e813d94f2c056f0b129fcbcabab4b54cfc2879112b0e201663cc05a47a3571e9352b693210fb93e72e658625d7fa7dd5326f2ce062f85ecea4d25d9e0af2544b3df95fae839f65672b63c51c51a12&#x27; # noqaX_WWW_FORM_HEADER = &#123; &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded; charset=UTF-8&#x27;, &#x27;Connection&#x27;: &#x27;close&#x27;&#125;class Client(object): u&quot;&quot;&quot;request库封装&quot;&quot;&quot; def __init__(self, host, username, pwd): self.client = requests.Session() self.auth = Auth(host, username, pwd) self.client.headers = self.auth.get_header() def post(self, url, **kwargs): return self.client.post(url, **kwargs) def get(self, url, **kwargs): return self.client.get(url, **kwargs) def delete(self, url, **kwargs): return self.client.delete(url, **kwargs) def put(self, url, **kwargs): return self.client.put(url, **kwargs)class Auth(object): u&quot;&quot;&quot;获取cookie和token&quot;&quot;&quot; def __init__(self, host, username, pwd, status=&#x27;agree&#x27;): self.host = host self.ticket_url = &#x27;https://%s:4430/ticket&#x27; % host self.username = username self.pwd = pwd self.status = status self.client = None def get_tokens(self, response): # noqa &quot;&quot;&quot; &#123; &quot;success&quot;: 1, &quot;data&quot;: &#123; &quot;username&quot;: &quot;admin&quot;, &quot;client_ip&quot;: &quot;172.23.13.106&quot;, &quot;CSRFPreventionToken&quot;: &quot;4984b0511212d1b2534b7888c9fcdcad&quot;, &quot;weak_password&quot;: 1, &quot;days&quot;: 18, &quot;passwd_is_expired&quot;: 0, &quot;passwd_remain_days&quot;: 0 &#125; &#125; :param response: :return: &quot;&quot;&quot; json_response = json.loads(response.text) csrf_prevention_token = json_response[&#x27;data&#x27;][&quot;CSRFPreventionToken&quot;] acmp_auth_token = list( list(list(response.cookies._cookies.values())[0].values())[0].values() # noqa )[0].value logging.debug(&quot;csrf_prevention_token: %s, acmp_auth_token: %s&quot; % ( csrf_prevention_token, acmp_auth_token)) return csrf_prevention_token, acmp_auth_token def post_urlencoded_data(self, request_url): &quot;&quot;&quot;获取ticket 功能说明：发送以form表单数据格式（它要求数据名称（name）和数据值（value）之间以等号相连， 与另一组name/value值之间用&amp;相连。例如：parameter1=12345&amp;parameter2=23456。） 请求到远程服务器，并获取请求响应报文。 该请求消息头要求为：&#123;&quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded; charset=UTF-8&quot;&#125;。 # noqa 输入参数说明：接收请求的URL;请求报文数据，格式为name1=value1&amp;name2=value2 输出参数：请求响应报文 :param request_url: :return: &quot;&quot;&quot; logging.debug(request_url) request_json_data = &#x27;username=%s&amp;password=%s&amp;status=%s&#x27; % ( self.username, self.pwd, self.status) request_json_data = str(request_json_data).replace(&#x27;+&#x27;, &#x27;%2B&#x27;) request_data = request_json_data.encode(&#x27;utf-8&#x27;) r = requests.post(request_url, data=request_data, headers=X_WWW_FORM_HEADER, verify=False) response_data = r.text logging.info(&#x27;response_data:\\n %s&#x27; % response_data) return self.get_tokens(r) def get_header(self): # 1.按照配置的IP和admin账号密码请求ticket接口 csrf, auth_token = self.post_urlencoded_data(self.ticket_url) # 2.构造API接口请求所需要的请求头 cookie = &#x27;UEDC_LOGIN_POLICY_VALUE=checked; aCMPAuthToken=%s; &#x27; \\ &#x27;login=local; jump_back=&#x27; % auth_token header = &#123; &#x27;CSRFPreventionToken&#x27;: csrf, &#x27;Content-Type&#x27;: &#x27;application/json;charset=UTF-8&#x27;, &#x27;Cookie&#x27;: cookie &#125; return headerclient = Client(SCC_HOST, USERNAME, PWD)def get_server_endpoints(): url = &#x27;https://%s:4430/aops/admin/view/server-list&#x27; % SCC_HOST res = client.get(url, verify=False) servers = res.json()[&#x27;data&#x27;] # 脚本插数据时 import_from=1，避免和同步过来的数据搞混 uuids = [server[&#x27;sf_uuid&#x27;] for server in servers if server[&#x27;import_from&#x27;] == &#x27;1&#x27;] logging.info(&#x27;the num of servers: %s&#x27;, len(uuids)) return uuidsdef push_cmdb_data(endpoint, step=30): # noqa url = &#x27;http://%s:8002/api/ams-ce/hosts/report&#x27; % SCC_HOST while True: meta = &#123; &#x27;objid&#x27;: &#x27;host&#x27;, &#x27;endpoint&#x27;: endpoint, &#x27;channel&#x27;: &#x27;snapshot2&#x27;, &#x27;metric&#x27;: &#x27;&#x27;, &#x27;data&#x27;: &#123; &#x27;model&#x27;: &#123; &#x27;bk_bios_version&#x27;: &#x27;BOCHS - 1&#x27;, &#x27;bk_boot_time&#x27;: &#x27;2021-07-15 11:47:39&#x27;, &#x27;bk_cpu&#x27;: 2, &#x27;bk_cpu_mhz&#x27;: 2594, &#x27;bk_cpu_module&#x27;: &#x27;Intel(R) Core(TM)2 Duo CPU T7700 @ 2.40GHz&#x27;, # noqa &#x27;bk_cpu_num&#x27;: 1, &#x27;bk_disk&#x27;: 80, &#x27;bk_host_innerip&#x27;: &#x27;10.10.10.110&#x27;, &#x27;bk_mac&#x27;: &#x27;fe:fc:fe:7d:9a:93&#x27;, &#x27;bk_mem&#x27;: 4096, &#x27;bk_os_bit&#x27;: &#x27;64&#x27;, &#x27;bk_os_name&#x27;: &#x27;Microsoft Windows Server 2012 R2 Standard&#x27;, &#x27;bk_os_type&#x27;: &#x27;2&#x27;, &#x27;bk_os_version&#x27;: &#x27;6.3.9600 Build 9600&#x27;, &#x27;bk_runtime&#x27;: 440, &#x27;bk_uuid&#x27;: endpoint &#125;, &#x27;snap&#x27;: &#123;&#125;, &#x27;association&#x27;: None &#125; &#125; meta = json.dumps(meta) item = [&#123; &#x27;metric&#x27;: &#x27;host.cmdb.info&#x27;, &#x27;value&#x27;: 1, &#x27;tags&#x27;: &#x27;&#x27;, &#x27;meta&#x27;: meta &#125;] data = json.dumps(item) res = requests.post(url=url, data=data, verify=False) logging.info(&#x27;%s cmdb_data: %s&#x27;, endpoint, res.status_code) time.sleep(step)def quit_(signum, frame): # noqa print &#x27;Bye&#x27; os._exit(0) # noqaif __name__ == &#x27;__main__&#x27;: endpoints = get_server_endpoints() logging.info(&#x27;endpoints: %s&#x27;, len(endpoints)) signal.signal(signal.SIGINT, quit_) signal.signal(signal.SIGTERM, quit_) threads = [] end_index = max(int(round(len(endpoints) / 100.0 * 5)), 1) for endpoint in endpoints[:end_index]: t = threading.Thread( target=push_cmdb_data, args=(endpoint,) ) t.daemon = True threads.append(t) for t in threads: t.start() while True: pass","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"技术开发/python","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/"},{"name":"Script","slug":"技术开发/python/Script","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/Script/"}],"tags":[{"name":"push_cmdb_data","slug":"push-cmdb-data","permalink":"https://tianxiafeiyu.github.io/tags/push-cmdb-data/"}]},{"title":"Golang与Java","slug":"技术开发/golang/Golang与Java","date":"2022-12-15T23:19:25.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/golang/Golang与Java/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/Golang%E4%B8%8EJava/","excerpt":"","text":"转载自 https://blog.csdn.net/pbrlovejava/article/details/108920137 一、Golang概述1.1 Golang基本介绍Go语言（或 Golang）起源于 2007 年，并在 2009 年正式对外发布。Go 是非常年轻的一门语言，它的主要目标是“兼具 Python 等动态语言的开发速度和 C&#x2F;C++ 等编译型语言的性能与安全性”。 Go语言的推出，旨在不损失应用程序性能的情况下降低代码的复杂性，具有“部署简单、并发性好、语言设计良好、执行性能好”等优势，目前国内诸多 IT 公司均已采用Go语言开发项目。 Go语言有时候被描述为“C 类似语言”，或者是“21 世纪的C语言”。Go 从C语言继承了相似的表达式语法、控制流结构、基础数据类型、调用参数传值、指针等很多思想，还有C语言一直所看中的编译后机器码的运行效率以及和现有操作系统的无缝适配。 因为Go语言没有类和继承的概念，所以它和 Java 或 C++ 看起来并不相同。但是它通过接口（interface）的概念来实现多态性。Go语言有一个清晰易懂的轻量级类型系统，在类型之间也没有层级之说。因此可以说Go语言是一门混合型的语言。 此外，很多重要的开源项目都是使用Go语言开发的，其中包括 Docker、Go-Ethereum、Thrraform 和 Kubernetes。 1.2 Golang使用场景 服务端开发（配合gin、gorm等库就能够完成高性能的后端服务） 容器开发（譬如Docker、K8s都是基于Golang开发的） 脚本开发（由于Golang自身部署简单，并且与操作系统API交互方便，所以还可替代Python作为脚本开发） 底层工具的开发（可代替C或者C++开发操作系统底层工具） 二、基本语法2.1 编码规约1. 左右花括号需要符合上下换行风格Golang是一门严格的工程语言，主要体现在编码风格及可见域规则上。在Java中，允许多种编码风格共存，譬如以下两种方法声明，对于Java来说都是允许的： 12345678public String getString(Integer num) &#123; return num.toString();&#125;public String getString(Integer num) &#123; return num.toString();&#125; 在Golang中，只允许出现一种换行风格，否则会报错，无法通过编译。 123func getString(num int) string &#123; return strconv.Itoa(num)&#125; 2. 变量声明后必须使用，不使用需要使用“_“来代替在Java中，变量可以声明了却不使用，而Golang中声明的变量必须被使用，否则需要使用_来替代掉变量名，表明该变量不会比使用到： 12345func getString(num int) string &#123; temp := num // 没有使用者，无法编译 _ := num // 正常编译 return strconv.Itoa(num)&#125; 3. 可见域规则Java对方法、变量及类的可见域规则是通过private、protected、public关键字来控制的，而Golang中控制可见域的方式只有一个，当字段首字母开头是大写时说明其是对外可见的、小写时只对包内成员可见。 123456789101112131415161718192021package entitytype Person struct &#123; Name string Age int id string&#125;type student struct &#123; detail Person&#125;func test() &#123; // 本包内可见 person := &amp;student&#123;detail: Person&#123; Name: &quot;ARong&quot;, Age: 21, id: &quot;211&quot;, &#125;&#125; fmt.Println(person)&#125; 123456789101112131415package mainimport ( &quot;fmt&quot; entity &quot;others/scope&quot;)func main() &#123; // id字段不可见 person := &amp;entity.Person&#123; Name: &quot;ARong&quot;, Age: 21, &#125; fmt.Println(person)&#125; 2.2 变量声明及初始化1. 变量声明及初始化的文法在Java中，通常声明变量及初始化的文法为： 12// Object:要声明的类型、v:变量名称、new Object()变量初始化Object v = new Object(); 而Golang使用var关键字来声明变量： 123456789101112// var：变量定义、v1:变量名称、int:变量类型var v1 intvar v2 stringvar v3 [10]int // 数组var v4 []int // 数组切片var v5 struct &#123; f int&#125;var v6 *int // 指针var v7 map[string]int // map，key为string类型，value为int类型var v8 func(a int) intvar v9,v10 int //v9和v10都声明为int型 也可以采用“:&#x3D;”自动推测变量类型: 123var v1 int = 10 // 正确的使用方式1var v2 = 10 // 正确的使用方式2，编译器可以自动推导出v2的类型v3 := 10 // 正确的使用方式3，编译器可以自动推导出v3的类型 2. 对于基本类型,声明即初始化；对于引用类型，声明则初始化为nil在Java中，如果在方法内部声明一个变量但不初始化，在使用时会出现编译错误： 123456public void solve() &#123; int num; Object object; System.out.println(num); // 编译错误 System.out.println(object); // 编译错误&#125; 而在Golang中，对于基本类型来讲，声明即初始化;对于引用类型，声明则初始化为nil。这样可以极大地避免NPE的发生。 123456func main() &#123; var num int var hashMap *map[string]int fmt.Println(num) // num = 0 fmt.Println(hashMap) // &amp;hashMap== nil&#125; 2.3 值类型及引用类型Golang的类型系统与Java相差不大，但是需要注意的是Java中的数组是属于引用类型，而Golang中的数组属于值类型，当向方法中传递数组时，Java可以直接通过该传入的数组修改原数组内部值（浅拷贝），但Golang则会完全复制出一份副本来进行修改（深拷贝）： Java123456789public static void main(String[] args) &#123; int[] array = &#123;1, 2, 3&#125;; change(array); System.out.println(Arrays.toString(array)); // -1,2,3&#125;private static void change(int[] array) &#123; array[0] = -1;&#125; Golang123456789func main() &#123; array := [...]int&#123;1, 2, 3&#125; change(array) fmt.Println(array) // 1,2,3&#125;func change(array [3]int) &#123; array[0] = -1&#125; 并且值得注意的是，在Golang中，只有同长度、同类型的数组才可视为“同一类型”，譬如 [2]int 和 [3]int 则会被视为不同的类型，这在参数传递的时候会造成编译错误。 所以在Golang中数组很少被直接使用，更多的是使用切片（基于数组指针）来代替数组。 在Golang中，只有切片、指针、channel、map及func属于引用类型，也就是在传递参数的时候，实质上复制的都是他们的指针，内部的修改会直接影响到外部： 12345678910111213141516171819202122232425262728293031323334353637func main() &#123; slice := []int&#123;1, 2, 3&#125; changeSlice(slice) fmt.Println(slice) // -1,2,3 mapper := map[string]int &#123; &quot;num&quot;: 0, &#125; changeMap(mapper) fmt.Println(mapper) // num = -1 array := [...]int&#123;1, 2, 3&#125; changePointer(&amp;array) fmt.Println(array) // -1,2,3 intChan := make(chan int, 1) intChan &lt;- 1 changeChannel(intChan) fmt.Println(&lt;- intChan) // -1&#125;func changeChannel(intChan chan int) &#123; &lt;- intChan intChan &lt;- -1&#125;func changePointer(array *[3]int) &#123; array[0] = -1&#125;func changeMap(mapper map[string]int) &#123; mapper[&quot;num&quot;] = -1&#125;func changeSlice(array []int) &#123; array[0] = -1&#125; 三、结构体、函数及指针3.1 结构体声明及使用在Golang中区别与Java最显著的一点是，Golang不存在“类”这个概念，组织数据实体的结构在Golang中被称为结构体。函数可以脱离“类”而存在，函数可以依赖于结构体来调用或者依赖于包名调用。 Golang中的结构体放弃了继承、实现等多态概念，结构体之间可使用组合来达到复用方法或者字段的效果。 要声明一个结构体只需使用 type + struct 关键字即可： 12345type Person struct &#123; Name string Age int id string&#125; 要使用一个结构体也很简单，一般有以下几种方式去创建结构体： 123456789personPoint := new(entity.Person) // 通过new方法创建结构体指针person1 := entity.Person&#123;&#125; // 通过Person&#123;&#125;创建默认字段的结构体person2 := entity.Person&#123; // 通过Person&#123;Name:x,Age:x&#125;创建结构体并初始化特定字段 Name: &quot;ARong&quot;, Age: 21,&#125;fmt.Println(personPoint) // &amp;&#123; 0 &#125;fmt.Println(person1) // &#123; 0 &#125;fmt.Println(person2) // &#123;ARong 21 &#125; 3.2 函数和方法的区别使用Java的朋友应该很少使用“函数”这个词，因为对于Java来说，所有的“函数”都是基于“类”这个概念构建的，也就是只有在“类”中才会包含所谓的“函数”，这里的“函数”被称为“方法”。 而“函数”这个词源于面向过程的语言，所以在Golang中，“函数”和“方法”的最基本区别是： 函数不基于结构体而是基于包名调用，方法基于结构体调用。 下面是一个例子，可以直观地看出方法和函数的区别： entity12345678910111213141516171819package entityimport &quot;fmt&quot;type Person struct &#123; Name string Age int id string&#125;// Person结构体/指针可调用的&quot;方法&quot;，属于Person结构体func (p *Person) Solve() &#123; fmt.Println(p)&#125;// 任何地方都可调用的&quot;函数&quot;，不属于任何结构体，可通过entity.Solve调用func Solve(p *Person) &#123; fmt.Println(p)&#125; main1234567func main() &#123; personPoint := new(entity.Person) // 通过new方法创建结构体指针 entity.Solve(personPoint) // 函数调用 personPoint.Solve() // 方法调用&#125; 3.3 指针的使用在Java中不存在显式的指针操作，而Golang中存在显式的指针操作，但是Golang的指针不像C那么复杂，不能进行指针运算。 下面从一个例子来看Java的隐式指针转化和Golang的显式指针转换：Java和Golang方法传参时传递的都是值类型，在Java中如果传递了引用类型（对象、数组等）会复制其指针进行传递， 而在Golang中必须要显式传递Person的指针，不然只是传递了该对象的一个副本。 Golang使用 * 来定义和声明指针，通过&amp;来取得对象的指针。 123456789101112131415161718func main() &#123; p1 := entity.Person&#123; Name: &quot;ARong1&quot;, Age: 21, &#125; changePerson(p1) fmt.Println(p1.Name) // ARong1 changePersonByPointer(&amp;p1) fmt.Println(p1.Name) // ARong2&#125;func changePersonByPointer(person *entity.Person) &#123; person.Name = &quot;ARong2&quot;&#125;func changePerson(person entity.Person) &#123; person.Name = &quot;ARong2&quot;&#125; 注意，如果结构体中需要组合其他结构体，那么建议采用指针的方式去声明，否则会出现更新丢失问题。 以下是Golang方法的一个隐式指针转换，结构体调用方法时，如果传递的是对象，那么会被自动转化为指针调用： 1234567891011121314151617181920212223type Person struct &#123; Name string Age int&#125;// Person结构体/指针可调用的&quot;方法&quot;，属于Person结构体func (p *Person) Solve() &#123; fmt.Println(p)&#125;func main() &#123; p := entity.Person&#123; Name: &quot;ARong&quot;, Age: 21, &#125; pp := &amp;p pp.Solve() // 显式 p.Solve // 隐式，自动将p转化为&amp;p&#125; 四、面向对象4.1 与Java面向对象的区别Golang是一门具备面向对象编程风格的语言，但是却不具备Java等传统面向对象语言中“继承（extends）、实现（implements）”的关键字。 在Golang中，通过接口或结构体的组合来实现非严格的“继承”，通过非侵入式的接口来实现非严格的“多态”，通过结构体及包和函数实现了代码细节的“封装”，有了封装、继承与多态，就可以很好地通过OO思维实现与现实需求所对应的程序了。 4.2 结构体组合假设有这么一个场景：动物（Animal）具备名字（Name）、年龄（Age）的基本特性，现在需要实现一个Dog类型，且Dog类型需要具备Animal所需的所有特性，并且自身具备犬吠（bark()）的方法，使用Java和Golang来实现该场景会有什么区别呢？ 首先来看看最熟悉的Java要如何写，很简单，使用抽象类描述Animal作为所有动物的超类，Dog extends Animal： Java 12345678910111213141516171819public abstract class Animal &#123; protected String name; protected int age;&#125;public class Dog extends Animal &#123; public void bark() &#123; System.out.println(age + &quot;岁的&quot; + name + &quot;在汪汪汪...&quot;); &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; Dog dog = new Dog(); dog.name = &quot;tom&quot;; dog.age = 2; dog.bark(); // 2岁的tom在汪汪汪... &#125;&#125; 在Golang中，可以这样通过结构体的组合来实现继承： Golang 12345678910111213141516171819202122232425package oomtype Animal struct &#123; Name string Age int&#125;type Dog struct &#123; *Animal&#125;func (d *Dog) Bark() &#123; fmt.Printf(&quot;%d岁的%s在汪汪汪...&quot;, d.Age, d.Name)&#125;// ----------package mainfunc main() &#123; dog := &amp;oom.Dog&#123;&amp;oom.Animal&#123; Name: &quot;tom&quot;, Age: 2, &#125;&#125; dog.Bark() // 2岁的tom在汪汪汪...&#125; 但是这种方式实现的继承是有缺陷的，也就是不具备多态的性质，Dog属于Animal，但是Dog并不是Animal，在方法中定义了Animal参数，Dog是无法作为该参数传入的。 Golang使用了非侵入式接口来实现“多态”。 4.3 非侵入式接口Go语言的接口并不是其他语言（C++、Java、C#等）中所提供的接口概念。在Go语言出现之前，接口主要作为不同组件之间的契约存在。对契约的实现是强制的，你必须声明你的确实现了该接口。为了实现一个接口，你需要从该接口继承： 12345678910111213interface IFoo &#123; void Bar();&#125;class Foo implements IFoo &#123; // Java文法// ...&#125;class Foo : public IFoo &#123; // C++文法// ...&#125;IFoo foo = new Foo; 这类接口我们称为侵入式接口。“侵入式”的主要表现在于实现类需要明确声明自己实现了某个接口。这种强制性的接口继承是面向对象编程思想发展过程中一个遭受相当多置疑的特性。 Golang的非侵入式接口不需要通过任何关键字声明类型与接口之间的实现关系，只要一个类型实现了接口的所有方法，那么这个类型就是这个接口的实现类型。 假设现在有一个Factory接口，该接口中定义了Produce()方法及Consume()方法，CafeFactory结构体作为其实现类型，那么可以通过以下代码实现： 1234567891011121314151617181920212223242526272829303132333435363738package oomtype Factory interface &#123; Produce() bool Consume() bool&#125;type CafeFactory struct &#123; ProductName string&#125;func (c *CafeFactory) Produce() bool &#123; fmt.Printf(&quot;CafeFactory生产%s成功&quot;, c.ProductName) return true&#125;func (c *CafeFactory) Consume() bool &#123; fmt.Printf(&quot;CafeFactory消费%s成功&quot;, c.ProductName) return true&#125;// --------------package mainfunc main() &#123; factory := &amp;oom.CafeFactory&#123;&quot;Cafe&quot;&#125; doProduce(factory) doConsume(factory)&#125;func doProduce(factory oom.Factory) bool &#123; return factory.Produce()&#125;func doConsume(factory oom.Factory) bool &#123; return factory.Consume()&#125; 可以看到，只要CafeFactory实现了所有的Factory方法，那么它就是一个Factory了，而不需要使用implements关键字去显式声明它们之间的实现关系。 Golang的非侵入式接口有许多好处： 1.在Go中，类型的继承树并无意义，我们只需要知道这个类型实现了哪些方法，每个方法是啥含义就足够了 2.实现类型的时候，只需要关心自己应该提供哪些方法，不用再纠结接口需要拆得多细才合理。接口由使用方按需定义，而不用事前规划 3.不用为了实现一个接口而导入一个包，因为多引用一个外部的包，就意味着更多的耦合。接口由使用方按自身需求来定义，使用方无需关心是否有其他模块定义过类似的接口 一句话总结非侵入式接口的好处就是简单、高效、按需实现。 4.4 interface{} 空接口interface{} 空接口是任意类型的接口，所有的类型都是空接口的实现类型。因为Golang对于实现类型的要求是实现了接口的所有方法，而空接口不存在方法，所以任意类型都可以充当空接口。有点类似Java的Object。 以下是一个使用空接口充当参数的类型判断例子： 12345678910func getType(key interface&#123;&#125;) string &#123; switch key.(type) &#123; case int: return &quot;this is a integer&quot; case string: return &quot;this is a string&quot; default: return &quot;unknown&quot; &#125;&#125; 五、异常处理5.1 与Java异常处理的区别在Java中通过try..catch..finally的方式进行异常处理，有可能出现异常的代码会被try块给包裹起来，在catch中捕获相关的异常并进行处理，最后通过finally块来统一执行最后的结束操作（释放资源、释放锁）。 而Golang中的异常处理（更贴切地说是错误处理）方式比Java的简单太多，所有可能出现异常的方法或者代码直接把错误当作第二个响应值进行返回，程序中对返回值进行判断，非空则进行处理并且立即中断程序的执行，避免错误的传播。 12345678910value, err := func(param)if err != nil &#123; // 返回了异常，进行处理 fmt.Printf(&quot;Error %s in pack1.Func1 with parameter %v&quot;, err.Error(), param1) return err&#125;// func执行正确，继续执行后续代码Process(value) Golang引入了一个关于错误处理的标准模式，即error接口，该接口的定义如下： 123type error interface &#123; Error() string&#125; 对于大多数函数，如果要返回错误，大致上都可以定义为如下模式，将 error 作为多种返回值中的最后一个，但这并非是强制要求： 12345678910111213141516171819202122unc main() &#123; if res, err := compute(1, 2, &quot;x&quot;); err != nil &#123; panic(err) &#125; else &#123; fmt.Println(res) &#125;&#125;func compute(a, b int, c string)(res int, err error) &#123; switch c &#123; case &quot;+&quot; : return a + b, nil case &quot;-&quot;: return a - b, nil case &quot;*&quot;: return a * b, nil case &quot;/&quot;: return a / b, nil default: return -1, fmt.Errorf(&quot;操作符不合法&quot;) &#125;&#125; 当然了，Golang中也可以像Java一样灵活地自定义错误类型，定义PathError结构体，并且实现Error接口后，该结构体就是一个错误类型了： PathError123456789type PathError struct &#123; Op string Path string Err error&#125;func (e *PathError) Error() string &#123; return e.Op + &quot; &quot; + e.Path + &quot;: &quot; + e.Err.Error()&#125; main12345678910func GetStat(name string) (fi FileInfo, err error) &#123; var stat syscall.Stat_t err = syscall.Stat(name, &amp;stat) if err != nil &#123; // 返回PathError错误类型 return nil, &amp;PathError &#123;&quot;stat&quot;, name, err&#125; &#125; // 程序正常，返回nil return fileInfoFromStat(&amp;stat, name), nil&#125; 这种异常处理方式是Golang的一大特色，外界对这种异常处理方式有褒有贬： 优点：代码清晰，所有的异常都需要被考虑到，出现异常后马上就需要处理 缺点：代码冗余，所有的异常都需要通过if err !&#x3D; nil {}去做判断和处理，不能够做到统一捕捉和处理 5.2 逗号 ok 模式在使用Golang编写代码的过程中，许多方法经常在一个表达式返回2个参数时使用这种模式：,ok，第一个参数是一个值或者nil，第二个参数是true&#x2F;false或者一个错误error。在一个需要赋值的if条件语句中，使用这种模式去检测第二个参数值会让代码显得优雅简洁。这种模式在Golang编码规范中非常重要。这也是Golang自身的函数多返回值特性的体现。 5.3 defer、panic及recoverdefer、pannic及recover是Golang错误处理中常用的关键字，它们各自的用途为: 1. deferdefer的作用是延迟执行某段代码，一般用于关闭资源或者执行必须执行的收尾操作，无论是否出现错误defer代码段都会执行，类似于Java中的finally代码块的作用： 123456789101112131415 func CopyFile(dst, src string) (w int64, err error) &#123; srcFile, err := os.Open(src) if err != nil &#123; return &#125; // 延迟关闭srcFile defer srcFile.Close() dstFile, err := os.Create(dstName) if err != nil &#123; return &#125; // 延迟关闭dstFile defer dstFile.Close() return io.Copy(dstFile, srcFile)&#125; defer也可以执行函数或者是匿名函数: 123456789defer func() &#123; // 清理工作&#125; ()// 这是传递参数给匿名函数时的写法var i := 1defer func(i int) &#123; // 做你复杂的清理工作&#125; (i) 需要注意的是，defer使用一个栈来维护需要执行的代码，所以defer函数所执行的顺序是和defer声明的顺序相反的。 1234567defer fmt.Println(1)defer fmt.Println(2)defer fmt.Println(3)// 执行结果// 3// 2// 1 2. panicpanic的作用是抛出错误，制造系统运行时恐慌，当在一个函数执行过程中调用panic()函数时，正常的函数执行流程将立即终止，但函数中之前使用defer关键字延迟执行的语句将正常展开执行，之后该函数将返回到调用函数，并导致逐层向上执行 panic流程，直至所属的goroutine中所有正在执行的函数被终止。 panic和Java中的throw关键字类似，用于抛出错误，阻止程序执行。 以下是基本使用方法: 123panic(404)panic(&quot;network broken&quot;)panic(Error(&quot;file not exists&quot;)) 3. recoverrecover的作用是捕捉panic抛出的错误并进行处理，需要联合defer来使用，类似于Java中的catch代码块： 12345678910111213141516171819202122func main() &#123; fmt.Println(&quot;main begin&quot;) // 必须要先声明defer，否则不能捕获到panic异常 defer func() &#123; fmt.Println(&quot;defer begin&quot;) if err := recover(); err != nil &#123; // 这里的err其实就是panic传入的内容 fmt.Println(err) &#125; fmt.Println(&quot;defer end&quot;) &#125;() f() // f中出现错误，这里开始下面代码不会再执行 fmt.Println(&quot;main end&quot;) &#125;func f() &#123; fmt.Println(&quot;f begin&quot;) panic(&quot;error&quot;) //这里开始下面代码不会再执行 fmt.Println(&quot;f end&quot;) &#125; 最后的执行结果为: 12345main beginf begindefer beginerrordefer end 利用recover处理panic指令，defer必须在panic之前声明，否则当panic时，recover无法捕获到panic。 六、并发编程6.1 CSP（MPG）并发模型介绍及对比在Java中，通常借助于共享内存（全局变量）作为线程间通信的媒介，但在Golang中使用的是通道（channel）作为协程间通信的媒介，这也是Golang中强调的: 不要通过共享内存通信，而通过通信来共享内存 在Java中，使用共享内存来进行通信常会遇到线程不安全问题，所以我们经常需要进行大量的额外处理，方式包括加锁（同步化）、使用原子类、使用volatile提升可见性等等。 CSP是Communicating Sequential Processes 的缩写，中文为顺序通信进程。CSP的核心思想是多个线程之间通过Channel来通信（对应到golang中的chan结构），这里的Channel可以理解为操作系统中的管道或者是消息中间件(不同之处在于这个MQ是为不同协程间服务的，而不是进程) 说到了CSP就得提一下Golang自身的并发模型MPG，MPG中M指的是内核线程、P指的是上下文环境、G指的是协程，其中M与P一起构成了G可运行的环境，M和P是一一对应关系，通过P来动态地对不同的G做映射和控制，所以Golang中的协程是建立在某个线程之上的用户态线程。 6.2 Goroutine及Channel的使用在Java中开启一个线程需要创建Thread实现类或Runnable实现类、重写run方法、通过t.start()开启线程执行特定任务，但在Golang中要开启一个Goroutine十分简单，只需使用go这个关键字即可。 12345678910// 开启协程执行一段代码go fmt.Println(&quot;go&quot;)// 开启协程执行函数go SomeMethod(1, 1)// 开启协程执行匿名函数go func() &#123; go fmt.Println(&quot;go&quot;)&#125;() 关于协程，有一些注意点: main函数运行的协程为主协程，其他协程为主协程的守护协程，当主协程死亡其它协程也会死亡 协程在执行完所需执行的方法及代码后会死亡，遇到panic导致程序结束时也会死亡 channel是Golang在语言级别提供的goroutine间的通信方式。我们可以使用channel在两个或多个goroutine之间传递消息,因此通过channel传递对象的过程和调用函数时的参数传递行为比较一致，比如也可以传递指针等。 channel是类型相关的。也就是说，一个channel只能传递一种类型的值，这个类型需要在声明channel时指定。 一般channel的声明形式为： 1var chanName chan ElementType 与一般的变量声明不同的地方仅仅是在类型之前加了chan关键字。 ElementType 指定这个channel所能传递的元素类型。举个例子，我们声明一个传递类型为 int channel： 1var ch chan int 或者，我们声明一个 map ，元素是 bool 型的channel: 1var m map[string] chan bool 初始化一个channel也很简单，直接使用内置的函数 make() 即可： 1ch := make(chan int) 在channel的用法中，最常见的包括写入和读出。将一个数据写入（发送）至channel的语法很直观，如下： 1ch &lt;- value 向channel写入数据通常会导致程序阻塞，直到有其他goroutine从这个channel中读取数据。从channel中读取数据的语法是 1value := &lt;-ch 如果channel之前没有写入数据，那么从channel中读取数据也会导致程序阻塞，直到channel中被写入数据为止。我们之后还会提到如何控制channel只接受写或者只允许读取，即单向channel。 channel有如下特性： 读取、写入操作为原子操作，无需担心并发时的数据安全问题，channel内数据的写入对所有协程可见 channel中阻塞的协程是FIFO的，严格按照入队顺序读写数据 对于非缓冲channel的读取和写入是同步发生的，写入会阻塞直到有读者，读取会阻塞直到有写者，类似于Java中的synchronousqueue；对于缓冲channel的读取和写入是异步的，写入时若队列已满则阻塞，直到有读者，读取时若队列为空则阻塞，直到有写者，类似于Java中的linkedblockingqueue 对于为nil的channel的写入和读取都会永久阻塞 七、垃圾回收7.1 Java的垃圾回收体系Java基于JVM完成了垃圾收集的功能，其体系很庞大，包括了垃圾回收器（G1、CMS、Serial、ParNew等）、垃圾回收算法(标记-清除、标记-整理、复制、分代收集)、可达性算法(可达性分析、引用计数法)、引用类型、JVM内存模型等内容。 7.2 Golang三色标记法三色标记法，主要流程如下： 所有对象最开始都是白色 从root开始找到所有可达对象，标记为灰色，放入待处理队列 遍历灰色对象队列，将其引用对象标记为灰色放入待处理队列，自身标记为黑色 处理完灰色对象队列，执行清扫工作 八、通用写法8.1 定时器来段源码 1234567891011121314151617181920212223if dl, ok := ctx.Deadline(); ok &#123; // If we have a deadline then we interpret it as a request to gracefully shutdown. We wait // until either all the connections have landed back in the pool (and have been closed) or // until the timer is done. ticker := time.NewTicker(1 * time.Second) defer ticker.Stop() timer := time.NewTimer(time.Now().Sub(dl)) defer timer.Stop() for &#123; select &#123; case &lt;-timer.C: case &lt;-ctx.Done(): case &lt;-ticker.C: // Can we replace this with an actual signal channel? We will know when p.inflight hits zero from the close method. p.Lock() if len(p.opened) &gt; 0 &#123; p.Unlock() continue &#125; p.Unlock() &#125; break &#125;&#125; 上面代码中，创建了循环定时器ticker、单次定时器timer，使用select监听3个管道， 实现的效果：阻塞当前流程，定时查询当前未关闭资源；当满足下列条件之一时，执行后续流程： 不存在未关闭资源 阻塞时间超过预定时间 上下文ctx cancel触发","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"golang","slug":"技术开发/golang","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/"}],"tags":[{"name":"Golang与Java","slug":"Golang与Java","permalink":"https://tianxiafeiyu.github.io/tags/Golang%E4%B8%8EJava/"}]},{"title":"golang学习大纲","slug":"技术开发/golang/golang学习大纲","date":"2022-12-15T23:19:25.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/golang/golang学习大纲/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/golang%E5%AD%A6%E4%B9%A0%E5%A4%A7%E7%BA%B2/","excerpt":"","text":"Golang核心知识总结 Go语言简介及特性 变量与常量的定义 内置类型 函数以及错误处理 面向对象之类型系统 面向对象之接口 使用协程和通道进行并发通信 net&#x2F;http包的使用 使用net&#x2F;http及goquery库爬取CSDN首页文章 Golang与Java各方面使用对比（上） Golang与Java各方面使用对比（下）","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"golang","slug":"技术开发/golang","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/"}],"tags":[{"name":"golang学习大纲","slug":"golang学习大纲","permalink":"https://tianxiafeiyu.github.io/tags/golang%E5%AD%A6%E4%B9%A0%E5%A4%A7%E7%BA%B2/"}]},{"title":"go流程控制","slug":"技术开发/golang/go流程控制","date":"2022-12-15T23:19:25.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/golang/go流程控制/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/go%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/","excerpt":"","text":"switchjava switch与go switch | Java | Golang—|—|—变量expression |byte、short、int 、 char和String | 任何类型break 语句 | 如果当前匹配成功的 case 语句块没有 break 语句，则从当前 case 开始，后续所有 case 的值都会输出，如果后续的 case 语句块有 break 语句则会跳出判断。default不需要break | switch 默认情况下 case 最后自带 break 语句，匹配成功后就不会执行其他 case，如果我们需要执行后面的 case，可以使用 fallthroughType Switch | 无 | switch 语句还可以被用于 type-switch 来判断某个 interface 变量中实际存储的变量类型 Java 1234567891011switch(expression)&#123; case value : //语句 break; //可选 case value : //语句 break; //可选 //你可以有任意数量的case语句 default : //可选 //语句&#125; Go 123456789switch expression&#123; case val1: ... case val2: ... fallthrough default: ...&#125; go switch 默认值的坑1234567891011121314151617181920212223242526272829303132333435363738package mainimport &quot;fmt&quot;func ff() bool &#123; return false&#125;func main() &#123; // switch 默认为true switch &#123; case true: fmt.Println(&quot;默认true&quot;) case false: fmt.Println(&quot;默认为fasle&quot;) &#125; &#125; // switch 支持初始化语句 switch f := ff(); f &#123; case true: fmt.Println(&quot;true&quot;) case false: fmt.Println(&quot;fasle&quot;) &#125; // switch 只有初始化语句 条件默认为true switch ff(); &#123; case true: fmt.Println(&quot;默认为true&quot;) case false: fmt.Println(&quot;默认为fasle&quot;) &#125;&#125;//默认true//fasle//默认为true forGo里面最强大的一个控制逻辑就是for，它即可以用来循环读取数据，又可以当作while来控制逻辑，还能迭代操作。它的语法如下： 123for expression1; expression2; expression3 &#123; //...&#125; expression1、expression2和expression3都是表达式，其中expression1和expression3是变量声明或者函数调用返回值之类的，expression2是用来条件判断，expression1在循环开始之前调用，expression3在每轮循环结束之时调用。 例子： 123456789101112package mainimport &quot;fmt&quot;func main()&#123; sum := 0; for index:=0; index &lt; 10 ; index++ &#123; sum += index &#125; fmt.Println(&quot;sum is equal to &quot;, sum)&#125;// 输出：// sum is equal to 45 有些时候需要进行多个赋值操作，由于Go里面没有,操作符，那么可以使用平行赋值i, j &#x3D; i+1, j-1 有些时候如果我们忽略expression1和expression3： 1234sum := 1for ; sum &lt; 1000; &#123; sum += sum&#125; 其中;也可以省略，那么就变成如下的代码了，是不是似曾相识？对，这就是while的功能。 1234sum := 1for sum &lt; 1000 &#123; sum += sum&#125; 在循环里面有两个关键操作break和continue ,break操作是跳出当前循环，continue是跳过本次循环。当嵌套过深的时候，break可以配合标签使用，即跳转至标签所指定的位置，详细参考如下例子： 12345678for index := 10; index&gt;0; index-- &#123; if index == 5&#123; break // 或者continue &#125; fmt.Println(index)&#125;// break打印出来10、9、8、7、6// continue打印出来10、9、8、7、6、4、3、2、1 break和continue还可以跟着标号，用来跳到多重循环中的外层循环 for配合range可以用于读取slice和map的数据： 1234for k,v:=range map &#123; fmt.Println(&quot;map&#x27;s key:&quot;,k) fmt.Println(&quot;map&#x27;s val:&quot;,v)&#125; 由于 Go 支持 “多值返回”, 而对于“声明而未被调用”的变量, 编译器会报错, 在这种情况下, 可以使用_来丢弃不需要的返回值 例如 123for _, v := range map&#123; fmt.Println(&quot;map&#x27;s val:&quot;, v)&#125; for range槽点https://juejin.cn/post/6844903474019172360 ifif也许是各种编程语言中最常见的了，它的语法概括起来就是:如果满足条件就做某事，否则做另一件事。 Go里面if条件判断语句中不需要括号，如下代码所示 12345if x &gt; 10 &#123; fmt.Println(&quot;x is greater than 10&quot;)&#125; else &#123; fmt.Println(&quot;x is less than 10&quot;)&#125; Go的if还有一个强大的地方就是条件判断语句里面允许声明一个变量，这个变量的作用域只能在该条件逻辑块内，其他地方就不起作用了，如下所示 12345678// 计算获取值x,然后根据x返回的大小，判断是否大于10。if x := computedValue(); x &gt; 10 &#123; fmt.Println(&quot;x is greater than 10&quot;)&#125; else &#123; fmt.Println(&quot;x is less than 10&quot;)&#125;//这个地方如果这样调用就编译出错了，因为x是条件里面的变量fmt.Println(x) 多个条件的时候如下所示： 1234567if integer == 3 &#123; fmt.Println(&quot;The integer is equal to 3&quot;)&#125; else if integer &lt; 3 &#123; fmt.Println(&quot;The integer is less than 3&quot;)&#125; else &#123; fmt.Println(&quot;The integer is greater than 3&quot;)&#125; selectgo里面提供了一个关键字select,通过select可以监听channel上的数据流动 select的用法与switch语言非常类似,由select开始一个新的选择块,每个选择块条件由case语句来描述 与switch语句可以选择任何可使用相等比较的条件相比,select有比较多的限制,其中最大的一条限制就是每个case语句里必须是一个IO操作 12345678910for &#123; select &#123; case &lt;-chan1: //..... case chan2&lt;-1: //.... default: //都没成功,进入...... &#125;&#125; 注意 监听的case中,没有满足条件的就阻塞，存在多个满足条件的就任选一个执行（用一种伪随机的算法在这些分支中选择一个并执行） select本身不带循环,需要外层的for default通常不用,会产生忙轮询 break只能跳出select中的一个case 加入了默认分支，那么无论涉及通道操作的表达式是否有阻塞，select语句都不会被阻塞。如果那几个表达式都阻塞了，或者说都没有满足求值的条件，那么默认分支就会被选中并执行。 如果没有加入默认分支，那么一旦所有的case表达式都没有满足求值条件，那么select语句就会被阻塞。直到至少有一个case表达式满足条件为止。 定时轮询加入timetricker防止超时 123456789func (pc *ProcessCache) Clean() &#123; ticker := time.NewTicker(10 * time.Minute) for &#123; select &#123; case &lt;-ticker.C: pc.clean() &#125; &#125;&#125; gotoGo有goto语句——请明智地使用它。用goto跳转到必须在当前函数内定义的标签。例如假设这样一个循环： 12345678func myFunc() &#123; i := 0Here: //这行的第一个词，以冒号结束作为标签 println(i) i++ goto Here //跳转到Here去&#125;// 标签名是大小写敏感的。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"golang","slug":"技术开发/golang","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/"}],"tags":[{"name":"go流程控制","slug":"go流程控制","permalink":"https://tianxiafeiyu.github.io/tags/go%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/"}]},{"title":"go项目标准布局","slug":"技术开发/golang/go项目标准布局","date":"2022-12-15T23:19:25.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/golang/go项目标准布局/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/go%E9%A1%B9%E7%9B%AE%E6%A0%87%E5%87%86%E5%B8%83%E5%B1%80/","excerpt":"","text":"建议的目录&#x2F;cmd项目主要的应用程序。 对于每个应用程序来说这个目录的名字应该和项目可执行文件的名字匹配（例如，&#x2F;cmd&#x2F;myapp）。 不要在这个目录中放太多的代码。如果目录中的代码可以被其他项目导入并使用，那么应该把他们放在&#x2F;pkg目录。如果目录中的代码不可重用，或者不希望被他人使用，应该将代码放在&#x2F;internal目录。显示的表明意图比较好！ 通常来说，项目都应该拥有一个小的main函数，并在main函数中导入或者调用&#x2F;internal和&#x2F;pkg目录中的代码。 更多详情，请看&#x2F;cmd目录中的例子。 &#x2F;internal私有的应用程序代码库。这些是不希望被其他人导入的代码。请注意：这种模式是Go编译器强制执行的。详细内容情况Go 1.4的release notes。再次注意，在项目的目录树中的任意位置都可以有internal目录，而不仅仅是在顶级目录中。 可以在内部代码包中添加一些额外的结构，来分隔共享和非共享的内部代码。这不是必选项（尤其是在小项目中），但是有一个直观的包用途是很棒的。应用程序实际的代码可以放在&#x2F;internal&#x2F;app目录（如，internal&#x2F;app&#x2F;myapp），而应用程序的共享代码放在&#x2F;internal&#x2F;pkg目录（如，internal&#x2F;pkg&#x2F;myprivlib）中。 &#x2F;pkg外部应用程序可以使用的库代码（如，&#x2F;pkg&#x2F;mypubliclib）。其他项目将会导入这些库来保证项目可以正常运行，所以在将代码放在这里前，一定要三思而行。请注意，internal目录是一个更好的选择来确保项目私有代码不会被其他人导入，因为这是Go强制执行的。使用&#x2F;pkg目录来明确表示代码可以被其他人安全的导入仍然是一个好方式。Travis Jeffery撰写的关于 I’ll take pkg over internal 文章很好地概述了pkg和inernal目录以及何时使用它们。 当您的根目录包含大量非Go组件和目录时，这也是一种将Go代码分组到一个位置的方法，从而使运行各种Go工具更加容易。 点击查看&#x2F;pkg就能看到那些使用这个布局模式的流行Go代码仓库。这是一种常见的布局模式，但未被普遍接受，并且Go社区中的某些人不推荐这样做。 如果项目确实很小并且嵌套的层次并不会带来多少价值（除非你就是想用它），那么就不要使用它。请仔细思考这种情况，当项目变得很大，并且根目录中包含的内容相当繁杂（尤其是有很多非Go的组件）。 &#x2F;vendor应用程序的依赖关系（通过手动或者使用喜欢的依赖管理工具，如新增的内置Go Modules特性）。执行go mod vendor命令将会在项目中创建&#x2F;vendor目录，注意，如果使用的不是Go 1.14版本，在执行go build进行编译时，需要添加-mod&#x3D;vendor命令行选项，因为它不是默认选项。 构建库文件时，不要提交应用程序依赖项。 请注意，从1.13开始，Go也启动了模块代理特性（使用https：&#x2F;&#x2F;proxy.golang.org作为默认的模块代理服务器）。点击这里阅读有关它的更多信息，来了解它是否符合所需要求和约束。如果Go Module满足需要，那么就不需要vendor目录。 &#x2F;apiOpenAPI&#x2F;Swagger规范，JSON模式文件，协议定义文件。 更多样例查看&#x2F;api目录。 &#x2F;webWeb应用程序特定的组件：静态Web资源，服务器端模板和单页应用（Single-Page App，SPA）。 &#x2F;configs配置文件模板或默认配置。 将confd或者consul-template文件放在这里。 &#x2F;init系统初始化（systemd、upstart、sysv）和进程管理（runit、supervisord）配置。 &#x2F;scripts用于执行各种构建，安装，分析等操作的脚本。 这些脚本使根级别的Makefile变得更小更简单（例如 https://github.com/hashicorp/terraform/blob/master/Makefile ）。 更多样例查看&#x2F;scripts。 &#x2F;build打包和持续集成。 将云（AMI），容器（Docker），操作系统（deb，rpm，pkg）软件包配置和脚本放在&#x2F;build&#x2F;package目录中。 将CI（travis、circle、drone）配置文件和就脚本放在build&#x2F;ci目录中。请注意，有一些CI工具（如，travis CI）对于配置文件的位置有严格的要求。尝试将配置文件放在&#x2F;build&#x2F;ci目录，然后链接到CI工具想要的位置。 &#x2F;deploymentsIaaS，PaaS，系统和容器编排部署配置和模板（docker-compose，kubernetes&#x2F;helm，mesos，terraform，bosh）。请注意，在某些存储库中（尤其是使用kubernetes部署的应用程序），该目录的名字是&#x2F;deploy。 &#x2F;test外部测试应用程序和测试数据。随时根据需要构建&#x2F;test目录。对于较大的项目，有一个数据子目录更好一些。例如，如果需要Go忽略目录中的内容，则可以使用&#x2F;test&#x2F;data或&#x2F;test&#x2F;testdata这样的目录名字。请注意，Go还将忽略以“.”或“_”开头的目录或文件，因此可以更具灵活性的来命名测试数据目录。 更多样例查看&#x2F;test。 &#x2F;docs设计和用户文档（除了godoc生成的文档）。 更多样例查看&#x2F;docs。 &#x2F;tools此项目的支持工具。请注意，这些工具可以从&#x2F;pkg和&#x2F;internal目录导入代码。 更多样例查看&#x2F;tools。 &#x2F;examples应用程序或公共库的示例。 更多样例查看&#x2F;examples。 &#x2F;third_party外部辅助工具，fork的代码和其他第三方工具（例如Swagger UI）。 &#x2F;githooksGit的钩子。 &#x2F;assets项目中使用的其他资源（图像，Logo等）。 &#x2F;website如果不使用Github pages，则在这里放置项目的网站数据。 更多样例查看&#x2F;website。 不应该出现的目录&#x2F;src有一些Go项目确实包含src文件夹，但通常只有在开发者是从Java（这是Java中一个通用的模式）转过来的情况下才会有。如果可以的话请不要使用这种Java模式。你肯定不希望你的Go代码和项目看起来像Java。 不要将项目级别的&#x2F;src目录与Go用于其工作空间的&#x2F;src目录混淆，就像How to Write Go Code中描述的那样。$GOPATH环境变量指向当前的工作空间（默认情况下指向非Windows系统中的$HOME&#x2F;go）。此工作空间包括顶级&#x2F;pkg，&#x2F;bin和&#x2F;src目录。实际的项目最终变成&#x2F;src下的子目录，因此，如果项目中有&#x2F;src目录，则项目路径将会变成：&#x2F;some&#x2F;path&#x2F;to&#x2F;workspace&#x2F;src&#x2F;your_project&#x2F; src&#x2F;your_code.go。请注意，使用Go 1.11，可以将项目放在GOPATH之外，但这并不意味着使用此布局模式是个好主意。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"golang","slug":"技术开发/golang","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/"}],"tags":[{"name":"go项目标准布局","slug":"go项目标准布局","permalink":"https://tianxiafeiyu.github.io/tags/go%E9%A1%B9%E7%9B%AE%E6%A0%87%E5%87%86%E5%B8%83%E5%B1%80/"}]},{"title":"http client最优配置","slug":"技术开发/golang/http client最优配置","date":"2022-12-15T23:19:25.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/golang/http client最优配置/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/http%20client%E6%9C%80%E4%BC%98%E9%85%8D%E7%BD%AE/","excerpt":"","text":"golang net&#x2F;http 连接池 https://cloud.tencent.com/developer/article/1900690 golang http client的MaxConnsPerHost限制http://t.zoukankan.com/albizzia-p-14301550.html Golang 你一定要懂的连接池https://studygolang.com/articles/30261 go http client 问题排查https://zhuanlan.zhihu.com/p/451642373 联众服务器超时中断,http连接中客户端中断了请求，服务端会中断执行吗？https://blog.csdn.net/weixin_29607637/article/details/119229443 Go中的HTTP请求之——HTTP1.1请求流程分析https://baijiahao.baidu.com/s?id=1673894064573900815&amp;wfr=spider&amp;for=pc","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"golang","slug":"技术开发/golang","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/"}],"tags":[{"name":"http client最优配置","slug":"http-client最优配置","permalink":"https://tianxiafeiyu.github.io/tags/http-client%E6%9C%80%E4%BC%98%E9%85%8D%E7%BD%AE/"}]},{"title":"优秀golang开源项目","slug":"技术开发/golang/优秀golang开源项目","date":"2022-12-15T23:19:25.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/golang/优秀golang开源项目/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/%E4%BC%98%E7%A7%80golang%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/","excerpt":"","text":"作者：茹姐链接：https://www.zhihu.com/question/20801814/answer/685254356来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 根据go语言中文社区提供的资料，还有互联网企业架构设计中的常见组件分类， 共精心挑选了153个开源项目（项目不限于在github开源的项目）， 分成以下17个大类。项目初衷是帮助到那些想学习和借鉴优秀golang开源项目，和在互联网架构设计时期望快速寻找合适轮子的人。 监控系统grafana&#x2F;grafanaGrafana是用于监控指标分析和图表展示的工具， 后端支持 Graphite, InfluxDB &amp; Prometheus &amp; Open-falcon等， 它是一个流行的监控组件， 目前在各大中小型公司中广泛应用。 prometheus&#x2F;prometheusPrometheus 是开源的服务监控系统和时间序列数据库， 提供监控数据存储，展示，告警等功能。 bosun-monitor&#x2F;bosun专业的跨平台开源系统监控项目，go语言编写，灵活的模板和表达式配合上各种collector可以监控任何应用或系统级的运行数据，比 zabbix更轻量级、更易入手和更适合定制。 sourcegraph&#x2F;checkup一个分布式的无锁的站点健康状态检查工具。 支持检查http，tcp，dns等的状态 并可将结果保存在s3。 自带了一个美观的界面。 rapidloop&#x2F;rtoprtop是一个简单的无代理的远程服务器监控工具，基于 SSH 连接进行工作。无需在被监控的服务器上安装任何软件。rtop 直接通过 SSH 连接到待监控服务器，然后执行命令来收集监控数据。rtop 每几秒钟就自动更新监控数据，类似其他 *top 命令。 influxdata&#x2F;kapacitorKapacitor 是一个开源框架，用来处理、监控和警告时间序列数据。 open-falcon&#x2F;of-releaseOpenFalcon是一款小米开源的监控系统。功能：数据采集免配置：agent自发现、支持Plugin、主动推送模式; 容量水平扩展：生产环境每秒50万次数据收集、告警、存储、绘图，可持续水平扩展。告警策略自发现：Web界面、支持策略模板、模板继承和覆盖、多种告警方式、支持回调动作。告警设置人性化：支持最大告警次数、告警级别设置、告警恢复通知、告警暂停、不同时段不同阈值、支持维护周期，支持告警合并。历史数据高效查询：秒级返回上百个指标一年的历史数据。Dashboard人性化：多维度的数据展示，用户自定义Dashboard等功能。架构设计高可用：整个系统无核心单点，易运维，易部署。 rach&#x2F;pomePome 是 Postgres Metrics 的意思。Pome 是一个 PostgreSQL 的指标仪表器，用来跟踪你的数据库的健康状况。 TalkingData&#x2F;owlOWL是TalkingData公司推出的一款开源分布式监控系统, 演示环境http://54.223.127.87/，登录账号密码demo/demo gy-games&#x2F;smartpingSmartPing为一个各机器(点)间间互PING检测工具，支持互PING，单向PING，绘制拓扑及报警功能。 系统设计为无中心化原则，所有的数据均存储自身点中，默认数据循环保留1个月时间，由自身点的数据绘制 出PING包 的状态，由各其他点的数据绘制 进PING包 的状态，并API接口获取其他点数据绘制整体PING拓扑图，拓扑图中存在报警功能。 pinggg&#x2F;pingdpingd 是世界上最简单的监控服务，使用 golang 编写。软件支持 IPv6，但是服务器不支持. pingd 允许同时 ping 上千个 IPs，在此期间还可以管理监控的主机。用户提供主机名或者 IP，还有用户邮箱地址，就可以使用 3 个生成 URLs 来开启，停止或者删除你的追踪。每当你的服务器停机或者后台在线都会发送通知，还包含控制 URLs。 cloudinsight&#x2F;cloudinsight-agent提供可视化监控的saas平台cloudinsight开源的一个监控客户端。 Cloudinsight 探针可以收集它所在操作系统的各种指标，然后发送到 Cloudinsight 后端服务 gravitational&#x2F;satellite用于监测kubernetes健康状态的一个工具／库。 其特点是：轻量级定期测试， 高可用性和弹性网络分区， 无单点故障， 以时间序列的格式存储监控数据。 kovetskiy&#x2F;zabbixctlZabbixctl是采用Zabbix服务API的命令行工具，它提供了有效的方式去查询和处理trigger 状态、主机最新数据和用户组。 容器技术docker&#x2F;dockerDocker是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）。几乎没有性能开销,可以很容易地在机器和数据中心中运行。最重要的是,他们不依赖于任何语言、框架或包装系统。 coreos&#x2F;rktRocket （也叫 rkt）是 CoreOS 推出的一款容器引擎，和 Docker 类似，帮助开发者打包应用和依赖包到可移植容器中，简化搭环境等部署工作。Rocket 和 Docker 不同的地方在于，Rocket 没有 Docker 那些为企业用户提供的“友好功能”，比如云服务加速工具、集群系统等。反过来说，Rocket 想做的，是一个更纯粹的业界标准。 vmware&#x2F;harbor容器应用的开发和运行离不开可靠的镜像管理。从安全和效率等方面考虑，部署在私有环境内的Registry是非常必要的。Project Harbor是由VMware公司中国团队为企业用户设计的Registry server开源项目，包括了权限管理(RBAC)、LDAP、审计、管理界面、自我注册、HA等企业必需的功能，同时针对中国用户的特点，设计镜像复制和中文支持等功能。 shipyard&#x2F;shipyardShipyard 是一个基于 Web 的 Docker 管理工具，支持多 host，可以把多个 Docker host 上的 containers 统一管理；可以查看 images，甚至 build images；并提供 RESTful API 等等。 Shipyard 要管理和控制 Docker host 的话需要先修改 Docker host 上的默认配置使其支持远程管理。 zettio&#x2F;weaveWeave 创建一个虚拟网络并连接到部署在多个主机上的 Docker 容器。 coreos&#x2F;clairClair 是一个容器漏洞分析服务。它提供一个能威胁容器漏洞的列表，并且在有新的容器漏洞发布出来后会发送通知给用户。 alibaba&#x2F;pouchPouch 是 Alibaba 公司开源的容器引擎技术，其主要功能包括基本的容器管理能力，安全稳定的强容器隔离能力，以及对应用无侵入性的富容器技术。 weaveworks&#x2F;scope一个docker&amp;kubernetes的管理，监控可视化工具， 可以看到容器间的拓扑关系和tcp通信。 docker&#x2F;swarmkitSwarmKit 是Docker公司开源的Docker集群管理和容器编排工具，其主要功能包括节点发现、基于raft算法的一致性和任务调度等。 emccode&#x2F;rexrayREX-Ray 是一个 EMC {code} 团队领导的开源项目，为 Docker、Mesos 及其他容器运行环境提供持续的存储访问。其设计旨在囊括通用存储、虚拟化和云平台，提供高级的存储功能。 docker&#x2F;libnetworkLibnetwork 提供一个原生 Go 实现的容器连接，是容器的网络。libnetwork 的目标是定义一个健壮的容器网络模型（Container Network Model），提供一个一致的编程接口和应用程序的网络抽象。 cloud66&#x2F;habitus一个快速实现docker build 流程的工具， 支持复杂的docker build流程，实现多个dockerfile的build流程，典型应用如将需要静态编译的程序，如go， java这类程序在一个docker build编译好之后，得到的二进制包用到后续的build流程。 vishvananda&#x2F;wormholeWormhole 是一个能识别命名空间的由 Socket 激活的隧道代理。可以让你安全的连接在不同物理机器上的 Docker 容器。可以用来完成一些有趣的功能，例如连接运行在容器本机的服务或者在连接后创建按需的服务。 PaaS工具kubernetes&#x2F;kubernetesKubernetes 是来自 Google 云平台的开源容器集群管理系统。基于 Docker 构建一个容器的调度服务。该系统可以自动在一个容器集群中选择一个工作容器供使用。其核心概念是 Container Pod。tsuru&#x2F;tsuru在 Tsuru 的 PaaS 服务下，你可以选择自己的编程语言，选择使用 SQL 或者 NoSQL 数据库，memcache、redis、等等许多服务，甚至与你可以使用 Git 版本控制工具来上传你应用。 laincloud&#x2F;lainLain 是一个基于 docker 的 PaaS 系统。其面向技术栈多样寻求高效运维方案的高速发展中的组织，devops 人力缺乏的 startup ，个人开发者。统一高效的开发工作流，降低应用运维复杂度；在 IaaS &#x2F; 私有 IDC 裸机的基础上直接提供应用开发，集成，部署，运维的一揽子解决方案。 ooyala&#x2F;atlantisAtlantis 是一款基于 Docker，使用 Go 编写，为 HTTP 应用准备的开源 PaaS。Atlantis 可以在路由请求中轻松的构建和部署应用到容器。Atlantis 在 Ooyala 的新应用中得到了很广泛的应用。 weibocom&#x2F;opendcpOpenDCP是一个基于Docker的云资源管理与调度平台，集镜像仓库、多云支持、服务编排、服务发现等功能与一身，支持服务池的扩缩容，其技术体系源于微博用于支持节假日及热点峰值流量的弹性调度DCP系统。OpenDCP允许利用公有云服务器搭建起适应互联网应用的IT基础设施，并且将运维的工作量降到最低。 mesos&#x2F;cloudfoundry-mesosCloud Foundry-Mesos框架由华为与Mesosphere的工程师合作完成，能够为应用提供安全可靠的、可伸缩、可扩展的云端运行环境，并且应用能够 享用Cloud Foundry生态圈内各类丰富的服务资源。企业能够通过Cloud Foundry开发云应用，并通过Cloud Foundry-Mesos将应用部署到DCOS上，使应用能够与DCOS上安装的其他服务及应用框架共享资源，实现资源利用率最大化，能够大幅降低企业 数据中心运营成本。DCOS能够运行在虚拟和物理环境上，能够支持Linux（以及很快支持Windows），并可适用于私有云、公有云及混合云环境。 微服务istio&#x2F;istioIstio是由Google、IBM和Lyft开源的微服务管理、保护和监控框架。使用istio可以很简单的创建具有负载均衡、服务间认证、监控等功能的服务网络，而不需要对服务的代码进行任何修改。 go-kit&#x2F;kitGo-kit 是一个 Go 语言的分布式开发包，用于开发微服务。 uber&#x2F;jaegerJaeger是Uber的分布式跟踪系统 ，基于google dapper的原理构建， 以Cassandra作为存储层 micro&#x2F;microMicro是一个专注于简化分布式系统开发的微服务生态系统。可插拔的插件化设计，提供强大的可插拔的架构来保证基础组件可以被灵活替换。 eBay&#x2F;fabiofabio 是 ebay 团队用 golang 开发的一个快速、简单零配置能够让 consul 部署的应用快速支持 http(s) 的负载均衡路由器。这里有一篇中文文章http://dockone.io/article/1567介绍了如何用fabio＋consul实现服务发现，负载均衡，并阐述了原理， 最后还有demo程序 goadesign&#x2F;goaGoa 是一款用 Go 用于构建微服务的框架，采用独特的设计优先的方法。 NYTimes&#x2F;gizmo纽约时报开源的go微服务工具.提供如下特性:标准化配置和日志;可配置策略的状态监测端点;用于管理 pprof 端点和日志级别的配置;结构化日志，提供基本请求信息;端点的有用度量;优雅的停止服务; 定义期待和词汇的基本接口 koding&#x2F;kite一个基于go语言的微服务框架, Kite是Koding公司内部的一个框架, 该框架提供服务发现，多种认证功能，服务端通过RPC进行通信，同时还提供了websocket的js库，方便浏览器于服务器间进行通信。afex&#x2F;hystrix-go用来隔离远程系统调用， 第三方库调用 ，服务调用， 提供熔断机制，避免雪崩效应的库， Hystrix的go 版本。 注Hystrixs是Netflix开源的一个java库fagongzi&#x2F;gatewayGateway是一个使用go实现的基于HTTP的API 网关。特性 ：API 聚合 ; 流控; 熔断; 负载均衡; 健康检查; 监控; 消息路由; 后端管理WebUI . 能做什么：规划更友好的URL给调用者。聚合多个API的结果返回给API调用者，利于移动端，后端可以实现原子接口。保护后端API服务不会被突发异常流量压垮。提供熔断机制，使得后端API Server具备自我恢复能力。借助消息路由能力，实现灰度发布，AB测试。goodrain&#x2F;rainbond云帮是一款以应用为中心的开源PaaS，深度整合Kubernetes的容器管理和Service Mesh微服务架构最佳实践，满足支撑业务高速发展所需的敏捷开发、高效运维和精益管理需求sourcegraph&#x2F;appdashgo版本的分布式应用跟踪系统， 基于google dapper的原理构建andot&#x2F;hproseHprose 是高性能远程对象服务引擎（High Performance Remote Object Service Engine）的缩写 —— 微服务首选引擎。它是一个先进的轻量级的跨语言跨平台面向对象的高性能远程动态通讯中间件。它不仅简单易用，而且功能强大。你只需要稍许的时间去学习，就能用它轻松构建跨语言跨平台的分布式应用系统了。CI&#x2F;CDdrone&#x2F;droneDrone 是一个基于 Docker 的持续发布平台，使用 Go 语言开发caicloud&#x2F;cycloneCyclone 是一个打造容器工作流的云原生持续集成持续发布平台，简单易用，使用 Go 语言开发，有详尽的中文文档数据库技术pingcap&#x2F;tidbTiDB 是国内 PingCAP 团队开发的一个分布式 SQL 数据库。其灵感来自于 Google 的 F1, TiDB 支持包括传统 RDBMS 和 NoSQL 的特性。influxdata&#x2F;influxdb一个可以水平扩展的时间序列数据库， 内建http api， 支持对数据打tag，灵活的查询策略和数据的实时查询，支持类sql语句进行查询cockroachdb&#x2F;cockroachCockroachDB (蟑螂数据库）是一个可伸缩的、支持地理位置处理、支持事务处理的数据存储系统。CockroachDB 提供两种不同的的事务特性，包括快照隔离（snapshot isolation，简称SI）和顺序的快照隔离（SSI）语义，后者是默认的隔离级别。google&#x2F;cayleyCayley 是 Google 的一个开源图(Graph)数据库，其灵感来自于 Freebase 和 Google 的 Knowledge Graph 背后的图数据库。dgraph-io&#x2F;dgraphdgraph 是可扩展的，分布式的，低延迟图形数据库。DGraph 的目标是提供 Google 生产水平的规模和吞吐量，在超过TB的结构数据里，未用户提供足够低延迟的实时查询。DGraph 支持 GraphQL 作为查询语言，响应 JSON。wandoulabs&#x2F;codisCodis 是一个分布式 Redis 解决方案, 对于上层的应用来说, 连接到 Codis Proxy 和连接原生的 Redis Server 没有明显的区别 (不支持的命令列表), 上层应用可以像使用单机的 Redis 一样使用, Codis 底层会处理请求的转发, 不停机的数据迁移等工作, 所有后边的一切事情, 对于前面的客户端来说是透明的, 可以简单的认为后边连接的是一个内存无限大的 Redis 服务.youtube&#x2F;vitessoutube出品的开源分布式MySQL工具集Vitess，自动分片存储MySQL数据表，将单个SQL查询改写为分布式发送到多个MySQL Server上，支持行缓存（比MySQL本身缓存效率高），支持复制容错，已用于Youtube生产环境sosedoff&#x2F;pgwebgweb 是一个采用 Go 语言开发的基于 Web 的 PostgreSQL 管理系统。flike&#x2F;kingshard一个高性能的mysql中间件， 支持读写分离， 数据分片， 安全审计等功能olivere&#x2F;elasticelastic是开源搜索引擎elasticsearch的golang客户端，API友好，支持绝大部分es的接口,支持的es版本全面，从1.x到最新的6.x全覆盖siddontang&#x2F;ledisdbledisdb是一个参考ssdb，采用go实现，底层基于leveldb，类似redis的高性能nosql数据库，提供了kv，list，hash以及zset数据结构的支持。outbrain&#x2F;orchestratorMySQL 复制拓扑可视化工具slicebit&#x2F;qbqb是用来让使更容易使用数据库的go语言的数据库工具包。它受Python最喜欢的ORM SQLAlchemy的启发，既是一个ORM，也是一个查询生成器。它在表达api和查询构建东西的情形下是相当模块化的。mediocregopher&#x2F;radix.v2radix.v2是redis官方推荐的客户端之一，相比于redigo,radix.v2特点是轻量、接口实现优雅、API友好chasex&#x2F;redis-go-clusterredis-go-cluster 是基于 Redigo 实现的 Golang Redis 客户端。redis-go-cluster 可以在本地缓存 slot 信息，并且当集群修改的时候会自动更新。此客户端管理每个节点连接池，使用 goroutine 来尽可能的并发执行，达到了高效，低延迟。hidu&#x2F;mysql-schema-syncmysql-schema-sync 是一款使用go开发的、跨平台的、绿色无依赖的 MySQL 表结构自动同步工具。用于将线上(其他环境)数据库结构变化同步到测试（本地）环境!goshawkdb&#x2F;serverGoshawkDB 是一个采用 Go 语言开发支持多平台的分布式的对象存储服务，支持事务以及容错。GoshawkDB 的事务控制是在客户端完成的。GoshawkDB 服务器端使用 AGPL 许可，而 Go 语言客户端使用 Apache 许可证degdb&#x2F;degdbDegDB 是分布式的经济图数据库。存储技术ipfs&#x2F;go-ipfsIPFS 是分布式文件系统，寻求连接所有计算机设备的相同文件系统。在某些方面，这很类似于原始的 Web 目标，但是 IPFS 最终会更像单个比特流群交换的 git 对象。IPFS ＝ InterPlanetary File Systemchrislusf&#x2F;seaweedfsSeaweedFS 是简单，高伸缩性的分布式文件系统，包含两部分：存储数十亿的文件；快速为文件服务。SeaweedFS 作为支持全 POSIX 文件系统语义替代，Seaweed-FS 选择仅实现 key-file 的映射，类似 “NoSQL”，也可以说是 “NoFS”。spf13&#x2F;aferoAfero 是一个文件系统框架，提供一个简单、统一和通用的 API 和任何文件系统进行交互，作为抽象层还提供了界面、类型和方法。Afero 的界面十分简洁，设计简单，舍弃了不必要的构造函数和初始化方法。Afero 作为一个库还提供了一组可交互操作的后台文件系统，这样在与 Afero 协作时，还可以保留 os 和 ioutil 软件包的功能和好处。coreos&#x2F;torusTorus是一种针对容器集群量身打造的存储系统，可以为通过Kubernetes编排和管理的容器集群提供可靠可扩展的存储。这是继etcd、rkt、flannel，以及CoreOS Linux之后CoreOS发布的另一个开源产品。emccode&#x2F;rexrayREX-Ray 是一个 EMC {code} 团队领导的开源项目，为 Docker、Mesos 及其他容器运行环境提供持续的存储访问。其设计旨在囊括通用存储、虚拟化和云平台，提供高级的存储功能。Terry-Mao&#x2F;bfsbfs 是使用 Go 编写的分布式文件系统（小文件存储）。gostor&#x2F;gotgtGotgt 是使用 Go 编写的高性能、可扩展的 iSCSI target 服务。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"golang","slug":"技术开发/golang","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/"}],"tags":[{"name":"优秀golang开源项目","slug":"优秀golang开源项目","permalink":"https://tianxiafeiyu.github.io/tags/%E4%BC%98%E7%A7%80golang%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"}]},{"title":"go ast","slug":"技术开发/golang/go ast","date":"2022-12-15T23:19:22.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/golang/go ast/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/go%20ast/","excerpt":"","text":"抽象语法树抽象语法树（abstract syntax code，AST）是源代码的抽象语法结构的树状表示，树上的每个节点都表示源代码中的一种结构。简单理解,就是把我们写的代码按照一定的规则转换成一种树形结构。 在传统的编译语言的流程中,程序的一段源代码在执行之前会经历三个步骤,统称为”编译”: 分词&#x2F;词法分析 这个过程会将由字符组成的字符串分解成有意义的代码块,这些代码块统称为词法单元(token). 举个例子: let a &#x3D; 1, 这段程序通常会被分解成为下面这些词法单元: let 、a、&#x3D;、1 ，空格是否被当成词法单元，取决于空格在这门语言中的意义。 解析&#x2F;语法分析 这个过程是将词法单元流转换成一个由元素嵌套所组成的代表了程序语法结构的树,这个树被称为”抽象语法树”（abstract syntax code，AST） 代码生成 将AST转换成可执行代码的过程被称为代码生成. 名词解释1.普通Node,不是特定语法结构,属于某个语法结构的一部分 Comment 表示一行注释 &#x2F;&#x2F; 或者 &#x2F; &#x2F; CommentGroup 表示多行注释 Field 表示结构体中的一个定义或者变量,或者函数签名当中的参数或者返回值 FieldList 表示以”{}”或者”()”包围的Filed列表 2.Expression &amp; Types (表达式和类型) BadExpr 包含语法错误的表达式的占位符，不能创建正确的表达式节点 Ident 比如包名,函数名,变量名 Ellipsis 省略号表达式,比如参数列表的最后一个可以写成 arg… BasicLit 基本类型,数字或者字符串 FuncLit 函数定义 CompositeLit 构造类型,比如{1,2,3,4} ParenExpr 括号表达式,被括号包裹的表达式 SelectorExpr 选择结构,类似于a.b的结构 IndexExpr 下标结构,类似这样的结构 expr[expr] SliceExpr 切片表达式,类似这样 expr[low:mid:high] TypeAssertExpr 类型断言类似于 X.(type) CallExpr 调用类型,类似于 expr() StarExpr 表达式,类似于 *X UnaryExpr 一元表达式 BinaryExpr 二元表达式 KeyValueExp 键值表达式 key:value ArrayType 数组或切片类型 StructType 结构体类型 FuncType 函数类型 InterfaceType 接口类型 MapType map类型 ChanType 管道类型 3.Statements （语句，一段代码） BadStmt 包含语法错误的语句的占位符，其中不能创建正确的语句节点 DeclStmt 在语句列表里的申明 EmptyStmt 空语句 LabeledStmt 标签语句类似于 indent:stmt ExprStmt 包含单独的表达式语句(例如：fmt.Printf()) SendStmt chan发送语句 IncDecStmt 自增或者自减语句 AssignStmt 表示赋值或短变量声明 GoStmt Go语句 DeferStmt 延迟语句 ReturnStmt return 语句 BranchStmt 分支语句 例如break continue BlockStmt 块语句 {} 包裹 IfStmt If 语句 CaseClause case 语句 SwitchStmt switch 语句 TypeSwitchStmt 类型switch 语句 switch x:&#x3D;y.(type) CommClause 发送或者接受的case语句,类似于 case x &lt;-: SelectStmt select 语句 ForStmt for 循环语句 RangeStmt range 语句 4.Declarations 声明 ImportSpec 导包声明 ValueSpec 常量或变量声明（ConstSpec 或 VarSpec 生成） TypeSpec 类型声明 BadDecl 包含语法错误的声明的占位符，其中不能创建正确的声明节点。 GenDecl 一般申明(和Spec相关,比如 import “a”,var a,type a) FuncDecl 函数申明 5.Files and Packages File 代表一个源文件节点,包含了顶级元素. Package 代表一个包,包含了很多文件. ast体验一个在线的go源码转ast网站： https://yuroyoro.github.io/goast-viewer/index.html 源码 foo.go package main import ( &quot;fmt&quot; ) var test = &quot;hello go&quot; func main() &#123; fmt.Printf(&quot;Hello, Golang\\n&quot;) &#125; ast 0 *ast.File &#123; 1 . Doc: nil 2 . Package: foo:1:1 3 . Name: *ast.Ident &#123; 4 . . NamePos: foo:1:9 5 . . Name: &quot;main&quot; 6 . . Obj: nil 7 . &#125; 8 . Decls: []ast.Decl (len = 3) &#123; 9 . . 0: *ast.GenDecl &#123; 10 . . . Doc: nil 11 . . . TokPos: foo:3:1 12 . . . Tok: import 13 . . . Lparen: foo:3:8 14 . . . Specs: []ast.Spec (len = 1) &#123; 15 . . . . 0: *ast.ImportSpec &#123; 16 . . . . . Doc: nil 17 . . . . . Name: nil 18 . . . . . Path: *ast.BasicLit &#123; 19 . . . . . . ValuePos: foo:4:2 20 . . . . . . Kind: STRING 21 . . . . . . Value: &quot;\\&quot;fmt\\&quot;&quot; 22 . . . . . &#125; 23 . . . . . Comment: nil 24 . . . . . EndPos: - 25 . . . . &#125; 26 . . . &#125; 27 . . . Rparen: foo:5:1 28 . . &#125; 29 . . 1: *ast.GenDecl &#123; 30 . . . Doc: nil 31 . . . TokPos: foo:7:1 32 . . . Tok: var 33 . . . Lparen: - 34 . . . Specs: []ast.Spec (len = 1) &#123; 35 . . . . 0: *ast.ValueSpec &#123; 36 . . . . . Doc: nil 37 . . . . . Names: []*ast.Ident (len = 1) &#123; 38 . . . . . . 0: *ast.Ident &#123; 39 . . . . . . . NamePos: foo:7:5 40 . . . . . . . Name: &quot;test&quot; 41 . . . . . . . Obj: *ast.Object &#123; 42 . . . . . . . . Kind: var 43 . . . . . . . . Name: &quot;test&quot; 44 . . . . . . . . Decl: *(obj @ 35) 45 . . . . . . . . Data: 0 46 . . . . . . . . Type: nil 47 . . . . . . . &#125; 48 . . . . . . &#125; 49 . . . . . &#125; 50 . . . . . Type: nil 51 . . . . . Values: []ast.Expr (len = 1) &#123; 52 . . . . . . 0: *ast.BasicLit &#123; 53 . . . . . . . ValuePos: foo:7:12 54 . . . . . . . Kind: STRING 55 . . . . . . . Value: &quot;\\&quot;hello go\\&quot;&quot; 56 . . . . . . &#125; 57 . . . . . &#125; 58 . . . . . Comment: nil 59 . . . . &#125; 60 . . . &#125; 61 . . . Rparen: - 62 . . &#125; 63 . . 2: *ast.FuncDecl &#123; 64 . . . Doc: nil 65 . . . Recv: nil 66 . . . Name: *ast.Ident &#123; 67 . . . . NamePos: foo:9:6 68 . . . . Name: &quot;main&quot; 69 . . . . Obj: *ast.Object &#123; 70 . . . . . Kind: func 71 . . . . . Name: &quot;main&quot; 72 . . . . . Decl: *(obj @ 63) 73 . . . . . Data: nil 74 . . . . . Type: nil 75 . . . . &#125; 76 . . . &#125; 77 . . . Type: *ast.FuncType &#123; 78 . . . . Func: foo:9:1 79 . . . . Params: *ast.FieldList &#123; 80 . . . . . Opening: foo:9:10 81 . . . . . List: nil 82 . . . . . Closing: foo:9:11 83 . . . . &#125; 84 . . . . Results: nil 85 . . . &#125; 86 . . . Body: *ast.BlockStmt &#123; 87 . . . . Lbrace: foo:9:13 88 . . . . List: []ast.Stmt (len = 1) &#123; 89 . . . . . 0: *ast.ExprStmt &#123; 90 . . . . . . X: *ast.CallExpr &#123; 91 . . . . . . . Fun: *ast.SelectorExpr &#123; 92 . . . . . . . . X: *ast.Ident &#123; 93 . . . . . . . . . NamePos: foo:10:2 94 . . . . . . . . . Name: &quot;fmt&quot; 95 . . . . . . . . . Obj: nil 96 . . . . . . . . &#125; 97 . . . . . . . . Sel: *ast.Ident &#123; 98 . . . . . . . . . NamePos: foo:10:6 99 . . . . . . . . . Name: &quot;Printf&quot; 100 . . . . . . . . . Obj: nil 101 . . . . . . . . &#125; 102 . . . . . . . &#125; 103 . . . . . . . Lparen: foo:10:12 104 . . . . . . . Args: []ast.Expr (len = 1) &#123; 105 . . . . . . . . 0: *ast.BasicLit &#123; 106 . . . . . . . . . ValuePos: foo:10:13 107 . . . . . . . . . Kind: STRING 108 . . . . . . . . . Value: &quot;\\&quot;Hello, Golang\\\\n\\&quot;&quot; 109 . . . . . . . . &#125; 110 . . . . . . . &#125; 111 . . . . . . . Ellipsis: - 112 . . . . . . . Rparen: foo:10:30 113 . . . . . . &#125; 114 . . . . . &#125; 115 . . . . &#125; 116 . . . . Rbrace: foo:11:1 117 . . . &#125; 118 . . &#125; 119 . &#125; 120 . Scope: *ast.Scope &#123; 121 . . Outer: nil 122 . . Objects: map[string]*ast.Object (len = 2) &#123; 123 . . . &quot;main&quot;: *(obj @ 69) 124 . . . &quot;test&quot;: *(obj @ 41) 125 . . &#125; 126 . &#125; 127 . Imports: []*ast.ImportSpec (len = 1) &#123; 128 . . 0: *(obj @ 15) 129 . &#125; 130 . Unresolved: []*ast.Ident (len = 1) &#123; 131 . . 0: *(obj @ 92) 132 . &#125; 133 . Comments: nil 134 &#125; 用法示例打印代码中的所有字符串 func extractString() error &#123; fset := token.NewFileSet() astFile, err := parser.ParseFile(fset, &quot;main.go&quot;, nil, parser.ParseComments|parser.AllErrors) if err != nil &#123; return err &#125; ast.Inspect(astFile, func(n ast.Node) bool &#123; switch x := n.(type) &#123; case *ast.BasicLit: s, _ := strconv.Unquote(x.Value) if len(s) &gt; 0 &amp;&amp; x.Kind == token.STRING &#123; fmt.Println(s) &#125; &#125; return true &#125;) return nil &#125;","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"golang","slug":"技术开发/golang","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/"}],"tags":[{"name":"go ast","slug":"go-ast","permalink":"https://tianxiafeiyu.github.io/tags/go-ast/"}]},{"title":"go csp并发模型","slug":"技术开发/golang/go csp并发模型","date":"2022-12-15T23:19:22.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/golang/go csp并发模型/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/go%20csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"CSP（communicating sequential processes）并发模型 Do not communicate by sharing memory; instead, share memory by communicating.“不要以共享内存的方式来通信，相反，要通过通信来共享内存。”","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"golang","slug":"技术开发/golang","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/"}],"tags":[{"name":"go csp并发模型","slug":"go-csp并发模型","permalink":"https://tianxiafeiyu.github.io/tags/go-csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"}]},{"title":"go gc","slug":"技术开发/golang/go gc","date":"2022-12-15T23:16:40.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/golang/go gc/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/go%20gc/","excerpt":"","text":"https://www.cnblogs.com/HinaChan/p/14842521.html GoGC机制垃圾回收(Garbage Collection，简称GC)是编程语言中提供的自动的内存管理机制，自动释放不需要的对象，让出存储器资源，无需程序员手动执行。 Golang中的垃圾回收主要应用三色标记法，GC过程和其他用户goroutine可并发运行，但需要一定时间的STW(stop the world)，STW的过程中，CPU不执行用户代码，全部用于垃圾回收，这个过程的影响很大，Golang进行了多次的迭代优化来解决这个问题。 一、Go V1.3之前的标记-清除(mark and sweep)算法此算法主要有两个主要的步骤： 标记(Mark phase)：暂停程序业务逻辑, 找出不可达的对象，然后做上标记。 清除(Sweep phase)：回收标记好的对象。 注意：mark and sweep算法在执行的时候，需要程序暂停！即 STW(stop the world)。也就是说，这段时间程序会卡在哪儿。 第一步，暂停程序业务逻辑 第二步, 开始标记，程序找出它所有可达的对象，并做上标记。 第三步, 标记完了之后，然后开始清除未标记的对象。 第四步, 停止暂停，让程序继续跑。然后循环重复这个过程，直到process程序生命周期结束。 缺点： STW，stop the world；让程序暂停，程序出现卡顿 (重要问题)。 标记需要扫描整个heap 清除数据会产生heap碎片 Go V1.3 做了简单的优化,将STW提前, STW结束后再清除 二、Go V1.5的三色并发标记法三色标记法 实际上就是通过三个阶段的标记来确定清除的对象都有哪些 第一步 , 就是只要是新创建的对象,默认的颜色都是标记为“白色” 第二步, 每次GC回收开始, 然后从根节点开始遍历所有对象（直接子节点），把遍历到的对象从白色集合放入“灰色”集合 第三步, 遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，之后将此灰色对象放入黑色集合 第四步, 重复第三步, 直到灰色中无任何对象 第五步: 回收所有的白色标记表的对象. 也就是回收垃圾 有点类似于人群中找人：寻找所有小明的朋友（朋友的朋友也是朋友）： 一开始，所有的人都在房间A 从小明开始，找到小明的所有朋友，放置到房间B 找到房间B的人里所有在房间A的朋友，放置到房间B，找完的人放到房间C 继续上一步，知道房间B没有人为止 解散房间A的人 没有STW的三色标记法屏障机制 我们让GC回收器,满足下面两种情况之一时,可保对象不丢失： “强-弱” 三色不变式 强三色不变式：不存在黑色对象引用到白色对象的指针。 弱三色不变式：所有被黑色对象引用的白色对象都处于灰色保护状态。 插入屏障具体操作: 在A对象引用B对象的时候，B对象被标记为灰色。(将B挂在A下游，B必须被标记为灰色) 满足: 强三色不变式.(不存在黑色对象引用白色对象的情况了， 因为白色会强制变成灰色) 伪码如下: 1234567添加下游对象(当前下游对象slot, 新下游对象ptr) &#123; //1 标记灰色(新下游对象ptr) //2 当前下游对象slot = 新下游对象ptr &#125; 场景： 12A.添加下游对象(nil, B) //A 之前没有下游， 新添加一个下游对象B， B被标记为灰色A.添加下游对象(C, B) //A 将下游对象C 更换为B， B被标记为灰色这段伪码逻辑就是写屏障,. 我们知道,黑色对象的内存槽有两种位置, 栈和堆. 栈空间的特点是容量小,但是要求相应速度快,因为函数调用弹出频繁使用, 所以“插入屏障”机制,在栈空间的对象操作中不使用. 而仅仅使用在堆空间对象的操作中。 栈中对象会额外进行一次STW的染色操作 删除屏障具体操作: 被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。 满足: 弱三色不变式. (保护灰色对象到白色对象的路径不会断) 伪代码： 123456789添加下游对象(当前下游对象slot， 新下游对象ptr) &#123; //1 if (当前下游对象slot是灰色 || 当前下游对象slot是白色) &#123; 标记灰色(当前下游对象slot) //slot为被删除对象， 标记为灰色 &#125; //2 当前下游对象slot = 新下游对象ptr&#125; 场景： 12A.添加下游对象(B, nil) //A对象，删除B对象的引用。 B被A删除，被标记为灰(如果B之前为白)A.添加下游对象(B, C) //A对象，更换下游B变成C。 B被A删除，被标记为灰(如果B之前为白) 我的理解，插入屏障和删除屏障，都是在引用关系发生变化时，将引用关系被修改的对象置为灰色，保护起来，放置在cg期间被清理掉","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"golang","slug":"技术开发/golang","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/"}],"tags":[{"name":"go gc","slug":"go-gc","permalink":"https://tianxiafeiyu.github.io/tags/go-gc/"}]},{"title":"xorm使用","slug":"技术开发/golang/xorm使用","date":"2022-12-15T23:16:40.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/golang/xorm使用/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/xorm%E4%BD%BF%E7%94%A8/","excerpt":"","text":"xormxorm是一个简单而强大的Go语言ORM库. 通过它可以使数据库操作非常简便。 特性 支持Struct和数据库表之间的灵活映射，并支持自动同步 事务支持 同时支持原始SQL语句和ORM操作的混合执行 使用连写来简化调用 支持使用Id, In, Where, Limit, Join, Having, Table, Sql, Cols等函数和结构体等方式作为条件 支持级联加载Struct Schema支持（仅Postgres） 支持缓存 支持根据数据库自动生成xorm的结构体 支持记录版本（即乐观锁） 内置SQL Builder支持 上下文缓存支持 驱动支持目前支持的Go数据库驱动和对应的数据库如下： Mysql: github.com&#x2F;go-sql-driver&#x2F;mysql MyMysql: github.com&#x2F;ziutek&#x2F;mymysql&#x2F;godrv Postgres: github.com&#x2F;lib&#x2F;pq Tidb: github.com&#x2F;pingcap&#x2F;tidb SQLite: github.com&#x2F;mattn&#x2F;go-sqlite3 MsSql: github.com&#x2F;denisenkom&#x2F;go-mssqldb MsSql: github.com&#x2F;lunny&#x2F;godbc Oracle: github.com&#x2F;mattn&#x2F;go-oci8 (试验性支持) 安装go get xorm.io/xorm 文档 操作指南 Godoc代码文档 快速开始 第一步创建引擎，driverName, dataSourceName和database&#x2F;sql接口相同 1engine, err := xorm.NewEngine(driverName, dataSourceName) 定义一个和表同步的结构体，并且自动同步结构体到数据库 1234567891011type User struct &#123; Id int64 Name string Salt string Age int Passwd string `xorm:&quot;varchar(200)&quot;` Created time.Time `xorm:&quot;created&quot;` Updated time.Time `xorm:&quot;updated&quot;`&#125;err := engine.Sync2(new(User)) 创建Engine组 12dataSourceNameSlice := []string&#123;masterDataSourceName, slave1DataSourceName, slave2DataSourceName&#125;engineGroup, err := xorm.NewEngineGroup(driverName, dataSourceNameSlice) 1234masterEngine, err := xorm.NewEngine(driverName, masterDataSourceName)slave1Engine, err := xorm.NewEngine(driverName, slave1DataSourceName)slave2Engine, err := xorm.NewEngine(driverName, slave2DataSourceName)engineGroup, err := xorm.NewEngineGroup(masterEngine, []*Engine&#123;slave1Engine, slave2Engine&#125;) 所有使用 engine 都可以简单的用 engineGroup 来替换。 Query 最原始的也支持SQL语句查询，返回的结果类型为 []map[string][]byte。QueryString 返回 []map[string]string, QueryInterface 返回 []map[string]interface&#123;&#125;. 12345678results, err := engine.Query(&quot;select * from user&quot;)results, err := engine.Where(&quot;a = 1&quot;).Query()results, err := engine.QueryString(&quot;select * from user&quot;)results, err := engine.Where(&quot;a = 1&quot;).QueryString()results, err := engine.QueryInterface(&quot;select * from user&quot;)results, err := engine.Where(&quot;a = 1&quot;).QueryInterface() Exec 执行一个SQL语句 1affected, err := engine.Exec(&quot;update user set age = ? where name = ?&quot;, age, name) Insert 插入一条或者多条记录 12345678910111213affected, err := engine.Insert(&amp;user)// INSERT INTO struct () values ()affected, err := engine.Insert(&amp;user1, &amp;user2)// INSERT INTO struct1 () values ()// INSERT INTO struct2 () values ()affected, err := engine.Insert(&amp;users)// INSERT INTO struct () values (),(),()affected, err := engine.Insert(&amp;user1, &amp;users)// INSERT INTO struct1 () values ()// INSERT INTO struct2 () values (),(),() Get 查询单条记录 &#96;&#96;&#96;Gohas, err :&#x3D; engine.Get(&amp;user)&#x2F;&#x2F; SELECT * FROM user LIMIT 1 has, err :&#x3D; engine.Where(“name &#x3D; ?”, name).Desc(“id”).Get(&amp;user)&#x2F;&#x2F; SELECT * FROM user WHERE name &#x3D; ? ORDER BY id DESC LIMIT 1 var name stringhas, err :&#x3D; engine.Table(&amp;user).Where(“id &#x3D; ?”, id).Cols(“name”).Get(&amp;name)&#x2F;&#x2F; SELECT name FROM user WHERE id &#x3D; ? var id int64has, err :","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"golang","slug":"技术开发/golang","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/"}],"tags":[{"name":"xorm使用","slug":"xorm使用","permalink":"https://tianxiafeiyu.github.io/tags/xorm%E4%BD%BF%E7%94%A8/"}]},{"title":"go checklist","slug":"技术开发/golang/go checklist","date":"2022-12-15T23:13:57.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/golang/go checklist/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/go%20checklist/","excerpt":"","text":"go checklist2. 介绍本文档参考开源(Urber)编码规范整理，记录 Go 代码中的惯用约定、规范，其中许多是 Go 语言的通用准则，期望通过引入业界最佳实践来提升团队编码能力，规范编码习惯，提高代码质量。 其他扩展准则依赖于下面外部的指南： Effective Go Go Common Mistakes Go Code Review Comments 3. 规范实施方法本规范作为Go语言编码的基本规范和准则，是代码自检和检视的参考文档，配合各部门编码checklist，共同看护编码质量。本规范中未标明非强制的规范和准则，均为强制规范&#x2F;准则。 4. 工程要求4.1. IDE 中集成下述工具插件 提交代码时，必须使用 gofmt 工具格式化代码。注意，gofmt 不识别空行，因为 gofmt 不能理解空行的意义。 提交代码前，必须使用 goimports 工具检查导入。 提交代码时，必须使用 golint 工具检查代码规范。 提交代码前，必须使用 go vet 工具静态分析代码实现 可以在以下 Go 编辑器工具支持页面中找到更为详细的信息： https://github.com/golang/go/wiki/IDEsAndTextEditorPlugins 5. 规范5.1. 基本约定5.1.1. 文件、函数大小约定单行长度尽量限制为 99个 字符 。 单个文件长度尽量不超过 500 行。 单个函数长度尽量不超过 50 行。 单个函数圈复杂度尽量不超过 10，禁止超过 15。 单个函数中嵌套尽量不超过 3 层。 这不是硬性限制，但是超过此限制需要向reviewer做适当解释。 5.1.2. 缩进、括号和空格约定缩进、括号和空格都使用 gofmt 工具处理。 强制使用 tab 缩进。 强制左大括号不换行。 强制所有的运算符和操作数之间要留空格。 5.1.3. 一致性本文中概述的一些标准都是客观性的评估，是根据场景、上下文、或者主观性的判断； 但是最重要的是，保持一致. 一致性的代码更容易维护、是更合理的、需要更少的学习成本、并且随着新的约定出现或者出现错误后更容易迁移、更新、修复 bug 相反，在一个代码库中包含多个完全不同或冲突的代码风格会导致维护成本开销、不确定性和认知偏差。所有这些都会直接导致速度降低、代码审查痛苦、而且增加 bug 数量。 将这些标准应用于代码库时，建议在 package（或更大）级别进行更改，子包级别的应用程序通过将多个样式引入到同一代码中，违反了上述关注点。 5.2. 分组规范5.2.1. 相似的声明放在一组Go 语言支持将相似的声明放在一个组内。 Bad 12import &quot;a&quot;import &quot;b&quot; Good 1234import ( &quot;a&quot; &quot;b&quot;) 这同样适用于常量、变量和类型声明： Bad 12345678const a = 1const b = 2var a = 1var b = 2type Area float64type Volume float64 Good 1234567891011121314const ( a = 1 b = 2)var ( a = 1 b = 2)type ( Area float64 Volume float64) 仅将相关的声明放在一组。不要将不相关的声明放在一组。 Bad 12345678type Operation intconst ( Add Operation = iota + 1 Subtract Multiply EnvVar = &quot;MY_ENV&quot;) Good 123456789type Operation intconst ( Add Operation = iota + 1 Subtract Multiply)const EnvVar = &quot;MY_ENV&quot; 分组使用的位置没有限制，例如：你可以在函数内部使用它们： Bad 1234567func f() string &#123; red := color.New(0xff0000) green := color.New(0x00ff00) blue := color.New(0x0000ff) ...&#125; Good 123456789func f() string &#123; var ( red = color.New(0xff0000) green = color.New(0x00ff00) blue = color.New(0x0000ff) ) ...&#125; 例外：如果变量声明与其他变量相邻，则应将变量声明（尤其是函数内部的声明）分组在一起。对一起声明的变量执行此操作，即使它们不相关。 Bad1234567func (c *client) request() &#123; caller := c.name format := &quot;json&quot; timeout := 5*time.Second var err error // ...&#125; Good12345678910func (c *client) request() &#123; var ( caller = c.name format = &quot;json&quot; timeout = 5*time.Second err error ) // ...&#125; 5.2.2. import 分组规范导入应该分为三组： 标准库 内部库 其他库 默认情况下，这是 goimports 应用的分组。 Bad 123456import ( &quot;fmt&quot; &quot;os&quot; &quot;go.sangfor.org/cloudtech/resourcecenter&quot; &quot;golang.org/x/sync/errgroup&quot;) Good 12345678910import ( &quot;fmt&quot; &quot;os&quot; &quot;go.sangfor.org/cloudtech/resourcecenter&quot; &quot;go.uber.org/atomic&quot; &quot;golang.org/x/sync/errgroup&quot;) 5.2.3. 函数分组与顺序函数应按粗略的调用顺序排序。 同一文件中的函数应按接收者分组。 因此，导出的函数应先出现在文件中，放在struct, const, var定义的后面。 在定义类型之后，但在接收者的其余方法之前，可能会出现一个 newXYZ()&#x2F;NewXYZ() 由于函数是按接收者分组的，因此普通工具函数应在文件末尾出现。 Bad12345678910111213func (s *something) Cost() &#123; return calcCost(s.weights)&#125;type something struct&#123; ... &#125;func calcCost(n []int) int &#123;...&#125;func (s *something) Stop() &#123;...&#125;func newSomething() *something &#123; return &amp;something&#123;&#125;&#125; Good12345678910111213type something struct&#123; ... &#125;func newSomething() *something &#123; return &amp;something&#123;&#125;&#125;func (s *something) Cost() &#123; return calcCost(s.weights)&#125;func (s *something) Stop() &#123;...&#125;func calcCost(n []int) int &#123;...&#125; 5.3. 命名规范5.3.1. 包名当命名包时，请按下面规则选择一个名称： 全部小写。没有大写或下划线。 大多数使用命名导入的情况下，不需要重命名。 简短而简洁。请记住，在每个使用的地方都完整标识了该名称。 不用复数。例如net&#x2F;url，而不是net&#x2F;urls。 不要用“common”，“util”，“shared”或“lib”。这些是不好的，信息量不足的名称。 另请参阅 Go 包命名规则 和 Go 包样式指南. 5.3.2. 文件名文件名为全小写单词，使用 “_” 分词。Golang 通常具有以下几种代码文件类型： 业务代码文件 模型代码文件 测试代码文件 工具代码文件 5.3.3. 函数名遵循 Go 社区关于使用 MixedCaps 作为函数名 的约定。 函数、方法（结构体或者接口下属的函数称为方法）命名规则： 动词 + 名词。 若函数、方法为判断类型（返回值主要为 bool 类型），则名称应以 Has、Is、Can 或 Allow 等判断性动词开头： 1234func HasPrefix(name string, prefixes []string) bool &#123; ... &#125;func IsEntry(name string, entries []string) bool &#123; ... &#125;func CanManage(name string) bool &#123; ... &#125;func AllowGitHook() bool &#123; ... &#125; 有一个例外，为了对相关的测试用例进行分组，函数名可能包含下划线，如：TestMyFunction_WhatIsBeingTested. 5.3.4. 结构体、接口名结构体命名规则：名词或名词短语。 接口命名规则：以 ”er” 作为后缀，例如：Reader、Writer。接口实现的方法则去掉 “er”，例如：Read、Write。 123456type Reader interface &#123; Read(p []byte) (n int, err error)&#125;// 多个函数接口type WriteFlusher interface &#123; Write([]byte) (int, error) Flush() error&#125; 5.3.5. 变量、常量名变量命名遵循驼峰法。 常量使用全大写单词，使用 “_” 分词。 首字母根据访问控制原则使用大写或者小写。 对于常规缩略语，一旦选择了大写或小写的风格，就应当在整份代码中保持这种风格，不要首字母大写和缩写两种风格混用。以 URL 为例，如果选择了缩写 URL 这种风格，则应在整份代码中保持。错误：UrlArray，正确：urlArray 或 URLArray。再以 ID 为例，如果选择了缩写 ID 这种风格，错误：appleId，正确：appleID。对于只在本文件中有效的顶级变量、常量，应该使用 “_” 前缀，避免在同一个包中的其他文件中意外使用错误的值。例如： 1234var ( _defaultPort = 8080 _defaultUser = &quot;user&quot;) 5.3.6. 导入别名如果程序包名称与导入路径的最后一个元素不匹配，则必须使用导入别名。 123456import ( &quot;net/http&quot; client &quot;example.com/client-go&quot; trace &quot;example.com/trace/v2&quot;) 在所有其他情况下，除非导入之间有直接冲突，否则应避免导入别名。 Bad 123456import ( &quot;fmt&quot; &quot;os&quot; nettrace &quot;golang.net/x/trace&quot;) Good 1234567import ( &quot;fmt&quot; &quot;os&quot; &quot;runtime/trace&quot; nettrace &quot;golang.net/x/trace&quot;) 5.4. 注释规范Golang 的 go doc 工具可以根据注释生成代码文档，所以注释的质量决定了代码文档的质量。 【强制】所有新增代码文件需添加版权声明 1/* Copyright @2022 Sangfor Technologies. All rights reserved. */ 5.4.1. 注释风格统一使用中文注释，中西文之间严格使用空格分隔，严格使用中文标点符号。 注释应当是一个完整的句子，以句号结尾。 句子类型的注释首字母均需大写，短语类型的注释首字母需小写。 注释的单行长度不能超过 99 个字符。 5.4.2. 包注释每个包都应该有一个包注释。包注释应该包含： 123包名，简介。创建者(使用团队名，个人名只在提交记录中体现，不在代码中体现)。创建时间。 对于 main 包，通常只有一行简短的注释用以说明包的用途，且以项目名称开头： 12// gormc(Go Resource Management Service) 是资源分配服务.package main 对于简单的非 main 包，也可用一行注释概括。 对于一个复杂项目的子包，一般情况下不需要包级别注释，除非是代表某个特定功能的模块。 对于相对功能复杂的非 main 包，一般都会增加一些使用示例或基本说明，且以 Package 开头： 12/* 包regexp 实现了一个简单的正则匹配库. 基本使用语法: regexp: concatenation &#123; &#x27;|&#x27; concatenation &#125; concatenation: &#123; closure &#125; closure: term [ &#x27;*&#x27; | &#x27;+&#x27; | &#x27;?&#x27; ] term: &#x27;^&#x27; &#x27;$&#x27; &#x27;.&#x27; character &#x27;[&#x27; [ &#x27;^&#x27; ] character-ranges &#x27;]&#x27; &#x27;(&#x27; regexp &#x27;)&#x27; */package regexp 对于特别复杂的包说明，一般使用 doc.go 文件用于编写包的描述，并提供与整个包相关的信息。 5.4.3. 函数、方法注释每个函数、方法（结构体或者接口下属的函数称为方法）都应该有注释说明，包括三个方面（顺序严格）： 函数、方法名，简要说明。 参数列表，每行一个参数。 返回值，每行一个返回值。123456// NewtAttrModel，属性数据层操作类的工厂方法。// 参数：// ctx：上下文信息。// 返回值：// 属性操作类指针。func NewAttrModel(ctx *common.Context) *AttrModel &#123;&#125; 如果一句话不足以说明全部问题，则可换行继续进行更加细致的描述：12// 复制函数将文件从源地址复制到目的地址.// 失败场景下返回false或error. 若函数或方法为判断类型（返回值主要为 bool 类型），则注释以&lt;函数名&gt; returns true if 开头：12// HasPrefix 返回 true，如果输入的name参数包含指定的prefix.func HasPrefix(name string, prefixes []string) bool &#123; ... 5.4.4. 结构体、接口注释每个自定义的结构体、接口都应该有注释说明，放在实体定义的前一行，格式为：名称、说明。同时，结构体内的每个成员都要有说明，该说明放在成员变量的后面（注意对齐），例如： 12345// User，用户实例，定义了用户的基础信息。type User struct&#123; Username string // 用户名 Email string // 邮箱&#125; 5.4.5. 其它说明当某个部分等待完成时，用 TODO(Your name): 开头的注释来提醒维护人员。 当某个部分存在已知问题进行需要修复或改进时，用 FIXME(Your name): 开头的注释来提醒维护人员。 当需要特别说明某个问题时，可用 NOTE(You name): 开头的注释。 5.5. 单元测试规范5.5.1. 测试命名和提交规范单元测试都必须使用 GoConvey 编写，且覆盖率必须在 80% 以上。 业务代码文件和单元测试文件放在同一目录下。 单元测试文件名以 *_test.go 为后缀，例如：example_test.go。 测试用例的函数名称必须以 Test 开头，例如：Test_Logger。 如果为结构体的方法编写测试用例，则需要以 Text__的形式命名，例如：Test_Macaron_Run。 每个重要的函数都要同步编写测试用例。 测试用例和业务代码同步提交，方便进行回归测试。 5.5.2. 表驱动测试当测试逻辑是重复的时候，通过 subtests 使用 table 驱动的方式编写 case 代码看上去会更简洁。 Bad123456789101112131415161718192021// func TestSplitHostPort(t *testing.T)host, port, err := net.SplitHostPort(&quot;192.0.2.0:8000&quot;)require.NoError(t, err)assert.Equal(t, &quot;192.0.2.0&quot;, host)assert.Equal(t, &quot;8000&quot;, port)host, port, err = net.SplitHostPort(&quot;192.0.2.0:http&quot;)require.NoError(t, err)assert.Equal(t, &quot;192.0.2.0&quot;, host)assert.Equal(t, &quot;http&quot;, port)host, port, err = net.SplitHostPort(&quot;:8000&quot;)require.NoError(t, err)assert.Equal(t, &quot;&quot;, host)assert.Equal(t, &quot;8000&quot;, port)host, port, err = net.SplitHostPort(&quot;1:8&quot;)require.NoError(t, err)assert.Equal(t, &quot;1&quot;, host)assert.Equal(t, &quot;8&quot;, port) Good12345678910111213141516171819202122232425262728293031323334353637// func TestSplitHostPort(t *testing.T)tests := []struct&#123; give string wantHost string wantPort string&#125;&#123; &#123; give: &quot;192.0.2.0:8000&quot;, wantHost: &quot;192.0.2.0&quot;, wantPort: &quot;8000&quot;, &#125;, &#123; give: &quot;192.0.2.0:http&quot;, wantHost: &quot;192.0.2.0&quot;, wantPort: &quot;http&quot;, &#125;, &#123; give: &quot;:8000&quot;, wantHost: &quot;&quot;, wantPort: &quot;8000&quot;, &#125;, &#123; give: &quot;1:8&quot;, wantHost: &quot;1&quot;, wantPort: &quot;8&quot;, &#125;,&#125;for _, tt := range tests &#123; t.Run(tt.give, func(t *testing.T) &#123; host, port, err := net.SplitHostPort(tt.give) require.NoError(t, err) assert.Equal(t, tt.wantHost, host) assert.Equal(t, tt.wantPort, port) &#125;)&#125; 很明显，使用 test table 的方式在代码逻辑扩展的时候，比如新增 test case，都会显得更加的清晰。 我们遵循这样的约定：将结构体切片称为tests。 每个测试用例称为tt。此外，我们鼓励使用give和want前缀说明每个测试用例的输入和输出值。 1234567891011tests := []struct&#123; give string wantHost string wantPort string&#125;&#123; // ...&#125;for _, tt := range tests &#123; // ...&#125; 5.6. 代码逻辑规范5.6.1. 变量声明规范5.6.1.1. 顶层变量声明规范在顶层，使用标准var关键字。请勿指定类型，除非它与表达式的类型不同。 Bad 123var _s string = F()func F() string &#123; return &quot;A&quot; &#125; Good 12345var _s = F()// 由于 F 已经明确了返回一个字符串类型，因此我们没有必要显式指定_s 的类型// 还是那种类型func F() string &#123; return &quot;A&quot; &#125; 如果表达式的类型与所需的类型不完全匹配，请指定类型。 12345678type myError struct&#123;&#125;func (myError) Error() string &#123; return &quot;error&quot; &#125;func F() myError &#123; return myError&#123;&#125; &#125;var _e error = F()// F 返回一个 myError 类型的实例，但是我们要 error 类型 5.6.1.2. 未导出的顶层常量和变量，使用_作为前缀在未导出的顶级vars和consts， 前面加上前缀_，以使它们在使用时明确表示它们是全局符号。 例外：未导出的错误值，应以err开头。 基本依据：顶级变量和常量具有包范围作用域。使用通用名称可能很容易在其他文件中意外使用错误的值。 Bad 1234567891011121314151617// foo.goconst ( defaultPort = 8080 defaultUser = &quot;user&quot;)// bar.gofunc Bar() &#123; defaultPort := 9090 ... fmt.Println(&quot;Default port&quot;, defaultPort) // We will not see a compile error if the first line of // Bar() is deleted.&#125; Good 123456// foo.goconst ( _defaultPort = 8080 _defaultUser = &quot;user&quot;) Exception:未导出的错误值可以使用不带下划线的前缀 err。 参见错误命名。 5.6.1.3. 本地变量声明如果将变量明确设置为某个值，则应使用短变量声明形式 (:&#x3D;)。 12var s = &quot;foo&quot;s := &quot;foo&quot; 但是，在某些情况下，var 使用关键字时默认值会更清晰。例如，声明空切片。 Bad 12345678func f(list []int) &#123; filtered := []int&#123;&#125; for _, v := range list &#123; if v &gt; 10 &#123; filtered = append(filtered, v) &#125; &#125;&#125; Good 12345678func f(list []int) &#123; var filtered []int for _, v := range list &#123; if v &gt; 10 &#123; filtered = append(filtered, v) &#125; &#125;&#125; 5.6.1.4. 缩小变量作用域如果有可能，尽量缩小变量作用范围。除非它与 减少嵌套的规则冲突。 Bad1234err := ioutil.WriteFile(name, data, 0644)if err != nil &#123; return err&#125; Good123if err := ioutil.WriteFile(name, data, 0644); err != nil &#123; return err&#125; 如果需要在 if 之外使用函数调用的结果，则不应尝试缩小范围。 Bad1234567891011if data, err := ioutil.ReadFile(name); err == nil &#123; err = cfg.Decode(data) if err != nil &#123; return err &#125; fmt.Println(cfg) return nil&#125; else &#123; return err&#125; Good1234567891011data, err := ioutil.ReadFile(name)if err != nil &#123; return err&#125;if err := cfg.Decode(data); err != nil &#123; return err&#125;fmt.Println(cfg)return nil 5.6.2. 函数定义规范5.6.2.1. 避免参数语义不明确 (Avoid Naked Parameters)函数调用中的意义不明确的参数可能会损害可读性。当参数名称的含义不明显时，请为参数添加 C 样式注释 (/* ... */) Bad123// func printInfo(name string, isLocal, done bool)printInfo(&quot;foo&quot;, true, true) Good123// func printInfo(name string, isLocal, done bool)printInfo(&quot;foo&quot;, true /* isLocal */, true /* done */) 对于上面的示例代码，还有一种更好的处理方式是将上面的 bool 类型换成自定义类型。将来，该参数可以支持不仅仅局限于两个状态（true&#x2F;false）。12345678910111213141516type Region intconst ( UnknownRegion Region = iota Local)type Status intconst ( StatusReady Status= iota + 1 StatusDone // Maybe we will have a StatusInProgress in the future.)func printInfo(name string, region Region, status Status) 5.6.2.2. 避免使用 init()尽可能避免使用init()。当init()是不可避免或可取的，代码应先尝试： 无论程序环境或调用如何，都要完全确定。 避免依赖于其他init()函数的顺序或副作用。虽然init()顺序是明确的，但代码可以更改，因此init()函数之间的关系可能会使代码变得脆弱和容易出错。 避免访问或操作全局或环境状态，如机器信息、环境变量、工作目录、程序参数&#x2F;输入等。 避免I&#x2F;O，包括文件系统、网络和系统调用。 不能满足这些要求的代码可能属于要作为main()调用的一部分（或程序生命周期中的其他地方），或者作为main()本身的一部分写入。特别是，打算由其他程序使用的库应该特别注意完全确定性，而不是执行“init magic”。 Bad 123456789type Foo struct &#123; // ...&#125;var _defaultFoo Foofunc init() &#123; _defaultFoo = Foo&#123; // ... &#125;&#125; Good 12345678910var _defaultFoo = Foo&#123; // ...&#125;// or，为了更好的可测试性：var _defaultFoo = defaultFoo()func defaultFoo() Foo &#123; return Foo&#123; // ... &#125;&#125; Bad 12345678910111213type Config struct &#123; // ...&#125;var _config Configfunc init() &#123; // Bad: 基于当前目录 cwd, _ := os.Getwd() // Bad: I/O raw, _ := ioutil.ReadFile( path.Join(cwd, &quot;config&quot;, &quot;config.yaml&quot;), ) yaml.Unmarshal(raw, &amp;_config)&#125; Good 1234567891011121314type Config struct &#123; // ...&#125;func loadConfig() Config &#123; cwd, err := os.Getwd() // handle err raw, err := ioutil.ReadFile( path.Join(cwd, &quot;config&quot;, &quot;config.yaml&quot;), ) // handle err var config Config yaml.Unmarshal(raw, &amp;config) return config&#125; 考虑到上述情况，在某些情况下，init()可能更可取或是必要的，可能包括： 不能表示为单个赋值的复杂表达式。 可插入的钩子，如database&#x2F;sql、编码类型注册表等。 对 Google Cloud Functions 和其他形式的确定性预计算的优化。 5.6.3. 结构体类型定义规范5.6.3.1. 使用字段名初始化结构初始化结构时，几乎应该始终指定字段名。目前由 go vet 强制执行。 Bad 1k := User&#123;&quot;John&quot;, &quot;Doe&quot;, true&#125; Good 12345k := User&#123; FirstName: &quot;John&quot;, LastName: &quot;Doe&quot;, Admin: true,&#125; 例外：当有 3 个或更少的字段时，测试表中的字段名may可以省略。 1234567tests := []struct&#123; op Operation want string&#125;&#123; &#123;Add, &quot;add&quot;&#125;, &#123;Subtract, &quot;subtract&quot;&#125;,&#125; 5.6.3.2. 省略结构中的零值字段初始化具有字段名的结构时，除非提供有意义的上下文，否则忽略值为零值的字段。也就是，让我们自动将这些设置为零值 Bad123456user := User&#123; FirstName: &quot;John&quot;, LastName: &quot;Doe&quot;, MiddleName: &quot;&quot;, Admin: false,&#125; Good1234user := User&#123; FirstName: &quot;John&quot;, LastName: &quot;Doe&quot;,&#125; 这有助于通过省略该上下文中的默认值来减少阅读的障碍。只指定有意义的值。 在字段名提供有意义上下文的地方包含零值。例如，表驱动测试 中的测试用例可以指定全部字段的名称，即使它们是零值的。 1234567tests := []struct&#123; give string want int&#125;&#123; &#123;give: &quot;0&quot;, want: 0&#125;, // ...&#125; 5.6.3.3. 对零值结构使用 var如果在声明中省略了结构的所有字段，请使用 var 声明结构。 Bad 1user := User&#123;&#125; Good 1var user User 这将零值结构与那些具有类似于为 初始化 Maps 创建的，区别于非零值字段的结构区分开来，并与我们更喜欢的 声明空切片 方式相匹配。 5.6.3.4. 初始化 Struct 引用在初始化结构引用时，请使用&amp;T{}代替new(T)，以使其与结构体初始化一致。 Bad12345sval := T&#123;Name: &quot;foo&quot;&#125;// inconsistentsptr := new(T)sptr.Name = &quot;bar&quot; Good123sval := T&#123;Name: &quot;foo&quot;&#125;sptr := &amp;T&#123;Name: &quot;bar&quot;&#125; 5.6.3.5. 结构体中的嵌入嵌入式类型（例如 mutex）应位于结构体内的字段列表的顶部，并且必须有一个空行将嵌入式字段与常规字段分隔开。 Bad1234type Client struct &#123; version int http.Client&#125; Good12345type Client struct &#123; http.Client version int&#125; 内嵌应该提供切实的好处，比如以语义上合适的方式添加或增强功能。 它应该在对用户没有任何不利影响的情况下使用。（另请参见：避免在公共结构中嵌入类型）。 例外：即使在未导出类型中，Mutex 也不应该作为内嵌字段。另请参见：零值 Mutex 是有效的。 嵌入 不应该: 纯粹是为了美观或方便。 使外部类型更难构造或使用。 影响外部类型的零值。如果外部类型有一个有用的零值，则在嵌入内部类型之后应该仍然有一个有用的零值。 作为嵌入内部类型的副作用，从外部类型公开不相关的函数或字段。 公开未导出的类型。 影响外部类型的复制形式。 更改外部类型的 API 或类型语义。 嵌入内部类型的非规范形式。 公开外部类型的实现详细信息。 允许用户观察或控制类型内部。 通过包装的方式改变内部函数的一般行为，这种包装方式会给用户带来一些意料之外情况。 简单地说，有意识地和有目的地嵌入。一种很好的测试体验是，”是否所有这些导出的内部方法&#x2F;字段都将直接添加到外部类型？”，如果答案是some或no，不要嵌入内部类型，而是使用字段。 Bad 12345678910111213141516171819202122232425type A struct &#123; // Bad: A.Lock() and A.Unlock() 现在可用 // 不提供任何功能性好处，并允许用户控制有关 A 的内部细节。 sync.Mutex&#125;type Book struct &#123; // Bad: 指针更改零值的有用性 io.ReadWriter // other fields&#125;// latervar b Bookb.Read(...) // panic: nil pointerb.String() // panic: nil pointerb.Write(...) // panic: nil pointertype Client struct &#123; sync.Mutex sync.WaitGroup bytes.Buffer url.URL&#125; Good 123456789101112131415161718192021222324252627282930type countingWriteCloser struct &#123; // Good: Write() 在外层提供用于特定目的， // 并且委托工作到内部类型的 Write() 中。 io.WriteCloser count int&#125;func (w *countingWriteCloser) Write(bs []byte) (int, error) &#123; w.count += len(bs) return w.WriteCloser.Write(bs)&#125;type Book struct &#123; // Good: 有用的零值 bytes.Buffer // other fields&#125;// latervar b Bookb.Read(...) // okb.String() // okb.Write(...) // oktype Client struct &#123; mtx sync.Mutex wg sync.WaitGroup buf bytes.Buffer url url.URL&#125; 5.6.4. 接口定义规范您几乎不需要指向接口类型的指针。您应该将接口作为值进行传递，在这样的传递过程中，实质上传递的底层数据仍然可以是指针。 接口实质上在底层用两个字段表示： 一个指向某些特定类型信息的指针。您可以将其视为”type”。 数据指针。如果存储的数据是指针，则直接存储。如果存储的数据是一个值，则存储指向该值的指针。 如果希望接口方法修改基础数据，则必须使用指针传递 (将对象指针赋值给接口变量)。 12345678910111213141516type F interface &#123; f()&#125;type S1 struct&#123;&#125;func (s S1) f() &#123;&#125;type S2 struct&#123;&#125;func (s *S2) f() &#123;&#125;// f1.f() 无法修改底层数据// f2.f() 可以修改底层数据，给接口变量 f2 赋值时使用的是对象指针var f1 F = S1&#123;&#125;var f2 F = &amp;S2&#123;&#125; 5.6.5. Map&#x2F;Slice 类型定义规范5.6.5.1. Map 类型定义规范对于空 map 请使用 make(..) 初始化， 并且 map 是通过编程方式填充的。 这使得 map 初始化在表现上不同于声明，并且它还可以方便地在 make 后添加大小提示。 Bad 1234567var ( // m1 读写安全; // m2 在写入时会 panic m1 = map[T1]T2&#123;&#125; m2 map[T1]T2)// 声明和初始化看起来非常相似的。 Good 1234567var ( // m1 读写安全; // m2 在写入时会 panic m1 = make(map[T1]T2) m2 map[T1]T2)// 声明和初始化看起来差别非常大。 在尽可能的情况下，请在初始化时提供 map 容量大小，详细请看 指定 Map 容量提示。 另外，如果 map 包含固定的元素列表，则使用 map literals(map 初始化列表) 初始化映射。 Bad1234m := make(map[T1]T2, 3)m[k1] = v1m[k2] = v2m[k3] = v3 Good12345m := map[T1]T2&#123; k1: v1, k2: v2, k3: v3,&#125; 基本准则是：在初始化时使用 map 初始化列表 来添加一组固定的元素。否则使用 make (如果可以，请尽量指定 map 容量)。 5.6.5.2. nil 是一个有效的 slicenil 是一个有效的长度为 0 的 slice，这意味着， 您不应明确返回长度为零的切片。应该返回nil 来代替。 Bad123if x == &quot;&quot; &#123; return []int&#123;&#125;&#125; Good123if x == &quot;&quot; &#123; return nil&#125; 要检查切片是否为空，请始终使用len(s) &#x3D;&#x3D; 0。而非 nil。 Bad123func isEmpty(s []string) bool &#123; return s == nil&#125; Good123func isEmpty(s []string) bool &#123; return len(s) == 0&#125; 零值切片（用var声明的切片）可立即使用，无需调用make()创建。 Bad12345678910nums := []int&#123;&#125;// or, nums := make([]int)if add1 &#123; nums = append(nums, 1)&#125;if add2 &#123; nums = append(nums, 2)&#125; Good123456789var nums []intif add1 &#123; nums = append(nums, 1)&#125;if add2 &#123; nums = append(nums, 2)&#125; 记住，虽然 nil 切片是有效的切片，但它不等于长度为 0 的切片（一个为 nil，另一个不是），并且在不同的情况下（例如序列化），这两个切片的处理方式可能不同。 5.6.6. 字符串类型定义规范5.6.6.1. 声明 Printf-style String 时，将其设置为 const 常量在函数外声明Printf-style 函数的格式字符串，请将其设置为const常量。 这有助于go vet对格式字符串执行静态分析。 Bad12msg := &quot;unexpected values %v, %v\\n&quot;fmt.Printf(msg, 1, 2) Good12const msg = &quot;unexpected values %v, %v\\n&quot;fmt.Printf(msg, 1, 2) 5.6.6.2. 使用原始字符串字符，避免转义Go 支持使用 原始字符串字符，也就是 “ &#96; “ 来表示原生字符串，在需要转义的场景下，我们应该尽量使用这种方案来替换。 可以跨越多行并包含引号。使用这些字符串可以避免更难阅读的手工转义的字符串。 Bad1wantError := &quot;unknown name:\\&quot;test\\&quot;&quot; Good1wantError := `unknown error:&quot;test&quot;` 5.6.6.3. 命名 Printf 样式的函数声明Printf-style 函数时，请确保go vet可以检测到它并检查格式字符串。 这意味着您应尽可能使用预定义的Printf-style 函数名称。go vet将默认检查这些。有关更多信息，请参见 Printf 系列。 如果不能使用预定义的名称，请以 f 结束选择的名称：Wrapf，而不是Wrap。go vet可以要求检查特定的 Printf 样式名称，但名称必须以f结尾。 $ go vet -printfuncs&#x3D;wrapf,statusf另请参阅 go vet: Printf family check. 6. 指导原则6.1. 减少嵌套代码应通过尽可能先处理错误情况&#x2F;特殊情况并尽早返回或继续循环来减少嵌套（不超过3 层嵌套）。减少嵌套多个级别的代码的代码量。 Bad123456789101112for _, v := range data &#123; if v.F1 == 1 &#123; v = process(v) if err := v.Call(); err == nil &#123; v.Send() &#125; else &#123; return err &#125; &#125; else &#123; log.Printf(&quot;Invalid v: %v&quot;, v) &#125;&#125; Good123456789101112for _, v := range data &#123; if v.F1 != 1 &#123; log.Printf(&quot;Invalid v: %v&quot;, v) continue &#125; v = process(v) if err := v.Call(); err != nil &#123; return err &#125; v.Send()&#125; 6.2. 替换不必要的 else如果在 if 的两个分支中都设置了变量，则可以将其替换为单个 if。 Bad123456var a intif b &#123; a = 100&#125; else &#123; a = 10&#125; Good1234a := 10if b &#123; a = 100&#125; 6.3. Interface 合理性验证在编译时验证接口的符合性。这包括： 将实现特定接口的导出类型作为接口 API 的一部分进行检查 实现同一接口的 (导出和非导出) 类型属于实现类型的集合 任何违反接口合理性检查的场景，都会终止编译，并通知给用户 补充：上面 3 条是编译器对接口的检查机制，大体意思是错误使用接口会在编译期报错。所以可以利用这个机制让部分问题在编译期暴露。 Bad12345678910// 如果 Handler 没有实现 http.Handler，会在运行时报错type Handler struct &#123; // ...&#125;func (h *Handler) ServeHTTP( w http.ResponseWriter, r *http.Request,) &#123; ...&#125; Good123456789101112type Handler struct &#123; // ...&#125;// 用于触发编译期的接口的合理性检查机制// 如果 Handler 没有实现 http.Handler，会在编译期报错var _ http.Handler = (*Handler)(nil)func (h *Handler) ServeHTTP( w http.ResponseWriter, r *http.Request,) &#123; // ...&#125; 如果 *Handler 与 http.Handler 的接口不匹配，那么语句 var _ http.Handler &#x3D; (*Handler)(nil) 将无法编译通过。 赋值的右边应该是断言类型的零值。对于指针类型（如 *Handler）、切片和映射，这是 nil；对于结构类型，这是空结构。 1234567891011type LogHandler struct &#123; h http.Handler log *zap.Logger&#125;var _ http.Handler = LogHandler&#123;&#125;func (h LogHandler) ServeHTTP( w http.ResponseWriter, r *http.Request,) &#123; // ...&#125; 6.4. 接收器 (receiver) 与接口使用值接收器的方法既可以通过值调用，也可以通过指针调用。 带指针接收器的方法只能通过指针或 addressable values 调用。 例如： 12345678910111213141516171819202122232425type S struct &#123; data string&#125;func (s S) Read() string &#123; return s.data&#125;func (s *S) Write(str string) &#123; s.data = str&#125;sVals := map[int]S&#123;1: &#123;&quot;A&quot;&#125;&#125;// 你只能通过值调用 ReadsVals[1].Read()// 这不能编译通过：// sVals[1].Write(&quot;test&quot;)sPtrs := map[int]*S&#123;1: &#123;&quot;A&quot;&#125;&#125;// 通过指针既可以调用 Read，也可以调用 Write 方法sPtrs[1].Read()sPtrs[1].Write(&quot;test&quot;) 类似的，即使方法有了值接收器，也同样可以用指针接收器来满足接口。 123456789101112131415161718192021222324type F interface &#123; f()&#125;type S1 struct&#123;&#125;func (s S1) f() &#123;&#125;type S2 struct&#123;&#125;func (s *S2) f() &#123;&#125;s1Val := S1&#123;&#125;s1Ptr := &amp;S1&#123;&#125;s2Val := S2&#123;&#125;s2Ptr := &amp;S2&#123;&#125;var i Fi = s1Vali = s1Ptri = s2Ptr// 下面代码无法通过编译。因为 s2Val 是一个值，而 S2 的 f 方法中没有使用值接收器// i = s2Val Effective Go 中有一段关于 pointers vs. values 的精彩讲解。 补充： 一个类型可以有值接收器方法集和指针接收器方法集 值接收器方法集是指针接收器方法集的子集，反之不是 规则 值对象只可以使用值接收器方法集 指针对象可以使用 值接收器方法集 + 指针接收器方法集 接口的匹配 (或者叫实现) 类型实现了接口的所有方法，叫匹配 具体的讲，要么是类型的值方法集匹配接口，要么是指针方法集匹配接口 具体的匹配分两种： 值方法集和接口匹配 给接口变量赋值的不管是值还是指针对象，都 ok，因为都包含值方法集 指针方法集和接口匹配 只能将指针对象赋值给接口变量，因为只有指针方法集和接口匹配 如果将值对象赋值给接口变量，会在编译期报错 (会触发接口合理性检查机制) 为啥 i &#x3D; s2Val 会报错，因为值方法集和接口不匹配。 6.5. 零值 Mutex 是有效的零值 sync.Mutex 和 sync.RWMutex 是有效的。所以指向 mutex 的指针基本是不必要的。 Bad 12mu := new(sync.Mutex)mu.Lock() Good 12var mu sync.Mutexmu.Lock() 如果你使用结构体指针，mutex 应该作为结构体的非指针字段。即使该结构体不被导出，也不要直接把 mutex 嵌入到结构体中。 Bad 1234567891011121314151617181920type SMap struct &#123; sync.Mutex data map[string]string&#125;func NewSMap() *SMap &#123; return &amp;SMap&#123; data: make(map[string]string), &#125;&#125;func (m *SMap) Get(k string) string &#123; m.Lock() defer m.Unlock() return m.data[k]&#125;// Mutex 字段， Lock 和 Unlock 方法是 SMap 导出的 API 中不刻意说明的一部分。 Good 1234567891011121314151617181920type SMap struct &#123; mu sync.Mutex data map[string]string&#125;func NewSMap() *SMap &#123; return &amp;SMap&#123; data: make(map[string]string), &#125;&#125;func (m *SMap) Get(k string) string &#123; m.mu.Lock() defer m.mu.Unlock() return m.data[k]&#125;// mutex 及其方法是 SMap 的实现细节，对其调用者不可见。 6.6. 在边界处拷贝 Slices 和 Mapsslices 和 maps 包含了指向底层数据的指针，因此在需要复制它们时要特别注意。 6.6.1. 接收 Slices 和 Maps请记住，当 map 或 slice 作为函数参数传入时，如果您存储了对它们的引用，则用户可以对其进行修改。 Bad123456789func (d *Driver) SetTrips(trips []Trip) &#123; d.trips = trips&#125;trips := ...d1.SetTrips(trips)// 你是要修改 d1.trips 吗？trips[0] = ... Good12345678910func (d *Driver) SetTrips(trips []Trip) &#123; d.trips = make([]Trip, len(trips)) copy(d.trips, trips)&#125;trips := ...d1.SetTrips(trips)// 这里我们修改 trips[0]，但不会影响到 d1.tripstrips[0] = ... 6.6.2. 返回 slices 或 maps同样，请注意用户对暴露内部状态的 map 或 slice 的修改。 Bad123456789101112131415161718type Stats struct &#123; mu sync.Mutex counters map[string]int&#125;// Snapshot 返回当前状态。func (s *Stats) Snapshot() map[string]int &#123; s.mu.Lock() defer s.mu.Unlock() return s.counters&#125;// snapshot 不再受互斥锁保护// 因此对 snapshot 的任何访问都将受到数据竞争的影响// 影响 stats.counterssnapshot := stats.Snapshot() Good12345678910111213141516171819type Stats struct &#123; mu sync.Mutex counters map[string]int&#125;func (s *Stats) Snapshot() map[string]int &#123; s.mu.Lock() defer s.mu.Unlock() result := make(map[string]int, len(s.counters)) for k, v := range s.counters &#123; result[k] = v &#125; return result&#125;// snapshot 现在是一个拷贝snapshot := stats.Snapshot() 6.7. 使用 defer 释放资源使用 defer 释放资源，诸如文件和锁。 Bad12345678910111213p.Lock()if p.count &lt; 10 &#123; p.Unlock() return p.count&#125;p.count++newCount := p.countp.Unlock()return newCount// 当有多个 return 分支时，很容易遗忘 unlock Good1234567891011p.Lock()defer p.Unlock()if p.count &lt; 10 &#123; return p.count&#125;p.count++return p.count// 更可读 Defer 的开销非常小，只有在您可以证明函数执行时间处于纳秒级的程度时，才应避免这样做。使用 defer 提升可读性是值得的，因为使用它们的成本微不足道。尤其适用于那些不仅仅是简单内存访问的较大的方法，在这些方法中其他计算的资源消耗远超过 defer。 6.8. Channel 的 size 要么是 1，要么是无缓冲的channel 通常 size 应为 1 或是无缓冲的。默认情况下，channel 是无缓冲的，其 size 为零。任何其他尺寸都必须经过严格的审查。我们需要考虑如何确定大小，考虑是什么阻止了 channel 在高负载下和阻塞写时的写入，以及当这种情况发生时系统逻辑有哪些变化。(翻译解释：按照原文意思是需要界定通道边界，竞态条件，以及逻辑上下文梳理) Bad12// 应该足以满足任何情况！c := make(chan int, 64) Good1234// 大小：1c := make(chan int, 1) // 或者// 无缓冲 channel，大小为 0c := make(chan int) 6.9. 枚举从 1 开始在 Go 中引入枚举的标准方法是声明一个自定义类型和一个使用了 iota 的 const 组。由于变量的默认值为 0，因此通常应以非零值开头枚举。 Bad123456789type Operation intconst ( Add Operation = iota Subtract Multiply)// Add=0, Subtract=1, Multiply=2 Good123456789type Operation intconst ( Add Operation = iota + 1 Subtract Multiply)// Add=1, Subtract=2, Multiply=3 在某些情况下，使用零值是有意义的（枚举从零开始），例如，当零值是理想的默认行为时。123456789type LogOutput intconst ( LogToStdout LogOutput = iota LogToFile LogToRemote)// LogToStdout=0, LogToFile=1, LogToRemote=2 6.10. 使用 time 处理时间时间处理很复杂。关于时间的错误假设通常包括以下几点。 一天有 24 小时 一小时有 60 分钟 一周有七天 一年 365 天 还有更多 例如，1 表示在一个时间点上加上 24 小时并不总是产生一个新的日历日。 因此，在处理时间时始终使用 “time” 包，因为它有助于以更安全、更准确的方式处理这些不正确的假设。 6.10.1. 使用 time.Time 表达瞬时时间在处理时间的瞬间时使用 time.Time，在比较、添加或减去时间时使用 time.Time 中的方法。 Bad123func isActive(now, start, stop int) bool &#123; return start &lt;= now &amp;&amp; now &lt; stop&#125; Good123func isActive(now, start, stop time.Time) bool &#123; return (start.Before(now) || start.Equal(now)) &amp;&amp; now.Before(stop)&#125; 6.10.2. 使用 time.Duration 表达时间段在处理时间段时使用 time.Duration . Bad1234567func poll(delay int) &#123; for &#123; // ... time.Sleep(time.Duration(delay) * time.Millisecond) &#125;&#125;poll(10) // 是几秒钟还是几毫秒？ Good1234567func poll(delay time.Duration) &#123; for &#123; // ... time.Sleep(delay) &#125;&#125;poll(10*time.Second) 回到第一个例子，在一个时间瞬间加上 24 小时，我们用于添加时间的方法取决于意图。如果我们想要下一个日历日 (当前天的下一天) 的同一个时间点，我们应该使用 Time.AddDate。但是，如果我们想保证某一时刻比前一时刻晚 24 小时，我们应该使用 Time.Add。12newDay := t.AddDate(0 /* years */, 0 /* months */, 1 /* days */)maybeNewDay := t.Add(24 * time.Hour) 6.10.3. 对外部系统使用 time.Time 和 time.Duration尽可能在与外部系统的交互中使用 time.Duration 和 time.Time 例如 : Command-line 标志: flag 通过 time.ParseDuration 支持 time.Duration JSON: encoding&#x2F;json 通过其 UnmarshalJSON method 方法支持将 time.Time 编码为 RFC 3339 字符串 SQL: database&#x2F;sql 支持将 DATETIME 或 TIMESTAMP 列转换为 time.Time，如果底层驱动程序支持则返回 YAML: gopkg.in&#x2F;yaml.v2 支持将 time.Time 作为 RFC 3339 字符串，并通过 time.ParseDuration 支持 time.Duration。 当不能在这些交互中使用 time.Duration 时，请使用 int 或 float64，并在字段名称中包含单位。 例如，由于 encoding&#x2F;json 不支持 time.Duration，因此该单位包含在字段的名称中。 Bad1234// &#123;&quot;interval&quot;: 2&#125;type Config struct &#123; Interval int `json:&quot;interval&quot;`&#125; Good1234// &#123;&quot;intervalMillis&quot;: 2000&#125;type Config struct &#123; IntervalMillis int `json:&quot;intervalMillis&quot;`&#125; 当在这些交互中不能使用 time.Time 时，除非达成一致，否则使用 string 和 RFC 3339 中定义的格式时间戳。默认情况下，Time.UnmarshalText 使用此格式，并可通过 time.RFC3339 在 Time.Format 和 time.Parse 中使用。 尽管这在实践中并不成问题，但请记住，”time” 包不支持解析闰秒时间戳（8728），也不在计算中考虑闰秒（15190）。如果您比较两个时间瞬间，则差异将不包括这两个瞬间之间可能发生的闰秒。 6.11. Errors6.11.1. 错误类型声明错误的选项很少。 在选择最适合您的用例的选项之前，请考虑以下事项。 调用者是否需要匹配错误以便他们可以处理它？如果是，我们必须通过声明顶级错误变量或自定义类型来支持 errors.Is 或 errors.As 函数。 错误消息是否为静态字符串，还是需要上下文信息的动态字符串？如果是静态字符串，我们可以使用 errors.New，但对于后者，我们必须使用 fmt.Errorf 或自定义错误类型。 我们是否正在传递由下游函数返回的新错误？如果是这样，请参阅错误包装部分。 错误匹配？ 错误消息 指导 No static errors.New No dynamic fmt.Errorf Yes static top-level var with errors.New Yes dynamic custom error type 例如，使用 errors.New 表示带有静态字符串的错误。如果调用者需要匹配并处理此错误，则将此错误导出为变量以支持将其与 errors.Is 匹配。 无错误匹配123456789101112// package foofunc Open() error &#123; return errors.New(&quot;could not open&quot;)&#125;// package barif err := foo.Open(); err != nil &#123; // Can&#x27;t handle the error. panic(&quot;unknown error&quot;)&#125; 错误匹配1234567891011121314151617// package foovar ErrCouldNotOpen = errors.New(&quot;could not open&quot;)func Open() error &#123; return ErrCouldNotOpen&#125;// package barif err := foo.Open(); err != nil &#123; if errors.Is(err, foo.ErrCouldNotOpen) &#123; // handle the error &#125; else &#123; panic(&quot;unknown error&quot;) &#125;&#125; 对于动态字符串的错误，如果调用者不需要匹配它，则使用 fmt.Errorf，如果调用者确实需要匹配它，则自定义 error。 无错误匹配123456789101112// package foofunc Open(file string) error &#123; return fmt.Errorf(&quot;file %q not found&quot;, file)&#125;// package barif err := foo.Open(&quot;testfile.txt&quot;); err != nil &#123; // Can&#x27;t handle the error. panic(&quot;unknown error&quot;)&#125; 错误匹配12345678910111213141516171819202122232425// package footype NotFoundError struct &#123; File string&#125;func (e *NotFoundError) Error() string &#123; return fmt.Sprintf(&quot;file %q not found&quot;, e.File)&#125;func Open(file string) error &#123; return &amp;NotFoundError&#123;File: file&#125;&#125;// package barif err := foo.Open(&quot;testfile.txt&quot;); err != nil &#123; var notFound *NotFoundError if errors.As(err, &amp;notFound) &#123; // handle the error &#125; else &#123; panic(&quot;unknown error&quot;) &#125;&#125; 请注意，如果您从包中导出错误变量或类型，它们将成为包的公共 API 的一部分。 6.11.2. 错误包装如果调用失败，有三种主要的错误调用选项： 按原样返回原始错误 add context with fmt.Errorf and the %w verb 使用fmt.Errorf和%w 使用 fmt.Errorf 和 %v 如果没有要添加的其他上下文，则按原样返回原始错误。这将保留原始错误类型和消息。这非常适合底层错误消息有足够的信息来追踪它来自哪里的错误。 否则，尽可能在错误消息中添加上下文这样就不会出现诸如“连接被拒绝”之类的模糊错误，您会收到更多有用的错误，例如“呼叫服务 foo：连接被拒绝”。 使用 fmt.Errorf 为你的错误添加上下文，根据调用者是否应该能够匹配和提取根本原因，在 %w 或 %v 动词之间进行选择。 如果调用者应该可以访问底层错误，请使用 %w。对于大多数包装错误，这是一个很好的默认值，但请注意，调用者可能会开始依赖此行为。因此，对于包装错误是已知var或类型的情况，请将其作为函数契约的一部分进行记录和测试。 使用 %v 来混淆底层错误。调用者将无法匹配它，但如果需要，您可以在将来切换到 %w。在为返回的错误添加上下文时，通过避免使用”failed to”之类的短语来保持上下文简洁，当错误通过堆栈向上渗透时，它会一层一层被堆积起来： 1234567s, err := store.New()if err != nil &#123; return fmt.Errorf( &quot;failed to create new store: %w&quot;, err)&#125;// failed to x: failed to y: failed to create new store: the error 1234567s, err := store.New()if err != nil &#123; return fmt.Errorf( &quot;new store: %w&quot;, err)&#125;// x: y: new store: the error 然而，一旦错误被发送到另一个系统，应该清楚消息是一个错误（例如err 标签或日志中的”Failed”前缀）。 另见 不要只检查错误，优雅地处理它们。 6.11.3. 错误命名对于存储为全局变量的错误值，根据是否导出，使用前缀 Err 或 err。请看指南 对于未导出的顶层常量和变量，使用_作为前缀。 12345678910var ( // 导出以下两个错误，以便此包的用户可以将它们与 errors.Is 进行匹配。 ErrBrokenLink = errors.New(&quot;link is broken&quot;) ErrCouldNotOpen = errors.New(&quot;could not open&quot;) // 这个错误没有被导出，因为我们不想让它成为我们公共 API 的一部分。 我们可能仍然在带有错误的包内使用它。 errNotFound = errors.New(&quot;not found&quot;)) 对于自定义错误类型，请改用后缀 Error。 123456789101112131415161718// 同样，这个错误被导出，以便这个包的用户可以将它与 errors.As 匹配。type NotFoundError struct &#123; File string&#125;func (e *NotFoundError) Error() string &#123; return fmt.Sprintf(&quot;file %q not found&quot;, e.File)&#125;// 并且这个错误没有被导出，因为我们不想让它成为公共 API 的一部分。 我们仍然可以在带有 errors.As 的包中使用它。type resolveError struct &#123; Path string&#125;func (e *resolveError) Error() string &#123; return fmt.Sprintf(&quot;resolve %q&quot;, e.Path)&#125; 6.12. 处理断言失败类型断言 将会在检测到不正确的类型时，以单一返回值形式返回 panic。 因此，请始终使用“逗号 ok”习语。 Bad1t := i.(string) Good1234t, ok := i.(string)if !ok &#123; // 优雅地处理错误&#125; 6.13. 不要使用 panic在生产环境中运行的代码必须避免出现 panic。panic 是 级联失败 的主要根源 。如果发生错误，该函数必须返回错误，并允许调用方决定如何处理它。 Bad12345678910func run(args []string) &#123; if len(args) == 0 &#123; panic(&quot;an argument is required&quot;) &#125; // ...&#125;func main() &#123; run(os.Args[1:])&#125; Godd1234567891011121314func run(args []string) error &#123; if len(args) == 0 &#123; return errors.New(&quot;an argument is required&quot;) &#125; // ... return nil&#125;func main() &#123; if err := run(os.Args[1:]); err != nil &#123; fmt.Fprintln(os.Stderr, err) os.Exit(1) &#125;&#125; panic&#x2F;recover 不是错误处理策略。仅当发生不可恢复的事情（例如：nil 引用）时，程序才必须 panic。程序初始化是一个例外：程序启动时应使程序中止的不良情况可能会引起 panic。 即使在测试代码中，也优先使用t.Fatal或者t.FailNow而不是 panic 来确保失败被标记。 Bad123456// func TestFoo(t *testing.T)f, err := ioutil.TempFile(&quot;&quot;, &quot;test&quot;)if err != nil &#123; panic(&quot;failed to set up test&quot;)&#125; Good123456// func TestFoo(t *testing.T)f, err := ioutil.TempFile(&quot;&quot;, &quot;test&quot;)if err != nil &#123; t.Fatal(&quot;failed to set up test&quot;)&#125; 6.14. 使用 go.uber.org&#x2F;atomic使用 sync&#x2F;atomic 包的原子操作对原始类型 (int32, int64等）进行操作，因为很容易忘记使用原子操作来读取或修改变量。 go.uber.org&#x2F;atomic 通过隐藏基础类型为这些操作增加了类型安全性。此外，它包括一个方便的atomic.Bool类型。 Bad123456789101112131415type foo struct &#123; running int32 // atomic&#125;func (f* foo) start() &#123; if atomic.SwapInt32(&amp;f.running, 1) == 1 &#123; // already running… return &#125; // start the Foo&#125;func (f *foo) isRunning() bool &#123; return f.running == 1 // race!&#125; Good123456789101112131415type foo struct &#123; running atomic.Bool&#125;func (f *foo) start() &#123; if f.running.Swap(true) &#123; // already running… return &#125; // start the Foo&#125;func (f *foo) isRunning() bool &#123; return f.running.Load()&#125; 6.15. 避免可变全局变量使用选择依赖注入方式避免改变全局变量。既适用于函数指针又适用于其他值类型 Bad12345678910111213141516// sign.govar _timeNow = time.Nowfunc sign(msg string) string &#123; now := _timeNow() return signWithTime(msg, now)&#125;// sign_test.gofunc TestSign(t *testing.T) &#123; oldTimeNow := _timeNow _timeNow = func() time.Time &#123; return someFixedTime &#125; defer func() &#123; _timeNow = oldTimeNow &#125;() assert.Equal(t, want, sign(give))&#125; Good12345678910111213141516171819202122// sign.gotype signer struct &#123; now func() time.Time&#125;func newSigner() *signer &#123; return &amp;signer&#123; now: time.Now, &#125;&#125;func (s *signer) Sign(msg string) string &#123; now := s.now() return signWithTime(msg, now)&#125;// sign_test.gofunc TestSigner(t *testing.T) &#123; s := newSigner() s.now = func() time.Time &#123; return someFixedTime &#125; assert.Equal(t, want, s.Sign(give))&#125; 6.16. 避免在公共结构中嵌入类型这些嵌入的类型泄漏实现细节、禁止类型演化和模糊的文档。 假设您使用共享的 AbstractList 实现了多种列表类型，请避免在具体的列表实现中嵌入 AbstractList。相反，只需手动将方法写入具体的列表，该列表将委托给抽象列表。 123456789type AbstractList struct &#123;&#125;// 添加将实体添加到列表中。func (l *AbstractList) Add(e Entity) &#123; // ...&#125;// 移除从列表中移除实体。func (l *AbstractList) Remove(e Entity) &#123; // ...&#125; Bad1234// ConcreteList 是一个实体列表。type ConcreteList struct &#123; *AbstractList&#125; Good123456789101112// ConcreteList 是一个实体列表。type ConcreteList struct &#123; list *AbstractList&#125;// 添加将实体添加到列表中。func (l *ConcreteList) Add(e Entity) &#123; l.list.Add(e)&#125;// 移除从列表中移除实体。func (l *ConcreteList) Remove(e Entity) &#123; l.list.Remove(e)&#125; Go 允许 类型嵌入 作为继承和组合之间的折衷。外部类型获取嵌入类型的方法的隐式副本。默认情况下，这些方法委托给嵌入实例的同一方法。 结构还获得与类型同名的字段。所以，如果嵌入的类型是 public，那么字段是 public。为了保持向后兼容性，外部类型的每个未来版本都必须保留嵌入类型。 很少需要嵌入类型。这是一种方便，可以帮助您避免编写冗长的委托方法。 即使嵌入兼容的抽象列表 interface，而不是结构体，这将为开发人员提供更大的灵活性来改变未来，但仍然泄露了具体列表使用抽象实现的细节。 Bad 123456789// AbstractList 是各种实体列表的通用实现。type AbstractList interface &#123; Add(Entity) Remove(Entity)&#125;// ConcreteList 是一个实体列表。type ConcreteList struct &#123; AbstractList&#125; Good 1234567891011121314151617// AbstractList 是各种实体列表的通用实现。type AbstractList interface &#123; Add(Entity) Remove(Entity)&#125;// ConcreteList 是一个实体列表。type ConcreteList struct &#123; list AbstractList&#125;// 添加将实体添加到列表中。func (l *ConcreteList) Add(e Entity) &#123; l.list.Add(e)&#125;// 移除从列表中移除实体。func (l *ConcreteList) Remove(e Entity) &#123; l.list.Remove(e)&#125; 无论是使用嵌入结构还是嵌入接口，都会限制类型的演化。 向嵌入接口添加方法是一个破坏性的改变。 从嵌入结构体删除方法是一个破坏性改变。 删除嵌入类型是一个破坏性的改变。 即使使用满足相同接口的类型替换嵌入类型，也是一个破坏性的改变。 尽管编写这些委托方法是乏味的，但是额外的工作隐藏了实现细节，留下了更多的更改机会，还消除了在文档中发现完整列表接口的间接性操作。 直白点说，就是不希望结构体暴露不必要的实现（方法和属性），符号最小依赖原则 6.17. 避免使用内置名称Go 语言规范 概述了几个内置的，不应在 Go 项目中使用的 预先声明的标识符。 根据上下文的不同，将这些标识符作为名称重复使用，将在当前作用域（或任何嵌套作用域）中隐藏原始标识符，或者混淆代码。在最好的情况下，编译器会报错；在最坏的情况下，这样的代码可能会引入潜在的、难以恢复的错误。 Bad123456789101112131415161718192021222324var error string// `error` 作用域隐式覆盖// orfunc handleErrorMessage(error string) &#123; // `error` 作用域隐式覆盖&#125;type Foo struct &#123; // 虽然这些字段在技术上不构成阴影，但`error`或`string`字符串的重映射现在是不明确的。 error error string string&#125;func (f Foo) Error() error &#123; // `error` 和 `f.error` 在视觉上是相似的 return f.error&#125;func (f Foo) String() string &#123; // `string` and `f.string` 在视觉上是相似的 return f.string&#125; Good12345678910111213141516171819202122var errorMessage string// `error` 指向内置的非覆盖// orfunc handleErrorMessage(msg string) &#123; // `error` 指向内置的非覆盖&#125;type Foo struct &#123; // `error` and `string` 现在是明确的。 err error str string&#125;func (f Foo) Error() error &#123; return f.err&#125;func (f Foo) String() string &#123; return f.str&#125; 注意，编译器在使用预先分隔的标识符时不会生成错误，但是诸如go vet之类的工具会正确地指出这些和其他情况下的隐式问题。 6.18. 追加时优先指定切片容量追加时优先指定切片容量 在尽可能的情况下，在初始化要追加的切片时为make()提供一个容量值。 Bad12345678for n := 0; n &lt; b.N; n++ &#123; data := make([]int, 0) for k := 0; k &lt; size; k++&#123; data = append(data, k) &#125;&#125;// BenchmarkBad-4 100000000 2.48s Good12345678for n := 0; n &lt; b.N; n++ &#123; data := make([]int, 0, size) for k := 0; k &lt; size; k++&#123; data = append(data, k) &#125;&#125;// BenchmarkGood-4 100000000 0.21s 6.19. 主函数退出方式 (Exit)Go 程序使用 os.Exit 或者 log.Fatal* 立即退出 (使用panic不是退出程序的好方法，请 不要使用 panic。) 仅在main() 中调用其中一个 os.Exit 或者 log.Fatal*。所有其他函数应将错误返回到信号失败中。 Bad 123456789101112131415func main() &#123; body := readFile(path) fmt.Println(body)&#125;func readFile(path string) string &#123; f, err := os.Open(path) if err != nil &#123; log.Fatal(err) &#125; b, err := ioutil.ReadAll(f) if err != nil &#123; log.Fatal(err) &#125; return string(b)&#125; Good 123456789101112131415161718func main() &#123; body, err := readFile(path) if err != nil &#123; log.Fatal(err) &#125; fmt.Println(body)&#125;func readFile(path string) (string, error) &#123; f, err := os.Open(path) if err != nil &#123; return &quot;&quot;, err &#125; b, err := ioutil.ReadAll(f) if err != nil &#123; return &quot;&quot;, err &#125; return string(b), nil&#125; 原则上： 有多个退出入口的程序存在一些问题： 不明显的控制流：任何函数都可以退出程序，因此很难对控制流进行推理。 难以测试：退出程序的函数也将退出调用它的测试。这使得函数很难测试，并引入了跳过 go test 尚未运行的其他测试的风险。 跳过清理：当函数退出程序时，会跳过已经进入defer队列里的函数调用。这增加了跳过重要清理任务的风险。 1.6.19.1. 一次性退出如果可能的话，你的main（）函数中 最多一次 调用 os.Exit或者log.Fatal。如果有多个错误场景停止程序执行，请将该逻辑放在单独的函数下并从中返回错误。这会缩短 main() 函数，并将所有关键业务逻辑放入一个单独的、可测试的函数中。 Bad1234567891011121314151617181920package mainfunc main() &#123; args := os.Args[1:] if len(args) != 1 &#123; log.Fatal(&quot;missing file&quot;) &#125; name := args[0] f, err := os.Open(name) if err != nil &#123; log.Fatal(err) &#125; defer f.Close() // 如果我们调用 log.Fatal 在这条线之后 // f.Close 将会被执行。 b, err := ioutil.ReadAll(f) if err != nil &#123; log.Fatal(err) &#125; // ...&#125; Good1234567891011121314151617181920212223package mainfunc main() &#123; if err := run(); err != nil &#123; log.Fatal(err) &#125;&#125;func run() error &#123; args := os.Args[1:] if len(args) != 1 &#123; return errors.New(&quot;missing file&quot;) &#125; name := args[0] f, err := os.Open(name) if err != nil &#123; return err &#125; defer f.Close() b, err := ioutil.ReadAll(f) if err != nil &#123; return err &#125; // ...&#125; 7. 性能性能方面的特定准则只适用于高频场景。普通场景下【非强制】 7.1. 优先使用 strconv 而不是 fmt将原语转换为字符串或从字符串转换时，strconv速度比fmt快。 Bad12345for i := 0; i &lt; b.N; i++ &#123; s := fmt.Sprint(rand.Int())&#125;// BenchmarkFmtSprint-4 143 ns/op 2 allocs/op Good12345for i := 0; i &lt; b.N; i++ &#123; s := strconv.Itoa(rand.Int())&#125;// BenchmarkStrconv-4 64.2 ns/op 1 allocs/op 7.2. 避免字符串到字节的转换不要反复从固定字符串创建字节 slice。相反，请执行一次转换并捕获结果。 Bad12345for i := 0; i &lt; b.N; i++ &#123; w.Write([]byte(&quot;Hello world&quot;))&#125;// BenchmarkBad-4 50000000 22.2 ns/op Good123456data := []byte(&quot;Hello world&quot;)for i := 0; i &lt; b.N; i++ &#123; w.Write(data)&#125;// BenchmarkGood-4 500000000 3.25 ns/op 7.3. 指定容器容量尽可能指定容器容量，以便为容器预先分配内存。这将在添加元素时最小化后续分配（通过复制和调整容器大小）。 7.3.1. 指定 Map 容量提示在尽可能的情况下，在使用 make() 初始化的时候提供容量信息 make(map[T1]T2, hint) 向make()提供容量提示会在初始化时尝试调整 map 的大小，这将减少在将元素添加到 map 时为 map 重新分配内存。 注意，与 slices 不同。map capacity 提示并不保证完全的抢占式分配，而是用于估计所需的 hashmap bucket 的数量。因此，在将元素添加到 map 时，甚至在指定 map 容量时，仍可能发生分配。 Bad12345678m := make(map[string]os.FileInfo)files, _ := ioutil.ReadDir(&quot;./files&quot;)for _, f := range files &#123; m[f.Name()] = f&#125;// m 是在没有大小提示的情况下创建的； 在运行时可能会有更多分配。 Good12345678files, _ := ioutil.ReadDir(&quot;./files&quot;)m := make(map[string]os.FileInfo, len(files))for _, f := range files &#123; m[f.Name()] = f&#125;// m 是有大小提示创建的；在运行时可能会有更少的分配。 7.3.2. 指定切片容量在尽可能的情况下，在使用make()初始化切片时提供容量信息，特别是在追加切片时。 make([]T, length, capacity) 与 maps 不同，slice capacity 不是一个提示：编译器将为提供给make()的 slice 的容量分配足够的内存，这意味着后续的 append()&#96;操作将导致零分配（直到 slice 的长度与容量匹配，在此之后，任何 append 都可能调整大小以容纳其他元素）。 Bad12345678for n := 0; n &lt; b.N; n++ &#123; data := make([]int, 0) for k := 0; k &lt; size; k++&#123; data = append(data, k) &#125;&#125;// BenchmarkBad-4 100000000 2.48s Good12345678for n := 0; n &lt; b.N; n++ &#123; data := make([]int, 0, size) for k := 0; k &lt; size; k++&#123; data = append(data, k) &#125;&#125;// BenchmarkGood-4 100000000 0.21s 8. 代码检查工具比任何 “blessed” linter 集更重要的是，lint 在一个代码库中始终保持一致。 要求至少使用以下 linters，因为它们有助于发现最常见的问题，并在不需要规定的情况下为代码质量建立一个高标准： errcheck 以确保错误得到处理 goimports 格式化代码和管理 imports golint 指出常见的文体错误 govet 分析代码中的常见错误","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"golang","slug":"技术开发/golang","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/"}],"tags":[{"name":"go checklist","slug":"go-checklist","permalink":"https://tianxiafeiyu.github.io/tags/go-checklist/"}]},{"title":"JTW详解","slug":"技术开发/java/JTW详解","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/JTW详解/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/JTW%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"JTW详解 spring boot集成jwt实现token认证； \\1. 什么是jwt? Json web token (JWT), 是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准（(RFC 7519).定义了一种简洁的，自包含的方法用于通信双方之间以JSON对象的形式安全的传递信息。因为数字签名的存在，这些信息是可信的，JWT可以使用HMAC算法或者是RSA的公私秘钥对进行签名。 \\2. jwt的工作流程 \\1. 用户使用账号和密码发出post请求； \\2. 服务器使用私钥创建一个jwt； \\3. 服务器返回这个jwt给浏览器； \\4. 浏览器将该jwt串在请求头中向服务器发送请求； \\5. 服务器验证该jwt； \\6. 返回响应的资源给浏览器。 \\3. jwt结构 1）Header 头部：JWT的头部承载两部分信息：token类型和采用的加密算法。 2）Payload：存放有效信息的地方。 3）Signature：签证信息。 （完整见博客https://www.jianshu.com/p/e88d3f8151db）","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"JTW详解","slug":"JTW详解","permalink":"https://tianxiafeiyu.github.io/tags/JTW%E8%AF%A6%E8%A7%A3/"}]},{"title":"JVM与Java程序","slug":"技术开发/java/JVM与Java程序","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/JVM与Java程序/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/JVM%E4%B8%8EJava%E7%A8%8B%E5%BA%8F/","excerpt":"","text":"当启动一个Java程序时，一个JVM实例也就产生。当该程序关闭退出，这个JVM实例也就随之消亡。 JVM实例负责运行一个Java程序 Java虚拟机及程序的生命周期：（1）通过java命令运行一个Java程序时，启动一个Java虚拟机进程； （2）Java虚拟机进程从启动到终止的过程，称为Java虚拟机生命周期； （3）程序生命周期和Java虚拟机生命周期是一致的，因为Java虚拟机进程从创建起的任务就是执行Java程序。 （4）每个运行中的Java程序会有独立的Java堆和非堆等物理资源，程序之间的jvm运行时状态是区分的。 类的加载，连接和初始化：Java程序要使用某个类时，Java虚拟机要确保这个类被加载，连接和运行，其中连接包括验证，准备和解析。 1、装载：查找并加载类的二进制数据 装载的最终目标是实现将编译后的class文件（class文件采用字节码，是JVM的机器语言）装入内存运行时数据区的方法区中，并在内存运行时数据区的堆区生成一个class对象，这个对象可以引用到方法区中的类定义 2、连接 （1）验证：确保加载类的正确性； （2）准备：为静态变量分配内存，并将其初始化为默认值； （3）解析：将类中的符号引用转换为直接引用。 3、初始化： 类的初始化过程是执行类的初始化语句，包括静态变量的声明语句，以及静态代码块，静态代码块的作用即是为静态变量赋初始化值。 4、卸载 只有没有任何引用指向Class对象的时候，这时候才会卸载类，结束类的生命周期。 装载验证准备解析初始化对象实例化垃圾收集对象终结卸载","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"JVM与Java程序","slug":"JVM与Java程序","permalink":"https://tianxiafeiyu.github.io/tags/JVM%E4%B8%8EJava%E7%A8%8B%E5%BA%8F/"}]},{"title":"Java创建线程的4种方式","slug":"技术开发/java/Java创建线程的4种方式","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Java创建线程的4种方式/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Java%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E7%9A%844%E7%A7%8D%E6%96%B9%E5%BC%8F/","excerpt":"","text":"一、概述1. 线程与进程进程（Process）是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。 线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。线程是程序中一个单一的顺序控制流程，在单个程序中同时运行多个线程完成不同的工作，称为多线程 2. 同步与异步同步（Synchronous）：同步是指一个进程在执行某个请求的时候，如果该请求需要一段时间才能返回信息，那么这个进程会一直等待下去，直到收到返回信息才继续执行下去。 异步（Asynchronous）：异步是指进程不需要一直等待下去，而是继续执行下面的操作，不管其他进程的状态，当有信息返回的时候会通知进程进行处理。 通俗地讲，也就是说，同步需要按部就班地走完一整个流程，完成一整个动作。而异步则不需要按部就班，可以在等待那个动作的时候同时做别的动作 3. 并行与并发并行：时间上是由重叠的，也就是说并行才是真正意义上的同一时刻可以有多个任务同时执行。 并发：任务在执行的时候，并发是没有时间上的重叠的，两个任务是交替执行的，由于切换的非常快，对于外界调用者来说相当于同一时刻多个任务一起执行了。 二、Java创建线程的3种方式1. 继承 Thread 类 定义 Thread 类的子类,并重写该类的 run() 方法,该 run() 方法的方法体就代表了线程需要完成的任务.因此把 run() 方法称为线程执行体。 创建 Thread 子类的实例,即创建了线程对象。 调用线程对象的 start() 方法来启动该线程。 123456789101112131415161718public class MyThread extends Thread &#123; public MyThread() &#123; &#125; public void run() &#123; for(int i=0;i&lt;10;i++) &#123; System.out.println(Thread.currentThread()+&quot;:&quot;+i); &#125; &#125; public static void main(String[] args) &#123; MyThread mThread1=new MyThread(); MyThread mThread2=new MyThread(); MyThread myThread3=new MyThread(); mThread1.start(); mThread2.start(); myThread3.start(); &#125;&#125; 2. 实现 Runnable 接口 定义 Runnable 接口的实现类,并重写该接口的 run() 方法,该 run() 方法的方法体同样是该线程的线程执行体。 创建 Runnable 实现类的实例,并以此实例作为 Thread 的target来创建 Thread 对象,该 Thread 对象才是真正的线程对象。 调用线程对象的 start() 方法来启动该线程。 12345678910111213141516171819202122public class MyThread implements Runnable&#123; public static int count=20; public void run() &#123; while(count&gt;0) &#123; try &#123; Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+&quot;-当前剩余票数:&quot;+count--); &#125; &#125; public static void main(String[] args) &#123; MyThread Thread1=new MyThread(); Thread mThread1=new Thread(Thread1,&quot;线程1&quot;); Thread mThread2=new Thread(Thread1,&quot;线程2&quot;); Thread mThread3=new Thread(Thread1,&quot;线程3&quot;); mThread1.start(); mThread2.start(); myThread3.start(); &#125;&#125; 推荐使用此方式 3. 使用 Callable 和 Future 创建 Callable 接口的实现类,并实现 call() 方法,该 call() 方法将作为线程执行体,且该 call() 方法有返回值,再创建 Callable 实现类的实例。 使用 FutureTask 类来包装 Callable 对象,该 FutureTask 对象封装了该 Callable 对象的 call() 方法的返回值。 使用 FutureTask 对象作为 Thread 对象的 target 创建并启动新线程。 调用 FutureTask 对象的 get() 方法来获得子线程执行结束后的返回值。 123456789101112131415161718192021222324252627282930import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask; public class MyThread implements Callable&lt;String&gt; &#123; private int count = 20; @Override public String call() throws Exception &#123; for (int i = count; i &gt; 0; i--) &#123; //Thread.yield(); System.out.println(Thread.currentThread().getName()+&quot;当前票数：&quot; + i); &#125; return &quot;sale out&quot;; &#125; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; Callable&lt;String&gt; callable =new MyThread(); FutureTask &lt;String&gt;futureTask=new FutureTask&lt;&gt;(callable); Thread mThread=new Thread(futureTask); Thread mThread2=new Thread(futureTask); Thread mThread3=new Thread(futureTask); //mThread.setName(&quot;hhh&quot;); mThread.start(); mThread2.start(); mThread3.start(); System.out.println(futureTask.get()); &#125;&#125; 4. 使用线程池通过 java.util.concurrent.Executors 的工具类可以创建三种类型的普通线程池： (1)SingleThreadPoolExecutor :单线程池适用于需要保证顺序执行各个任务的场景。 12345678910111213141516171819202122import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors; public class Test &#123; public static void main(String[] args) &#123; ExecutorService ex=Executors.newSingleThreadExecutor(); for(int i=0;i&lt;5;i++) &#123; ex.submit(new Runnable() &#123; @Override public void run() &#123; for(int j=0;j&lt;10;j++) &#123; System.out.println(Thread.currentThread().getName()+j); &#125; &#125; &#125;); &#125; ex.shutdown(); &#125; &#125; (2) FixThreadPool(int n); 固定大小的线程池使用于为了满足资源管理需求而需要限制当前线程数量的场合。使用于负载比较重的服务器。 12345678910111213141516171819202122import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors; public class Test &#123; public static void main(String[] args) &#123; ExecutorService ex=Executors.newFixedThreadPool(5); for(int i=0;i&lt;5;i++) &#123; ex.submit(new Runnable() &#123; @Override public void run() &#123; for(int j=0;j&lt;10;j++) &#123; System.out.println(Thread.currentThread().getName()+j); &#125; &#125; &#125;); &#125; ex.shutdown(); &#125; &#125; (5)CashedThreadPool(); 缓存线程池当提交任务速度高于线程池中任务处理速度时，缓存线程池会不断的创建线程 适用于提交短期的异步小程序，以及负载较轻的服务器 12345678910111213141516171819202122import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors; public class Test &#123; public static void main(String[] args) &#123; ExecutorService ex=Executors.newCachedThreadPool(); for(int i=0;i&lt;5;i++) &#123; ex.submit(new Runnable() &#123; @Override public void run() &#123; for(int j=0;j&lt;10;j++) &#123; System.out.println(Thread.currentThread().getName()+j); &#125; &#125; &#125;); &#125; ex.shutdown(); &#125; &#125;","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Java创建线程的4种方式","slug":"Java创建线程的4种方式","permalink":"https://tianxiafeiyu.github.io/tags/Java%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E7%9A%844%E7%A7%8D%E6%96%B9%E5%BC%8F/"}]},{"title":"Java序列化与反序列化","slug":"技术开发/java/Java序列化与反序列化","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Java序列化与反序列化/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Java%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/","excerpt":"","text":"1、序列化把对象转换为字节序列的过程。 2、反序列化把字节序列恢复为对象的过程。 3、对象的序列化主要有两种用途：1） 把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中； 2） 在网络上传送对象的字节序列。 4、serialVersionUID的作用对象序列化的版本号，凡是实现Serializable接口的类都有一个表示序列化版本标识符的静态变量。 如果没有显式定义serialVersionUID，那么java编译器会自动给这个class进行一个摘要算法，类似于指纹算法，只要这个文件多一个空格，得到的UID就会截然不同的，可以保证在这么多类中，这个编号是唯一的。所以class有了修改之后，已修改类的serialVersionUID和之前已经序列化的文件流中的类的的serialVersionUID是不一致的，处于安全机制考虑，程序抛出了错误，并且拒绝载入。 如果显式定义了serialVersionUID，在序列化后，在类中添加字段，或者方法，不会影响到后期的还原。可以说serialVersionUID是序列化和反序列化之间彼此认识的唯一信物。 显式地定义serialVersionUID有两种用途： 1、 在某些场合，希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有相同的serialVersionUID； 2、 在某些场合，不希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有不同的serialVersionUID。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Java序列化与反序列化","slug":"Java序列化与反序列化","permalink":"https://tianxiafeiyu.github.io/tags/Java%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/"}]},{"title":"Java异常处理原则","slug":"技术开发/java/Java异常处理原则","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Java异常处理原则/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Java%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E5%8E%9F%E5%88%99/","excerpt":"","text":"Java的异常处理原则 Java异常处理中的“反例”： 丢弃异常 捕获了异常却不作任何处理，可以算得上Java编程中的杀手。调用一下printStackTrace算不上“处理异常”。既然捕获了异常，就要对它进行适当的处理。不要捕获异常之后又把它丢弃，不予理睬。 不指定具体的异常 用一个catch语句捕获所有的异常。最常见的情形就是使用catch（Exception ex）语句。在catch语句中尽可能指定具体的异常类型，必要时使用多个catch.不要试图处理所有可能出现的异常。 占用资源不释放 如果程序用到了文件、Socket、JDBC连接之类的资源，即使遇到了异常，也要正确释放占用的资源。Java提供了一个简化这类操作的关键词finally。 保证所有资源都被正确释放。充分运用finally关键词。 不说明异常的详细信息 在出现异常时，最好能够提供一些文字信息，例如当前正在执行的类、方法和其他状态信息，包括以一种更适合阅读的方式整理和组织printStackTrace提供的信息。 过于庞大的try块 一些新手常常把大量的代码放入单个try块，然后再在catch语句中声明Exception，而不是分离各个可能出现异常的段落并分别捕获其异常。这种做法为分析程序抛出异常的原因带来了困难，因为一大段代码中有太多的地方可能抛出Exception。应尽量减小try块的体积。 输出数据不完整 不完整的数据是Java程序的隐形杀手。出现异常导致输出数据不完整，应该加入提示说明。全面考虑可能出现的异常以及这些异常对执行流程的影响。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Java异常处理原则","slug":"Java异常处理原则","permalink":"https://tianxiafeiyu.github.io/tags/Java%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E5%8E%9F%E5%88%99/"}]},{"title":"Java构造函数细节","slug":"技术开发/java/Java构造函数细节","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Java构造函数细节/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Java%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E7%BB%86%E8%8A%82/","excerpt":"","text":"（1）. 当类中没有定义构造函数时，系统会指定给该类加上一个空参数的构造函数。这个是类中默认的构造函数。当类中如果自定义了构造函数，这时默认的构造函数就没有了。 注意: 有时候无参构造函数是必须的，比如用 @RequestBody 接收参数对象，如果没有无参数构造函数，无法正确接收参数，报错： 1JSON parse error: Can not construct instance of xxx: no suitable constructor found, can not deserialize from Object value （2）. 在一个类中可以定义多个构造函数，以进行不同的初始化。多个构造函数存在于类中，是以重载的形式体现的。因为构造函数的名称都相同。 构造函数与普通函数的区别： 一般函数是用于定义对象应该具备的功能。而构造函数定义的是，对象在调用功能之前，在建立时，应该具备的一些内容。也就是对象的初始化内容。 构造函数是在对象建立时由 jvm 调用, 给对象初始化。一般函数是对象建立后，当对象调用该功能时才会执行。 普通函数可以使用对象多次调用，构造函数就在创建对象时调用。 构造函数的函数名要与类名一样，而普通的函数只要符合标识符的命名规则即可。 构造函数没有返回值类型。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Java构造函数细节","slug":"Java构造函数细节","permalink":"https://tianxiafeiyu.github.io/tags/Java%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E7%BB%86%E8%8A%82/"}]},{"title":"Java正则表达式","slug":"技术开发/java/Java正则表达式","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Java正则表达式/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Java%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"","text":"一直都有接触正则表达式，但是都是照搬过来使用的程度，没有能系统的学习，也没有留下一些笔记，下次使用还需网上查找资料。此次正好稍微做点记录，方便遗忘后重拾。 1. 什么是正则表达式正则表达式(Regular Expression)是一种文本模式，包括普通字符（例如，a 到 z 之间的字母）和特殊字符（称为”元字符”）。正则表达式使用单个字符串来描述、匹配一系列匹配某个句法规则的字符串。 2. 正则表达式知识点 一个字符串其实就是一个简单的正则表达式，例如 Hello World 正则表达式匹配 “Hello World” 字符串。 java.util.regex 包主要包括以下三个类： Pattern 类：pattern 对象是一个正则表达式的编译表示。Pattern 类没有公共构造方法。要创建一个 Pattern 对象，你必须首先调用其公共静态编译方法，它返回一个 Pattern 对象。该方法接受一个正则表达式作为它的第一个参数。 Matcher 类：Matcher 对象是对输入字符串进行解释和匹配操作的引擎。与Pattern 类一样，Matcher 也没有公共构造方法。你需要调用 Pattern 对象的 matcher 方法来获得一个 Matcher 对象。 PatternSyntaxException：PatternSyntaxException 是一个非强制异常类，它表示一个正则表达式模式中的语法错误。 以下实例中使用了正则表达式 .runoob. 用于查找字符串中是否包了 runoob 子串： 12345678910111213import java.util.regex.*; class RegexExample1&#123; public static void main(String args[])&#123; String content = &quot;I am noob &quot; + &quot;from runoob.com.&quot;; String pattern = &quot;.*runoob.*&quot;; boolean isMatch = Pattern.matches(pattern, content); System.out.println(&quot;字符串中是否包含了 &#x27;runoob&#x27; 子字符串? &quot; + isMatch); &#125;&#125; 3. Java 正则表达式语法在其他语言中，\\ 表示：我想要在正则表达式中插入一个普通的（字面上的）反斜杠，请不要给它任何特殊的意义。 在 Java 中，\\ 表示：我要插入一个正则表达式的反斜线，所以其后的字符具有特殊的意义。 所以，在其他的语言中（如Perl），一个反斜杠 \\ 就足以具有转义的作用，而在 Java 中正则表达式中则需要有两个反斜杠才能被解析为其他语言中的转义作用。也可以简单的理解在 Java 的正则表达式中，两个 \\ 代表其他语言中的一个 \\，这也就是为什么表示一位数字的正则表达式是 \\d，而表示一个普通的反斜杠是 \\\\。 字符 说明 \\ 将下一字符标记为特殊字符、文本、反向引用或八进制转义符。例如，”n”匹配字符”n”。”\\n”匹配换行符。序列”\\\\“匹配”\\“，”\\(“匹配”(“。 ^ 匹配输入字符串开始的位置。如果设置了 RegExp 对象的 Multiline 属性，^ 还会与”\\n”或”\\r”之后的位置匹配。 $ 匹配输入字符串结尾的位置。如果设置了 RegExp 对象的 Multiline 属性，$ 还会与”\\n”或”\\r”之前的位置匹配。 | 零次或多次匹配前面的字符或子表达式。例如，zo* 匹配”z”和”zoo”。* 等效于 {0,}。+ | 一次或多次匹配前面的字符或子表达式。例如，”zo+”与”zo”和”zoo”匹配，但与”z”不匹配。+ 等效于 {1,}。? | 零次或一次匹配前面的字符或子表达式。例如，”do(es)?”匹配”do”或”does”中的”do”。? 等效于 {0,1}。{n} | n 是非负整数。正好匹配 n 次。例如，”o{2}”与”Bob”中的”o”不匹配，但与”food”中的两个”o”匹配。{n,} | n 是非负整数。至少匹配 n 次。例如，”o{2,}”不匹配”Bob”中的”o”，而匹配”foooood”中的所有 o。”o{1,}”等效于”o+”。”o{0,}”等效于”o*”。{n,m} | m 和 n 是非负整数，其中 n &lt;&#x3D; m。匹配至少 n 次，至多 m 次。例如，”o{1,3}”匹配”fooooood”中的头三个 o。’o{0,1}’ 等效于 ‘o?’。注意：您不能将空格插入逗号和数字之间。? | 当此字符紧随任何其他限定符（*、+、?、{n}、{n,}、{n,m}）之后时，匹配模式是”非贪心的”。”非贪心的”模式匹配搜索到的、尽可能短的字符串，而默认的”贪心的”模式匹配搜索到的、尽可能长的字符串。例如，在字符串”oooo”中，”o+?”只匹配单个”o”，而”o+”匹配所有”o”。x|y | 匹配 x 或 y。例如，’z|food’ 匹配”z”或”food”。’(z|f)ood’ 匹配”zood”或”food”。[xyz] | 字符集。匹配包含的任一字符。例如，”[abc]”匹配”plain”中的”a”。[^xyz] | 反向字符集。匹配未包含的任何字符。例如，”[^abc]”匹配”plain”中”p”，”l”，”i”，”n”。[a-z] | 字符范围。匹配指定范围内的任何字符。例如，”[a-z]”匹配”a”到”z”范围内的任何小写字母。[^a-z] | 反向范围字符。匹配不在指定的范围内的任何字符。例如，”[^a-z]”匹配任何不在”a”到”z”范围内的任何字符。\\b | 匹配一个字边界，即字与空格间的位置。例如，”er\\b”匹配”never”中的”er”，但不匹配”verb”中的”er”。\\B | 非字边界匹配。”er\\B”匹配”verb”中的”er”，但不匹配”never”中的”er”。\\cx | 匹配 x 指示的控制字符。例如，\\cM 匹配 Control-M 或回车符。x 的值必须在 A-Z 或 a-z 之间。如果不是这样，则假定 c 就是”c”字符本身。\\d | 数字字符匹配。等效于 [0-9]。\\D | 非数字字符匹配。等效于 [^0-9]。\\f | 换页符匹配。等效于 \\x0c 和 \\cL。\\n | 换行符匹配。等效于 \\x0a 和 \\cJ。\\r | 匹配一个回车符。等效于 \\x0d 和 \\cM。\\s | 匹配任何空白字符，包括空格、制表符、换页符等。与 [ \\f\\n\\r\\t\\v] 等效。\\S | 匹配任何非空白字符。与 [^ \\f\\n\\r\\t\\v] 等效。\\t | 制表符匹配。与 \\x09 和 \\cI 等效。\\v | 垂直制表符匹配。与 \\x0b 和 \\cK 等效。\\w | 匹配任何字类字符，包括下划线。与”[A-Za-z0-9_]”等效。\\W | 与任何非单词字符匹配。与”[^A-Za-z0-9_]”等效。 4. 正则表达式应用 匹配字符串，如 手机号校验、邮箱校验 切割字符串，提取字符串信息 场景：需要从一串字符串中提取出其中的主机ip信息 123456String str = &quot;ip地址是127.0.0.1:8848，真的，不骗你&quot;Pattern pattern = Pattern.compile(&quot;(((localhost)|(\\\\d+.&#123;1&#125;\\\\d+.&#123;1&#125;\\\\d+.&#123;1&#125;\\\\d+))\\\\:&#123;1&#125;\\\\d+)&quot;);Matcher matcher = pattern.matcher(str);while (matcher.find())&#123; // 一定要先调用 find()函数！ host = matcher.group(); &#125; 详情见： 菜鸟教程：Java 正则表达式&amp;emsp;&amp;emsp; &amp;emsp; &amp;ensp;JAVA正则表达式：Pattern类与Matcher类详解","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Java正则表达式","slug":"Java正则表达式","permalink":"https://tianxiafeiyu.github.io/tags/Java%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}]},{"title":"Java获取时间工具类","slug":"技术开发/java/Java获取时间工具类","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Java获取时间工具类/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Java%E8%8E%B7%E5%8F%96%E6%97%B6%E9%97%B4%E5%B7%A5%E5%85%B7%E7%B1%BB/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738public class CalendarUtil &#123; /** * 获取当前时间 * @Param format：时间格式，例：yyyy-MM-dd HH:mm:ss * @return */ public static String getTimeNow(String format)&#123; Calendar calendar= Calendar.getInstance(); SimpleDateFormat dateFormat= new SimpleDateFormat(format); return dateFormat.format(calendar.getTime()); &#125; /** * 获取当前时间的前n天 * @Param format：时间格式，例：yyyy-MM-dd HH:mm:ss * @return */ public static String getTimeDayBefore(int n, String format)&#123; Calendar calendar= Calendar.getInstance(); calendar.add(Calendar.DAY_OF_MONTH, - n); SimpleDateFormat dateFormat= new SimpleDateFormat(format); return dateFormat.format(calendar.getTime()); &#125; /** * 更加自由的时间字符串获取 * @param n 当前时间之间 n 个单位 * @param step 步进单位，如 Calendar.MONTH(2) * @param format 时间格式，如：yyyy-MM-dd HH:mm:ss * @return */ public static String getTimeBefore(int n, int step, String format)&#123; Calendar calendar= Calendar.getInstance(); calendar.add(step, - n); SimpleDateFormat dateFormat= new SimpleDateFormat(format); return dateFormat.format(calendar.getTime()); &#125;&#125;","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Java获取时间工具类","slug":"Java获取时间工具类","permalink":"https://tianxiafeiyu.github.io/tags/Java%E8%8E%B7%E5%8F%96%E6%97%B6%E9%97%B4%E5%B7%A5%E5%85%B7%E7%B1%BB/"}]},{"title":"Jenkins遇到的坑","slug":"技术开发/java/Jenkins遇到的坑","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Jenkins遇到的坑/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Jenkins%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/","excerpt":"","text":"一开始是仓库没有jar包，编译报错，上传jar后仍然报错，确认信息填写正确。 报错： 1Failure to find com.github.sanjusoftware:yamlbeans:jar:1.11 in http://nexus.apusic.net/content/groups/public was cached in the local repository, resolution will not be reattempted until the update interval of nexus has elapsed or updates are forced 由于之前编译有了缓存信息，后面再编译不会再从远程仓库拉取，需要删掉本地仓库缓存文件。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Jenkins遇到的坑","slug":"Jenkins遇到的坑","permalink":"https://tianxiafeiyu.github.io/tags/Jenkins%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/"}]},{"title":"Skywalking使用graphql查询","slug":"技术开发/java/Skywalking使用graphql查询","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Skywalking使用graphql查询/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Skywalking%E4%BD%BF%E7%94%A8graphql%E6%9F%A5%E8%AF%A2/","excerpt":"","text":"查询单个服务的数据信息1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&#123; &quot;query&quot;: &quot;query queryData($serviceId: ID!,$duration: Duration!) &#123; serviceApdexScore: getLinearIntValues(metric: &#123; name: \\&quot;service_apdex\\&quot; id: $serviceId &#125;, duration: $duration) &#123; values &#123;value&#125; &#125; serviceResponseTime: getLinearIntValues(metric: &#123; name: \\&quot;service_resp_time\\&quot; id: $serviceId &#125;, duration: $duration) &#123; values &#123;value&#125; &#125; serviceThroughput: getLinearIntValues(metric: &#123; name: \\&quot;service_cpm\\&quot; id: $serviceId &#125;, duration: $duration) &#123; values &#123; value &#125; &#125; serviceSLA: getLinearIntValues(metric: &#123; name: \\&quot;service_sla\\&quot; id: $serviceId &#125;, duration: $duration) &#123; values &#123; value &#125; &#125; globalPercentile: getMultipleLinearIntValues(metric: &#123; name: \\&quot;all_percentile\\&quot; &#125;, numOfLinear: 5, duration: $duration) &#123; values &#123; value &#125; &#125; servicePercentile: getMultipleLinearIntValues(metric: &#123; name: \\&quot;service_percentile\\&quot; id: $serviceId &#125;, numOfLinear: 5, duration: $duration) &#123; values &#123; value &#125; &#125; serviceSlowEndpoint: getEndpointTopN( serviceId: $serviceId duration: $duration name: \\&quot;endpoint_avg\\&quot;, topN: 10, order: DES ) &#123; key: id label: name value &#125; serviceInstanceThroughput: getServiceInstanceTopN( serviceId: $serviceId duration: $duration name: \\&quot;service_instance_cpm\\&quot;, topN: 10, order: DES ) &#123; key: id label: name value &#125;&#125;&quot;, &quot;variables&quot;:&#123; &quot;atabaseId&quot;:&quot;&quot;, &quot;duration&quot;:&#123;&quot;start&quot;: &quot;2020-05-18&quot;, &quot;end&quot;: &quot;2020-05-21&quot;, &quot;step&quot;: &quot;DAY&quot;&#125;, &quot;endpointId&quot;:&quot;4&quot;, &quot;endpointName&quot;:&quot;/api/items&quot;, &quot;instanceId&quot;:&quot;5&quot;, &quot;serviceId&quot;:&quot;4&quot; &#125;&#125;&#123;&quot;data&quot;:&#123;&quot;serviceApdexScore&quot;:&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:10000&#125;]&#125;,&quot;serviceResponseTime&quot;:&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:380&#125;]&#125;,&quot;serviceThroughput&quot;:&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;]&#125;,&quot;serviceSLA&quot;:&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:10000&#125;]&#125;,&quot;globalPercentile&quot;:[&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:370&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:410&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:410&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:1560&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:1560&#125;]&#125;],&quot;servicePercentile&quot;:[&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:370&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:380&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:380&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:380&#125;]&#125;,&#123;&quot;values&quot;:[&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:0&#125;,&#123;&quot;value&quot;:380&#125;]&#125;],&quot;serviceSlowEndpoint&quot;:[&#123;&quot;key&quot;:&quot;4&quot;,&quot;label&quot;:&quot;/api/items&quot;,&quot;value&quot;:380&#125;],&quot;serviceInstanceThroughput&quot;:[&#123;&quot;key&quot;:&quot;5&quot;,&quot;label&quot;:&quot;provider-pid:4920@KFW7BT1P01V035&quot;,&quot;value&quot;:0&#125;]&#125;&#125; 2. 查询一段时间内的服务id和名称1234567891011121314151617181920212223242526272829303132&#123; &quot;query&quot;: &quot;query queryServices($duration: Duration!) &#123;services: getAllServices(duration: $duration) &#123;id, name&#125;&#125;&quot;, &quot;variables&quot;: &#123; &quot;duration&quot;: &#123; &quot;start&quot;: &quot;2020-05-21&quot;, &quot;end&quot;: &quot;2020-05-22&quot;, &quot;step&quot;: &quot;DAY&quot; &#125; &#125;&#125;&#123; &quot;data&quot;: &#123; &quot;services&quot;: [ &#123; &quot;id&quot;: &quot;3&quot;, &quot;name&quot;: &quot;consumer&quot; &#125;, &#123; &quot;id&quot;: &quot;7&quot;, &quot;name&quot;: &quot;SpringBootWithSkywalking-HelloTomcat&quot; &#125;, &#123; &quot;id&quot;: &quot;2&quot;, &quot;name&quot;: &quot;hello-world-demo&quot; &#125;, &#123; &quot;id&quot;: &quot;4&quot;, &quot;name&quot;: &quot;provider&quot; &#125; ] &#125;&#125; 获得服务的id和name，可以用来查询响应时间、可用性等指标 3. 根据服务id数组查询响应时间、服务apdex分数、slas数、吞吐量123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119&#123; &quot;query&quot;: &quot;query queryData($serviceIds: [ID!]!,$duration: Duration!) &#123; serviceResponseTime: getValues(metric: &#123; name: \\&quot;service_resp_time\\&quot; ids: $serviceIds &#125;, duration: $duration) &#123; values &#123;id, value&#125; &#125; serviceApdexScore: getValues(metric: &#123; name: \\&quot;service_apdex\\&quot; ids: $serviceIds &#125;, duration: $duration) &#123; values &#123; id,value&#125; &#125; serviceSLA: getValues(metric: &#123; name: \\&quot;service_sla\\&quot; ids: $serviceIds &#125;, duration: $duration) &#123; values &#123;id, value&#125; &#125; serviceThroughput: getValues(metric: &#123; name: \\&quot;service_cpm\\&quot; ids: $serviceIds &#125;, duration: $duration) &#123; values &#123;id, value&#125; &#125; &#125;&quot;, &quot;variables&quot;:&#123; &quot;duration&quot;:&#123;&quot;start&quot;: &quot;2020-05-21&quot;, &quot;end&quot;: &quot;2020-05-22&quot;, &quot;step&quot;: &quot;DAY&quot;&#125;, &quot;serviceIds&quot;:[&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;7&quot;] &#125;&#125;&#123; &quot;data&quot;: &#123; &quot;serviceResponseTime&quot;: &#123; &quot;values&quot;: [ &#123; &quot;id&quot;: &quot;2&quot;, &quot;value&quot;: 191 &#125;, &#123; &quot;id&quot;: &quot;3&quot;, &quot;value&quot;: 989 &#125;, &#123; &quot;id&quot;: &quot;4&quot;, &quot;value&quot;: 380 &#125;, &#123; &quot;id&quot;: &quot;7&quot;, &quot;value&quot;: 144 &#125; ] &#125;, &quot;serviceApdexScore&quot;: &#123; &quot;values&quot;: [ &#123; &quot;id&quot;: &quot;2&quot;, &quot;value&quot;: 10000 &#125;, &#123; &quot;id&quot;: &quot;3&quot;, &quot;value&quot;: 7500 &#125;, &#123; &quot;id&quot;: &quot;4&quot;, &quot;value&quot;: 10000 &#125;, &#123; &quot;id&quot;: &quot;7&quot;, &quot;value&quot;: 10000 &#125; ] &#125;, &quot;serviceSLA&quot;: &#123; &quot;values&quot;: [ &#123; &quot;id&quot;: &quot;2&quot;, &quot;value&quot;: 10000 &#125;, &#123; &quot;id&quot;: &quot;3&quot;, &quot;value&quot;: 10000 &#125;, &#123; &quot;id&quot;: &quot;4&quot;, &quot;value&quot;: 10000 &#125;, &#123; &quot;id&quot;: &quot;7&quot;, &quot;value&quot;: 10000 &#125; ] &#125;, &quot;serviceThroughput&quot;: &#123; &quot;values&quot;: [ &#123; &quot;id&quot;: &quot;2&quot;, &quot;value&quot;: 0 &#125;, &#123; &quot;id&quot;: &quot;3&quot;, &quot;value&quot;: 0 &#125;, &#123; &quot;id&quot;: &quot;4&quot;, &quot;value&quot;: 0 &#125;, &#123; &quot;id&quot;: &quot;7&quot;, &quot;value&quot;: 0 &#125; ] &#125; &#125;&#125;","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Skywalking使用graphql查询","slug":"Skywalking使用graphql查询","permalink":"https://tianxiafeiyu.github.io/tags/Skywalking%E4%BD%BF%E7%94%A8graphql%E6%9F%A5%E8%AF%A2/"}]},{"title":"Skywalking学习","slug":"技术开发/java/Skywalking学习","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Skywalking学习/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Skywalking%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"SkyWalking 中非常重要的三个概念： 服务(Service) ：表示对请求提供相同行为的一系列或一组工作负载。在使用 Agent 或 SDK 的时候，你可以定义服务的名字。如果不定义的话，SkyWalking 将会使用你在平台（例如说 Istio）上定义的名字。 服务实例(Service Instance) ：上述的一组工作负载中的每一个工作负载称为一个实例。就像 Kubernetes 中的 pods 一样, 服务实例未必就是操作系统上的一个进程。但当你在使用 Agent 的时候, 一个服务实例实际就是操作系统上的一个真实进程。 端点(Endpoint) ：对于特定服务所接收的请求路径, 如 HTTP 的 URI 路径和 gRPC 服务的类名 + 方法签名。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Skywalking学习","slug":"Skywalking学习","permalink":"https://tianxiafeiyu.github.io/tags/Skywalking%E5%AD%A6%E4%B9%A0/"}]},{"title":"Spring boot单元测试","slug":"技术开发/java/Spring boot单元测试","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Spring boot单元测试/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Spring%20boot%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/","excerpt":"","text":"公司职级认证有单元测试要求，花了一天时间把欠下的的补完了。。。 spring boot引入单元测试pom.xml 文件中写入： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; spring boot中单元测试目录与main同级 spring boot使用单元测试 快捷生成测试类idea 中选中要测试的类 -&gt; Ctrl+Shift+T 打开创建测试类窗口 -&gt; 选择要测试的方法，创建测试类 生成的类路径为 Test 包下的同名路径。 自己创建测试类Test 目录下自己创建类。。。 类创建完成后还需要加上注解，如下： 123456789@RunWith(SpringRunner.class)@SpringBootTestpublic class myServiceTest &#123; @Test public void test()&#123; //... &#125;&#125; 不同场景下的单元测试 对于 Controller 层单元测试，使用 @AutoConfigureMockMvc，示例代码如下： 1234567891011121314151617181920212223242526272829303132@RunWith(SpringRunner.class)@SpringBootTest@AutoConfigureMockMvcpublic class LicenseInfoResourceTest extends AbstractRestControllerTest &#123; /** * 初始化MockMvc */ @Autowired private MockMvc mvc; /** * 测试的controller */ @MockBean private LicenseInfoResource licenseInfoResource; @Before public void setUp() &#123; SecurityContextHolder.clearContext(); &#125; @Test @WithMockUser(username = &quot;admin&quot;, password = &quot;admin&quot;) public void getLicenseInfo() throws Exception &#123; MvcResult mvcResult = mvc.perform(MockMvcRequestBuilders.get(&quot;/license/get_platform_info&quot;)) .andExpect(MockMvcResultMatchers.status().isOk()) .andDo(MockMvcResultHandlers.print()) .andReturn(); System.out.println(&quot;content&quot; + mvcResult.getResponse().getContentAsString()); &#125;&#125; 对于有运行时环境的要求，当前用户记录等，需要在类或者方法上加上注册变量： 1@WithMockUser(username = &quot;admin&quot;, password = &quot;admin&quot;) 对于单点登陆应用，调用接口需要 token ,可以先获取token，然后加入到请求头中： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/* 获取token工具类 */public final class LogInUtils &#123; private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper(); private LogInUtils() &#123; &#125; public static String getTokenForLogin(String username, String password, MockMvc mockMvc) throws Exception &#123; // 设置验证码 MockHttpSession session = new MockHttpSession(); session.setAttribute(&quot;vrifyCode&quot;, &quot;123456&quot;); String code = &quot;123456&quot;; String content = mockMvc.perform(post(&quot;/api/authenticate&quot;) .contentType(MediaType.APPLICATION_JSON) .session(session) .content(&quot;&#123;\\&quot;password\\&quot;: \\&quot;&quot; + password + &quot;\\&quot;, \\&quot;username\\&quot;: \\&quot;&quot; + username + &quot;\\&quot;, \\&quot;code\\&quot;: \\&quot;&quot;+ code + &quot;\\&quot;&#125;&quot;)) .andReturn() .getResponse() .getContentAsString(); AuthenticationResponse authResponse = OBJECT_MAPPER.readValue(content, AuthenticationResponse.class); return authResponse.getIdToken(); &#125; private static class AuthenticationResponse &#123; @JsonAlias(&quot;id_token&quot;) private String idToken; public void setIdToken(String idToken) &#123; this.idToken = idToken; &#125; public String getIdToken() &#123; return idToken; &#125; &#125;&#125;/* 获取token加入到请求头 */@Testpublic void createRole() throws Exception &#123; final String token = LogInUtils.getTokenForLogin(&quot;admin&quot;, &quot;admin&quot;, mvc); String json = &quot;&#123;\\&quot;name\\&quot;:\\&quot;超级管理员2\\&quot;,\\&quot;remark\\&quot;:\\&quot;权限\\&quot;,\\&quot;permissionIds\\&quot;:\\&quot;1\\&quot;&#125;&quot;; MvcResult mvcResult = mvc.perform(MockMvcRequestBuilders.post(&quot;/role/create_role&quot;) .contentType(MediaType.APPLICATION_JSON) .content(json) .header(&quot;Authorization&quot;, &quot;Bearer &quot; + token)) .andExpect(MockMvcResultMatchers.status().isOk()) .andDo(MockMvcResultHandlers.print()) .andReturn(); System.out.println(&quot;status: &quot; + mvcResult.getResponse().getStatus());&#125; MocMvc详解转载自 https://blog.csdn.net/wo541075754/article/details/88983708 什么是Mock?模拟对象（mock object），是以可控的方式模拟真实对象行为的假对象。在编程过程中，通常通过模拟一些输入数据，来验证程序是否达到预期结果。使用模拟对象，可以模拟复杂的、真实的对象行为。如果在单元测试中无法使用真实对象，可采用模拟对象进行替代。 什么是MockMvc？MockMvc是由spring-test包提供，实现了对Http请求的模拟，能够直接使用网络的形式，转换到Controller的调用，使得测试速度快、不依赖网络环境。同时提供了一套验证的工具，结果的验证十分方便。 spring使用MocMvcspring中使用MockMvcBuilder来构造MocMvc。它有两种实现方式：StandaloneMockMvcBuilder和DefaultMockMvcBuilder，分别对应两种测试方式，即独立安装和集成Web环境测试（并不会集成真正的web环境，而是通过相应的Mock API进行模拟测试，无须启动服务器）。代码示例： 1234567891011121314151617181920//SpringBoot1.4版本之前用的是SpringJUnit4ClassRunner.class@RunWith(SpringRunner.class)//SpringBoot1.4版本之前用的是@SpringApplicationConfiguration(classes = Application.class)@SpringBootTest//测试环境使用，用来表示测试环境使用的ApplicationContext将是WebApplicationContext类型的@WebAppConfigurationpublic class HelloWorldTest &#123; private MockMvc mockMvc; @Autowired private WebApplicationContext webApplicationContext; @Before public void setup() &#123; // 实例化方式一 mockMvc = MockMvcBuilders.standaloneSetup(new HelloWorldController()).build(); // 实例化方式二// mockMvc = MockMvcBuilders.webAppContextSetup(webApplicationContext).build(); &#125; 单元测试方法： 12345678910111213141516171819202122@Testpublic void testHello() throws Exception &#123; /* * 1、mockMvc.perform执行一个请求。 * 2、MockMvcRequestBuilders.get(&quot;XXX&quot;)构造一个请求。 * 3、ResultActions.param添加请求传值 * 4、ResultActions.accept(MediaType.TEXT_HTML_VALUE))设置返回类型 * 5、ResultActions.andExpect添加执行完成后的断言。 * 6、ResultActions.andDo添加一个结果处理器，表示要对结果做点什么事情 * 比如此处使用MockMvcResultHandlers.print()输出整个响应结果信息。 * 7、ResultActions.andReturn表示执行完成后返回相应的结果。 */ mockMvc.perform(MockMvcRequestBuilders .get(&quot;/hello&quot;) // 设置返回值类型为utf-8，否则默认为ISO-8859-1 .accept(MediaType.APPLICATION_JSON_UTF8_VALUE) .param(&quot;name&quot;, &quot;Tom&quot;)) .andExpect(MockMvcResultMatchers.status().isOk()) .andExpect(MockMvcResultMatchers.content().string(&quot;Hello Tom!&quot;)) .andDo(MockMvcResultHandlers.print());&#125; 整个过程如下： 1234561、准备测试环境2、通过MockMvc执行请求3、添加验证断言4、添加结果处理器5、得到MvcResult进行自定义断言/进行下一步的异步请求6、卸载测试环境 Sping boot2.0后使用MocMvc更加方便，只需要在测试类加上@AutoConfigureMockMvc注解，就可以注入MocMvc: 123456789101112@RunWith(SpringRunner.class)@SpringBootTest@AutoConfigureMockMvcpublic class Test &#123; /** * 初始化MockMvc */ @Autowired private MockMvc mvc; //...&#125; 注意事项：如果使用DefaultMockMvcBuilder进行MockMvc实例化时需在SpringBoot启动类上添加组件扫描的package的指定，否则会出现404。如： 1@ComponentScan(basePackages = &quot;com.secbro2&quot;) 一些常用的测试 测试普通控制器 123456mockMvc.perform(get(&quot;/user/&#123;id&#125;&quot;, 1)) //执行请求 .andExpect(model().attributeExists(&quot;user&quot;)) //验证存储模型数据 .andExpect(view().name(&quot;user/view&quot;)) //验证viewName .andExpect(forwardedUrl(&quot;/WEB-INF/jsp/user/view.jsp&quot;))//验证视图渲染时forward到的jsp .andExpect(status().isOk())//验证状态码 .andDo(print()); //输出MvcResult到控制台 得到MvcResult自定义验证 123MvcResult result = mockMvc.perform(get(&quot;/user/&#123;id&#125;&quot;, 1))//执行请求 .andReturn(); //返回MvcResult Assert.assertNotNull(result.getModelAndView().getModel().get(&quot;user&quot;)); //自定义断言 验证请求参数绑定到模型数据及Flash属性 123456mockMvc.perform(post(&quot;/user&quot;).param(&quot;name&quot;, &quot;zhang&quot;)) //执行传递参数的POST请求(也可以post(&quot;/user?name=zhang&quot;)) .andExpect(handler().handlerType(UserController.class)) //验证执行的控制器类型 .andExpect(handler().methodName(&quot;create&quot;)) //验证执行的控制器方法名 .andExpect(model().hasNoErrors()) //验证页面没有错误 .andExpect(flash().attributeExists(&quot;success&quot;)) //验证存在flash属性 .andExpect(view().name(&quot;redirect:/user&quot;)); //验证视图 文件上传 1234byte[] bytes = new byte[] &#123;1, 2&#125;; mockMvc.perform(fileUpload(&quot;/user/&#123;id&#125;/icon&quot;, 1L).file(&quot;icon&quot;, bytes)) //执行文件上传 .andExpect(model().attribute(&quot;icon&quot;, bytes)) //验证属性相等性 .andExpect(view().name(&quot;success&quot;)); //验证视图 JSON请求&#x2F;响应验证 123456789101112131415String requestBody = &quot;&#123;\\&quot;id\\&quot;:1, \\&quot;name\\&quot;:\\&quot;zhang\\&quot;&#125;&quot;; mockMvc.perform(post(&quot;/user&quot;) .contentType(MediaType.APPLICATION_JSON).content(requestBody) .accept(MediaType.APPLICATION_JSON)) //执行请求 .andExpect(content().contentType(MediaType.APPLICATION_JSON)) //验证响应contentType .andExpect(jsonPath(&quot;$.id&quot;).value(1)); //使用Json path验证JSON 请参考http://goessner.net/articles/JsonPath/ String errorBody = &quot;&#123;id:1, name:zhang&#125;&quot;; MvcResult result = mockMvc.perform(post(&quot;/user&quot;) .contentType(MediaType.APPLICATION_JSON).content(errorBody) .accept(MediaType.APPLICATION_JSON)) //执行请求 .andExpect(status().isBadRequest()) //400错误请求 .andReturn(); Assert.assertTrue(HttpMessageNotReadableException.class.isAssignableFrom(result.getResolvedException().getClass()));//错误的请求内容体 异步测试 1234567891011121314151617181920//Callable MvcResult result = mockMvc.perform(get(&quot;/user/async1?id=1&amp;name=zhang&quot;)) //执行请求 .andExpect(request().asyncStarted()) .andExpect(request().asyncResult(CoreMatchers.instanceOf(User.class))) //默认会等10秒超时 .andReturn(); mockMvc.perform(asyncDispatch(result)) .andExpect(status().isOk()) .andExpect(content().contentType(MediaType.APPLICATION_JSON)) .andExpect(jsonPath(&quot;$.id&quot;).value(1)); //Callable MvcResult result = mockMvc.perform(get(&quot;/user/async1?id=1&amp;name=zhang&quot;)) //执行请求 .andExpect(request().asyncStarted()) .andExpect(request().asyncResult(CoreMatchers.instanceOf(User.class))) //默认会等10秒超时 .andReturn(); mockMvc.perform(asyncDispatch(result)) .andExpect(status().isOk()) .andExpect(content().contentType(MediaType.APPLICATION_JSON)) .andExpect(jsonPath(&quot;$.id&quot;).value(1)); 全局配置 12345678mockMvc = webAppContextSetup(wac) .defaultRequest(get(&quot;/user/1&quot;).requestAttr(&quot;default&quot;, true)) //默认请求 如果其是Mergeable类型的，会自动合并的哦mockMvc.perform中的RequestBuilder .alwaysDo(print()) //默认每次执行请求后都做的动作 .alwaysExpect(request().attribute(&quot;default&quot;, true)) //默认每次执行后进行验证的断言 .build(); mockMvc.perform(get(&quot;/user/1&quot;)) .andExpect(model().attributeExists(&quot;user&quot;));","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Spring boot单元测试","slug":"Spring-boot单元测试","permalink":"https://tianxiafeiyu.github.io/tags/Spring-boot%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"}]},{"title":"Spring boot读取配置文件问题","slug":"技术开发/java/Spring boot读取配置文件问题","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Spring boot读取配置文件问题/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Spring%20boot%E8%AF%BB%E5%8F%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E9%97%AE%E9%A2%98/","excerpt":"","text":"1. 加载自定义文件 YAML files cannot be loaded by using the @PropertySource annotation. So, in the case that you need to load values that way, you need to use a properties file.即@PropertySource不支持YAML文件。 要让@PropertySource支持Yaml文件，可以做如下配置： 继承DefaultPropertySourceFactory类并修改 12345678910111213141516171819202122public class YamlConfigFactory extends DefaultPropertySourceFactory &#123; @Override public PropertySource&lt;?&gt; createPropertySource(String name, EncodedResource resource) throws IOException &#123; String sourceName = name != null ? name : resource.getResource().getFilename(); if (!resource.getResource().exists()) &#123; return new PropertiesPropertySource(sourceName, new Properties()); &#125; else if (sourceName.endsWith(&quot;.yml&quot;) || sourceName.endsWith(&quot;.yaml&quot;)) &#123; Properties propertiesFromYaml = loadYml(resource); return new PropertiesPropertySource(sourceName, propertiesFromYaml); &#125; else &#123; return super.createPropertySource(name, resource); &#125; &#125; private Properties loadYml(EncodedResource resource) throws IOException &#123; YamlPropertiesFactoryBean factory = new YamlPropertiesFactoryBean(); factory.setResources(resource.getResource()); factory.afterPropertiesSet(); return factory.getObject(); &#125;&#125; 配置注解： 1@PropertySource(value = &#123;&quot;classpath:application-my.yml&quot;&#125;,factory = YamlConfigFactory.class) 2. spring boot中配置文件访问优先级优先级如下 第一种是在执行命令的目录下建config文件夹，然后把配置文件放到这个文件夹下。(在jar包的同一个目录下建config文件夹，执行命令需要在jar包所在目录下才行) 第二种是直接把配置文件放到jar包的同级目录 第三种在classpath下建一个config文件夹，然后把配置文件放进去。 第四种是在classpath下直接放配置文件。 springboot默认是优先读取它本身同级目录下的一个config&#x2F;application.properties文件的。在src&#x2F;main&#x2F;resource文件夹下创建的application.properties文件的优先级是最低的 所以springboot启动读取外部配置文件，只需要在外面加一层配置文件覆盖默认的即可，不用修改代码 3. 指定配置文件路径启动程序#通过 –spring.config.location指定配置文件路径 1nohup java -Xms256M -Xmx1024M -jar mailgateway-2.0.0.12.jar --spring.config.location=/usr/ums_chenly/application-prod.properties --spring.profiles.active=prod &gt; mailgateway_nohup_out_`date +%Y%m%d`.txt 2&gt;&amp;1 &amp; 说明 如果启动程序时指定配置文件路径，则程序运行时只读取指定的配置文件。指定配置文件不存在则报错，程序启动失败。 如果不指定配置文件路径，则按上述优先级加载，如果优先级高的配置文件中没有某个配置项，则会到优先级低的配置文件中找该配置项，即具有互补功能(文件名相同才会互补，比如classpath下的application-prod.properties会补jar包的同级目录下application-prod.properties的某个配置项，但是classpath下的application.properties不会补application-prod.properties的某个配置项)。如果指定配置文件路径，则不互补，只会读取指定的配置文件。 如果spring.config.location和 spring.profiles.active都不指定， 默认找application.properties文件。如果spring.profiles.active指定dev，则默认找application-dev.properties文件。如果spring.profiles.active指定prod,则会找application-prod.properties文件","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Spring boot读取配置文件问题","slug":"Spring-boot读取配置文件问题","permalink":"https://tianxiafeiyu.github.io/tags/Spring-boot%E8%AF%BB%E5%8F%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E9%97%AE%E9%A2%98/"}]},{"title":"Spring security实现权限认证","slug":"技术开发/java/Spring security实现权限认证","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Spring security实现权限认证/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Spring%20security%E5%AE%9E%E7%8E%B0%E6%9D%83%E9%99%90%E8%AE%A4%E8%AF%81/","excerpt":"","text":"配置适配器 WebSecurityConfigurerAdapter 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126/** * spring security 核心配置文件 */@Configurationpublic class BrowerSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired private AuthenticationManager authenticationManager; @Autowired //自定义的安全元 数据源 实现FilterInvocationSecurityMetadataSource private MyInvocationSecurityMetadataSourceService myInvocationSecurityMetadataSourceService; @Autowired //自定义访问决策器 private MyAccessDecisionManager myAccessDecisionManager; @Override protected void configure(HttpSecurity http) throws Exception &#123; /** * from表单登录设置 */ http.formLogin() .loginPage(&quot;&quot;) //登录页面 /login .passwordParameter(&quot;&quot;) //设置form表单中对应的name参数 默认为 password 下同 .usernameParameter(&quot;&quot;) // .defaultSuccessUrl(&quot;&quot;) //认证成功后的跳转页面 默认跳转页面 可以设置是否总是默认 不是的话可以跳转与用户的target-url .failureUrl(&quot;&quot;) .failureForwardUrl(&quot;&quot;) //登录失败 转发 的url .successForwardUrl(&quot;&quot;) //登录成功 转发 的url 与successHandler对应 即处理完后请求转发的url .failureHandler(null) //自定义的认证失败 做什么处理 .successHandler(null) //自定义认证成功 后做的处理 ----- 例如 想记录用户信息判断用户状态等 .permitAll() //对于需要所有用户都可以访问的界面 或者url进行设置 .loginProcessingUrl(&quot;&quot;) //自定义处理认证的url 默认为 /login .authenticationDetailsSource(null) //自定义身份验证的数据源 理解为查出数据库中的密码 和权限（可以不加） 然后再交给security ////修改和替换配置 已经配置好的修改 例如下面修改 安全拦截器的安全数据源 .withObjectPostProcessor(new ObjectPostProcessor&lt;FilterSecurityInterceptor&gt;() &#123; public &lt;O extends FilterSecurityInterceptor&gt; O postProcess( O fsi) &#123; fsi.setPublishAuthorizationSuccess(true); //修改成自定义的 安全元数据源 权限的源 ！！！！！ fsi.setSecurityMetadataSource(myInvocationSecurityMetadataSourceService); //修改成自定义的 访问决策器 自定义的 fsi.setAccessDecisionManager(myAccessDecisionManager); //使用系统的 fsi.setAuthenticationManager(authenticationManager); return fsi; &#125; &#125;); /** * 请求认证管理 */ http.authorizeRequests() .antMatchers(&quot;url匹配路径&quot;).permitAll() //url匹配路径 permitAll 运行 全部访问 不用认证 .accessDecisionManager(null) //访问决策器 .filterSecurityInterceptorOncePerRequest(true) //过滤每个请求一次的安全拦截器 ？？？ .anyRequest().authenticated() //其他的请求 需要认证， .antMatchers(&quot;/admin/**&quot;).hasRole(&quot;ADMIN&quot;) //url匹配路径 具有怎样的角色 .antMatchers(&quot;/admin/**&quot;).access(&quot;hasRole(&#x27;ROLE_ADMIN&#x27;)&quot;) //url匹配路径 具有怎样的角色 或者是权限 ; /** * anonymous * * 匿名访问时 存在默认 用户名 annonymousUser */ http.anonymous().disable().csrf().disable(); //禁止匿名 关闭csrf /** * 登出操作管理 */ http.logout() //登出处理 .logoutUrl(&quot;/my/logout&quot;) .logoutSuccessUrl(&quot;/my/index&quot;) .logoutSuccessHandler(null) .invalidateHttpSession(true) .addLogoutHandler(null) .deleteCookies(&quot;cookieNamesToClear&quot;) ; /** * session 会话管理 */ http.sessionManagement() //session管理 .maximumSessions(2) //最大session 数量 --用户 .maxSessionsPreventsLogin(false) //超过最大sessin数量后时候阻止登录 .expiredUrl(&quot;/&quot;) //会话失效后跳转的url .expiredSessionStrategy(null) //自定义session 过期错略 .sessionRegistry(null) //自定义的session 注册 表 ; &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; /** * 基础的配置 */ auth /** * 认证 时触发的事件 */ .authenticationEventPublisher(null) /** * 用户细节服务 * * 认证管理器数据的来源 吧 用户身份凭证信息和 权限信息 */ .userDetailsService(null) /** * 密码编辑器 对密码进行加密 */ .passwordEncoder(null) ; &#125; @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception &#123; return super.authenticationManagerBean(); &#125; @Override public void configure(WebSecurity web) throws Exception &#123; /** * 不进行拦截的mvc */ web.ignoring().mvcMatchers(); /** * 添加自定义的 安全过滤器 */ web.addSecurityFilterChainBuilder(null); &#125;&#125;","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Spring security实现权限认证","slug":"Spring-security实现权限认证","permalink":"https://tianxiafeiyu.github.io/tags/Spring-security%E5%AE%9E%E7%8E%B0%E6%9D%83%E9%99%90%E8%AE%A4%E8%AF%81/"}]},{"title":"lombok","slug":"技术开发/java/lombok","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/lombok/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/lombok/","excerpt":"","text":"lombok简介Lombok 是能自动接通编辑器和构建工具的一个Java库，对于简单的Java对象，通过注解的形式例如@Setter @Getter，可以替代代码中的getter和setter方法。Lombok中用到了注解，但是它并没有用到反射，而是在代码编译时期动态将注解替换为具体的代码。所以JVM实际运行的代码，和我们手动编写的包含了各种工具方法的类相同。 lombok常用注解 @Data：注解在类上，将类提供的所有属性都添加get、set方法，并添加、equals、canEquals、hashCode、toString方法 @Setter：注解在类上，为所有属性添加set方法、注解在属性上为该属性提供set方法 @Getter：注解在类上，为所有的属性添加get方法、注解在属性上为该属性提供get方法 @NotNull：在参数中使用时，如果调用时传了null值，就会抛出空指针异常 @NoArgsConstructor：创建一个无参构造函数 @toString：创建toString方法。 @UtilityClass:工具类 idea项目中使用lombok第一步： pom.xml中加入lombok依赖包 123456&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.20&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency 第二步：加入lombok插件File —&gt; Settings —&gt; Plugins：搜索lombok，点击安装install。然后会提示重启，重启。 第三步：idea配置File —&gt; Settings —&gt; Build, Execution, Deployment —&gt; Compiler —&gt; Java Compiler —&gt; User compiler：选择javacFile —&gt; Settings —&gt; Build, Execution, Deployment —&gt; Compiler —&gt; Annotation Processors -&gt; Enable annotation processors -&gt; 勾选 注意事项 1、使用 lombok.Data 注解实体类时，boolean类型的get方法，会变成is方法；若需要get方法，使用封装类Boolean。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"lombok","slug":"lombok","permalink":"https://tianxiafeiyu.github.io/tags/lombok/"}]},{"title":"null==obj or obj==null ？","slug":"技术开发/java/null==obj or obj==null ？","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/null==obj or obj==null ？/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/null==obj%20or%20obj==null%20%EF%BC%9F/","excerpt":"","text":"在比较操作中，有人提倡常量前置的写法，但是读起来就会怪怪的。 据说在 c++ 中，if(obj = null)是可以通过编译的，但是在运行时会报错，为了防止这种情况发生，所以提倡常量前置的写法。 但是在 Java 中 if(obj = null)是在编译时会报错的，所以不存在这一隐患。时候判断常量前置真的没有必要了呢？其实有两面性，有好有坏，具体要看个人和规范的要求。 好处： 可以避免if(obj = null)类似错误 类似&quot;str&quot;.equals(obj)的写法可以避免空指针错误 坏处： 影响代码可读性 使得代码存在隐患。出现了预料之外的空指针，应该积极去处理，而不是掩盖 特例Boolean 类情况： 12345678910111213141516public class Test&#123; public static void main(String[] args)&#123; Boolean obj = Boolean.FALSE; if(null = obj)&#123; // 编译器报错 //... &#125; &#125;&#125;public class Test&#123; public static void main(String[] args)&#123; Boolean obj = Boolean.FALSE; if(obj = null)&#123; // 编译器不报错，运行时报错 //... &#125; &#125;&#125; 这个算是 Java 中的特例，值得注意 反正我是喜欢常量前置的","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"null==obj or obj==null ？","slug":"null-obj-or-obj-null-？","permalink":"https://tianxiafeiyu.github.io/tags/null-obj-or-obj-null-%EF%BC%9F/"}]},{"title":"spring boot + jasypt实现配置文件信息加密","slug":"技术开发/java/spring boot + jasypt实现配置文件信息加密","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/spring boot + jasypt实现配置文件信息加密/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/spring%20boot%20+%20jasypt%E5%AE%9E%E7%8E%B0%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%BF%A1%E6%81%AF%E5%8A%A0%E5%AF%86/","excerpt":"","text":"配置文件敏感信息的加密，对于生产环境来说还是很有必要的。之前自己实现了一个粗糙的配置文件加密方案，详见spring boot中代码修改配置文件。后面有老师傅提出了有更成熟通过的方案，jasypt，本次就来使用它。 1、添加Maven依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt; &lt;artifactId&gt;jasypt-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.8&lt;/version&gt;&lt;/dependency&gt; 最新版本是2.1.1，但是只能spring-boot-2.x以上使用。因为我的程序中使用的是spring-boot-1.5.3,所以选择1.8版本。 2、编写加密脚本 下载jasypt-1.9.2.jar，添加依赖后，也可以从本地仓库中获取，如：LocalRepository\\org\\jasypt\\jasypt\\1.9.2 Windows脚本： 12345678@echo offcd /d %~dp0cd ..set /p user=请输入要加密的账户名称: java -cp lib/jasypt-1.9.2.jar org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI input=%user% password=apusic.net algorithm=PBEWithMD5AndDESset /p password=请输入要加密的密码: java -cp lib/jasypt-1.9.2.jar org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI input=%password% password=apusic.net algorithm=PBEWithMD5AndDESpause Linux脚本： 12345678910#!/bin/shBASE_DIR=$(cd `dirname $0`; pwd)/..cd $BASE_DIRread -p &quot;输入要加密的账户名称：&quot; userjava -cp $BASE_DIR/lib/jasypt-1.9.2.jar org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI input=$user password=apsuic.net algorithm=PBEWithMD5AndDESread -p &quot;输入要加密的账号密码：&quot; passwordjava -cp $BASE_DIR/lib/jasypt-1.9.2.jar org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI input=$password password=apsuic.net algorithm=PBEWithMD5AndDES 运行脚本，根据提示输入账号密码后可以获得加密串 3、使用加密字符串 程序入口（main）添加注解：@EnableConfigurationProperties 配置文件中如下格式填写加密串： 12client.user=ENC(40+Fa4B+kj2wbOQHa+JuWQ==)client.password=ENC(qX2Its/37OKPVUgxM38I7qgEhitVnuPV) 加密串用ENC()标注 填写加密key,即jasypt.encryptor.password，可以在注入到程序运行时变量中，也可以写在配置文件中，不推荐。 运行时变量方式： 1java -jar lib/exporter-aas-v9-0.0.1-SNAPSHOT.jar --spring.config.location=conf/application.properties --jasypt.encryptor.password=apusic.net 配置文件方式： 1asypt.encryptor.password=apusic.net 这样在程序运行时候jasypt就会先解析加密串，程序获取到的是解析后的账号密码。 完成","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"spring boot + jasypt实现配置文件信息加密","slug":"spring-boot-jasypt实现配置文件信息加密","permalink":"https://tianxiafeiyu.github.io/tags/spring-boot-jasypt%E5%AE%9E%E7%8E%B0%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%BF%A1%E6%81%AF%E5%8A%A0%E5%AF%86/"}]},{"title":"spring boot中代码修改配置文件","slug":"技术开发/java/spring boot中代码修改配置文件","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/spring boot中代码修改配置文件/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/spring%20boot%E4%B8%AD%E4%BB%A3%E7%A0%81%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/","excerpt":"","text":"配置文件中有用户的账号密码等信息，需要为用户保护信息。 怎么做呢？暂时没有想到很好的办法，现在设想是用户第一次使用程序时候，配置文件中明文填写账号密码等信息。启用程序连接成功后加密账号密码，输出加密字符串到配置文件中，以后使用密文进行连接。其实这也只是表面功夫，因为实际的连接需要用到明文的账号密码，必须使用对称加密还原账号密码，加密key是写在程序中的，解包后就能获取到。但是怎么说呢，世界上没有攻破不了的防御，只是这个成本问题而已，增加信息被泄漏成本，加密的本质而已。 废话不多说，开始实现： 网上找到加密工具类EncryptUtil，这个加密工具类的好处是不用第三方jar包，简单方便，功能全面： 123456789101112131415161718192021222324252627282930//用账号密码长度判断是否已经加密，当然也可以加密后向配置文件中加入额外加密标识if(clientConfig.getUser().length() &gt; 30 &amp;&amp; clientConfig.getPassword().length() &gt; 30)&#123; //尝试使用解码后的账号密码进行连接 user.put(JMXConnector.CREDENTIALS, new String[] &#123;encryptUtil.AESdecode(clientConfig.getUser(), ENCRYPT_AES_KEY), encryptUtil.AESdecode(clientConfig.getPassword(), ENCRYPT_AES_KEY) &#125;); jmxc = JMXConnectorFactory.connect(url,user); mbsc = jmxc.getMBeanServerConnection(); &#125;else &#123; //尝试直接使用配置文件账号密码信息连接 user.put(JMXConnector.CREDENTIALS, new String[] &#123; clientConfig.getUser(), clientConfig.getPassword() &#125;); jmxc = JMXConnectorFactory.connect(url,user); mbsc = jmxc.getMBeanServerConnection(); try &#123; // 若是能够连接成功，加密账号密码，输出到配置文件中 Environment environment = SpringUtil.getBean(&quot;environment&quot;); String profilepath = environment.getProperty(&quot;application.file.path&quot;); LinkedProperties properties = new LinkedProperties(); FileReader fileReader = new FileReader(profilepath); properties.load(fileReader); FileWriter fileWriter = new FileWriter(profilepath); properties.setProperty(&quot;client.user&quot;, encryptUtil.AESencode(clientConfig.getUser(), ENCRYPT_AES_KEY)); properties.setProperty(&quot;client.password&quot;, encryptUtil.AESencode(clientConfig.getPassword(), ENCRYPT_AES_KEY)); properties.store(fileWriter, &quot;account and password is encrypted&quot;); fileReader.close(); fileWriter.close(); &#125; catch (IOException var2) &#123; var2.printStackTrace(); &#125; 这里我使用了自定义的 LinkedProperties ，如果使用Properties读写配置文件的话会乱序。查看Properties源码，可以看到 123class Properties extends Hashtable&lt;Object,Object&gt; &#123; //...&#125; Properties其实是一个Hashtable，所以里面的键值对会乱序。要想实现顺序也比较简单，写入我们额外使用一个LinkHashMap来保存键值对，写出时使用LinkHashMap里的数据写出即可。 12345678910111213141516171819202122232425262728public class LinkedProperties extends Properties &#123; private Map&lt;String, String&gt; linkedPropertiesMap = new LinkedHashMap&lt;&gt;(); public Map&lt;String, String&gt; getLinkedPropertiesMap()&#123; return linkedPropertiesMap; &#125; @Override public synchronized void load(Reader reader) throws IOException &#123; //... linkedPropertiesMap.put(key, value); &#125; @Override public synchronized Object setProperty(String key, String value) &#123; linkedPropertiesMap.put(key, value); return put(key, value); &#125; @Override public void store(Writer writer, String comments) throws IOException&#123; //... for(Map.Entry&lt;String, String&gt; entry : linkedPropertiesMap.entrySet())&#123;&#125; //... &#125; //...&#125; EncryptUtil工具类代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286import com.sun.org.apache.xerces.internal.impl.dv.util.Base64;import javax.crypto.Cipher;import javax.crypto.KeyGenerator;import javax.crypto.Mac;import javax.crypto.SecretKey;import javax.crypto.spec.SecretKeySpec;import java.security.MessageDigest;import java.security.SecureRandom;public class EncryptUtil &#123; public static final String MD5 = &quot;MD5&quot;; public static final String SHA1 = &quot;SHA1&quot;; public static final String HmacMD5 = &quot;HmacMD5&quot;; public static final String HmacSHA1 = &quot;HmacSHA1&quot;; public static final String DES = &quot;DES&quot;; public static final String AES = &quot;AES&quot;; /**编码格式；默认使用uft-8*/ public String charset = &quot;utf-8&quot;; /**DES*/ public int keysizeDES = 0; /**AES*/ public int keysizeAES = 128; public static EncryptUtil me; private EncryptUtil()&#123; //单例 &#125; //双重锁 public static EncryptUtil getInstance()&#123; if (me==null) &#123; synchronized (EncryptUtil.class) &#123; if(me == null)&#123; me = new EncryptUtil(); &#125; &#125; &#125; return me; &#125; /** * 使用MessageDigest进行单向加密（无密码） * @param res 被加密的文本 * @param algorithm 加密算法名称 * @return */ private String messageDigest(String res,String algorithm)&#123; try &#123; MessageDigest md = MessageDigest.getInstance(algorithm); byte[] resBytes = charset==null?res.getBytes():res.getBytes(charset); return base64(md.digest(resBytes)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; /** * 使用KeyGenerator进行单向/双向加密（可设密码） * @param res 被加密的原文 * @param algorithm 加密使用的算法名称 * @param key 加密使用的秘钥 * @return */ private String keyGeneratorMac(String res,String algorithm,String key)&#123; try &#123; SecretKey sk = null; if (key==null) &#123; KeyGenerator kg = KeyGenerator.getInstance(algorithm); sk = kg.generateKey(); &#125;else &#123; byte[] keyBytes = charset==null?key.getBytes():key.getBytes(charset); sk = new SecretKeySpec(keyBytes, algorithm); &#125; Mac mac = Mac.getInstance(algorithm); mac.init(sk); byte[] result = mac.doFinal(res.getBytes()); return base64(result); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; /** * 使用KeyGenerator双向加密，DES/AES，注意这里转化为字符串的时候是将2进制转为16进制格式的字符串，不是直接转，因为会出错 * @param res 加密的原文 * @param algorithm 加密使用的算法名称 * @param key 加密的秘钥 * @param keysize * @param isEncode * @return */ private String keyGeneratorES(String res,String algorithm,String key,int keysize,boolean isEncode)&#123; try &#123; KeyGenerator kg = KeyGenerator.getInstance(algorithm); if (keysize == 0) &#123; byte[] keyBytes = charset==null?key.getBytes():key.getBytes(charset); kg.init(new SecureRandom(keyBytes)); &#125;else if (key==null) &#123; kg.init(keysize); &#125;else &#123; byte[] keyBytes = charset==null?key.getBytes():key.getBytes(charset); kg.init(keysize, new SecureRandom(keyBytes)); &#125; SecretKey sk = kg.generateKey(); SecretKeySpec sks = new SecretKeySpec(sk.getEncoded(), algorithm); Cipher cipher = Cipher.getInstance(algorithm); if (isEncode) &#123; cipher.init(Cipher.ENCRYPT_MODE, sks); byte[] resBytes = charset==null?res.getBytes():res.getBytes(charset); return parseByte2HexStr(cipher.doFinal(resBytes)); &#125;else &#123; cipher.init(Cipher.DECRYPT_MODE, sks); return new String(cipher.doFinal(parseHexStr2Byte(res))); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; private String base64(byte[] res)&#123; return Base64.encode(res); &#125; /**将二进制转换成16进制 */ public static String parseByte2HexStr(byte buf[]) &#123; StringBuffer sb = new StringBuffer(); for (int i = 0; i &lt; buf.length; i++) &#123; String hex = Integer.toHexString(buf[i] &amp; 0xFF); if (hex.length() == 1) &#123; hex = &#x27;0&#x27; + hex; &#125; sb.append(hex.toUpperCase()); &#125; return sb.toString(); &#125; /**将16进制转换为二进制*/ public static byte[] parseHexStr2Byte(String hexStr) &#123; if (hexStr.length() &lt; 1) return null; byte[] result = new byte[hexStr.length()/2]; for (int i = 0;i&lt; hexStr.length()/2; i++) &#123; int high = Integer.parseInt(hexStr.substring(i*2, i*2+1), 16); int low = Integer.parseInt(hexStr.substring(i*2+1, i*2+2), 16); result[i] = (byte) (high * 16 + low); &#125; return result; &#125; /** * md5加密算法进行加密（不可逆） * @param res 需要加密的原文 * @return */ public String MD5(String res) &#123; return messageDigest(res, MD5); &#125; /** * md5加密算法进行加密（不可逆） * @param res 需要加密的原文 * @param key 秘钥 * @return */ public String MD5(String res, String key) &#123; return keyGeneratorMac(res, HmacMD5, key); &#125; /** * 使用SHA1加密算法进行加密（不可逆） * @param res 需要加密的原文 * @return */ public String SHA1(String res) &#123; return messageDigest(res, SHA1); &#125; /** * 使用SHA1加密算法进行加密（不可逆） * @param res 需要加密的原文 * @param key 秘钥 * @return */ public String SHA1(String res, String key) &#123; return keyGeneratorMac(res, HmacSHA1, key); &#125; /** * 使用DES加密算法进行加密（可逆） * @param res 需要加密的原文 * @param key 秘钥 * @return */ public String DESencode(String res, String key) &#123; return keyGeneratorES(res, DES, key, keysizeDES, true); &#125; /** * 对使用DES加密算法的密文进行解密（可逆） * @param res 需要解密的密文 * @param key 秘钥 * @return */ public String DESdecode(String res, String key) &#123; return keyGeneratorES(res, DES, key, keysizeDES, false); &#125; /** * 使用AES加密算法经行加密（可逆） * @param res 需要加密的密文 * @param key 秘钥 * @return */ public String AESencode(String res, String key) &#123; return keyGeneratorES(res, AES, key, keysizeAES, true); &#125; /** * 对使用AES加密算法的密文进行解密 * @param res 需要解密的密文 * @param key 秘钥 * @return */ public String AESdecode(String res, String key) &#123; return keyGeneratorES(res, AES, key, keysizeAES, false); &#125; /** * 使用异或进行加密 * @param res 需要加密的密文 * @param key 秘钥 * @return */ public String XORencode(String res, String key) &#123; byte[] bs = res.getBytes(); for (int i = 0; i &lt; bs.length; i++) &#123; bs[i] = (byte) ((bs[i]) ^ key.hashCode()); &#125; return parseByte2HexStr(bs); &#125; /** * 使用异或进行解密 * @param res 需要解密的密文 * @param key 秘钥 * @return */ public String XORdecode(String res, String key) &#123; byte[] bs = parseHexStr2Byte(res); for (int i = 0; i &lt; bs.length; i++) &#123; bs[i] = (byte) ((bs[i]) ^ key.hashCode()); &#125; return new String(bs); &#125; /** * 直接使用异或（第一调用加密，第二次调用解密） * @param res 密文 * @param key 秘钥 * @return */ public int XOR(int res, String key) &#123; return res ^ key.hashCode(); &#125; /** * 使用Base64进行加密 * @param res 密文 * @return */ public String Base64Encode(String res) &#123; return Base64.encode(res.getBytes()); &#125; /** * 使用Base64进行解密 * @param res * @return */ public String Base64Decode(String res) &#123; return new String(Base64.decode(res));&#125;","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"spring boot中代码修改配置文件","slug":"spring-boot中代码修改配置文件","permalink":"https://tianxiafeiyu.github.io/tags/spring-boot%E4%B8%AD%E4%BB%A3%E7%A0%81%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"}]},{"title":"spring boot使用单例模式的痛","slug":"技术开发/java/spring boot使用单例模式的痛","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/spring boot使用单例模式的痛/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/spring%20boot%E4%BD%BF%E7%94%A8%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E7%97%9B/","excerpt":"","text":"单例模式好处多多，是工具类中经常使用的设计模式，但是笔者在spring boot中使用单例模式中，尝到了许多痛苦的滋味。。。 Spring注解给开发带来了很多便利，要使用到这种便利，就需要使用spring的IOC注入，即类的创建需要交由spring来管理。如@Autowired，一个类如果在使用@Autowired注入了另一个类，但是当这个类被new时，@Autowired注入将会失效，出现NPE报错。 比如 1234567891011121314151617181920public class A&#123; //...&#125;public class B&#123; @Autowired A a; private static volatile B instance; private B(); public static B getInstance()&#123; if(null == instance)&#123; synchronized (B.class) &#123; instance = new B(); //B的@Autowired不生效，b.a==null &#125; &#125; return instance; &#125; //...&#125; 一些spring辅助类是必须要交由spring注入的，比如Environment，单例模式就很不方便了。 当然，办法也是有的，可以使用ApplicationContext来注入Bean： 123456789101112131415161718192021public class SpringUtil implements ApplicationContextAware &#123; private static ApplicationContext applicationContext; public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; SpringUtil.applicationContext = applicationContext; &#125; //beanName是类名，第一个字母小写 public static &lt;T&gt; T getBean(String beanName) &#123; if(applicationContext.containsBean(beanName))&#123; return (T) applicationContext.getBean(beanName); &#125;else&#123; return null; &#125; &#125; public static &lt;T&gt; Map&lt;String, T&gt; getBeansOfType(Class&lt;T&gt; baseType)&#123; return applicationContext.getBeansOfType(baseType); &#125;&#125; 要使用某一个类的时候SpringUtil.getBean(beanName)就可以的，坏处也是有的，无法使用全局变量，每个方法使用这个类时都需要注入一次。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"spring boot使用单例模式的痛","slug":"spring-boot使用单例模式的痛","permalink":"https://tianxiafeiyu.github.io/tags/spring-boot%E4%BD%BF%E7%94%A8%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E7%97%9B/"}]},{"title":"spring boot使用多线程","slug":"技术开发/java/spring boot使用多线程","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/spring boot使用多线程/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/spring%20boot%E4%BD%BF%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"业务场景：查询数据分页，每条数据需要添加上概览信息，获取概览信息需要调用一些http接口，有一定的等待时间，单线程查询效率较慢。现在需要在查出了数据库持久化数据的基础上，使用多线程给数据添加概览信息，而且在所有异步线程都完成后，再返回分页信息给前端。 1.应用主程序添加注解 @EnableAsync 来开启 Springboot 对于异步任务的支持 1234567@SpringBootApplication@EnableAsyncpublic class SpringBootApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootApplication.class, args); &#125;&#125; 2.配置类实现接口 AsyncConfigurator，返回一个 ThreadPoolTaskExecutor 线程池对象。 12345678910111213141516171819202122232425262728293031323334@Configuration@EnableAsyncpublic class AsyncTaskConfig implements AsyncConfigurer &#123; // ThredPoolTaskExcutor的处理流程 // 当池子大小小于corePoolSize，就新建线程，并处理请求 // 当池子大小等于corePoolSize，把请求放入workQueue中，池子里的空闲线程就去workQueue中取任务并处理 // 当workQueue放不下任务时，就新建线程入池，并处理请求，如果池子大小撑到了maximumPoolSize，就用RejectedExecutionHandler来做拒绝处理 // 当池子的线程数大于corePoolSize时，多余的线程会等待keepAliveTime长时间，如果无请求可处理就自行销毁 @Override @Bean public Executor getAsyncExecutor() &#123; ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); //设置核心线程数 threadPool.setCorePoolSize(10); //设置最大线程数 threadPool.setMaxPoolSize(20); //线程池所使用的缓冲队列 threadPool.setQueueCapacity(10); // 等待时间 （默认为0，此时立即停止），并没等待xx秒后强制停止 threadPool.setAwaitTerminationSeconds(60); // 线程名称前缀 threadPool.setThreadNamePrefix(&quot;my-Async-&quot;); // 初始化线程 threadPool.initialize(); return threadPool; &#125; @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() &#123; return null; &#125;&#125; 3.异步调用的方法上添加注解@Async，表明该方法是异步方法，如果注解在类上，那表明这个类里面的所有方法都是异步的。异步方法必须是public修饰的，而且需要在另一个类中调用才会生效，否则无法实现异步。 Service层： 12345@Asyncpublic CompletableFuture&lt;Long&gt; addOverViewInfo(K8sClusterDTO k8sClusterDTO) throws ApiException &#123; // 添加概览信息 // return CompletableFuture.completedFuture(k8sClusterId);&#125; Controller层： 123456789101112131415161718// result = 查询数据库得到的分页数据List&lt;CompletableFuture&lt;Long&gt;&gt; completableFutureList = new ArrayList&lt;&gt;();// 多线程添加集群概览数据for (K8sClusterDTO k8sClusterDTO : result.getObjectList())&#123; try&#123; CompletableFuture&lt;Long&gt; completableFuture = k8sClusterService.addOverViewInfo(k8sClusterDTO); completableFutureList.add(completableFuture); &#125;catch (Exception e) &#123; e.printStackTrace(); continue; &#125;&#125;CompletableFuture&lt;Long&gt;[] completableFutureArray = new CompletableFuture[completableFutureList.size()];// 合并线程，确保子线程全部执行完CompletableFuture.allOf(completableFutureList.toArray(completableFutureArray)).join();return result; 4.至此，功能完成。查询效率确实有所提高。这算是第一次成功在实际项目中使用多线程，网上查询了很多博客，spring boot中使用多线程是很方便的，但是关键是如何等待所有子线程执行完，像这种直接使用注解来声明一个异步方法，很多网上的方案都行不通，最后看到简书上的一篇文章才有了思路。 使用了异步编程后，接口调用顺序大概是这样的： 查询数据库分页数据返回分页数据给前端第一次调用异步方法第二次调用异步方法…… 所以还没等到数据添加上概览信息，就已经返回了结果，这肯定是行不通的。 使用了CompletableFuture.allOf(…).jion() 方法后，顺序大概就是： 查询数据库分页数据第一次调用异步方法第二次调用异步方法……最后一个异步方法执行完毕返回分页数据给前端 这样才能返回正确的结果 5.CompletableFuture allOf().jion():法实现多实例的同时返回，如果allOf里面的所有线程未执行完毕，主线程会阻塞，直到allOf里面的所有线程都执行，主线程就会被唤醒，继续向下运行。总的来说就是保证了子线程之间的异步，又保证了主线程和子线程的同步。 6.参考资料： Spring Boot 创建及使用多线程。https://blog.csdn.net/asd136912/article/details/87716215 SpringBoot 多线程异步调用-提高程序执行效率。https://www.jianshu.com/p/d919f4372351","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"spring boot使用多线程","slug":"spring-boot使用多线程","permalink":"https://tianxiafeiyu.github.io/tags/spring-boot%E4%BD%BF%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"spring security学习【转】","slug":"技术开发/java/spring security学习【转】","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/spring security学习【转】/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/spring%20security%E5%AD%A6%E4%B9%A0%E3%80%90%E8%BD%AC%E3%80%91/","excerpt":"","text":"转载自 spring-security-4介绍 虽然现在已经到了5.x版本了，但是大同小异，知识还是不会过时的。。。 前言本教程主要分为个部分： spring security Java配置的搭建 spring security过滤器的创建与注册原理 spring security Java配置搭建中认证与授权的分析 spring security Java配置实现自定义的表单认证与授权 这篇教程主要是用来教会你以下几点： 怎么搭建spring security spring secuirty过滤器的创建与注册原理（工作的基本原理） 简单的认证与授权的原理 在明白如何实现简单的认证与授权的基础上实现自定义的认证与授权 环境说明： 版本：本教程使用的spring security版本是4.2.3.RELEASE，对应的spring版本是4.3.11.RELEASE。 工具：开发工具为eclipse，构建工具为maven 一、什么是spring security?spring security是基于spring开发的为JavaEE企业级应用提供安全服务的框架。安全服务主要是指 认证（Authentication）和 授权（Authorization）。 二、spring security的模块 搭建spring security首先我们要导入必须的jar，即maven的依赖。spring security按模块划分，一个模块对应一个jar。 spring security分为以下九个模块： 1. Core spring-security-core.jar：核心模块。包含核心的认证（authentication）和授权（authorization）的类和接口，远程支持和基础配置API。 2. Remoting spring-security-remoting.jar：提供与spring remoting整合的支持。 3. Web spring-security-web.jar：包含过滤器和相关的网络安全的代码。用于我们进行web安全验证和基于URL的访问控制。 4. Config spring-security-config.jar：包含security namepace的解析代码。 5. LDAP spring-security-ldap.jar：提供LDAP验证和配置的支持。 6. ACL spring-security-acl.jar：提供对特定domain对象的ACL（访问控制列表）实现。用来限定对特定对象的访问 7. CAS sprig-security-cas.jar：提供与spring security CAS客户端集成 8. OpenID spring-security-openid.jar：提供OpenId Web验证支持。基于一个外部OpenId服务器对用户进行验证。 9. Test spring-security-test.jar：提供spring security的测试支持。 一般情况下，Core和Config模块都是需要的，因为我们本教程只是用于Java web应用表单的验证登录，所以这里我们还需要引入Web。 说明：本篇教程的代码已上传github，地址：https://github.com/wutianqi/spring_security_create 三、工程搭建1.项目工程结构 2. 代码展示2.1 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.wuqi&lt;/groupId&gt; &lt;artifactId&gt;spring_security_create&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring_security_create Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;!-- web --&gt; &lt;jsp.version&gt;2.2&lt;/jsp.version&gt; &lt;servlet.version&gt;3.1.0&lt;/servlet.version&gt; &lt;jstl.version&gt;1.2&lt;/jstl.version&gt; &lt;!-- spring 和 spring security --&gt; &lt;spring-security.version&gt;4.2.3.RELEASE&lt;/spring-security.version&gt; &lt;spring-framework.version&gt;4.3.11.RELEASE&lt;/spring-framework.version&gt; &lt;!-- Logging --&gt; &lt;logback.version&gt;1.0.13&lt;/logback.version&gt; &lt;slf4j.version&gt;1.7.5&lt;/slf4j.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-framework.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-framework.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring security --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-config&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 其他一些依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;javax&lt;/groupId&gt; &lt;artifactId&gt;javaee-web-api&lt;/artifactId&gt; &lt;version&gt;7.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;$&#123;servlet.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;$&#123;jstl.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;$&#123;jsp.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt; &lt;artifactId&gt;jackson-dataformat-xml&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 日志 --&gt; &lt;!-- 使用SLF4J和LogBack作为日志 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--logback日志--&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--实现slf4j接口并整合--&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-access&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;spring_security_create&lt;/finalName&gt; &lt;plugins&gt; &lt;!-- 配置maven的内嵌的tomcat，通过内置的tomcat启动 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;uriEncoding&gt;utf8&lt;/uriEncoding&gt; &lt;!-- 配置启动的端口为9090 --&gt; &lt;port&gt;9090&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 该pom文件除了包括了spring security的依赖外，还包括了spring、springmvc、日志的一些依赖，除了spring security的依赖，其他的你没必要太过于纠结。直接拿过来用就可以了。日志我使用了logback，这个你也直接拿过来用就行了，直接将logback.xml放在你的类路径下就可以起作用了。而且这些知识也不是本篇教程所讨论的。 2.2 MyWebConfig 1234567891011121314151617181920212223242526272829package com.wuqi.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.EnableWebMvc;import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;import org.springframework.web.servlet.view.InternalResourceViewResolver;import org.springframework.web.servlet.view.JstlView;/** * MVC配置类 * @author wuqi * @date 2018/06/13 */@EnableWebMvc@Configuration@ComponentScan(&quot;com.wuqi&quot;)public class MyWebConfig extends WebMvcConfigurerAdapter &#123; //配置mvc视图解析器 @Bean public InternalResourceViewResolver viewResolver() &#123; InternalResourceViewResolver viewResolver = new InternalResourceViewResolver(); viewResolver.setPrefix(&quot;/WEB-INF/classes/views/&quot;); viewResolver.setSuffix(&quot;.jsp&quot;); viewResolver.setViewClass(JstlView.class); return viewResolver; &#125; &#125; MyWebConfig是SpringMvc的配置类，这里只配置了视图解析器 2.3 WebInitializer 123456789101112131415161718192021222324252627package com.wuqi.config;import org.springframework.web.servlet.support.AbstractAnnotationConfigDispatcherServletInitializer;/** * 替代web.xml的配置 * @author wuqi * @date 2018/06/13 */public class WebInitializer extends AbstractAnnotationConfigDispatcherServletInitializer &#123; @Override protected Class&lt;?&gt;[] getRootConfigClasses() &#123; return null; &#125; @Override protected Class&lt;?&gt;[] getServletConfigClasses() &#123; return new Class[] &#123;MyWebConfig.class&#125;; &#125; @Override protected String[] getServletMappings() &#123; //将DispatcherServlet映射到 / return new String[] &#123;&quot;/&quot;&#125;; &#125;&#125; WebInitializer相当于在web.xml中注册DispatcherServlet，以及配置Spring Mvc的配置文件 2.4 MySecurityConfig 12345678910111213141516171819202122232425package com.wuqi.config;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;/** * spring security配置类 * @author wuqi * @date 2018/06/13 */@EnableWebSecurity@Configurationpublic class MySecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired public void configUser(AuthenticationManagerBuilder builder) throws Exception &#123; builder .inMemoryAuthentication() //创建用户名为user，密码为password的用户 .withUser(&quot;user&quot;).password(&quot;password&quot;).roles(&quot;USER&quot;); &#125; &#125; MySecurityConfig是spring security的配置类，定制spring security的一些行为就在这里。其中@EnableWebSecurity用于创建过滤器 2.5 SecurityInitializer 1234567891011package com.wuqi.config;import org.springframework.security.web.context.AbstractSecurityWebApplicationInitializer;/** * security初始化类，用户注册过滤器 * @author wuqi * @date 2018/06/13 */public class SecurityInitializer extends AbstractSecurityWebApplicationInitializer &#123;&#125; SecurityInitializer主要就是用于注册spring secuirty的过滤器 2.6 logback.xml 1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;configuration scan=&quot;true&quot; scanPeriod=&quot;1 seconds&quot;&gt; &lt;contextListener class=&quot;ch.qos.logback.classic.jul.LevelChangePropagator&quot;&gt; &lt;resetJUL&gt;true&lt;/resetJUL&gt; &lt;/contextListener&gt; &lt;jmxConfigurator /&gt; &lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;logbak: %d&#123;HH:mm:ss.SSS&#125; %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;logger name=&quot;org.springframework.security.web&quot; level=&quot;DEBUG&quot; /&gt; &lt;logger name=&quot;org.springframework.security&quot; level=&quot;DEBUG&quot; /&gt; &lt;logger name=&quot;org.springframework.security.config&quot; level=&quot;DEBUG&quot; /&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;console&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; 该日志文件就是将web、core、config模块的日志级别调为debug模式。 3. 运行展示3.1 通过maven内置的Tomcat启动项目（不知道的网上看下，有很多资料），访问端口为9090。地址栏访问 http://localhost:9090 由此可以看到当访问我们的项目时，spring security将我们的项目保护了起来，并提供了一个默认的登录页面，让我们去登录。我们在MySecurityConfig中配置了一个用户。用户名为”user”，密码为”password”，输入这个用户名和密码，即可正常访问我们的项目。 3.2 输入用户名和密码 4. 小结到现在为止，我们已经搭建了一个基于spring(spring mvc)的spring security项目。可能你会很疑惑，为什么会产生这种效果。那个输入用户名和密码的页面，我们在项目中也没有创建，是怎么出来的呢？ 其实这一切都是经过我们上述的配置，我们创建并注册了spring security的过滤器。是这些过滤器为我们做到的。除此之外，spring security还为我们做了额外的其他的保护。总的来说，经过我们上述的配置后，spring security为我们的应用提供了以下默认功能： 访问应用中的每个URL都需要进行验证 生成一个登陆表单 允许用户使用username和password来登陆 允许用户注销 CSRF攻击拦截 Session Fixation（session固定攻击） 安全Header集成 7.1 HTTP Strict Transport Security for secure requests 7.2 X-Content-Type-Options integration 7.3 缓存控制 (can be overridden later by your application to allow caching of your static resources) 7.4 X-XSS-Protection integration 7.5 X-Frame-Options integration to help prevent Clickjacking Integrate with the following Servlet API methods 8.1 HttpServletRequest#getRemoteUser() 8.2 HttpServletRequest.html#getUserPrincipal() 8.3 HttpServletRequest.html#isUserInRole(java.lang.String) 8.4 HttpServletRequest.html#login(java.lang.String, java.lang.String) 8.5 HttpServletRequest.html#logout() 下一节，通过spring security过滤器的创建和注册源码的分析，你将会了解这一切！ 四、spring security过滤器的创建与注册原理1. Spring Security过滤器的创建原理让我们首先看下MySecurityConfig类 123456789101112@EnableWebSecurity@Configurationpublic class MySecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired public void configUser(AuthenticationManagerBuilder builder) throws Exception &#123; builder .inMemoryAuthentication() //创建用户名为user，密码为password的用户 .withUser(&quot;user&quot;).password(&quot;password&quot;).roles(&quot;USER&quot;); &#125;&#125; 可以看到MySecurityConfig上的@EnableWebSecurity注解，查看该注解的源码 123456789101112131415@Retention(value = java.lang.annotation.RetentionPolicy.RUNTIME)@Target(value = &#123; java.lang.annotation.ElementType.TYPE &#125;)@Documented@Import(&#123; WebSecurityConfiguration.class, SpringWebMvcImportSelector.class &#125;)@EnableGlobalAuthentication@Configurationpublic @interface EnableWebSecurity &#123; /** * Controls debugging support for Spring Security. Default is false. * @return if true, enables debug support with Spring Security */ boolean debug() default false;&#125; @EnableWebSecurity上的@Import注解引入了两个类WebSecurityConfiguration和SpringWebMvcImportSelector，spring security的过滤器正是由WebSecurityConfiguration创建。让我们看下WebSecurityConfiguration的部分源码 123456789101112131415161718... //查看AbstractSecurityWebApplicationInitializer的源码可以看到 //AbstractSecurityWebApplicationInitializer.DEFAULT_FILTER_NAME = &quot;springSecurityFilterChain&quot; @Bean(name = AbstractSecurityWebApplicationInitializer.DEFAULT_FILTER_NAME) public Filter springSecurityFilterChain() throws Exception &#123; boolean hasConfigurers = webSecurityConfigurers != null &amp;&amp; !webSecurityConfigurers.isEmpty(); //如果没有配置类那么就new一个WebSecurityConfigurerAdapter,也就是说我们没有配置MySecurityConfig或者说其没有被spring扫描到 if (!hasConfigurers) &#123; WebSecurityConfigurerAdapter adapter = objectObjectPostProcessor .postProcess(new WebSecurityConfigurerAdapter() &#123; &#125;); webSecurity.apply(adapter); &#125; //创建Filter return webSecurity.build(); &#125;... 从源码中可以看到通过WebSecurity.build()创建出名字为springSecurityFilterChain的Filter对象。（特别说明一下，一定要保证我们的MySecurityConfig类注解了@Configuration并可以被spring扫描到，如果没有被sping扫描到，那么spring security会认为没有配置类，就会新new 出一个WebSecurityConfigureAdapter对象，这会导致我们配置的用户名和密码失效。）那么该Filter的类型是什么呢？别着急，我们先来看下WeSecurity的继承体系。 build方法定义在AbstractSecurityBuilder中，源码如下： 12345678910...public final O build() throws Exception &#123; if (this.building.compareAndSet(false, true)) &#123; //通过doBuild方法创建 this.object = doBuild(); return this.object; &#125; throw new AlreadyBuiltException(&quot;This object has already been built&quot;);&#125;... doBuild方法定义在AbstractConfiguredSecurityBuilder中，源码如下： 123456789101112131415161718192021222324...protected final O doBuild() throws Exception &#123; synchronized (configurers) &#123; buildState = BuildState.INITIALIZING; beforeInit(); init(); buildState = BuildState.CONFIGURING; beforeConfigure(); configure(); buildState = BuildState.BUILDING; //performBuild方法创建 O result = performBuild(); buildState = BuildState.BUILT; return result; &#125; &#125;... performBuild()方法定义在WebSecurity中，源码如下 1234567891011121314151617181920212223242526272829303132333435363738...protected Filter performBuild() throws Exception &#123; Assert.state( !securityFilterChainBuilders.isEmpty(), &quot;At least one SecurityBuilder&lt;? extends SecurityFilterChain&gt; needs to be specified. Typically this done by adding a @Configuration that extends WebSecurityConfigurerAdapter. More advanced users can invoke &quot; + WebSecurity.class.getSimpleName() + &quot;.addSecurityFilterChainBuilder directly&quot;); int chainSize = ignoredRequests.size() + securityFilterChainBuilders.size(); List&lt;SecurityFilterChain&gt; securityFilterChains = new ArrayList&lt;SecurityFilterChain&gt;( chainSize); for (RequestMatcher ignoredRequest : ignoredRequests) &#123; securityFilterChains.add(new DefaultSecurityFilterChain(ignoredRequest)); &#125; for (SecurityBuilder&lt;? extends SecurityFilterChain&gt; securityFilterChainBuilder : securityFilterChainBuilders) &#123; securityFilterChains.add(securityFilterChainBuilder.build()); &#125; //创建FilterChainProxy FilterChainProxy filterChainProxy = new FilterChainProxy(securityFilterChains); if (httpFirewall != null) &#123; filterChainProxy.setFirewall(httpFirewall); &#125; filterChainProxy.afterPropertiesSet(); Filter result = filterChainProxy; if (debugEnabled) &#123; logger.warn(&quot;\\n\\n&quot; + &quot;********************************************************************\\n&quot; + &quot;********** Security debugging is enabled. *************\\n&quot; + &quot;********** This may include sensitive information. *************\\n&quot; + &quot;********** Do not use in a production system! *************\\n&quot; + &quot;********************************************************************\\n\\n&quot;); result = new DebugFilter(filterChainProxy); &#125; postBuildAction.run(); return result;&#125;... 不关心其具体实现，我们从源码中看到spring security创建的过滤器类型为FilterChainProxy。由此完成过滤器的创建。 2. Spring Security过滤器的注册原理看下我们创建的SecurityInitializer类： 123public class SecurityInitializer extends AbstractSecurityWebApplicationInitializer &#123;&#125; 这段代码虽然很简单，但却是注册过滤器所必须的。 根据Servlet3.0中，提供了ServletContainerInitializer接口，该接口提供了一个onStartup方法，用于在容器启动时动态注册Servlet,Filter,Listener等。因为我们建立的是web项目，那我们的依赖中肯定是由spring-web依赖的 根据Servlet 3.0规范，Servlet容器在启动时，会负责创建图中红色箭头所指的类，即SpringServletContainerInitializer，该类是ServletContainerInitializer的实现类。那么该类必有onStartup方法。让我们看下它的源码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package org.springframework.web;import java.lang.reflect.Modifier;import java.util.LinkedList;import java.util.List;import java.util.ServiceLoader;import java.util.Set;import javax.servlet.ServletContainerInitializer;import javax.servlet.ServletContext;import javax.servlet.ServletException;import javax.servlet.annotation.HandlesTypes;import org.springframework.core.annotation.AnnotationAwareOrderComparator;@HandlesTypes(WebApplicationInitializer.class)public class SpringServletContainerInitializer implements ServletContainerInitializer &#123; @Override public void onStartup(Set&lt;Class&lt;?&gt;&gt; webAppInitializerClasses, ServletContext servletContext) throws ServletException &#123; List&lt;WebApplicationInitializer&gt; initializers = new LinkedList&lt;WebApplicationInitializer&gt;(); if (webAppInitializerClasses != null) &#123; for (Class&lt;?&gt; waiClass : webAppInitializerClasses) &#123; //如果waiClass不为接口，抽象类，并且属于WebApplicationInitializer类型 //那么通过反射构造该接口的实例。 if (!waiClass.isInterface() &amp;&amp; !Modifier.isAbstract(waiClass.getModifiers()) &amp;&amp; WebApplicationInitializer.class.isAssignableFrom(waiClass)) &#123; try &#123; initializers.add((WebApplicationInitializer) waiClass.newInstance()); &#125; catch (Throwable ex) &#123; throw new ServletException(&quot;Failed to instantiate WebApplicationInitializer class&quot;, ex); &#125; &#125; &#125; &#125; if (initializers.isEmpty()) &#123; servletContext.log(&quot;No Spring WebApplicationInitializer types detected on classpath&quot;); return; &#125; AnnotationAwareOrderComparator.sort(initializers); servletContext.log(&quot;Spring WebApplicationInitializers detected on classpath: &quot; + initializers); for (WebApplicationInitializer initializer : initializers) &#123; //调用所有WebApplicationInitializer实例的onStartup方法 initializer.onStartup(servletContext); &#125; &#125;&#125; 请注意该类上的@HandlesTypes(WebApplicationInitializer.class)注解，根据Sevlet3.0规范，Servlet容器要负责以Set集合的方式注入指定类的子类（包括接口，抽象类）。其中AbstractSecurityWebApplicationInitializer是WebApplicationInitializer的抽象子类，我我们看下它的onStartup方法 123456789101112131415161718...public final void onStartup(ServletContext servletContext) throws ServletException &#123; beforeSpringSecurityFilterChain(servletContext); if (this.configurationClasses != null) &#123; AnnotationConfigWebApplicationContext rootAppContext = new AnnotationConfigWebApplicationContext(); rootAppContext.register(this.configurationClasses); servletContext.addListener(new ContextLoaderListener(rootAppContext)); &#125; if (enableHttpSessionEventPublisher()) &#123; servletContext.addListener( &quot;org.springframework.security.web.session.HttpSessionEventPublisher&quot;); &#125; servletContext.setSessionTrackingModes(getSessionTrackingModes()); //注册过滤器 insertSpringSecurityFilterChain(servletContext); afterSpringSecurityFilterChain(servletContext);&#125;... 该类中的insertSpringSecurityFilterChain(servletContext)就是在注册过滤器。因为在过滤器创建中所说的springSecurityFilterChain，它其实是spring中的bean，而servletContext也必定可以获取到该bean。我们接着看insertSpringSecurityFilterChain的源码 1234567891011121314151617...public static final String DEFAULT_FILTER_NAME = &quot;springSecurityFilterChain&quot;;private void insertSpringSecurityFilterChain(ServletContext servletContext) &#123; String filterName = DEFAULT_FILTER_NAME; //通过DelegatingFilterProxy代理 DelegatingFilterProxy springSecurityFilterChain = new DelegatingFilterProxy( filterName); String contextAttribute = getWebApplicationContextAttribute(); if (contextAttribute != null) &#123; springSecurityFilterChain.setContextAttribute(contextAttribute); &#125; //完成过滤器的注册 registerFilter(servletContext, true, filterName, springSecurityFilterChain);&#125;... 一开始我们就提到了调用过滤器链springSecurityFilterChain需要DelegatingFilterProxy进行代理，将其与web.xml联系起来。这段代码就是很好的证明。DelegatingFilterProxy中维护了一个类型为String，名字叫做targetBeanName的字段，targetBeanName就是DelegatingFilterProxy所代理的类的名称。最后通过registerFilter最终完成过滤器的注册。 五、spring security 认证和授权原理在上一节我们讨论了spring security过滤器的创建和注册原理。请记住springSecurityFilterChain（类型为FilterChainProxy）是实际起作用的过滤器链，DelegatingFilterProxy起到代理作用。 但是这还没有解决我们最初的所有问题，那就是虽然创建了springSecurityFilterChain过滤器链，那么过滤器链中的过滤器是如何一一创建的？这些过滤器是如何实现认证和授权的？本节我们来讨论这个问题。 注意：本节代码示例，采用的依然第二节中基于Java配置的搭建中的代码为例。 1. 过滤器的创建我们创建的MySecurityConfig继承了WebSecurityConfigurerAdapter。WebSecurityConfigurerAdapter中有个configure(HttpSecurity http)的方法： 12345678protected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() //拦截请求，创建FilterSecurityInterceptor .anyRequest().authenticated() //在创建过滤器的基础上的一些自定义配置 .and() //用and来表示配置过滤器结束，以便进行下一个过滤器的创建和配置 .formLogin().and() //设置表单登录，创建UsernamePasswordAuthenticationFilter .httpBasic(); //basic验证，创建BasicAuthenticationFilter&#125; 该方法用来实现spring security的一些自定义的配置，其中就包括Filter的创建。其中http.authorizeRequests()、http.formLogin()、http.httpBasic()分别创建了ExpressionUrlAuthorizationConfigurer，FormLoginConfigurer，HttpBasicConfigurer。在三个类从父级一直往上找，会发现它们都是SecurityConfigurer的子类。SecurityConfigurer中又有configure方法。该方法被子类实现就用于创建各个过滤器，并将过滤器添加进HttpSecurity中维护的装有Filter的List中，比如HttpBasicConfigurer中的configure方法，源码如下： 123456789101112131415161718public void configure(B http) throws Exception &#123; AuthenticationManager authenticationManager = http .getSharedObject(AuthenticationManager.class); //创建BasicAuthenticationFilter过滤器 BasicAuthenticationFilter basicAuthenticationFilter = new BasicAuthenticationFilter( authenticationManager, this.authenticationEntryPoint); if (this.authenticationDetailsSource != null) &#123; basicAuthenticationFilter .setAuthenticationDetailsSource(this.authenticationDetailsSource); &#125; RememberMeServices rememberMeServices = http.getSharedObject(RememberMeServices.class); if(rememberMeServices != null) &#123; basicAuthenticationFilter.setRememberMeServices(rememberMeServices); &#125; basicAuthenticationFilter = postProcess(basicAuthenticationFilter); //添加过滤器 http.addFilter(basicAuthenticationFilter);&#125; 另外，并非所有的过滤器都是在configure中进行创建的，比如UsernamePasswordAuthenticationFilter是在调用FormLoginConfigurer的构造方法时创建的。FormLoginConfigurer部分源码如下： 12345public FormLoginConfigurer() &#123; super(new UsernamePasswordAuthenticationFilter(), null); usernameParameter(&quot;username&quot;); passwordParameter(&quot;password&quot;);&#125; HttpSecurity的父类是AbstractConfiguredSecurityBuilder，该类中有个configure方法用来获取所有SecurityConfigurer，并调用所有SecurityConfigurer的configure方法。源码如下： 123456789private void configure() throws Exception &#123; //获取所有SecurityConfigurer类 Collection&lt;SecurityConfigurer&lt;O, B&gt;&gt; configurers = getConfigurers(); for (SecurityConfigurer&lt;O, B&gt; configurer : configurers) &#123; //调用所有SecurityConfigurer的configure方法 configurer.configure((B) this); &#125;&#125; 以上就是过滤器的创建过程。当我们的MySecurityConfig继承了WebSecurityConfigurerAdapter以后，就默认有了configure(HttpSecurity http)方法。我们也可以在MySecurityConfig中重写此方法来进行更灵活的配置。 12345678910111213141516171819202122@Override protected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() //注册FilterSecurityInterceptor .antMatchers(&quot;/index.html&quot;).permitAll()//访问index.html不要权限验证 .anyRequest().authenticated()//其他所有路径都需要权限校验 .and() .csrf().disable()//默认开启，可以显示关闭 .formLogin() //内部注册 UsernamePasswordAuthenticationFilter .loginPage(&quot;/login.html&quot;) //表单登录页面地址 .loginProcessingUrl(&quot;/login&quot;)//form表单POST请求url提交地址，默认为/login .passwordParameter(&quot;password&quot;)//form表单用户名参数名 .usernameParameter(&quot;username&quot;) //form表单密码参数名 .successForwardUrl(&quot;/success.html&quot;) //登录成功跳转地址 .failureForwardUrl(&quot;/error.html&quot;) //登录失败跳转地址 //.defaultSuccessUrl()//如果用户没有访问受保护的页面，默认跳转到页面 //.failureUrl() //.failureHandler(AuthenticationFailureHandler) //.successHandler(AuthenticationSuccessHandler) //.failureUrl(&quot;/login?error&quot;) .permitAll();//允许所有用户都有权限访问loginPage，loginProcessingUrl，failureForwardUrl &#125; 虽然我们上面仅仅看到了三种过滤器的创建，但是真正创建的远不止三种，spring secuirty会默认帮我们注册一些过滤器。比如SecurityContextPersistenceFilter，该过滤器用于在我们请求到来时，将SecurityContext从Session中取出放入SecuirtyContextHolder中供我们使用。并在请求结束时将SecuirtyContext存进Session中便于下次使用。还有DefaultLoginPageGeneratingFilter，该过滤器在我们没有自定义配置loginPage时会自动生成，用于生成我们默认的登录页面，也就是我们一开始在搭建中看到的登录页面。对于自定义配置spring security详细参考javaDoc。spring secuirty核心过滤器以及其顺序如下（并未包括所有）： 2. 认证与授权 认证(Authentication)：确定一个用户的身份的过程。授权(Authorization)：判断一个用户是否有访问某个安全对象的权限。下面讨论一下spring security中最基本的认证与授权。 首先明确一下在认证与授权中关键的三个过滤器，其他过滤器不讨论： 1. UsernamePasswordAuthenticationFilter：该过滤器用于拦截我们表单提交的请求（默认为/login），进行用户的认证过程吧。 2. ExceptionTranslationFilter：该过滤器主要用来捕获处理spring security抛出的异常，异常主要来源于FilterSecurityInterceptor。 3. FilterSecurityInterceptor：该过滤器主要用来进行授权判断。 下面根据我们访问应用的顺序并结合源码分析一下spring security的认证与授权。代码仍然是前面基于Java配置的搭建中的 我们在浏览器中输入http://localhost:9090/ 访问应用，因为我们的路径被spring secuirty保护起来了，我们是没有权限访问的，所以我们会被引导至登录页面进行登录。 此路径因为不是表单提交的路径(&#x2F;login)，该过程主要起作用的过滤器为FilterSecurityInterceptor。其部分源码如下： 1234567891011121314151617181920212223242526272829303132333435363738... public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; FilterInvocation fi = new FilterInvocation(request, response, chain); invoke(fi); &#125; public void invoke(FilterInvocation fi) throws IOException, ServletException &#123; //过滤器对每个请求只处理一次 if ((fi.getRequest() != null) &amp;&amp; (fi.getRequest().getAttribute(FILTER_APPLIED) != null) &amp;&amp; observeOncePerRequest) &#123; // filter already applied to this request and user wants us to observe // once-per-request handling, so don&#x27;t re-do security checking fi.getChain().doFilter(fi.getRequest(), fi.getResponse()); &#125; else &#123; // first time this request being called, so perform security checking if (fi.getRequest() != null) &#123; fi.getRequest().setAttribute(FILTER_APPLIED, Boolean.TRUE); &#125; //前处理 InterceptorStatusToken token = super.beforeInvocation(fi); try &#123; fi.getChain().doFilter(fi.getRequest(), fi.getResponse()); &#125; finally &#123; //使SecurityContextHolder中的Authentication保持原样，因为RunAsManager会暂时改变 //其中的Authentication super.finallyInvocation(token); &#125; //调用后的处理 super.afterInvocation(token, null); &#125; &#125;... 真正进行权限判断的为beforeInvocation，该方法定义在FilterSecurityInterceptor的父类AbstractSecurityInterceptor中，源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114... protected InterceptorStatusToken beforeInvocation(Object object) &#123; Assert.notNull(object, &quot;Object was null&quot;); final boolean debug = logger.isDebugEnabled(); //判断object是否为过滤器支持的类型，在这里是FilterInvocation(里面记录包含了请求的request,response,FilterChain) //这里可以把FilterInvocation看做是安全对象，因为通过它可以获得request,通过request可以获得请求的URI。 //而实际的安全对象就是URI if (!getSecureObjectClass().isAssignableFrom(object.getClass())) &#123; throw new IllegalArgumentException( &quot;Security invocation attempted for object &quot; + object.getClass().getName() + &quot; but AbstractSecurityInterceptor only configured to support secure objects of type: &quot; + getSecureObjectClass()); &#125; //获取安全对象所对应的ConfigAttribute，ConfigAtrribute实际就是访问安全所应该有的权限集。 Collection&lt;ConfigAttribute&gt; attributes = this.obtainSecurityMetadataSource() .getAttributes(object); //判断安全对象是否拥有权限集，没有的话说明所访问的安全对象是一个公共对象，就是任何人都可以访问的。 if (attributes == null || attributes.isEmpty()) &#123; //如果rejectPublicInvocations为true,说明不支持公共对象的访问，此时会抛出异常。 if (rejectPublicInvocations) &#123; throw new IllegalArgumentException( &quot;Secure object invocation &quot; + object + &quot; was denied as public invocations are not allowed via this interceptor. &quot; + &quot;This indicates a configuration error because the &quot; + &quot;rejectPublicInvocations property is set to &#x27;true&#x27;&quot;); &#125; if (debug) &#123; logger.debug(&quot;Public object - authentication not attempted&quot;); &#125; publishEvent(new PublicInvocationEvent(object)); return null; // no further work post-invocation &#125; if (debug) &#123; logger.debug(&quot;Secure object: &quot; + object + &quot;; Attributes: &quot; + attributes); &#125; //判断SecurityCntext中是否存在Authentication,不存在则说明访问着根本没登录 //调用下面的credentialsNotFound()方法则会抛出一个AuthenticationException， //该异常会被ExceptionTranslationFilter捕获，并做出处理。 //不过默认情况下Authentication不会为null,因为AnonymouseFilter会默认注册到 //过滤链中，如果用户没登录的话，会将其当做匿名用户(Anonymouse User)来对待。 //除非你自己将AnonymouseFilter从过滤链中去掉。 if (SecurityContextHolder.getContext().getAuthentication() == null) &#123; credentialsNotFound(messages.getMessage( &quot;AbstractSecurityInterceptor.authenticationNotFound&quot;, &quot;An Authentication object was not found in the SecurityContext&quot;), object, attributes); &#125; //Autentication存在，则说明用户已经被认证（但是不表示已登录，因为匿名用户也是相当于被认证的）， //判断用户是否需要再次被认证，如果你配置了每次访问必须重新验证，那么就会再次调用AuthenticationManager //的authenticate方法进行验证。 Authentication authenticated = authenticateIfRequired(); // Attempt authorization try &#123; //判断用户是否有访问被保护对象的权限。 //ed。默认的AccessDesicisonManager的实现类是AffirmativeBased //AffirmativeBased采取投票的形式判断用户是否有访问安全对象的权限 //票就是配置的Role。AffirmativeBased采用WebExpressionVoter进行投票 this.accessDecisionManager.decide(authenticated, object, attributes); &#125; catch (AccessDeniedException accessDeniedException) &#123; publishEvent(new AuthorizationFailureEvent(object, attributes, authenticated, accessDeniedException)); throw accessDeniedException; &#125; if (debug) &#123; logger.debug(&quot;Authorization successful&quot;); &#125; if (publishAuthorizationSuccess) &#123; publishEvent(new AuthorizedEvent(object, attributes, authenticated)); &#125; // Attempt to run as a different user Authentication runAs = this.runAsManager.buildRunAs(authenticated, object, attributes); if (runAs == null) &#123; if (debug) &#123; logger.debug(&quot;RunAsManager did not change Authentication object&quot;); &#125; // no further work post-invocation return new InterceptorStatusToken(SecurityContextHolder.getContext(), false, attributes, object); &#125; else &#123; if (debug) &#123; logger.debug(&quot;Switching to RunAs Authentication: &quot; + runAs); &#125; SecurityContext origCtx = SecurityContextHolder.getContext(); SecurityContextHolder.setContext(SecurityContextHolder.createEmptyContext()); SecurityContextHolder.getContext().setAuthentication(runAs); // need to revert to token.Authenticated post-invocation return new InterceptorStatusToken(origCtx, true, attributes, object); &#125; &#125;... 看这段代码，请明确几点: beforeInvocation(Object object)中的object为安全对象，类型为FilterInvocation。安全对象就是受spring security保护的对象。虽然按道理来说安全对象应该是我们访问的url，但是FilterInvocation中封装了request，那么url也可以获取到。 Collection attributes &#x3D; this.obtainSecurityMetadataSource().getAttributes(object) 每个安全对象都会有对应的访问权限集(Collection)，而且在容器启动后所有安全对象的所有权限集就已经被获取到并被放在安全元数据中（SecurityMetadataSource中），通过安全元数据可以获取到各个安全对象的权限集。因为我们每个安全对象都是登录才可以访问的（anyRequest().authenticated()），这里我们只需要知道此时每个对象的权限集只有一个元素，并且是authenticated。如果一个对象没有权限集，说明它是一个公共对象，不受spring security保护。 当我们没有登录时，我们会被当做匿名用户（Anonymouse）来看待。被当做匿名用户对待是AnonymouseAuthenticationFilter来拦截封装成一个Authentication对象，当用户被认证后就会被封装成一个Authentication对象。Authentication对象中封装了用户基本信息，该对象会在认证中做详细介绍。AnonymouseAuthenticationFilter也是默认被注册的。 最中进行授权判断的是AccessDecisionManager的子类AffirmativeBased的decide方法。我在来看其decide的源码： 12345678910111213141516171819202122232425262728293031323334353637...public void decide(Authentication authentication, Object object, Collection&lt;ConfigAttribute&gt; configAttributes) throws AccessDeniedException &#123; int deny = 0; for (AccessDecisionVoter voter : getDecisionVoters()) &#123; //根据用户的authenticton和权限集得出能否访问的结果 int result = voter.vote(authentication, object, configAttributes); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Voter: &quot; + voter + &quot;, returned: &quot; + result); &#125; switch (result) &#123; case AccessDecisionVoter.ACCESS_GRANTED: return; case AccessDecisionVoter.ACCESS_DENIED: deny++; break; default: break; &#125; &#125; if (deny &gt; 0) &#123; //如果deny&gt;0说明没有足够的权限去访问安全对象，此时抛出的 //AccessDeniedException会被ExceptionTranslationFilter捕获处理。 throw new AccessDeniedException(messages.getMessage( &quot;AbstractAccessDecisionManager.accessDenied&quot;, &quot;Access is denied&quot;)); &#125; // To get this far, every AccessDecisionVoter abstained checkAllowIfAllAbstainDecisions();&#125;... 因为我们首次登录，所以会抛出AccessDeniedexception。此异常会被ExceptionTranslationFilter捕获并进行处理的。其部分源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182...public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; try &#123; chain.doFilter(request, response); logger.debug(&quot;Chain processed normally&quot;); &#125; catch (IOException ex) &#123; throw ex; &#125; catch (Exception ex) &#123; // Try to extract a SpringSecurityException from the stacktrace Throwable[] causeChain = throwableAnalyzer.determineCauseChain(ex); RuntimeException ase = (AuthenticationException) throwableAnalyzer .getFirstThrowableOfType(AuthenticationException.class, causeChain); if (ase == null) &#123; ase = (AccessDeniedException) throwableAnalyzer.getFirstThrowableOfType( AccessDeniedException.class, causeChain); &#125; if (ase != null) &#123; //真正处理异常的地方 handleSpringSecurityException(request, response, chain, ase); &#125; else &#123; // Rethrow ServletExceptions and RuntimeExceptions as-is if (ex instanceof ServletException) &#123; throw (ServletException) ex; &#125; else if (ex instanceof RuntimeException) &#123; throw (RuntimeException) ex; &#125; // Wrap other Exceptions. This shouldn&#x27;t actually happen // as we&#x27;ve already covered all the possibilities for doFilter throw new RuntimeException(ex); &#125; &#125;&#125;private void handleSpringSecurityException(HttpServletRequest request, HttpServletResponse response, FilterChain chain, RuntimeException exception) throws IOException, ServletException &#123; if (exception instanceof AuthenticationException) &#123; logger.debug( &quot;Authentication exception occurred; redirecting to authentication entry point&quot;, exception); //未被认证，引导去登录 sendStartAuthentication(request, response, chain, (AuthenticationException) exception); &#125; else if (exception instanceof AccessDeniedException) &#123; Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (authenticationTrustResolver.isAnonymous(authentication) || authenticationTrustResolver.isRememberMe(authentication)) &#123; logger.debug( &quot;Access is denied (user is &quot; + (authenticationTrustResolver.isAnonymous(authentication) ? &quot;anonymous&quot; : &quot;not fully authenticated&quot;) + &quot;); redirecting to authentication entry point&quot;, exception); //如果为匿名用户说明未登录，引导去登录 sendStartAuthentication( request, response, chain, new InsufficientAuthenticationException( &quot;Full authentication is required to access this resource&quot;)); &#125; else &#123; logger.debug( &quot;Access is denied (user is not anonymous); delegating to AccessDeniedHandler&quot;, exception); //用户已登录，但是没有足够权限去访问安全对象，说明权限不足。进行 //权限不足的提醒 accessDeniedHandler.handle(request, response, (AccessDeniedException) exception); &#125; &#125;&#125;... 因为我们是以匿名用户的身份进行登录的，所以，会被引导去登录页面。登录页面的创建是由默认注册的过滤器DefaultLoginPageGeneratingFilter产生的。具体怎么产生的这里不做分析。我们只需要是谁做的就可以了。实际在使用时我们也不大可能去用默认生成的登录页面，因为太丑了。。。 2、在被引导至登录页面后，我们将输入用户名和密码，提交至应用。应用会校验用户名和密码，校验成功后，我们成功访问应用。 此时访问的路径为&#x2F;login，这是UsernamePasswordAuthenticationFilter将拦截请求进行认证。UsernamePasswordAuthenticationFilter的doFilter方法定义在其父类AbstractAuthenticationProcessingFilter中，源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; //判断请求是否需要进行验证处理。默认对/login并且是POST请求的路径进行拦截 if (!requiresAuthentication(request, response)) &#123; chain.doFilter(request, response); return; &#125; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Request is to process authentication&quot;); &#125; Authentication authResult; try &#123; //调用UsernamePasswordAuthenticationFilter的attemptAuthentication方法进行验证，并返回 //完整的被填充的Authentication对象 authResult = attemptAuthentication(request, response); if (authResult == null) &#123; // return immediately as subclass has indicated that it hasn&#x27;t completed // authentication return; &#125; //进行session固定攻击的处理 sessionStrategy.onAuthentication(authResult, request, response); &#125; catch (InternalAuthenticationServiceException failed) &#123; logger.error( &quot;An internal error occurred while trying to authenticate the user.&quot;, failed); unsuccessfulAuthentication(request, response, failed); return; &#125; catch (AuthenticationException failed) &#123; // 认证失败后的处理 unsuccessfulAuthentication(request, response, failed); return; &#125; // Authentication success if (continueChainBeforeSuccessfulAuthentication) &#123; chain.doFilter(request, response); &#125; //认证成功后的处理 successfulAuthentication(request, response, chain, authResult); &#125; 实际认证发生在UsernamePasswordAuthenticationFilter的attemptAuthentication中，如果认证失败，则会调用unsuccessfulAuthentication进行失败后的处理，一般是提示用户认证失败，要求重新输入用户名和密码，如果认证成功，那么会调用successfulAuthentication进行成功后的处理，一般是将Authentication存进SecurityContext中并跳转至之前访问的页面或者默认页面（这部分在读者读完本节后自行去看源码是怎么处理的，这里不做讨论，现在只需知道会跳到一开始我们访问的页面中）。下面我们来看认证即attemptAuthentication的源码： 123456789101112131415161718192021222324252627282930313233...public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException &#123; if (postOnly &amp;&amp; !request.getMethod().equals(&quot;POST&quot;)) &#123; throw new AuthenticationServiceException( &quot;Authentication method not supported: &quot; + request.getMethod()); &#125; String username = obtainUsername(request); String password = obtainPassword(request); if (username == null) &#123; username = &quot;&quot;; &#125; if (password == null) &#123; password = &quot;&quot;; &#125; username = username.trim(); //将用户名和密码封装在Authentication的实现UsernamePasswordAuthenticationToken //以便于AuthentictionManager进行认证 UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken( username, password); // Allow subclasses to set the &quot;details&quot; property setDetails(request, authRequest); //获得AuthenticationManager进行认证 return this.getAuthenticationManager().authenticate(authRequest);&#125;... spring security在进行认证时，会将用户名和密码封装成一个Authentication对象，在进行认证后，会将Authentication的权限等信息填充完全返回。Authentication会被存在SecurityContext中，供应用之后的授权等操作使用。此处介绍下Authentication，Authentication存储的就是访问应用的用户的一些信息。下面是Authentication源码： 12345678910111213141516171819public interface Authentication extends Principal, Serializable &#123; //用户的权限集合 Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); //用户登录的凭证，一般指的就是密码 Object getCredentials(); //用户的一些额外的详细信息，一般不用 Object getDetails(); //这里认为Principal就为登录的用户 Object getPrincipal(); //是否已经被认证了 boolean isAuthenticated(); //设置认证的状态 void setAuthenticated(boolean isAuthenticated) throws IllegalArgumentException;&#125; 讲解了Authentication后，我们回过头来再看attemptAuthentication方法，该方法会调用AuthenticationManager的authenticate方法进行认证并返回一个填充完整的Authentication对象。 在这里我们又要讲解一下认证的几个核心的类，很重要！ a). AuthenticationManager b).ProviderManager c).AuthenticationProvider d).UserDetailsService e).UserDetails 现在来说一下这几个类的作用以及关联关系。 a). AuthenticationManager是一个接口，提供了authenticate方法用于认证。 b). AuthenticationManager有一个默认的实现ProviderManager，其实现了authenticate方法。 c). ProviderManager内部维护了一个存有AuthenticationProvider的集合，ProviderManager实现的authenticate方法再调用这些AuthenticationProvider的authenticate方法去认证，表单提交默认用的AuthenticationProvider实现是DaoAuthenticationProvider。 d). AuthenticationProvider中维护了UserDetailsService，我们使用内存中的用户，默认的实现是InMemoryUserDetailsManager。UserDetailsService用来查询用户的详细信息，该详细信息就是UserDetails。UserDetails的默认实现是User。查询出来UserDetails后再对用户输入的密码进行校验。校验成功则将UserDetails中的信息填充进Authentication中返回。校验失败则提醒用户密码错误。 以上说的这些接口的实现类是由我们在MySecurityConfig中配置时生成的，即下面的代码: 1234567@Autowired public void configUser(AuthenticationManagerBuilder builder) throws Exception &#123; builder .inMemoryAuthentication() //创建用户名为user，密码为password的用户 .withUser(&quot;user&quot;).password(&quot;password&quot;).roles(&quot;USER&quot;); &#125; 这里不再讨论具体是怎么生成的，记住即可。因为我们实际在项目中一般都会用自定义的这些核心认证类。 下面我们来分析源码，先来看ProviderManager的authenticate方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788...public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; Class&lt;? extends Authentication&gt; toTest = authentication.getClass(); AuthenticationException lastException = null; Authentication result = null; boolean debug = logger.isDebugEnabled(); //获取所有AuthenticationProvider，循环进行认证 for (AuthenticationProvider provider : getProviders()) &#123; if (!provider.supports(toTest)) &#123; continue; &#125; if (debug) &#123; logger.debug(&quot;Authentication attempt using &quot; + provider.getClass().getName()); &#125; try &#123; //对authentication进行认证 result = provider.authenticate(authentication); if (result != null) &#123; //填充成完整的Authentication copyDetails(authentication, result); break; &#125; &#125; catch (AccountStatusException e) &#123; prepareException(e, authentication); // SEC-546: Avoid polling additional providers if auth failure is due to // invalid account status throw e; &#125; catch (InternalAuthenticationServiceException e) &#123; prepareException(e, authentication); throw e; &#125; catch (AuthenticationException e) &#123; lastException = e; &#125; &#125; if (result == null &amp;&amp; parent != null) &#123; // Allow the parent to try. try &#123; result = parent.authenticate(authentication); &#125; catch (ProviderNotFoundException e) &#123; // ignore as we will throw below if no other exception occurred prior to // calling parent and the parent // may throw ProviderNotFound even though a provider in the child already // handled the request &#125; catch (AuthenticationException e) &#123; lastException = e; &#125; &#125; if (result != null) &#123; if (eraseCredentialsAfterAuthentication &amp;&amp; (result instanceof CredentialsContainer)) &#123; // Authentication is complete. Remove credentials and other secret data // from authentication ((CredentialsContainer) result).eraseCredentials(); &#125; eventPublisher.publishAuthenticationSuccess(result); return result; &#125; // Parent was null, or didn&#x27;t authenticate (or throw an exception). if (lastException == null) &#123; //如果所有的AuthenticationProvider进行认证完result仍然为null //此时表示为提供AuthenticationProvider，抛出ProviderNotFoundException异常 lastException = new ProviderNotFoundException(messages.getMessage( &quot;ProviderManager.providerNotFound&quot;, new Object[] &#123; toTest.getName() &#125;, &quot;No AuthenticationProvider found for &#123;0&#125;&quot;)); &#125; prepareException(lastException, authentication); throw lastException;&#125;... ProviderManager用AuthenticationProvider对authentication进行认证。如果没有提供AuthenticationProvider，那么最终将抛出ProviderNotFoundException。 我们表单提交认证时，AuthenticationProvider默认的实现是DaoAuthenticationProvider，DaoAuthenticationProvider的authenticate方法定义在其父类AbstractUserDetailsAuthenticationProvider中，其源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879...public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; Assert.isInstanceOf(UsernamePasswordAuthenticationToken.class, authentication, messages.getMessage( &quot;AbstractUserDetailsAuthenticationProvider.onlySupports&quot;, &quot;Only UsernamePasswordAuthenticationToken is supported&quot;)); // Determine username String username = (authentication.getPrincipal() == null) ? &quot;NONE_PROVIDED&quot; : authentication.getName(); boolean cacheWasUsed = true; UserDetails user = this.userCache.getUserFromCache(username); if (user == null) &#123; cacheWasUsed = false; try &#123; //获取UserDetails，即用户详细信息 user = retrieveUser(username, (UsernamePasswordAuthenticationToken) authentication); &#125; catch (UsernameNotFoundException notFound) &#123; logger.debug(&quot;User &#x27;&quot; + username + &quot;&#x27; not found&quot;); if (hideUserNotFoundExceptions) &#123; throw new BadCredentialsException(messages.getMessage( &quot;AbstractUserDetailsAuthenticationProvider.badCredentials&quot;, &quot;Bad credentials&quot;)); &#125; else &#123; throw notFound; &#125; &#125; Assert.notNull(user, &quot;retrieveUser returned null - a violation of the interface contract&quot;); &#125; try &#123; preAuthenticationChecks.check(user); //进行密码校验 additionalAuthenticationChecks(user, (UsernamePasswordAuthenticationToken) authentication); &#125; catch (AuthenticationException exception) &#123; if (cacheWasUsed) &#123; // There was a problem, so try again after checking // we&#x27;re using latest data (i.e. not from the cache) cacheWasUsed = false; user = retrieveUser(username, (UsernamePasswordAuthenticationToken) authentication); preAuthenticationChecks.check(user); additionalAuthenticationChecks(user, (UsernamePasswordAuthenticationToken) authentication); &#125; else &#123; //认证失败抛出认证异常 throw exception; &#125; &#125; postAuthenticationChecks.check(user); if (!cacheWasUsed) &#123; this.userCache.putUserInCache(user); &#125; Object principalToReturn = user; if (forcePrincipalAsString) &#123; principalToReturn = user.getUsername(); &#125; //认证成功，返回装有用户权限等信息的authentication对象 return createSuccessAuthentication(principalToReturn, authentication, user);&#125;... retrieveUser方法定义在DaoAuthenticationProvider中，用来获取UserDetails这里不再展示源码，请读者自行去看。你会发现获取获取UserDetails正是由其中维护的UserDetailsService来完成的。获取到UserDetails后再调用其 additionalAuthenticationChecks方法进行密码的验证。如果认证失败，则抛出AuthenticationException，如果认证成功则返回装有权限等信息的Authentication对象。 3、小节到目前为止，我们结合我们创建的项目和spring security的源码分析了web应用认证和授权的原理。内容比较多，现在理一下重点。 springSecurityFilterChain中各个过滤器怎么创建的只需了解即可。不要太过关注。 重点记忆UsernamePasswordAuthenticationFilter，ExceptionTranslationFilter，FilterSecurityInterceptor这三个过滤器的作用及源码分析。 重要记忆认证中Authentication，AuthenticationManager，ProviderManager，AuthenticationProvider，UserDetailsService，UserDetails这些类的作用及源码分析。 重点记忆授权中FilterInvoction，SecurityMetadataSource，AccessDecisionManager的作用。 将这些类理解的关键是建立起关联，建立起关联的方式就是跟着本节中的案例走下去，一步步看代码如何实现的。 六、spring security Java配置实现自定义表单认证与授权前面三节讲解了spring security的搭建以及简单的表单认证与授权原理。本篇将实现我们自定义的表单登录与认证。 本篇不会再讲项目的搭建过程，因为跟第二节的搭建如出一辙。本篇也不会将项目中所有的代码全部给出，因为代码量有点大。项目的代码被放在了github上，请拉下来根据讲解去看代码，代码的注释写的也比较详细。github地址https://github.com/wutianqi/spring_security_extend.git。另外，因为项目中使用了mysql数据库，对于表结构和数据这里截图会很明白的给出。 1. 项目结构及表结构1.1 项目结构 1.2 表结构 创建名称为spring_security的数据库，创建三张表：user、role、user_role 用户表（user）： id user_name password 1 admin admin 2 test test 角色表（role）： id role_name 1 user 2 admin 用户角色表（user_role）： id user_id role_id 1 1 1 2 2 2 2. 项目功能在讲解代码之前还是要介绍一下本项目利用spring security实现的功能，便于读者分析代码。 2.1 本项目围绕着admin.jsp，user.jsp，other.jsp展开。 admin.jsp只有admin角色的用户才可以访问，ls拥有admin角色。 user.jsp有user角色或admin角色都可以访问，zs拥有user角色。 other.jsp只要用户登录就可以访问，ww什么角色都没有。为了简单起见，项目中other.jsp就代表其他任何登录后就可以访问的路径 3. 代码解读关于spring security认证与授权原理的讲解在前一篇讲的比较清楚了，这里不再详细介绍，这里只介绍一下自己认为比较重要的代码。 3.1 MySecurityConfig spring secuirty提供了一种后处理bean方式提供一个自定义配置过滤器的口子，就是下面这段代码： 这段代码对FilterSecurityInterceptor的AccessDecisionManager属性进行了自定义的配置。目的是让spring security用我们自定义的AccessDecisionManager。 3.2 MyAccessDecisionManager 在用户没有登录时，decide中的authentication参数是AnonymousAuthenticationToken，此时他会有ROLE_ANONYMOUS的角色，就是匿名角色。这是AnonymousAuthenticationFilter来做的。 这样下面这段代码就好理解了 1234if(authorityString.contains(&quot;ROLE_ANONYMOUS&quot;)) &#123; //未登录 throw new AccessDeniedException(&quot;未登录&quot;);&#125; 3.3 MyAuthenticationProvider 我们的MyAuthenticationProvider继承了AbstractUserDetailsAuthenticationProvider，我们自定义provider的真正认证过程实际发生在AbstractUserDetailsAuthenticationProvider的authenticate中。我们的MyAuthenticationProvider只是实现了retrieveUser来获取用户信息并在其中检查用户名是否存在，以及实现了additionalAuthenticationChecks检验用户输入的密码。其他一些诸如填充完整的Authentication的行为交给父类来做了。因为父类处理的很好所以我们无须自己再做。MySuccessHandler也是将认证成功后的处理都交给父类去处理了。 4. 小节本spring security系列，只是对我们web应用中常见的表单认证与登录进行了讲解。spring security还有很多安全功能。比如方法安全，域安全等。本文没有进行讲解。想了解更多，可以查看官方文档。自己以后也会再学，到时候也会再写相关博文。 项目地址 https://github.com/wutianqi/spring_security_extend.git","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"spring security学习【转】","slug":"spring-security学习【转】","permalink":"https://tianxiafeiyu.github.io/tags/spring-security%E5%AD%A6%E4%B9%A0%E3%80%90%E8%BD%AC%E3%80%91/"}]},{"title":"关于线程安全","slug":"技术开发/java/关于线程安全","date":"2022-12-15T23:12:12.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/关于线程安全/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/%E5%85%B3%E4%BA%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/","excerpt":"","text":"关于线程安全（摘自https://www.cnblogs.com/nizuimeiabc1/p/4254127.html） 1）常量始终是线程安全的，因为只存在读操作。 2）每次调用方法前都新建一个实例是线程安全的，因为不会访问共享的资源。 3）局部变量是线程安全的。因为每执行一个方法，都会在独立的空间创建局部变量，它不是共享的资源。局部变量包括方法的参数变量和方法内变量。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"关于线程安全","slug":"关于线程安全","permalink":"https://tianxiafeiyu.github.io/tags/%E5%85%B3%E4%BA%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"}]},{"title":"2020 学习计划（成长之路）","slug":"技术开发/java/2020 学习计划（成长之路）","date":"2022-12-15T23:12:09.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/2020 学习计划（成长之路）/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/2020%20%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92%EF%BC%88%E6%88%90%E9%95%BF%E4%B9%8B%E8%B7%AF%EF%BC%89/","excerpt":"","text":"2020 学习计划（成长之路） 领导怎么说： k8s docker 多读源码 逛逛开源社区 提高英文文档阅读能力 设计模式，工作中体现 一个优秀的软件架构师，首先一定是一个出色的程序员 eBay的架构师[RandyShoup先生]是如何总结架构师在项目中的职责的： l 具备丰富的一线大中型开发项目的整体规划、方案设计及技术队伍管理经验。 2 具备软件行业工作经验，熟悉业务领域的技术应用和发展。 3 具有项目管理理论基础，并在应用系统开发平台和项目管理上有实践经验。 4 对相关的技术标准有深刻的认识，对软件工程标准规范有良好的把握。 具备C&#x2F;S或B&#x2F;S体系结构或特定领域软件产品开发及架构和设计的经验。 5 具有面向对象分析（Object-Oriented Analysis, OOA）、设计（OOD）、开发（OOP）能力，精通UML和XML等，熟练使用Rational Rose、PowerDesigner等CASE工具进行设计开发。 6 对相关编程技术及整个解决方案有深刻的理解及熟练的应用，并且精通架构和设计模式，并在此基础上设计产品框架。 7 精通大型数据库如Oracle、Sql Server、MySQL等的开发。l 对计算机系统、网络和安全、应用系统架构等有全面的认识。 8 良好的团队意识和写作精神，有较强的内外沟通能力。 学习计划： \\1. Java 基础知识的深入理解 反射、IO、接口&#x2F;抽象类、内部类、异常、Enum、序列化、static、final、Iterator，Iterable和Comparable,Comparator 等等知识点，虽然都有学习，按实际上还差得很远，还有很多细节与需要深入学习理解。还应该尝试看 Java 源码，源码阅读理解是程序员成长中的必经之路，在源码中可以得到更多细节。最近在看《On Java 8》(事实上的 《Java 编程思想》第五版)这本书，书中讲解真的很详细，内容也非常多，需要反复深入学习。2020 年需要攻克完成这本书，不单单只是阅读浏览一遍，应该要融会贯通，对晦涩难懂的知识多思考，争取掌握。 \\2. 设计模式 设计模式很重要，支撑起代码的整个生命历程。设计模式应该被理解，被应用到项目中，而不是只是简单的概念层面上的了解，当然，也不应该生搬硬套。能够简化流程，优化项目的设计模式，才是好的设计模式。2020年希望能够掌握常用的设计模式，理解设计模式的套路，加深编程经验。完成《大话设计模式》这本书的学习理解。四人帮(GOF)的书籍《. Design Patterns》可能较之有一定的学习难度，但是经典还是需要了解。 \\3. 微服务、容器等知识 现如今，微服务非常重要，阿里系的Dubbo+Zookeeper，Spring系的SpringCloud，以及在此基础上二次开发可能更优秀的SpringCloud。主要学习SpringCloud。 Docker 是微服务中至关重要的工具，也需要学习。之前有比较简单的学习，还需要深入学习，注意在实践中多使用 Docker 技术，争取融会贯通，学以致用。 kubernetes 也需要学习理解，这是基于容器的集群管理平台，现在事实上的标准，需要掌握。主要通过网课学习。 \\4. 分布式架构 分布式缓存、分布式存储、分布式锁、幂等性、分布式事务、流量削峰、服务容错、服务降级等等，现在的分布式太火了，必须要对分布式有一定的理解和把握。计划是通过网课学习分布式架构。 \\5. 数据库等知识 常用的关系型数据库有MySQL、Oracle、DB2等，MySQL应该是使用最多的，深入学习和掌握MySQL，是高级程序员的基本要求。还又 Redis、消息中间件等也需要有一定的知识储备。 \\6. 开发工具 开发工具保证了开发效率，现在基本上离不开开发工具了，一个项目的开发到部署的过程都设计到许多的软件工具。作为使用者和潜在使用者，更应该对它们有深入的了解，就算是最熟悉的 idea, 我也不敢说完全掌握，Idea、maven、git、svn、jenkins、tomcat 等等也需要学习掌握。 \\7. 提高英语水平 如今流行的编程语言都是贴近英语语法。大家更倾向于写出来的代码是好读易懂的。能够快速的理解原作者的用词，就可以更快的读懂代码结构，这比纯粹的分析编程语法要简单且自然的多。 能够流畅的阅读英文文档，对于程序员而言，是非常重要的。这也是非常艰难的，英语也确实是我的短板，提高的英语的阅读能力，通过逼迫自己去看，去理解英文来实现，尝试去读英文的工具文档、逛外国的开发论坛，stackoverflow、github。YouTube、Reddit、ins 等也可以多逛逛。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"2020 学习计划（成长之路）","slug":"2020-学习计划（成长之路）","permalink":"https://tianxiafeiyu.github.io/tags/2020-%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92%EF%BC%88%E6%88%90%E9%95%BF%E4%B9%8B%E8%B7%AF%EF%BC%89/"}]},{"title":"Java 归并排序【转】","slug":"技术开发/java/Java 归并排序【转】","date":"2022-12-15T23:12:09.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/Java 归并排序【转】/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Java%20%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E3%80%90%E8%BD%AC%E3%80%91/","excerpt":"","text":"归并排序1、原理归并排序是一种概念上最简单的排序算法，与快速排序一样，归并排序也是基于分治法的。归并排序将待排序的元素序列分成两个长度相等的子序列，为每一个子序列排序，然后再将他们合并成一个子序列。合并两个子序列的过程也就是两路归并。 2、复杂度归并排序是一种稳定的排序算法，归并排序的主要问题在于它需要一个与待排序数组一样大的辅助数组空间。由于归并排序每次划分时两个子序列的长度基本一样，所以归并排序最好、最差和平均时间复杂度都是nlog2n。 我们可以通过下图非常容易看懂归并排序的过程： 时间复杂度： 3、完整Java代码12345678910111213141516171819202122232425262728293031323334353637383940import org.junit.Test;public class MergeSort &#123; //两路归并算法，两个排好序的子序列合并为一个子序列 public void merge(int []a,int left,int mid,int right)&#123; int []tmp=new int[a.length];//辅助数组 int p1=left,p2=mid+1,k=left;//p1、p2是检测指针，k是存放指针 while(p1&lt;=mid &amp;&amp; p2&lt;=right)&#123; if(a[p1]&lt;=a[p2]) tmp[k++]=a[p1++]; else tmp[k++]=a[p2++]; &#125; while(p1&lt;=mid) tmp[k++]=a[p1++];//如果第一个序列未检测完，直接将后面所有元素加到合并的序列中 while(p2&lt;=right) tmp[k++]=a[p2++];//同上 //复制回原素组 for (int i = left; i &lt;=right; i++) a[i]=tmp[i]; &#125; public void mergeSort(int [] a,int start,int end)&#123; if(start&lt;end)&#123;//当子序列中只有一个元素时结束递归 int mid=(start+end)/2;//划分子序列 mergeSort(a, start, mid);//对左侧子序列进行递归排序 mergeSort(a, mid+1, end);//对右侧子序列进行递归排序 merge(a, start, mid, end);//合并 &#125; &#125; @Test public void test()&#123; int[] a = &#123; 49, 38, 65, 97, 76, 13, 27, 50 &#125;; mergeSort(a, 0, a.length-1); System.out.println(&quot;排好序的数组：&quot;); for (int e : a) System.out.print(e+&quot; &quot;); &#125;&#125; 原文链接：https://blog.csdn.net/qq_36442947/article/details/81612870","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Java 归并排序【转】","slug":"Java-归并排序【转】","permalink":"https://tianxiafeiyu.github.io/tags/Java-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E3%80%90%E8%BD%AC%E3%80%91/"}]},{"title":"acmp开发记录","slug":"技术开发/java/acmp开发记录","date":"2022-12-15T23:12:09.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/acmp开发记录/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/acmp%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/","excerpt":"","text":"1. 数据库存储创建日期是Instant格式，后台需要根据今天日期查找今天创建的记录。主要是需要得到Instant格式的今天的最小日期，用于比对。123LocalDate localDate = LocalDate.now();LocalDateTime minTime = localDate.atTime(LocalTime.MIN);Instant today = minTime.toInstant(ZoneOffset.of(&quot;+0&quot;)); 2. 物理分页查询（数据库分页）业务场景：查询数据库表联系人分页，筛选条件pid、status、name；按创建时间降序排序。 12345678910111213Specification&lt;AlarmContact&gt; specification = (Specification&lt;AlarmContact&gt;) (root, query, criteriaBuilder) -&gt; &#123; List&lt;Predicate&gt; list = new ArrayList&lt;&gt;(); list.add(criteriaBuilder.equal(root.get(&quot;projectId&quot;), projectId)); list.add(criteriaBuilder.equal(root.get(&quot;status&quot;), ResourceStatus.ENABLE)); if (name.length() != 0) &#123; // 此处为查询含有name的数据 list.add(criteriaBuilder.like(root.get(&quot;name&quot;),&quot;%&quot;+ name +&quot;%&quot; )); &#125; Predicate[] p = new Predicate[list.size()]; return criteriaBuilder.and(list.toArray(p)); &#125;;Pageable pageable = new PageRequest(page, limit, Sort.Direction.DESC, &quot;createdDate&quot;);Page&lt;AlarmContact&gt; alarmContact，Page = alarmContactRepository.findAll(specification, pageable); 3. 集合分页业务场景：拥有用户的集合，需要将这个集合进行分页返回给前端。 12345678910111213141516171819List&lt;User&gt; userList;//默认已经有List数据//根据传进来的用户名字进行模糊筛选 if(0 != name.length())&#123; List&lt;User&gt; temList = new ArrayList&lt;&gt;(); temList.addAll(userList); for(User user : temList)&#123; if(!user.getUsername().contains(name))&#123; userList.remove(user); &#125; &#125; &#125;//集合转PagePageable pageable = new PageRequest(page, limit, Sort.Direction.ASC, &quot;id&quot;);// 当前页第一条数据在List中的位置int start = (int)pageable.getOffset();// 当前页最后一条数据在List中的位置int end = (start + pageable.getPageSize()) &gt; userList.size() ? userList.size() : ( start + pageable.getPageSize());// 配置分页数据Page&lt;User&gt; userPagePage = new PageImpl&lt;&gt;(userList.subList(start, end), pageable, userList.size()); 4. 树的相关操作业务场景：在做权限控制的时候，权限是树的形式，根据前端需求需要提供不同的数据格式。 求出当前用户的所有具体权限（叶子节点） 1234567891011121314151617181920212223242526public Set&lt;Permission&gt; getEXactPermission() &#123; Set&lt;Role&gt; roles = userRoleRepository.findByUserId(userCache.getId()).stream().map(userRole -&gt; userRole.getRole()).collect(Collectors.toSet()); Set&lt;Permission&gt; permissions = roles.stream().flatMap(role -&gt; role.getPermissions().stream()).collect(Collectors.toSet()); Set&lt;Permission&gt; exactPermissions = new HashSet&lt;&gt;(); for(Permission permission : permissions)&#123; Set&lt;Permission&gt; permissions1 = new HashSet&lt;&gt;(); findTreeleafs(permission, permissions1); exactPermissions.addAll(permissions1); &#125; return exactPermissions;&#125;//递归遍历树的叶子节点，如果只有一个节点，它也是叶子public void findTreeleafs(Permission permission, Set&lt;Permission&gt; permissionSet) &#123; if(permission.getChildren().size() == 0)&#123; permissionSet.add(permission); &#125; for(Permission permission1 : permission.getChildren())&#123; if (permission.getChildren().size() == 0) &#123; permissionSet.addAll(permission.getChildren()); &#125; else &#123; findTreeleafs(permission1, permissionSet); &#125; &#125;&#125; 获取权限子树。就是用户拥有权限的完整路径 思路：获取用户的具体权限集合（叶子节点），删除完整树中没有达到集合中的路径。 5. spring boot JPA多条件查询1）Repository需要继承JpaRepository和JpaSpecificationExecutor 123public interface projectRepository extends JpaRepository&lt;Project, Long&gt;, JpaSpecificationExecutor&lt;Project&gt; &#123; &#125; 2）构建筛选器 123456789101112131415161718192021222324/** * 分页查询获取分页列表 * @param companyId * @return */ public Page&lt;Project&gt; getListByCompanyPage(PageFilter pageFilter,String companyId,Date beginDate,Date endDate,String projectName) &#123; Page&lt;Project&gt; l=projectRepository.findAll(new Specification&lt;Project&gt;() &#123; @Override public Predicate toPredicate(Root&lt;Project&gt; root, CriteriaQuery&lt;?&gt; criteriaQuery, CriteriaBuilder cBuilder) &#123; //开始，定义一个Predicate Predicat e p = cBuilder.conjunction(); /**精确查询**/ p = cBuilder.and(p, cBuilder.equal(root.get(&quot;companyId&quot;), companyId)); /**模糊查询**/ p = cBuilder.and(p, cBuilder.like(root.get(&quot;projectName&quot;), &quot;%&quot;+projectName+&quot;%&quot;)); /**时间段查询**/ //大于等于开始时间 p = cBuilder.and(p, cBuilder.greaterThanOrEqualTo(root.get(&quot;createTime&quot;), beginDate)); //小于等于结束时间 p = cBuilder.and(p, cBuilder.lessThanOrEqualTo(root.get(&quot;createTime&quot;), endDate)); return p; &#125; &#125;, pageFilter.getPageRequest()); return l; 6. jpa delete无法删除问题描述：两张表表1和表2通过一张中间表表3关联，都是一对多关系。表1的一条记录 a 已经和表2的记录 b 关联起来了。逻辑删除 a 记录，现在需要删除 b 记录，表3的关联记录还存在，要先根据 b 记录删掉表3的关联记录，但是此时用 JPA 的 deleteAllBy… 不生效，非常疑惑，自定义 sql 删除生效。 12@Modifying@Query(&quot;delete from UserRole where role.id = ?1&quot;) 解答：看到网上有说法说是 JPA 的 entity 对象生命周期问题，由于表 1 还存在记录的引用，之后会更新回来。。。 7. 分页查询结果集中某个属性等于某个值的元素排在前面业务场景：分页查询数据库，状态为 ON 的值排在前面，且根据最后修改时间排序。 分析讨论：Java分页查询的排序并不是很难，特别是使用Pagable时排序非常方便，但是一般的排序都市按照升序或者降序排序，根据某个属性的特定值排序很少看见，头疼。 问题解决： 1）偷懒办法，如果只有两种状态，仍然可以用升序降序进行排序，这时候比较的就是两种不同值的相对大小（数值、字符串类型等）； 12Sort sort =new Sort(Sort.Direction.DESC, &quot;status&quot;).and(new Sort(Sort.Direction.DESC, &quot;lastModifiedDate&quot;));Pageable pageable = new PageRequest(page, limit, sort); 2）有多种不同状态时，可以使用 sql 语句进行查询 3）查询出元素集合列表，进行排序，然后对集合进行分页。 8. 读取 jar 包中MANIFEST.MF文件信息123456789101112// 通过JarFile的getJarEntry方法读取META-INF/MANIFEST.MFjarFile = new JarFile(jarFilePath);JarEntry entry = jarFile.getJarEntry(&quot;META-INF/MANIFEST.MF&quot;);// 如果读取到MANIFEST. F文件内容，则转换为stringif (entry != null) &#123; InputStream in = jarFile.getInputStream(entry); StringBuilder sb = new StringBuilder(); BufferedReader br = new BufferedReader(new InputStreamReader(in)); String line = &quot;&quot;; while ((line = br.readLine()) != null) &#123; sb.append(line+&quot;&lt;br&gt;&quot;); &#125; 9. 编写泛型方法错误示例： 1public static Page&lt;T&gt; getPage(int page, int limit, List&lt;T&gt; data)&#123; // ... &#125; 实际使用时候会报类型无法匹配的错误。 正确写法： 123public static &lt;T extends Object&gt; Page&lt;T&gt; getPage(int page, int limit, List&lt;T&gt; data)&#123; // ...&#125; 10. Java中父类能不能强转为子类？一般来说父类是不能强转为子类对象的，因为子类中可能包含父类没有的属性或方法，父类强转子类会存在不确定性。 《java面向对象程序设计（第2版）》，一个父类类型的对象如果是用子类new出来的时候, 就不能称之为父类对象，而是一个子类的上转型对象。这两者是有区别的，区别的其中一点就是父类对象不可强制转换为子类对象，而子类的上转型对象可以强制转换回子类对象 1234567891011121314class Father&#123; &#125;class Son extends Father&#123; &#125;public class Main&#123; public static void main(String[] args)&#123; Father father1 = new Father(); Father father2 = new Son(); Son son1 = (Son) father1;//报错 Son son2 = (Son) father2;//不报错 &#125;&#125; 网上看到很搞笑的一段描述：孙子可能会装大爷，大爷永远不会装孙子。 哈哈，非常贴切生动了。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"acmp开发记录","slug":"acmp开发记录","permalink":"https://tianxiafeiyu.github.io/tags/acmp%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"}]},{"title":"idea+maven+git 开发环境安装","slug":"技术开发/java/idea+maven+git 开发环境安装","date":"2022-12-15T23:12:09.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/idea+maven+git 开发环境安装/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/idea+maven+git%20%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/","excerpt":"","text":"1. jdk安装网上下载jdk，运行安装程序 配置环境变量： 系统变量-&gt;新增-&gt;变量名：JAVA_HOME，变量值：java安装根目录 path变量-&gt;新增 -&gt;%JAVA_HOME%\\bin 控制台输入java -version验证 2. idea安装百度搜索下载安装、破解，没啥好说的 3. maven安装http://maven.apache.org/download.cgi 下载二进制安装包，直接解压到磁盘 配置环境变量： 系统变量-&gt;新增-&gt;变量名：MAVEN_HOME，变量值：maven根目录 path变量-&gt;新增 -&gt;%MAVEN_HOME%\\bin 控制台输入mvn -v验证 配置本地仓库和远程仓库：打开%MAVEN_HOME%\\conf\\settings.xml文件，编辑 本地仓库：解开localRepository标签注释，将地址改为要设置的本地仓库地址 远程仓库：在mirrors标签中添加子标签如下： 123456&lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;name&gt;nexus-aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; 4. git安装https://git-scm.com/downloads 下载安装程序，会有很多安装选项，可以一路选择默认选项，安装完成 安装过程会自动添加git环境变量，不再需要手动配置 控制台输入git --version验证 配置git 用户和邮箱: 12345git config --global user.name [github注册用户名]git config --global user.email [github邮箱]git config --global user.password [用户密码]git config --list 查看当前配置# 需要修改信息的话重新运行以上命令即可 常用命令： git init ：给项目添加仓库 git add . ：添加项目下的所有文件到仓库中，也可以指定文件 git commit -m [提交时的描述信息] ：提交时的附带信息 git remote add origin [自己的仓库url地址] ：将本地的仓库关联到github的仓库，需要先在github上创建仓库 git push -u origin master ：项目上传到github仓库中 git clone [github仓库url地址] :克隆项目到当前目录下 5. idea使用mavenFile -&gt; Settings -&gt; Build, Execution, Deployment -&gt; Build Tools -&gt; Maven : Maven home directory -&gt; 选择%MAVEN_HOME% User settings file -&gt; 选择%MAVEN_HOME%\\conf\\settings Local repository -&gt; 选择本地仓库 出现版本不兼容的bug:idea version：2019.1.1maven version：3.6.3问题描述：pom文件导入依赖包时报错No implementation for org.apache.maven.model.path.PathTranslator was bound解决办法：升级idea版本或者降低maven版本。 6. idea使用git从github仓库中下载项目到本地： settings -&gt; 配置git.exe 首页选择check out from version control，登录github，输入账号密码，就可以选择要下载的仓库了 本地项目更新到gitbub仓库中：","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"idea+maven+git 开发环境安装","slug":"idea-maven-git-开发环境安装","permalink":"https://tianxiafeiyu.github.io/tags/idea-maven-git-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"}]},{"title":"idea使用心得","slug":"技术开发/java/idea使用心得","date":"2022-12-15T23:12:09.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/idea使用心得/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/idea%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/","excerpt":"","text":"说是心得，其实就是一些常用到，但是容易忘记，或者有一些坑的地方的记录 全局替换查找ctrl + shift + r: 在路径中替换，指的是在选定的目录下或者类包下，查找要被替换的字符，再在第二个输入框中输入要替换的字符，点击弹出框的右下角的replace或者replaceall即可。 大小写转换 有时候需要把一大串小写的字符串常转化为大写的，或者大写的切换为小写的。idea中选中内容后，快捷键 Ctrl+Shift+u即可实现大小写的快速切换，或者 Edit -&gt; Toggle Case. 快速生成测试类 Ctrl+Shift+t","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"idea使用心得","slug":"idea使用心得","permalink":"https://tianxiafeiyu.github.io/tags/idea%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/"}]},{"title":"《On Java 8》读书笔记","slug":"技术开发/java/《On Java 8》读书笔记","date":"2022-12-15T23:12:09.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/java/《On Java 8》读书笔记/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/%E3%80%8AOn%20Java%208%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","excerpt":"","text":"《On Java 8》读书笔记1. java 8 接口可以有默认方法和静态方法增加默认方法的极具说服力的理由是它允许在不破坏已使用接口的代码的情况下，在接口中增加新的方法。默认方法有时也被称为守卫方法或虚拟扩展方法。 默认方法的最佳实践是 java 8 的 stream api。 接口使用了默认方法，继承了这个接口的类可以不用实现接口中的默认方法。如： 12345// interfaces/AnInterface.javainterface AnInterface &#123; void firstMethod(); void secondMethod();&#125; 类实现接口 12345678910111213141516// interfaces/AnImplementation.javapublic class AnImplementation implements AnInterface &#123; public void firstMethod() &#123; System.out.println(&quot;firstMethod&quot;); &#125; public void secondMethod() &#123; System.out.println(&quot;secondMethod&quot;); &#125; public static void main(String[] args) &#123; AnInterface i = new AnImplementation(); i.firstMethod(); i.secondMethod(); &#125;&#125; 如果我们在 AnInterface 中增加一个新方法 newMethod()，而在 AnImplementation 中没有实现它，编译器就会报错。如果我们使用关键字 default 为 newMethod() 方法提供默认的实现，那么所有与接口有关的代码能正常工作，不受影响，而且这些代码还可以调用新的方法 newMethod()： 123456789// interfaces/InterfaceWithDefault.javainterface InterfaceWithDefault &#123; void firstMethod(); void secondMethod(); default void newMethod() &#123; System.out.println(&quot;newMethod&quot;); &#125;&#125; 只要修改接口，不用修改实现类。 12345678910111213141516171819// interfaces/Implementation2.javapublic class Implementation2 implements InterfaceWithDefault &#123; @Override public void firstMethod() &#123; System.out.println(&quot;firstMethod&quot;); &#125; @Override public void secondMethod() &#123; System.out.println(&quot;secondMethod&quot;) &#125; public static void main(String[] args) &#123; InterfaceWithDefault i = new Implementation2(); i.firstMethod(); i.secondMethod(); i.newMethod(); &#125;&#125; 2. java 8 多继承类可以实现多个接口，由于默认方法的加入，java class 有了多继承的特性，如果一个类实现的接口中有重复的方法签名相同（方法签名包括方法名和参数类型）的默认方法，类就需要覆写冲突的方法，或者重新实现方法。 3. 数组是保存一组对象最有效的方式4. 关于集合类（Collection ）的写法12List&lt;Apple&gt; apples = new LinkedList&lt;&gt;();LinkedList&lt;Apple&gt; apples = new LinkedList&lt;&gt;(); 请注意， ArrayList 已经被向上转型为了 List接口，这是大多数情况下的写法。但是如果需要用到具体的集合类的功能特性时，就不能将它们向上转型为更通用的接口。 5. 优化是一个很棘手的问题，最好的策略就是置之不顾，直到发现必须要去担心它了（尽管去理解这些问题总是一个很好的主意）6 . 集合类中迭代器（Iterators）的理解迭代器是一个对象，它在一个序列中移动并选择该序列中的每个对象，而客户端程序员不知道或不关心该序列的底层结构。另外，迭代器通常被称为轻量级对象（lightweight object）：创建它的代价小。ava 的 Iterator 只能单向移动。这个 Iterator 只能用来： 使用 iterator() 方法要求集合返回一个 Iterator。 Iterator 将准备好返回序列中的第一个元素。 使用 next() 方法获得序列中的下一个元素。 使用 hasNext() 方法检查序列中是否还有元素。 使用 remove() 方法将迭代器最近返回的那个元素删除。 有了 Iterator ，就不必再为集合中元素的数量操心了。这是由 hasNext() 和 next() 关心的事情。也可以不用考虑到集合的确切类型。迭代器能够将遍历序列的操作与该序列的底层结构分离，统一了对集合的访问方式。 用法示例： 123456789101112131415161718192021222324252627282930313233// collections/CrossCollectionIteration.javaimport typeinfo.pets.*;import java.util.*;public class CrossCollectionIteration &#123; public static void display(Iterator&lt;Pet&gt; it) &#123; while(it.hasNext()) &#123; Pet p = it.next(); System.out.print(p.id() + &quot;:&quot; + p + &quot; &quot;); &#125; System.out.println(); &#125; public static void main(String[] args) &#123; List&lt;Pet&gt; pets = Pets.list(8); LinkedList&lt;Pet&gt; petsLL = new LinkedList&lt;&gt;(pets); HashSet&lt;Pet&gt; petsHS = new HashSet&lt;&gt;(pets); TreeSet&lt;Pet&gt; petsTS = new TreeSet&lt;&gt;(pets); display(pets.iterator()); display(petsLL.iterator()); display(petsHS.iterator()); display(petsTS.iterator()); &#125;&#125;/* Output:0:Rat 1:Manx 2:Cymric 3:Mutt 4:Pug 5:Cymric 6:Pug7:Manx0:Rat 1:Manx 2:Cymric 3:Mutt 4:Pug 5:Cymric 6:Pug7:Manx0:Rat 1:Manx 2:Cymric 3:Mutt 4:Pug 5:Cymric 6:Pug7:Manx5:Cymric 2:Cymric 7:Manx 1:Manx 3:Mutt 6:Pug 4:Pug0:Rat*/ ListIterator 是一个更强大的 Iterator 子类型，它只能由各种 List 类生成。 Iterator 只能向前移动，而 ListIterator 可以双向移动。它还可以生成相对于迭代器在列表中指向的当前位置的后一个和前一个元素的索引，并且可以使用 set() 方法替换它访问过的最近一个元素。 7. Java8 中的堆栈声明为1Deque&lt;String&gt; stack = new ArrayDeque&lt;&gt;(); 之所以是 Deque 而不是Stack，这是因为 Java 1.0 中附带了一个 Stack 类，结果设计得很糟糕（为了向后兼容，后续保留了这个类）。Java 6 添加了 ArrayDeque。 8. 队列LinkedList 实现了 Queue 接口，并且提供了一些方法以支持队列行为，因此 LinkedList 可以用作 Queue 的一种实现。 通过将 LinkedList 向上转换为 Queue 。 1Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); 9. for-in 语法糖Java 5 引入了一个名为 Iterable 的接口，该接口包含一个能够生成 Iterator 的 iterator() 方法。for-in 使用此 Iterable 接口来遍历序列。因此，如果创建了任何实现了 Iterable 的类，都可以将它用于 for-in 语句中。 1234567891011121314151617181920212223242526272829303132// collections/IterableClass.java// Anything Iterable works with for-inimport java.util.*;public class IterableClass implements Iterable&lt;String&gt; &#123; protected String[] words = (&quot;And that is how &quot; + &quot;we know the Earth to be banana-shaped.&quot; ).split(&quot; &quot;); @Override public Iterator&lt;String&gt; iterator() &#123; return new Iterator&lt;String&gt;() &#123; private int index = 0; @Override public boolean hasNext() &#123; return index &lt; words.length; &#125; @Override public String next() &#123; return words[index++]; &#125; @Override public void remove() &#123; // Not implemented throw new UnsupportedOperationException(); &#125; &#125;; &#125; public static void main(String[] args) &#123; for(String s : new IterableClass()) System.out.print(s + &quot; &quot;); &#125;&#125;/* Output:And that is how we know the Earth to be banana-shaped.*/ 10. 不要在新代码中使用遗留类 Vector ，Hashtable 和 Stack 。11. Lambda 表达式123456789101112static Body bod = h -&gt; h + &quot; No Parens!&quot;; // [1] static Body bod2 = (h) -&gt; h + &quot; More details&quot;; // [2] static Description desc = () -&gt; &quot;Short info&quot;; // [3] static Multi mult = (h, n) -&gt; h + n; // [4] static Description moreLines = () -&gt; &#123; // [5] System.out.println(&quot;moreLines()&quot;); return &quot;from moreLines()&quot;; &#125;; Lambda 表达式基本语法： 参数。 接着 -&gt;，可视为“产出”。 -&gt; 之后的内容都是方法体。 当只用一个参数，可以不需要括号 ()。 然而，这是一个特例。 正常情况使用括号 () 包裹参数。 为了保持一致性，也可以使用括号 () 包裹单个参数，虽然这种情况并不常见。 如果没有参数，则必须使用括号 () 表示空参数列表。 对于多个参数，将参数列表放在括号 () 中。 到目前为止，所有 Lambda 表达式方法体都是单行。 该表达式的结果自动成为 Lambda 表达式的返回值，在此处使用 return 关键字是非法的。 这是 Lambda 表达式缩写用于描述功能的语法的另一种方式。 如果在 Lambda 表达式中确实需要多行，则必须将这些行放在花括号中。 在这种情况下，就 需要使用 return。Lambda 表达式通常比匿名内部类产生更易读的代码，尽可能使用它们。 Fibonacci 序列改为使用递归 Lambda 表达式来实现： 123456789101112131415161718192021interface IntCall &#123; int call(int arg);&#125;public class RecursiveFibonacci &#123; IntCall fib; RecursiveFibonacci() &#123; fib = n -&gt; n == 0 ? 0 : n == 1 ? 1 : fib.call(n - 1) + fib.call(n - 2); &#125; int fibonacci(int n) &#123; return fib.call(n); &#125; public static void main(String[] args) &#123; RecursiveFibonacci rf = new RecursiveFibonacci(); for(int i = 0; i &lt;= 10; i++) System.out.println(rf.fibonacci(i)); &#125;&#125; 12. 流操作流操作的类型有三种：创建流，修改流元素（中间操作， Intermediate Operations），消费流元素（终端操作， Terminal Operations），收集流元素（通常是到集合中）。 13. 异常处理finally 子句永远会执行，即使前面有 return 语句。由于 Java 有垃圾回收机制，所以 finally 语句主要是用来恢复内存之外的资源回到初始状态，需要清理的资源包括：已经打开的文件或网络连接，在屏幕上画的图形，甚至可以是外部世界的某个开关。 14. 永恒真理你永远不能保证你的代码是正确的，你只能证明它是错的。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"《On Java 8》读书笔记","slug":"《On-Java-8》读书笔记","permalink":"https://tianxiafeiyu.github.io/tags/%E3%80%8AOn-Java-8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"git 笔记","slug":"技术开发/grocery/git 笔记","date":"2022-12-15T23:11:56.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/git 笔记/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/git%20%E7%AC%94%E8%AE%B0/","excerpt":"","text":"删除本地文件后从远程仓库获取问题在本地删除文件后，git pull从远程仓库获取，但是一直提示 up-to-date，无法获取被删除的文件。 原因：当前本地库处于另一个分支中，需将本分支发Head重置至master。 将本分支发Head重置至master: 12$ git checkout master $ git reset --hard 强行pull并覆盖本地文件 123$ git fetch --all $ git reset --hard origin/master $ git pull","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"git 笔记","slug":"git-笔记","permalink":"https://tianxiafeiyu.github.io/tags/git-%E7%AC%94%E8%AE%B0/"}]},{"title":"mysql、redis开启远程访问","slug":"技术开发/database/mysql、redis开启远程访问","date":"2022-12-15T23:11:35.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/database/mysql、redis开启远程访问/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/mysql%E3%80%81redis%E5%BC%80%E5%90%AF%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/","excerpt":"","text":"要在本地使用云服务器中的mysql、redis服务，需要开启远程访问，阿里云还需要在控制台中开放3306、6379访问端口。 1、mysql开启远程访问默认情况下，mysql帐号不允许从远程登陆，只能在localhost登录。 在localhost登入mysql后，更改 “mysql” 数据库里的 “user” 表里的 “host” 项，将”localhost”改为”%” 12345678$ mysql -u root -p Enter password: …… mysql&gt; mysql&gt;update user set host = &#x27;%&#x27; where user = &#x27;root&#x27;; mysql&gt;select host, user from user; 2、redis开启远程访问防火墙开放6379端口： 123vim /etc/sysconfig/iptables添加字段：-A RH-Firewall-1-INPUT -m state NEW -m tcp -dport 8080 -j ACCEPT 修改redis配置文件vim &#x2F;etc&#x2F;redis.conf bind127.0.0.1 这一行注释掉 protected-mode yes 改为 protected-mode no 保存后重启：sysremctl restart redis 2020-6-1：由于鄙人暴露了mysql到公网上，不加约束、放荡不羁，如今数据库已遭到比特币勒索，血与泪的教训，以后要多加规范，防火防盗防小人","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"database","slug":"技术开发/database","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/"}],"tags":[{"name":"mysql、redis开启远程访问","slug":"mysql、redis开启远程访问","permalink":"https://tianxiafeiyu.github.io/tags/mysql%E3%80%81redis%E5%BC%80%E5%90%AF%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/"}]},{"title":"Elasticsearch Java Rest Client","slug":"技术开发/database/es/Elasticsearch Java Rest Client","date":"2022-12-15T23:11:35.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/database/es/Elasticsearch Java Rest Client/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/es/Elasticsearch%20Java%20Rest%20Client/","excerpt":"","text":"基于 Elasticsearch 6.x 概述Rest client 分成两部分： Java Low Level REST Client官方低级别 es 客户端，使用 http 协议与 Elastiicsearch 集群通信，与所有 es 版本兼容。 Java High level REST Client官方高级别 es 客户端，基于低级别的客户端，它会暴露 API 特定的方法。 使用方法： 12345&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;6.3.2&lt;/version&gt;&lt;/dependency&gt; 初始化： 1234RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(&quot;localhost&quot;, 9200, &quot;http&quot;), new HttpHost(&quot;localhost&quot;, 9201, &quot;http&quot;))); 文档(Document) API单文档 API index API Get API Delete API Update API 多文档 API Bulk API Multi-Get API Index APIIndexRequest四种方式构建 IndexRequest： json 12345678910IndexRequest indexRequest = new IndexRequest( &quot;posts&quot;, // 索引 Index &quot;doc&quot;, // Type &quot;1&quot;); // 文档 Document Id String jsonString = &quot;&#123;&quot; + &quot;\\&quot;user\\&quot;:\\&quot;kimchy\\&quot;,&quot; + &quot;\\&quot;postDate\\&quot;:\\&quot;2013-01-30\\&quot;,&quot; + &quot;\\&quot;message\\&quot;:\\&quot;trying out Elasticsearch\\&quot;&quot; + &quot;&#125;&quot;;indexRequest.source(jsonString, XContentType.JSON); // 文档源格式为 json string Map 123456Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;();jsonMap.put(&quot;user&quot;, &quot;kimchy&quot;);jsonMap.put(&quot;postDate&quot;, new Date());jsonMap.put(&quot;message&quot;, &quot;trying out Elasticsearch&quot;);IndexRequest indexRequest = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .source(jsonMap); // 会自动将 Map 转换为 JSON 格式 XContentBuilder : Document Source 提供的帮助类，专门用来产生 json 格式的数据 12345678910XContentBuilder builder = XContentFactory.jsonBuilder();builder.startObject();&#123; builder.field(&quot;user&quot;, &quot;kimchy&quot;); builder.timeField(&quot;postDate&quot;, new Date()); builder.field(&quot;message&quot;, &quot;trying out Elasticsearch&quot;);&#125;builder.endObject();IndexRequest indexRequest = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .source(builder); Object 键值对 1234IndexRequest indexRequest = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .source(&quot;user&quot;, &quot;kimchy&quot;, &quot;postDate&quot;, new Date(), &quot;message&quot;, &quot;trying out Elasticsearch&quot;); 同步索引1IndexResponse indexResponse = client.index(indexRequest); 异步索引异步执行函数需要添加 listener 作为回调函数, 而对于 index 而言，这个 listener 的类型就是 ActionListener 12345678910111213ActionListener&lt;IndexResponse&gt; listener = new ActionListener&lt;IndexResponse&gt;() &#123; @Override public void onResponse(IndexResponse indexResponse) &#123; //执行成功，调用 onResponse 函数 &#125; @Override public void onFailure(Exception e) &#123; //执行失败，调用 onFailure 函数 &#125;&#125;;IndexResponse indexResponse = client.indexAsync(indexRequest, listener); IndexResponse不管是同步还是异步，如果调用成功，都会返回 IndexRespose 对象。 123456789101112131415161718tring index = indexResponse.getIndex();String type = indexResponse.getType();String id = indexResponse.getId();long version = indexResponse.getVersion();if (indexResponse.getResult() == DocWriteResponse.Result.CREATED) &#123; // 文档第一次创建 &#125; else if (indexResponse.getResult() == DocWriteResponse.Result.UPDATED) &#123; // 文档之前已存在，当前是重写&#125;ReplicationResponse.ShardInfo shardInfo = indexResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; // 成功的分片数量少于总分片数量 &#125;if (shardInfo.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); // 处理潜在的失败信息 &#125;&#125; GET APIGetRequest每个 GET 请求都必须需传入下面 3 个参数： Index Type Document id 1234GetRequest getRequest = new GetRequest( &quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;); 可选参数： 不获取源数据，默认是获取的 1getRequest.fetchSourceContext(FetchSourceContext.DO_NOT_FETCH_SOURCE); 配置返回数据中包含指定字段 12345String[] includes = new String[]&#123;&quot;message&quot;, &quot;*Date&quot;&#125;;String[] excludes = Strings.EMPTY_ARRAY;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);getRequest.fetchSourceContext(fetchSourceContext); 配置返回数据中排除指定字段 12345String[] includes = Strings.EMPTY_ARRAY;String[] excludes = new String[]&#123;&quot;message&quot;&#125;;FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes);getRequest.fetchSourceContext(fetchSourceContext); 实时 默认为 true 1getRequest.realtime(false); 版本 1getRequest.version(2); 版本类型 1getRequest.versionType(VersionType.EXTERNAL); 执行同步执行： 1GetResponse getResponse = client.get(getRequest); 异步执行： 12345678910111213ActionListener&lt;IndexResponse&gt; listener = new ActionListener&lt;IndexResponse&gt;() &#123; @Override public void onResponse(IndexResponse indexResponse) &#123; //执行成功，调用 onResponse 函数 &#125; @Override public void onFailure(Exception e) &#123; //执行失败，调用 onFailure 函数 &#125;&#125;;GetResponse getResponse = client.indexAsync(indexRequest, listener); GetResponse返回的 GetResponse 对象包含要请求的文档数据（包含元数据和字段） 1234567891011String index = getResponse.getIndex();String type = getResponse.getType();String id = getResponse.getId();if (getResponse.isExists()) &#123; long version = getResponse.getVersion(); String sourceAsString = getResponse.getSourceAsString(); // string 形式 Map&lt;String, Object&gt; sourceAsMap = getResponse.getSourceAsMap(); // map byte[] sourceAsBytes = getResponse.getSourceAsBytes(); // 字节形式 &#125; else &#123; // 没有发现请求的文档 &#125; Exists API如果文档存在 Exists API 返回 true, 否则返回 fasle。 GetRequest用法和 Get API 差不多，两个对象的可选参数是相同的。由于 exists() 方法只返回 true 或者 false， 应该将获取 _source 以及任何存储字段的值关闭，尽量使请求轻量级。 123456GetRequest getRequest = new GetRequest( &quot;posts&quot;, // Index &quot;doc&quot;, // Type &quot;1&quot;); // Document idgetRequest.fetchSourceContext(new FetchSourceContext(false)); // 禁用 _source 字段getRequest.storedFields(&quot;_none_&quot;); // 禁止存储任何字段 执行同步执行： 1boolean exists = client.exists(getRequest); 异步执行： 12345678910111213ActionListener&lt;Boolean&gt; listener = new ActionListener&lt;Boolean&gt;() &#123; @Override public void onResponse(Boolean exists) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;boolean exists = client.existsAsync(getRequest, listener); Delete APIDeleteRequestDeleteRequest 必须传入下面参数： Index Type Document id 1234DeleteRequest deleteRequest = new DeleteRequest( &quot;posts&quot;, // index &quot;doc&quot;, // doc &quot;1&quot;); // document id 可选参数： 超时时间 12deleteRequest.timeout(TimeValue.timeValueMinutes(2)); deleteRequest.timeout(&quot;2m&quot;); 刷新策略 12deleteRequest.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); deleteRequest.setRefreshPolicy(&quot;wait_for&quot;); 版本 1deleteRequest.version(2); 版本类型 1deleteRequest.versionType(VersionType.EXTERNAL); 执行同步执行： 1DeleteResponse deleteResponse = client.delete(deleteRequest); 异步执行 12345678910111213ActionListener&lt;DeleteResponse&gt; listener = new ActionListener&lt;DeleteResponse&gt;() &#123; @Override public void onResponse(DeleteResponse deleteResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;DeleteResponse deleteResponse = client.deleteAsync(deleteResponse, listener); DeleteResponseDeleteResponse 可以检索执行操作的信息 12345678910111213String index = deleteResponse.getIndex();String type = deleteResponse.getType();String id = deleteResponse.getId();long version = deleteResponse.getVersion();ReplicationResponse.ShardInfo shardInfo = deleteResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; // 成功分片数目小于总分片&#125;if (shardInfo.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); // 处理潜在失败 &#125;&#125; Update APIUpdateRequestUpdateRequest 必须传入下面参数： Index Type Document id 1234UpdateRequest updateRequest = new DeleteRequest( &quot;posts&quot;, // index &quot;doc&quot;, // doc &quot;1&quot;); // document id 和 index api 类似，UpdateRequest 也支持四种文档格式： json 123456UpdateRequest updateRequest = new UpdateRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;);String jsonString = &quot;&#123;&quot; + &quot;\\&quot;updated\\&quot;:\\&quot;2017-01-01\\&quot;,&quot; + &quot;\\&quot;reason\\&quot;:\\&quot;daily update\\&quot;&quot; + &quot;&#125;&quot;;request.doc(jsonString, XContentType.JSON); map 12345Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;();jsonMap.put(&quot;updated&quot;, new Date());jsonMap.put(&quot;reason&quot;, &quot;daily update&quot;);UpdateRequest updateRequest = new UpdateRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .doc(jsonMap); XContentBuilder 123456789XContentBuilder builder = XContentFactory.jsonBuilder();builder.startObject();&#123; builder.timeField(&quot;updated&quot;, new Date()); builder.field(&quot;reason&quot;, &quot;daily update&quot;);&#125;builder.endObject();UpdateRequest updateRequest = new UpdateRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .doc(builder); object 键值对 123UpdateRequest updateRequest = new UpdateRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .doc(&quot;updated&quot;, new Date(), &quot;reason&quot;, &quot;daily update&quot;); 可选参数： 超时时间 12updateRequest.timeout(TimeValue.timeValueSeconds(1)); updateRequest.timeout(&quot;1s&quot;); 刷新策略 12updateRequest.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); updateRequest.setRefreshPolicy(&quot;wait_for&quot;); 冲突后重试次数 1updateRequest.retryOnConflict(3); 获取数据源，默认是开启的 1updateRequest.fetchSource(true); 包括特定字段 123String[] includes = new String[]&#123;&quot;updated&quot;, &quot;r*&quot;&#125;;String[] excludes = Strings.EMPTY_ARRAY;updateRequest.fetchSource(new FetchSourceContext(true, includes, excludes)); 排除特定字段 123String[] includes = Strings.EMPTY_ARRAY;String[] excludes = new String[]&#123;&quot;updated&quot;&#125;;updateRequest.fetchSource(new FetchSourceContext(true, includes, excludes)); 指定版本 1updateRequest.version(2); 禁用 noop detection 1updateRequest.scriptedUpsert(true); 设置如果更新的文档不存在，就必须要创建一个 1updateRequest.docAsUpsert(true); 执行同步执行： 1UpdateResponse updateResponse = client.update(updateRequest); 异步执行： 12345678910111213ActionListener&lt;UpdateResponse&gt; listener = new ActionListener&lt;UpdateResponse&gt;() &#123; @Override public void onResponse(UpdateResponse updateResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;UpdateResponse updateResponse = client.updateAsync(request, listener); UpdateResponse12345678910111213String index = updateResponse.getIndex();String type = updateResponse.getType();String id = updateResponse.getId();long version = updateResponse.getVersion();if (updateResponse.getResult() == DocWriteResponse.Result.CREATED) &#123; // 文档已创建&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.UPDATED) &#123; // 文档已更新&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.DELETED) &#123; // 文档已删除&#125; else if (updateResponse.getResult() == DocWriteResponse.Result.NOOP) &#123; // 文档不受更新的影响&#125; 如果在 UpdateRequest 中设置了获取源数据，响应中则包含了更新后的源文档信息： 12345678GetResult result = updateResponse.getGetResult(); if (result.isExists()) &#123; String sourceAsString = result.sourceAsString(); // 将获取的文档以 string 格式输出 Map&lt;String, Object&gt; sourceAsMap = result.sourceAsMap(); // 以 Map 格式输出 byte[] sourceAsBytes = result.source(); // 字节形式&#125; else &#123; // 默认情况下，不会返回文档源数据&#125; 检测是否分片失败： 123456789ReplicationResponse.ShardInfo shardInfo = updateResponse.getShardInfo();if (shardInfo.getTotal() != shardInfo.getSuccessful()) &#123; // 成功的分片数量小于总分片数量&#125;if (shardInfo.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) &#123; String reason = failure.reason(); // 得到分片失败的原因 &#125;&#125; Bulk API 批量处理BulkRequest 批量请求使用 BulkRequest 可以在一次请求中执行多个索引，更新和删除的操作: 1234567BulkRequest request = new BulkRequest(); request.add(new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;) .source(XContentType.JSON,&quot;field&quot;, &quot;foo&quot;)); // 将第一个 IndexRequest 添加到批量请求中request.add(new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;2&quot;) .source(XContentType.JSON,&quot;field&quot;, &quot;bar&quot;)); // 第二个request.add(new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;3&quot;) .source(XContentType.JSON,&quot;field&quot;, &quot;baz&quot;)); // 第三个 在同一个 BulkRequest 也可以添加不同的操作类型: 123456BulkRequest bulkRequest = new BulkRequest();bulkRequest.add(new DeleteRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;3&quot;)); bulkRequest.add(new UpdateRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;2&quot;) .doc(XContentType.JSON,&quot;other&quot;, &quot;test&quot;));jbulkRequest.add(new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;4&quot;) .source(XContentType.JSON,&quot;field&quot;, &quot;baz&quot;)); 可选参数： 超时时间 12bulkRequest.timeout(TimeValue.timeValueMinutes(2)); bulkRequest.timeout(&quot;2m&quot;); 刷新策略 12bulkRequest.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); bulkRequest.setRefreshPolicy(&quot;wait_for&quot;); 设置在批量操作前必须有几个分片处于激活状态 1234bulkRequest.waitForActiveShards(2); bulkRequest.waitForActiveShards(ActiveShardCount.ALL); // 全部分片都处于激活状态bulkRequest.waitForActiveShards(ActiveShardCount.DEFAULT); // 默认bulkRequest.waitForActiveShards(ActiveShardCount.ONE); // 一个 执行同步请求： 1BulkResponse bulkResponse = client.bulk(request); 异步请求： 12345678910111213ActionListener&lt;BulkResponse&gt; listener = new ActionListener&lt;BulkResponse&gt;() &#123; @Override public void onResponse(BulkResponse bulkResponse) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;BulkResponse bulkResponse = client.bulkAsync(request, listener); BulkResponseBulkResponse 中包含执行操作后的信息，并允许对每个操作结果迭代 1234567891011121314for (BulkItemResponse bulkItemResponse : bulkResponse) &#123; // 遍历所有的操作结果 DocWriteResponse itemResponse = bulkItemResponse.getResponse(); // 获取操作结果的响应，可以是 IndexResponse, UpdateResponse or DeleteResponse, 它们都可以惭怍是 DocWriteResponse 实例 if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.INDEX || bulkItemResponse.getOpType() == DocWriteRequest.OpType.CREATE) &#123; IndexResponse indexResponse = (IndexResponse) itemResponse; // index 操作后的响应结果 &#125; else if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.UPDATE) &#123; UpdateResponse updateResponse = (UpdateResponse) itemResponse; // update 操作后的响应结果 &#125; else if (bulkItemResponse.getOpType() == DocWriteRequest.OpType.DELETE) &#123; DeleteResponse deleteResponse = (DeleteResponse) itemResponse; // delete 操作后的响应结果 &#125;&#125; 此外，批量响应还有一个非常便捷的方法来检测是否有一个或多个操作失败 12345678if (bulkResponse.hasFailures()) &#123; // 表示至少有一个操作失败 // 遍历所有的操作结果，检查是否是失败的操作，并获取对应的失败信息 for (BulkItemResponse bulkItemResponse : bulkResponse) &#123; if (bulkItemResponse.isFailed()) &#123; // 检测给定的操作是否失败 BulkItemResponse.Failure failure = bulkItemResponse.getFailure(); // 获取失败信息 &#125; &#125;&#125; BulkProcessorBulkProcessor 是为了简化 Bulk API 的操作提供的一个工具类，要执行操作，就需要下面组件: RestHighLevelClient 用来执行 BulkRequest 并获取 BulkResponse BulkProcessor.Listener 对 BulkRequest 执行前后以及失败时监听 BulkProcessor.builder 方法用来构建一个新的 BulkProcessor： 1234567891011121314151617181920ulkProcessor.Listener listener = new BulkProcessor.Listener() &#123; @Override public void beforeBulk(long executionId, BulkRequest request) &#123; // 在每个 BulkRequest 执行前调用 &#125; @Override public void afterBulk(long executionId, BulkRequest request, BulkResponse response) &#123; // 在每个 BulkRequest 执行后调用 &#125; @Override public void afterBulk(long executionId, BulkRequest request, Throwable failure) &#123; // 失败时调用 &#125;&#125;;BulkProcessor bulkProcessor = BulkProcessor.builder(client::bulkAsync, listener).build(); // 构建 BulkProcessor, RestHighLevelClient.bulkAsync() 用来执行 BulkRequest BulkProcessor.Builder 提供了多个方法来配置 BulkProcessor 如何来处理请求的执行: 1234567BulkProcessor.Builder builder = BulkProcessor.builder(client::bulkAsync, listener);builder.setBulkActions(500); // 指定多少操作时，就会刷新一次builder.setBulkSize(new ByteSizeValue(1L, ByteSizeUnit.MB)); builder.setConcurrentRequests(0); // 指定多大容量，就会刷新一次builder.setFlushInterval(TimeValue.timeValueSeconds(10L)); // 允许并发执行的数量 builder.setBackoffPolicy(BackoffPolicy .constantBackoff(TimeValue.timeValueSeconds(1L), 3)); BulkProcessor 创建后，各种请求就可以添加进去： 12345678910111213IndexRequest one = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;1&quot;). source(XContentType.JSON, &quot;title&quot;, &quot;In which order are my Elasticsearch queries executed?&quot;);IndexRequest two = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;2&quot;) .source(XContentType.JSON, &quot;title&quot;, &quot;Current status and upcoming changes in Elasticsearch&quot;);IndexRequest three = new IndexRequest(&quot;posts&quot;, &quot;doc&quot;, &quot;3&quot;) .source(XContentType.JSON, &quot;title&quot;, &quot;The Future of Federated Search in Elasticsearch&quot;);bulkProcessor.add(one);bulkProcessor.add(two);bulkProcessor.add(three); BulkProcessor 执行时，会对每个 bulk request调用 BulkProcessor.Listener ， listener 提供了下面方法来访问 BulkRequest 和 BulkResponse: 123456789101112131415161718192021222324BulkProcessor.Listener listener = new BulkProcessor.Listener() &#123; @Override public void beforeBulk(long executionId, BulkRequest request) &#123; int numberOfActions = request.numberOfActions(); // 在执行前获取操作的数量 logger.debug(&quot;Executing bulk [&#123;&#125;] with &#123;&#125; requests&quot;, executionId, numberOfActions); &#125; @Override public void afterBulk(long executionId, BulkRequest request, BulkResponse response) &#123; if (response.hasFailures()) &#123; // 执行后查看响应中是否包含失败的操作 logger.warn(&quot;Bulk [&#123;&#125;] executed with failures&quot;, executionId); &#125; else &#123; logger.debug(&quot;Bulk [&#123;&#125;] completed in &#123;&#125; milliseconds&quot;, executionId, response.getTook().getMillis()); &#125; &#125; @Override public void afterBulk(long executionId, BulkRequest request, Throwable failure) &#123; logger.error(&quot;Failed to execute bulk&quot;, failure); // 请求失败时打印信息 &#125;&#125;; 请求添加到 BulkProcessor ， 它的实例可以使用下面两种方法关闭请求： awaitClose() 在请求返回后或等待一定时间关闭 1boolean terminated = bulkProcessor.awaitClose(30L, TimeUnit.SECONDS); close() 立刻关闭 1bulkProcessor.close(); 两个方法都会在关闭前对处理器中的请求进行刷新，并避免新的请求添加进去。 Multi-Get APImultiGet API 可以在单个 http 交互中并行的执行多个 get 请求。 MultiGetRequestMultiGetRequest 实例化时参数为空，实例化后可以通过添加 MultiGetRequest.Item 来配置获取的信息 123456MultiGetRequest request = new MultiGetRequest();request.add(new MultiGetRequest.Item( &quot;index&quot;, // 索引 &quot;type&quot;, // 类型 &quot;example_id&quot;)); // 文档 idjrequest.add(new MultiGetRequest.Item(&quot;index&quot;, &quot;type&quot;, &quot;another_id&quot;)); // 添加另外一个条目 可选参数： 与前面 Get API 可选参数相同 执行同步执行： 1MultiGetResponse response = client.multiGet(request); 异步执行： 12345678910111213ActionListener&lt;MultiGetResponse&gt; listener = new ActionListener&lt;MultiGetResponse&gt;() &#123; @Override public void onResponse(MultiGetResponse response) &#123; &#125; @Override public void onFailure(Exception e) &#123; &#125;&#125;;client.multiGetAsync(request, listener); MultiGetResponseMultiGetResponse 中getResponse 方法包含的 MultiGetItemResponse 顺序与请求时的相 MultiGetItemResponse ，如果执行成功，就会返回 GetResponse 对象，失败则返回 MultiGetResponse.Failure 12345678910111213141516MultiGetItemResponse firstItem = response.getResponses()[0];assertNull(firstItem.getFailure()); // 执行成功，则返回 null GetResponse firstGet = firstItem.getResponse(); // 返回 GetResponse 对象String index = firstItem.getIndex();String type = firstItem.getType();String id = firstItem.getId();if (firstGet.isExists()) &#123; long version = firstGet.getVersion(); String sourceAsString = firstGet.getSourceAsString(); // string 格式 Map&lt;String, Object&gt; sourceAsMap = firstGet.getSourceAsMap(); // Map byte[] sourceAsBytes = firstGet.getSourceAsBytes(); // bytes &#125; else &#123; // 没有发现文档 // 尽管响应中会返回 404 状态码，也会返回一个有效的 GetResponse // 这是可以使用 isExists 方法来判断&#125; 如果子请求中对应的 index 不存在，返回的响应中的getFailure 方法中会包含 exception: 1234567assertNull(missingIndexItem.getResponse()); // 获取的响应为空 Exception e = missingIndexItem.getFailure().getFailure(); // 获取 exceptionElasticsearchException ee = (ElasticsearchException) e; // TODO status is broken! fix in a followup// assertEquals(RestStatus.NOT_FOUND, ee.status()); assertThat(e.getMessage(), containsString(&quot;reason=no such index&quot;)); 查询（Search）APIJava High Level REST Client 支持下面的 Search API： Search API Search Scroll API Clear Scroll API Multi-Search API Ranking Evaluation API Search APISearchRequestsearchRequest 用来完成和搜索文档，聚等相关的操作同时也提供了各种方式来完成对查询结果的高亮操作。 最基本的查询操作如下: 1234SearchRequest searchRequest = new SearchRequest(); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchAllQuery()); // 添加 match_all 查询searchRequest.source(searchSourceBuilder); // 将 SearchSourceBuilder 添加到 SeachRequest 中 可选参数: 1234SearchRequest searchRequest = new SearchRequest(&quot;posts&quot;); // 设置搜索的 indexsearchRequest.types(&quot;doc&quot;); // 设置搜索的 typesearchRequest.routing(&quot;routing&quot;); // 设置 routing 参数searchRequest.preference(&quot;_local&quot;); // 配置搜索时偏爱使用本地分片，默认是使用随机分片 SearchSourceBuilder对搜索行为的配置可以使用 SearchSourceBuilder 来完成: 12345678SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); // 默认配置sourceBuilder.query(QueryBuilders.termQuery(&quot;user&quot;, &quot;kimchy&quot;)); // 设置搜索，可以是任何类型的 QueryBuildersourceBuilder.from(0); // 起始 indexsourceBuilder.size(5); // 大小 sizesourceBuilder.timeout(new TimeValue(60, TimeUnit.SECONDS)); // 设置搜索的超时时间SearchRequest searchRequest = new SearchRequest();searchRequest.source(sourceBuilder); SearchSourceBuilder 可选配置有： 1. 构建查询条件查询请求是通过使用 QueryBuilder 对象来完成的，并且支持 Query DSL（领域特定语言，是指专注于某个应用程序领域的计算机语言）。 使用构造函数来创建 QueryBuilder： 123456MatchQueryBuilder matchQueryBuilder = new MatchQueryBuilder(&quot;user&quot;, &quot;kimchy&quot;); // 配置查询选项matchQueryBuilder.fuzziness(Fuzziness.AUTO); // 模糊查询matchQueryBuilder.prefixLength(3); // 前缀查询的长度matchQueryBuilder.maxExpansions(10); // max expansion 选项，用来控制模糊查询 也可以使用QueryBuilders 工具类来创建 QueryBuilder 对象。这个类提供了函数式编程风格的各种方法用来快速创建 QueryBuilder 对象。 1234QueryBuilder matchQueryBuilder = QueryBuilders.matchQuery(&quot;user&quot;, &quot;kimchy&quot;) .fuzziness(Fuzziness.AUTO) .prefixLength(3) .maxExpansions(10); 最后要添加到 SearchSourceBuilder 中: 1searchSourceBuilder.query(matchQueryBuilder); 2. 指定排序SearchSourceBuilder 允许添加一个或多个SortBuilder 实例。这里包含 4 种特殊的实现, (Field-, Score-, GeoDistance- 和 ScriptSortBuilder) 12sourceBuilder.sort(new ScoreSortBuilder().order(SortOrder.DESC)); // 根据分数 _score 降序排列 (默认行为)sourceBuilder.sort(new FieldSortBuilder(&quot;_uid&quot;).order(SortOrder.ASC)); // 根据 id 降序排列 3. 过滤数据源默认情况下，查询请求会返回文档的内容 _source ,当然我们也可以配置它。例如，禁止对 _source 的获取 1sourceBuilder.fetchSource(false); 也可以使用通配符模式以更细的粒度包含或排除特定的字段: 123String[] includeFields = new String[] &#123;&quot;title&quot;, &quot;user&quot;, &quot;innerObject.*&quot;&#125;;String[] excludeFields = new String[] &#123;&quot;_type&quot;&#125;;sourceBuilder.fetchSource(includeFields, excludeFields); 4. 高亮请求可以通过在 SearchSourceBuilder 上设置 HighlightBuilder 完成对结果的高亮，而且可以配置不同的字段具有不同的高亮行为。 123456789SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();HighlightBuilder highlightBuilder = new HighlightBuilder(); HighlightBuilder.Field highlightTitle = new HighlightBuilder.Field(&quot;title&quot;); // title 字段高亮highlightTitle.highlighterType(&quot;unified&quot;); // 配置高亮类型highlightBuilder.field(highlightTitle); // 添加到 builderHighlightBuilder.Field highlightUser = new HighlightBuilder.Field(&quot;user&quot;);highlightBuilder.field(highlightUser);searchSourceBuilder.highlighter(highlightBuilder); 5. 聚合请求要实现聚合请求分两步 创建合适的 AggregationBuilder 作为参数配置在 SearchSourceBuilder 123456SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();TermsAggregationBuilder aggregation = AggregationBuilders.terms(&quot;by_company&quot;) .field(&quot;company.keyword&quot;);aggregation.subAggregation(AggregationBuilders.avg(&quot;average_age&quot;) .field(&quot;age&quot;));searchSourceBuilder.aggregation(aggregation); 6. 建议请求 Requesting SuggestionsSuggestionBuilder 实现类是由 SuggestBuilders 工厂类来创建的。 123456SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();SuggestionBuilder termSuggestionBuilder = SuggestBuilders.termSuggestion(&quot;user&quot;).text(&quot;kmichy&quot;); SuggestBuilder suggestBuilder = new SuggestBuilder();suggestBuilder.addSuggestion(&quot;suggest_user&quot;, termSuggestionBuilder); searchSourceBuilder.suggest(suggestBuilder); 7. 对请求和聚合分析分析 API 可用来对一个特定的查询操作中的请求和聚合进行分析，此时要将SearchSourceBuilder 的 profile标志位设置为 true 12SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();searchSourceBuilder.profile(true); 执行同步执行 同步执行是阻塞式的，只有结果返回后才能继续执行 1SearchResponse searchResponse = client.search(searchRequest); 异步执行 异步执行使用的是 listener 对结果进行处理 12345678910111213ActionListener&lt;SearchResponse&gt; listener = new ActionListener&lt;SearchResponse&gt;() &#123; @Override public void onResponse(SearchResponse searchResponse) &#123; // 查询成功 &#125; @Override public void onFailure(Exception e) &#123; // 查询失败 &#125;&#125;;SearchResponse searchResponse = client.search(searchRequest); SearchResponse查询执行完成后，会返回 SearchResponse 对象，并在对象中包含查询执行的细节和符合条件的文档集合。 SerchResponse 包含的信息如下： 请求本身的信息，如 HTTP 状态码，执行时间，或者请求是否超时 1234RestStatus status = searchResponse.status(); // HTTP 状态码TimeValue took = searchResponse.getTook(); // 查询占用的时间Boolean terminatedEarly = searchResponse.isTerminatedEarly(); // 是否由于 SearchSourceBuilder 中设置 terminateAfter 而过早终止boolean timedOut = searchResponse.isTimedOut(); // 是否超时 查询影响的分片数量的统计信息，成功和失败的分片 123456int totalShards = searchResponse.getTotalShards();int successfulShards = searchResponse.getSuccessfulShards();int failedShards = searchResponse.getFailedShards();for (ShardSearchFailure failure : searchResponse.getShardFailures()) &#123; // failures should be handled here&#125; SearchHits 1234567891011121314151617181920SearchHits hits = searchResponse.getHits();long totalHits = hits.getTotalHits();float maxScore = hits.getMaxScore();SearchHit[] searchHits = hits.getHits();for (SearchHit hit : searchHits) &#123; // do something with the SearchHit String index = hit.getIndex(); String type = hit.getType(); String id = hit.getId(); float score = hit.getScore(); // 获取文档源数据 String sourceAsString = hit.getSourceAsString(); Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); String documentTitle = (String) sourceAsMap.get(&quot;title&quot;); List&lt;Object&gt; users = (List&lt;Object&gt;) sourceAsMap.get(&quot;user&quot;); Map&lt;String, Object&gt; innerObject = (Map&lt;String, Object&gt;) sourceAsMap.get(&quot;innerObject&quot;);&#125;","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"database","slug":"技术开发/database","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/"},{"name":"es","slug":"技术开发/database/es","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/es/"}],"tags":[{"name":"Elasticsearch Java Rest Client","slug":"Elasticsearch-Java-Rest-Client","permalink":"https://tianxiafeiyu.github.io/tags/Elasticsearch-Java-Rest-Client/"}]},{"title":"Elasticsearch版本特性","slug":"技术开发/database/es/Elasticsearch版本特性","date":"2022-12-15T23:11:35.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/database/es/Elasticsearch版本特性/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/es/Elasticsearch%E7%89%88%E6%9C%AC%E7%89%B9%E6%80%A7/","excerpt":"","text":"elasticsearch 各版本特性5.0支持Lucene 6.x Instant Aggregations，在Shard层面提供了Aggregation缓存 新增 Sliced Scroll类型，现在Scroll接口可以并发来进行数据遍历了。每个Scroll请求，可以分成多个Slice请求，可以理解为切片，各Slice独立并行，利用Scroll重建或者遍历要快很多倍。 新增了Profile API 同时支持search和aggregation的profile 有一个新的 Search After 机制，其实和 scroll 类似，也是游标的机制，它的原理是对文档按照多个字段进行排序，然后利用上一个结果的最后一个文档作为起始值，拿 size 个文档，一般我们建议使用 _uid 这个字段，它的值是唯一的 id 新增Shrink API 新增了Rollover API 新增Reindex 提供了第一个Java原生的REST客户端SDK 基于HTTP协议的客户端对Elasticsearch的依赖解耦，没有jar包冲突，提供了集群节点自动发现、日志处理、节点请求失败自动进行请求轮询，充分发挥Elasticsearch的高可用能力 新增Wait for refresh，提供了文档级别的Refresh 新增Ingest Node 新增Painless Scripting 新增Task Manager 新增Depreated logging 新增Cluster allocation explain API 新增 half_float 类型 新增 :Matrix Stats Aggregation 为索引写操作添加顺序号 引入新的字段类型 Text&#x2F;Keyword 来替换 String 关于 Index Settings 现在，配置验证更加严格和保证原子性，如果其中一项失败，那个整个都会更新请求都会失败，不会一半成功一半失败。下面主要说两点： 1.设置可以重设会默认值，只需要设置为 null即可 2.获取设置接口新增参数include_defaults,可以直接返回所有设置和默认值 集群管理方面，新增Deleted Index Tombstones Cluster state 的修改现在会和所有节点进行 ack 确认。 Shard 的一个副本如果失败了， Primary 标记失败的时候会和 Master 节点确认完毕再返回。 使用 UUID 来作为索引的物理的路径名，有很多好处，避免命名的冲突。 _timestamp 和 _ttl 已经移除，需要在 Ingest 或者程序端处理。 ES 可直接用 HDFS 来进行备份还原（ Snapshot&#x2F;Restore ）了 Delete-by-query 和 Update-by-query 重新回到 core ，以前是插件，现在可以直接使用了，也是构建在 Reindex 机制之上。(es1.x版本是直接支持，在es2.x中提取为插件，5.x继续回归直接支持) HTTP 请求默认支持压缩，当然 http 调用端需要在 header 信息里面传对应的支持信息。 创建索引不会再让集群变红了，不会因为这个卡死集群了。 默认使用 BM25 评分算法，效果更佳，之前是 TF&#x2F;IDF。 快照 Snapshots 添加 UUID 解决冲突 限制索引请求大小，避免大量并发请求压垮 ES 限制单个请求的 shards 数量，默认 1000 个 移除 site plugins ，就是说 head 、 bigdesk 都不能直接装 es 里面了，不过可以部署独立站点（反正都是静态文件）或开发 kibana 插件 允许现有 parent 类型新增 child 类型 这个功能对于使用parent-child特性的人应该非常有用。 支持分号（；）来分割 url 参数，与符号（ &amp; ）一样 6.0无宕机升级 使之能够从 5 的最后一个版本滚动升级到 6 的最后一个版本，不需要集群的完整重启。无宕机在线升级，无缝滚动升级 跨多个 Elasticsearch 群集搜索 和以前一样，Elasticsearch 6.0 能够读取在 5.x 中创建的 Indices ，但不能读取在 2.x 中创建的 Indices 。不同的是，现在不必重新索引所有的旧 Indices ，你可以选择将其保留在 5.x 群集中，并使用跨群集搜索同时在 6.x 和 5.x 群集上进行搜索 迁移助手 Kibana X-Pack 插件提供了一个简单的用户界面，可帮助重新索引旧 Indices ，以及将 Kibana、Security 和 Watcher 索引升级到 6.0 。 群集检查助手在现有群集上运行一系列检查，以帮助在升级之前更正任何问题。 你还应该查阅弃用日志，以确保您没有使用 6.0 版中已删除的功能 使用序列号更快地重启和还原 6.0 版本中最大的一个新特性就是序列 ID，它允许基于操作的分片恢复。 以前，如果由于网络问题或节点重启而从集群断开连接的节点，则节点上的每个分区都必须通过将分段文件与主分片进行比较并复制任何不同的分段来重新同步。 这可能是一个漫长而昂贵的过程，甚至使节点的滚动重新启动非常缓慢。 使用序列 ID，每个分片将只能重放该分片中缺少的操作，使恢复过程更加高效 使用排序索引更快查询 通过索引排序，只要收集到足够的命中，搜索就可以终止。它对通常用作过滤器的低基数字段（例如 age, gender, is_published）进行排序时可以更高效的搜索，因为所有潜在的匹配文档都被分组在一起。 稀疏区域改进 以前，每个列中的每个字段都预留了一个存储空间。如果只有少数文档出现很多字段，则可能会导致磁盘空间的巨大浪费。现在，你付出你使用的东西。密集字段将使用与以前相同的空间量，但稀疏字段将显着减小。这不仅可以减少磁盘空间使用量，还可以减少合并时间并提高查询吞吐量，因为可以更好地利用文件系统缓存 7.x集群连接变化：TransportClient被废弃 以至于，es7的java代码，只能使用restclient。然后，个人综合了一下，对于java编程，建议采用 High-level-rest-client 的方式操作ES集群 ES数据存储结构变化：去除了Type es6时，官方就提到了es7会删除type，并且es6时已经规定每一个index只能有一个type。在es7中使用默认的_doc作为type，官方说在8.x版本会彻底移除type。 api请求方式也发送变化，如获得某索引的某ID的文档：GET index&#x2F;_doc&#x2F;id其中index和id为具体的值 High-level REST client 改变 已删除接受Header参数的API方法；Cluster Health API默认为集群级别； ES程序包默认打包jdk：以至于7.x版本的程序包大小突然边300MB+ 对比6.x发现，包大了200MB+， 正是JDK的大小 默认配置变化：默认节点名称为主机名，默认分片数改为1，不再是5。 查询相关性速度优化：Weak-AND算法 啥是weak-and算法？ 核心原理：取TOP N结果集，估算命中记录数。 简单来说，一般我们在计算文本相关性的时候，会通过倒排索引的方式进行查询，通过倒排索引已经要比全量遍历节约大量时间，但是有时候仍然很慢。 原因是很多时候我们其实只是想要top n个结果，一些结果明显较差的也进行了复杂的相关性计算， 而weak-and算法通过计算每个词的贡献上限来估计文档的相关性上限，从而建立一个阈值对倒排中的结果进行减枝，从而得到提速的效果。 间隔查询(Intervals queries)： 某些搜索用例（例如，法律和专利搜索）引入了查找单词或短语彼此相距一定距离的记录的需要。 Elasticsearch 7.0中的间隔查询引入了一种构建此类查询的全新方式，与之前的方法（跨度查询span queries）相比，使用和定义更加简单。 与跨度查询相比，间隔查询对边缘情况的适应性更强。 引入新的集群协调子系统 移除 minimum_master_nodes 参数，让 Elasticsearch 自己选择可以形成仲裁的节点。 典型的主节点选举现在只需要很短的时间就可以完成。 集群的伸缩变得更安全、更容易，并且可能造成丢失数据的系统配置选项更少了。 节点更清楚地记录它们的状态，有助于诊断为什么它们不能加入集群或为什么无法选举出主节点。 时间戳纳秒级支持，提升数据精度 加粗样式 不再内存溢出 新的 Circuit Breaker 在JVM 堆栈层面监测内存使用，Elasticsearch 比之前更加健壮。 设置indices.breaker.fielddata.limit的默认值已从JVM堆大小的60％降低到40％。 ES7与旧版本的区别1. 关于 type（类型）使用 kibana 开发工具查询时候，指定类型查询会出现下面的提示： Deprecation: [types removal] Specifying types in document get requests is deprecated, use the &#x2F;{index}&#x2F;_doc&#x2F;{id} endpoint instead. es6时，官方就提到了es7会删除type，并且es6时已经规定每一个index只能有一个type。在es7中使用默认的_doc作为type，官方说在8.x版本会彻底移除type。 api请求方式也发送变化，如获得某索引的某ID的文档： 1GET index/_doc/id 其中index和id为具体的值 2. 弃用 “string”, 使用 “text” 域指定映射的时候使用 String 的话将会报错： 1No handler for type [string] declared on field xxx 使用 text 替代 string","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"database","slug":"技术开发/database","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/"},{"name":"es","slug":"技术开发/database/es","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/es/"}],"tags":[{"name":"Elasticsearch版本特性","slug":"Elasticsearch版本特性","permalink":"https://tianxiafeiyu.github.io/tags/Elasticsearch%E7%89%88%E6%9C%AC%E7%89%B9%E6%80%A7/"}]},{"title":"Apdex 应用性能指数","slug":"技术开发/grocery/Apdex 应用性能指数","date":"2022-12-15T23:10:53.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/Apdex 应用性能指数/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/Apdex%20%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD%E6%8C%87%E6%95%B0/","excerpt":"","text":"Apdex 应用性能指数是站在用户角度衡量用户对应用满意度的数值。 假设用户对于服务的响应容忍度权值为 T 满意（1分） 容忍（0.5分） 失望（0分） 0~T T~4T 4T~ Apdex指数 &#x3D; (满意样本 x 1 + 容忍样本 x 0.5)&#x2F; 样本总数","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"Apdex 应用性能指数","slug":"Apdex-应用性能指数","permalink":"https://tianxiafeiyu.github.io/tags/Apdex-%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD%E6%8C%87%E6%95%B0/"}]},{"title":"GraphQL 入门","slug":"技术开发/grocery/GraphQL 入门","date":"2022-12-15T23:10:53.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/GraphQL 入门/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/GraphQL%20%E5%85%A5%E9%97%A8/","excerpt":"","text":"GraphQL 入门GraphQL 是一个用于 API 的查询语言，是一个使用基于类型系统来执行查询的服务端运行时（类型系统由你的数据定义）。GraphQL 并没有和任何特定数据库或者存储引擎绑定，而是依靠你现有的代码和数据支撑。 一个 GraphQL 服务是通过定义类型和类型上的字段来创建的，然后给每个类型上的每个字段提供解析函数。例如，一个 GraphQL 服务告诉我们当前登录用户是 me，这个用户的名称可能像这样： 12345678type Query &#123; me: User&#125;type User &#123; id: ID name: String&#125; 一并的还有每个类型上字段的解析函数： 1234567function Query_me(request) &#123; return request.auth.user;&#125;function User_name(user) &#123; return user.getName();&#125; 一旦一个 GraphQL 服务运行起来（通常在 web 服务的一个 URL 上），它就能接收 GraphQL 查询，并验证和执行。接收到的查询首先会被检查确保它只引用了已定义的类型和字段，然后运行指定的解析函数来生成结果。 例如： 12345&#123; me &#123; name &#125;&#125; 返回结果： 12345&#123; &quot;me&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot; &#125;&#125; GraphQL 的查询和变更字段（Fields）简单而言，GraphQL 是关于请求对象上的特定字段。我们以一个非常简单的查询以及其结果为例： 12345&#123; hero &#123; name &#125;&#125; 1234567&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot; &#125; &#125;&#125; 查询和其结果拥有几乎一样的结构。这是 GraphQL 最重要的特性，因为这样一来，你就总是能得到你想要的数据，而服务器也准确地知道客户端请求的字段。 name 字段返回 String 类型，在这个示例中是《星球大战》主角的名字是：&quot;R2-D2&quot;。 前一例子中，我们请求了我们主角的名字，返回了一个字符串类型（String），但是字段也能指代对象类型（Object）。这个时候，你可以对这个对象的字段进行次级选择（sub-selection）。GraphQL 查询能够遍历相关对象及其字段，使得客户端可以一次请求查询大量相关数据，而不像传统 REST 架构中那样需要多次往返查询。 123456789&#123; hero &#123; name # 查询可以有备注！ friends &#123; name &#125; &#125;&#125; 123456789101112131415161718&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;friends&quot;: [ &#123; &quot;name&quot;: &quot;Luke Skywalker&quot; &#125;, &#123; &quot;name&quot;: &quot;Han Solo&quot; &#125;, &#123; &quot;name&quot;: &quot;Leia Organa&quot; &#125; ] &#125; &#125;&#125; 这个例子中，friends 返回了一个数组的项目，GraphQL 查询会同等看待单个项目或者一个列表的项目，然而我们可以通过 schema 所指示的内容来预测将会得到哪一种。 参数（Arguments）即使我们能做的仅仅是遍历对象及其字段，GraphQL 就已经是一个非常有用的数据查询语言了。但是当你加入给字段传递参数的能力时，事情会变得更加有趣。 123456&#123; human(id: &quot;1000&quot;) &#123; name height &#125;&#125; 12345678&#123; &quot;data&quot;: &#123; &quot;human&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot;, &quot;height&quot;: 1.72 &#125; &#125;&#125; 参数可以是多种不同的类型。上面例子中，我们使用了一个枚举类型，其代表了一个有限选项集合（本例中为长度单位，即是 METER 或者 FOOT）。GraphQL 自带一套默认类型，但是 GraphQL 服务器可以声明一套自己的定制类型，只要能序列化成你的传输格式即可。 更多的 GraphQL 类型系统请点击这里 别名（Aliases）如果你眼睛够锐利，你可能已经发现，即便结果中的字段与查询中的字段能够匹配，但是因为他们并不包含参数，你就没法通过不同参数来查询相同字段。这便是为何你需要别名 —— 这可以让你重命名结果中的字段为任意你想到的名字。 12345678&#123; empireHero: hero(episode: EMPIRE) &#123; name &#125; jediHero: hero(episode: JEDI) &#123; name &#125;&#125; 12345678910&#123; &quot;data&quot;: &#123; &quot;empireHero&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot; &#125;, &quot;jediHero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot; &#125; &#125;&#125; 上例中，两个 hero 字段将会存在冲突，但是因为我们可以将其另取一个别名，我们也就可以在一次请求中得到两个结果。 片段（Fragments）假设我们的 app 有比较复杂的页面，将正反派主角及其友军分为两拨。你立马就能想到对应的查询会变得复杂，因为我们需要将一些字段重复至少一次 —— 两方各一次以作比较。 这就是为何 GraphQL 包含了称作片段的可复用单元。片段使你能够组织一组字段，然后在需要它们的的地方引入。下面例子展示了如何使用片段解决上述场景： 12345678910111213141516&#123; leftComparison: hero(episode: EMPIRE) &#123; ...comparisonFields &#125; rightComparison: hero(episode: JEDI) &#123; ...comparisonFields &#125;&#125;fragment comparisonFields on Character &#123; name appearsIn friends &#123; name &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445&#123; &quot;data&quot;: &#123; &quot;leftComparison&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot;, &quot;appearsIn&quot;: [ &quot;NEWHOPE&quot;, &quot;EMPIRE&quot;, &quot;JEDI&quot; ], &quot;friends&quot;: [ &#123; &quot;name&quot;: &quot;Han Solo&quot; &#125;, &#123; &quot;name&quot;: &quot;Leia Organa&quot; &#125;, &#123; &quot;name&quot;: &quot;C-3PO&quot; &#125;, &#123; &quot;name&quot;: &quot;R2-D2&quot; &#125; ] &#125;, &quot;rightComparison&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;appearsIn&quot;: [ &quot;NEWHOPE&quot;, &quot;EMPIRE&quot;, &quot;JEDI&quot; ], &quot;friends&quot;: [ &#123; &quot;name&quot;: &quot;Luke Skywalker&quot; &#125;, &#123; &quot;name&quot;: &quot;Han Solo&quot; &#125;, &#123; &quot;name&quot;: &quot;Leia Organa&quot; &#125; ] &#125; &#125;&#125; 你可以看到上面的查询如何漂亮地重复了字段。片段的概念经常用于将复杂的应用数据需求分割成小块，特别是你要将大量不同片段的 UI 组件组合成一个初始数据获取的时候。 在片段内使用变量 片段可以访问查询或变更中声明的变量。详见 变量。 1234567891011121314151617181920query HeroComparison($first: Int = 3) &#123; leftComparison: hero(episode: EMPIRE) &#123; ...comparisonFields &#125; rightComparison: hero(episode: JEDI) &#123; ...comparisonFields &#125;&#125;fragment comparisonFields on Character &#123; name friendsConnection(first: $first) &#123; totalCount edges &#123; node &#123; name &#125; &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&#123; &quot;data&quot;: &#123; &quot;leftComparison&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot;, &quot;friendsConnection&quot;: &#123; &quot;totalCount&quot;: 4, &quot;edges&quot;: [ &#123; &quot;node&quot;: &#123; &quot;name&quot;: &quot;Han Solo&quot; &#125; &#125;, &#123; &quot;node&quot;: &#123; &quot;name&quot;: &quot;Leia Organa&quot; &#125; &#125;, &#123; &quot;node&quot;: &#123; &quot;name&quot;: &quot;C-3PO&quot; &#125; &#125; ] &#125; &#125;, &quot;rightComparison&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;friendsConnection&quot;: &#123; &quot;totalCount&quot;: 3, &quot;edges&quot;: [ &#123; &quot;node&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot; &#125; &#125;, &#123; &quot;node&quot;: &#123; &quot;name&quot;: &quot;Han Solo&quot; &#125; &#125;, &#123; &quot;node&quot;: &#123; &quot;name&quot;: &quot;Leia Organa&quot; &#125; &#125; ] &#125; &#125; &#125;&#125; 变量（Variables）目前为止，我们将参数写在了查询字符串内。但是在很多应用中，字段的参数可能是动态的：例如，可能是一个”下拉菜单”让你选择感兴趣的《星球大战》续集，或者是一个搜索区，或者是一组过滤器。 将这些动态参数直接传进查询字符串并不是好主意，因为这样我们的客户端就得动态地在运行时操作这些查询字符串了，再把它序列化成 GraphQL 专用的格式。其实，GraphQL 拥有一级方法将动态值提取到查询之外，然后作为分离的字典传进去。这些动态值即称为变量。 使用变量之前，我们得做三件事： 使用 $variableName 替代查询中的静态值。 声明 $variableName 为查询接受的变量之一。 将 variableName: value 通过传输专用（通常是 JSON）的分离的变量字典中。 全部做完之后就像这个样子： 123456789# &#123; &quot;graphiql&quot;: true, &quot;variables&quot;: &#123; &quot;episode&quot;: JEDI &#125; &#125;query HeroNameAndFriends($episode: Episode) &#123; hero(episode: $episode) &#123; name friends &#123; name &#125; &#125;&#125; 这样一来，我们的客户端代码就只需要传入不同的变量，而不用构建一个全新的查询了。这事实上也是一个良好实践，意味着查询的参数将是动态的 —— 我们决不能使用用户提供的值来字符串插值以构建查询。 变量定义（Variable definitions）变量定义看上去像是上述查询中的 ($episode: Episode)。其工作方式跟类型语言中函数的参数定义一样。它以列出所有变量，变量前缀必须为 $，后跟其类型，本例中为 Episode。 所有声明的变量都必须是标量、枚举型或者输入对象类型。所以如果想要传递一个复杂对象到一个字段上，你必须知道服务器上其匹配的类型。可以从Schema页面了解更多关于输入对象类型的信息。 变量定义可以是可选的或者必要的。上例中，Episode 后并没有 !，因此其是可选的。但是如果你传递变量的字段要求非空参数，那变量一定是必要的。 如果想要进一步了解变量定义的句法，可以学习 GraphQL 的 schema 语言。schema 语言在 Schema 中有细述。 默认变量（Default variables）可以通过在查询中的类型定义后面附带默认值的方式，将默认值赋给变量。 12345678query HeroNameAndFriends($episode: Episode = &quot;JEDI&quot;) &#123; hero(episode: $episode) &#123; name friends &#123; name &#125; &#125;&#125; 当所有变量都有默认值的时候，你可以不传变量直接调用查询。如果任何变量作为变量字典的部分传递了，它将覆盖其默认值。 指令（Directives）我们上面讨论的变量使得我们可以避免手动字符串插值构建动态查询。传递变量给参数解决了一大堆这样的问题，但是我们可能也需要一个方式使用变量动态地改变我们查询的结构。譬如我们假设有个 UI 组件，其有概括视图和详情视图，后者比前者拥有更多的字段。 我们来构建一个这种组件的查询： 1234567891011121314query Hero($episode: Episode, $withFriends: Boolean!) &#123; hero(episode: $episode) &#123; name friends @include(if: $withFriends) &#123; name &#125; &#125;&#125;variables:&#123; &quot;episode&quot;: &quot;JEDI&quot;, &quot;withFriends&quot;: false&#125; 1234567&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot; &#125; &#125;&#125; 尝试修改上面的变量，传递 true 给 withFriends，看看结果的变化。 我们用了 GraphQL 中一种称作指令的新特性。一个指令可以附着在字段或者片段包含的字段上，然后以任何服务端期待的方式来改变查询的执行。GraphQL 的核心规范包含两个指令，其必须被任何规范兼容的 GraphQL 服务器实现所支持： @include(if: Boolean) 仅在参数为 true 时，包含此字段。 @skip(if: Boolean) 如果参数为 true，跳过此字段。 指令在你不得不通过字符串操作来增减查询的字段时解救你。服务端实现也可以定义新的指令来添加新的特性。 变更（Mutations）GraphQL 的大部分讨论集中在数据获取，但是任何完整的数据平台也都需要一个改变服务端数据的方法。 REST 中，任何请求都可能最后导致一些服务端副作用，但是约定上建议不要使用 GET 请求来修改数据。GraphQL 也是类似 —— 技术上而言，任何查询都可以被实现为导致数据写入。然而，建一个约定来规范任何导致写入的操作都应该显式通过变更（mutation）来发送。 就如同查询一样，如果任何变更字段返回一个对象类型，你也能请求其嵌套字段。获取一个对象变更后的新状态也是十分有用的。我们来看看一个变更例子： 123456789101112131415mutation CreateReviewForEpisode($ep: Episode!, $review: ReviewInput!) &#123; createReview(episode: $ep, review: $review) &#123; stars commentary &#125;&#125;variables:&#123; &quot;ep&quot;: &quot;JEDI&quot;, &quot;review&quot;: &#123; &quot;stars&quot;: 5, &quot;commentary&quot;: &quot;This is a great movie!&quot; &#125;&#125; 12345678&#123; &quot;data&quot;: &#123; &quot;createReview&quot;: &#123; &quot;stars&quot;: 5, &quot;commentary&quot;: &quot;This is a great movie!&quot; &#125; &#125;&#125; 注意 createReview 字段如何返回了新建的 review 的 stars 和 commentary 字段。这在变更已有数据时特别有用，例如，当一个字段自增的时候，我们可以在一个请求中变更并查询这个字段的新值。 你也可能注意到，这个例子中，我们传递的 review 变量并非标量。它是一个输入对象类型，一种特殊的对象类型，可以作为参数传递。你可以在 Schema 页面上了解到更多关于输入类型的信息。 变更中的多个字段（Multiple fields in mutations）一个变更也能包含多个字段，一如查询。查询和变更之间名称之外的一个重要区别是： 查询字段时，是并行执行，而变更字段时，是线性执行，一个接着一个。 这意味着如果我们一个请求中发送了两个 incrementCredits 变更，第一个保证在第二个之前执行，以确保我们不会出现竞态。 内联片段（Inline Fragments）跟许多类型系统一样，GraphQL schema 也具备定义接口和联合类型的能力。在 schema 指南中可了解更多。 如果你查询的字段返回的是接口或者联合类型，那么你可能需要使用内联片段来取出下层具体类型的数据： 12345678910111213141516query HeroForEpisode($ep: Episode!) &#123; hero(episode: $ep) &#123; name ... on Droid &#123; primaryFunction &#125; ... on Human &#123; height &#125; &#125;&#125;variables:&#123; &quot;ep&quot;: &quot;JEDI&quot;&#125; 12345678&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;primaryFunction&quot;: &quot;Astromech&quot; &#125; &#125;&#125; 这个查询中，hero 字段返回 Character 类型，取决于 episode 参数，其可能是 Human 或者 Droid 类型。在直接选择的情况下，你只能请求 Character 上存在的字段，譬如 name。 如果要请求具体类型上的字段，你需要使用一个类型条件内联片段。因为第一个片段标注为 ... on Droid，primaryFunction 仅在 hero 返回的 Character 为 Droid 类型时才会执行。同理适用于 Human 类型的 height 字段。 具名片段也可以用于同样的情况，因为具名片段总是附带了一个类型。 元字段（Meta fields）某些情况下，你并不知道你将从 GraphQL 服务获得什么类型，这时候你就需要一些方法在客户端来决定如何处理这些数据。GraphQL 允许你在查询的任何位置请求 __typename，一个元字段，以获得那个位置的对象类型名称。 1234567891011121314&#123; search(text: &quot;an&quot;) &#123; __typename ... on Human &#123; name &#125; ... on Droid &#123; name &#125; ... on Starship &#123; name &#125; &#125;&#125; 123456789101112131415161718&#123; &quot;data&quot;: &#123; &quot;search&quot;: [ &#123; &quot;__typename&quot;: &quot;Human&quot;, &quot;name&quot;: &quot;Han Solo&quot; &#125;, &#123; &quot;__typename&quot;: &quot;Human&quot;, &quot;name&quot;: &quot;Leia Organa&quot; &#125;, &#123; &quot;__typename&quot;: &quot;Starship&quot;, &quot;name&quot;: &quot;TIE Advanced x1&quot; &#125; ] &#125;&#125; 上面的查询中，search 返回了一个联合类型，其可能是三种选项之一。没有 __typename 字段的情况下，几乎不可能在客户端分辨开这三个不同的类型。 GraphQL 服务提供了不少元字段，剩下的部分用于描述 内省 系统。 Schema 和类型在本节中，，你将学到关于 GraphQL 类型系统中所有你需要了解的知识，以及类型系统如何描述可以查询的数据。因为 GraphQL 可以运行在任何后端框架或者编程语言之上，我们将摒除实现上的细节而仅仅专注于其概念。 类型系统（Type System）如果你之前见到过 GraphQL 查询，你就知道 GraphQL 查询语言基本上就是关于选择对象上的字段。因此，例如在下列查询中： 123456&#123; hero &#123; name appearsIn &#125;&#125; 123456789101112&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;appearsIn&quot;: [ &quot;NEWHOPE&quot;, &quot;EMPIRE&quot;, &quot;JEDI&quot; ] &#125; &#125;&#125; 我们以一个特殊的对象 “root” 开始 选择其上的 hero 字段 对于 hero 返回的对象，我们选择 name 和 appearsIn 字段 因为一个 GraphQL 查询的结构和结果非常相似，因此即便不知道服务器的情况，你也能预测查询会返回什么结果。但是一个关于我们所需要的数据的确切描述依然很有意义，我们能选择什么字段？服务器会返回哪种对象？这些对象下有哪些字段可用？这便是引入 schema 的原因。 每一个 GraphQL 服务都会定义一套类型，用以描述你可能从那个服务查询到的数据。每当查询到来，服务器就会根据 schema 验证并执行查询。 类型语言（Type Language）GraphQL 服务可以用任何语言编写，因为我们并不依赖于任何特定语言的句法句式（譬如 JavaScript）来与 GraphQL schema 沟通，我们定义了自己的简单语言，称之为 “GraphQL schema language” —— 它和 GraphQL 的查询语言很相似，让我们能够和 GraphQL schema 之间可以无语言差异地沟通。 对象类型和字段（Object Types and Fields）一个 GraphQL schema 中的最基本的组件是对象类型，它就表示你可以从服务上获取到什么类型的对象，以及这个对象有什么字段。使用 GraphQL schema language，我们可以这样表示它： 1234type Character &#123; name: String! appearsIn: [Episode!]!&#125; 虽然这语言可读性相当好，但我们还是一起看看其用语，以便我们可以有些共通的词汇： Character 是一个 GraphQL 对象类型，表示其是一个拥有一些字段的类型。你的 schema 中的大多数类型都会是对象类型。 name 和 appearsIn 是 Character 类型上的字段。这意味着在一个操作 Character 类型的 GraphQL 查询中的任何部分，都只能出现 name 和 appearsIn 字段。 String 是内置的标量类型之一 —— 标量类型是解析到单个标量对象的类型，无法在查询中对它进行次级选择。后面我们将细述标量类型。 String! 表示这个字段是非空的，GraphQL 服务保证当你查询这个字段后总会给你返回一个值。在类型语言里面，我们用一个感叹号来表示这个特性。 [Episode!]! 表示一个 Episode 数组。因为它也是非空的，所以当你查询 appearsIn 字段的时候，你也总能得到一个数组（零个或者多个元素）。且由于 Episode! 也是非空的，你总是可以预期到数组中的每个项目都是一个 Episode 对象。 现在你知道一个 GraphQL 对象类型看上去是怎样，也知道如何阅读基础的 GraphQL 类型语言了。 参数（Arguments）GraphQL 对象类型上的每一个字段都可能有零个或者多个参数，例如下面的 length 字段 12345type Starship &#123; id: ID! name: String! length(unit: LengthUnit = METER): Float&#125; 所有参数都是具名的，不像 JavaScript 或者 Python 之类的语言，函数接受一个有序参数列表，而在 GraphQL 中，所有参数必须具名传递。本例中，length 字段定义了一个参数，unit。 参数可能是必选或者可选的，当一个参数是可选的，我们可以定义一个默认值 —— 如果 unit 参数没有传递，那么它将会被默认设置为 METER。 查询和变更类型（The Query and Mutation Types）你的 schema 中大部分的类型都是普通对象类型，但是一个 schema 内有两个特殊类型： 1234schema &#123; query: Query mutation: Mutation&#125; 每一个 GraphQL 服务都有一个 query 类型，可能有一个 mutation 类型。这两个类型和常规对象类型无差，但是它们之所以特殊，是因为它们定义了每一个 GraphQL 查询的入口。因此如果你看到一个像这样的查询： 12345678query &#123; hero &#123; name &#125; droid(id: &quot;2000&quot;) &#123; name &#125;&#125; 12345678910&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot; &#125;, &quot;droid&quot;: &#123; &quot;name&quot;: &quot;C-3PO&quot; &#125; &#125;&#125; 那表示这个 GraphQL 服务需要一个 Query 类型，且其上有 hero 和 droid 字段： 1234type Query &#123; hero(episode: Episode): Character droid(id: ID!): Droid&#125; 变更也是类似的工作方式 —— 你在 Mutation 类型上定义一些字段，然后这些字段将作为 mutation 根字段使用，接着你就能在你的查询中调用。 有必要记住的是，除了作为 schema 的入口，Query 和 Mutation 类型与其它 GraphQL 对象类型别无二致，它们的字段也是一样的工作方式。 标量类型（Scalar Types）一个对象类型有自己的名字和字段，而某些时候，这些字段必然会解析到具体数据。这就是标量类型的来源：它们表示对应 GraphQL 查询的叶子节点。 下列查询中，name 和 appearsIn 字段将解析到标量类型： 123456&#123; hero &#123; name appearsIn &#125;&#125; 123456789101112&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;appearsIn&quot;: [ &quot;NEWHOPE&quot;, &quot;EMPIRE&quot;, &quot;JEDI&quot; ] &#125; &#125;&#125; 我们知道这些字段没有任何次级字段 —— 因为让它们是查询的叶子节点。 GraphQL 自带一组默认标量类型： Int：有符号 32 位整数。 Float：有符号双精度浮点值。 String：UTF‐8 字符序列。 Boolean：true 或者 false。 ID：ID 标量类型表示一个唯一标识符，通常用以重新获取对象或者作为缓存中的键。ID 类型使用和 String 一样的方式序列化；然而将其定义为 ID 意味着并不需要人类可读型。 大部分的 GraphQL 服务实现中，都有自定义标量类型的方式。例如，我们可以定义一个 Date 类型： 1scalar Date 然后就取决于我们的实现中如何定义将其序列化、反序列化和验证。例如，你可以指定 Date 类型应该总是被序列化成整型时间戳，而客户端应该知道去要求任何 date 字段都是这个格式。 枚举类型（Enumeration Types）也称作枚举（enum），枚举类型是一种特殊的标量，它限制在一个特殊的可选值集合内。这让你能够： 验证这个类型的任何参数是可选值的的某一个 与类型系统沟通，一个字段总是一个有限值集合的其中一个值。 下面是一个用 GraphQL schema 语言表示的 enum 定义： 12345enum Episode &#123; NEWHOPE EMPIRE JEDI&#125; 这表示无论我们在 schema 的哪处使用了 Episode，都可以肯定它返回的是 NEWHOPE、EMPIRE 和 JEDI 之一。 注意，各种语言实现的 GraphQL 服务会有其独特的枚举处理方式。对于将枚举作为一等公民的语言，它的实现就可以利用这个特性；而对于像 JavaScript 这样没有枚举支持的语言，这些枚举值可能就被内部映射成整数值。当然，这些细节都不会泄漏到客户端，客户端会根据字符串名称来操作枚举值。 列表和非空（Lists and Non-Null）对象类型、标量以及枚举是 GraphQL 中你唯一可以定义的类型种类。但是当你在 schema 的其他部分使用这些类型时，或者在你的查询变量声明处使用时，你可以给它们应用额外的类型修饰符来影响这些值的验证。我们先来看一个例子： 1234type Character &#123; name: String! appearsIn: [Episode]!&#125; 此处我们使用了一个 String 类型，并通过在类型名后面添加一个感叹号!将其标注为非空。这表示我们的服务器对于这个字段，总是会返回一个非空值，如果它结果得到了一个空值，那么事实上将会触发一个 GraphQL 执行错误，以让客户端知道发生了错误。 非空类型修饰符也可以用于定义字段上的参数，如果这个参数上传递了一个空值（不管通过 GraphQL 字符串还是变量），那么会导致服务器返回一个验证错误。 12345678910query DroidById($id: ID!) &#123; droid(id: $id) &#123; name &#125;&#125;variables:&#123; &quot;id&quot;: null&#125; 12345678910111213&#123; &quot;errors&quot;: [ &#123; &quot;message&quot;: &quot;Variable \\&quot;$id\\&quot; of required type \\&quot;ID!\\&quot; was not provided.&quot;, &quot;locations&quot;: [ &#123; &quot;line&quot;: 1, &quot;column&quot;: 17 &#125; ] &#125; ]&#125; 列表的运作方式也类似：我们也可以使用一个类型修饰符来标记一个类型为 List，表示这个字段会返回这个类型的数组。在 GraphQL schema 语言中，我们通过将类型包在方括号（[ 和 ]）中的方式来标记列表。列表对于参数也是一样的运作方式，验证的步骤会要求对应值为数组。 非空和列表修饰符可以组合使用。例如你可以要求一个非空字符串的数组： 1myField: [String!] 这表示数组本身可以为空，但是其不能有任何空值成员。用 JSON 举例如下： 1234myField: null // 有效myField: [] // 有效myField: [&#x27;a&#x27;, &#x27;b&#x27;] // 有效myField: [&#x27;a&#x27;, null, &#x27;b&#x27;] // 错误 然后，我们来定义一个不可为空的字符串数组： 1myField: [String]! 这表示数组本身不能为空，但是其可以包含空值成员： 1234myField: null // 错误myField: [] // 有效myField: [&#x27;a&#x27;, &#x27;b&#x27;] // 有效myField: [&#x27;a&#x27;, null, &#x27;b&#x27;] // 有效 你可以根据需求嵌套任意层非空和列表修饰符。 接口（Interfaces）跟许多类型系统一样，GraphQL 支持接口。一个接口是一个抽象类型，它包含某些字段，而对象类型必须包含这些字段，才能算实现了这个接口。 例如，你可以用一个 Character 接口用以表示《星球大战》三部曲中的任何角色： 123456interface Character &#123; id: ID! name: String! friends: [Character] appearsIn: [Episode]!&#125; 这意味着任何实现 Character 的类型都要具有这些字段，并有对应参数和返回类型。 例如，这里有一些可能实现了 Character 的类型： 12345678910111213141516type Human implements Character &#123; id: ID! name: String! friends: [Character] appearsIn: [Episode]! starships: [Starship] totalCredits: Int&#125;type Droid implements Character &#123; id: ID! name: String! friends: [Character] appearsIn: [Episode]! primaryFunction: String&#125; 可见这两个类型都具备 Character 接口的所有字段，但也引入了其他的字段 totalCredits、starships 和 primaryFunction，这都属于特定的类型的角色。 当你要返回一个对象或者一组对象，特别是一组不同的类型时，接口就显得特别有用。 注意下面例子的查询会产生错误： 1234567891011query HeroForEpisode($ep: Episode!) &#123; hero(episode: $ep) &#123; name primaryFunction &#125;&#125;variables:&#123; &quot;ep&quot;: &quot;JEDI&quot;&#125; 12345678910111213&#123; &quot;errors&quot;: [ &#123; &quot;message&quot;: &quot;Cannot query field \\&quot;primaryFunction\\&quot; on type \\&quot;Character\\&quot;. Did you mean to use an inline fragment on \\&quot;Droid\\&quot;?&quot;, &quot;locations&quot;: [ &#123; &quot;line&quot;: 4, &quot;column&quot;: 5 &#125; ] &#125; ]&#125; hero 字段返回 Character 类型，取决于 episode 参数，它可能是 Human 或者 Droid 类型。上面的查询中，你只能查询 Character 接口中存在的字段，而其中并不包含 primaryFunction。 如果要查询一个只存在于特定对象类型上的字段，你需要使用内联片段： 12345678910111213query HeroForEpisode($ep: Episode!) &#123; hero(episode: $ep) &#123; name ... on Droid &#123; primaryFunction &#125; &#125;&#125;variables:&#123; &quot;ep&quot;: &quot;JEDI&quot;&#125; 12345678&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;primaryFunction&quot;: &quot;Astromech&quot; &#125; &#125;&#125; 你可以在查询指南的 内联片段 章节了解更多相关信息。 联合类型（Union Types）联合类型和接口十分相似，但是它并不指定类型之间的任何共同字段。 1union SearchResult = Human | Droid | Starship 在我们的schema中，任何返回一个 SearchResult 类型的地方，都可能得到一个 Human、Droid 或者 Starship。注意，联合类型的成员需要是具体对象类型；你不能使用接口或者其他联合类型来创造一个联合类型。 这时候，如果你需要查询一个返回 SearchResult 联合类型的字段，那么你得使用条件片段才能查询任意字段。 1234567891011121314151617&#123; search(text: &quot;an&quot;) &#123; __typename ... on Human &#123; name height &#125; ... on Droid &#123; name primaryFunction &#125; ... on Starship &#123; name length &#125; &#125;&#125; 123456789101112131415161718192021&#123; &quot;data&quot;: &#123; &quot;search&quot;: [ &#123; &quot;__typename&quot;: &quot;Human&quot;, &quot;name&quot;: &quot;Han Solo&quot;, &quot;height&quot;: 1.8 &#125;, &#123; &quot;__typename&quot;: &quot;Human&quot;, &quot;name&quot;: &quot;Leia Organa&quot;, &quot;height&quot;: 1.5 &#125;, &#123; &quot;__typename&quot;: &quot;Starship&quot;, &quot;name&quot;: &quot;TIE Advanced x1&quot;, &quot;length&quot;: 9.2 &#125; ] &#125;&#125; _typename 字段解析为 String，它允许你在客户端区分不同的数据类型。 此外，在这种情况下，由于 Human 和 Droid 共享一个公共接口（Character），你可以在一个地方查询它们的公共字段，而不必在多个类型中重复相同的字段： 123456789101112131415161718&#123; search(text: &quot;an&quot;) &#123; __typename ... on Character &#123; name &#125; ... on Human &#123; height &#125; ... on Droid &#123; primaryFunction &#125; ... on Starship &#123; name length &#125; &#125;&#125; 注意 name 仍然需要指定在 Starship 上，否则它不会出现在结果中，因为 Starship 并不是一个 Character！ 输入类型（Input Types）目前为止，我们只讨论过将例如枚举和字符串等标量值作为参数传递给字段，但是你也能很容易地传递复杂对象。这在变更（mutation）中特别有用，因为有时候你需要传递一整个对象作为新建对象。在 GraphQL schema language 中，输入对象看上去和常规对象一模一样，除了关键字是 input 而不是 type： 1234input ReviewInput &#123; stars: Int! commentary: String&#125; 你可以像这样在变更（mutation）中使用输入对象类型： 123456789101112131415mutation CreateReviewForEpisode($ep: Episode!, $review: ReviewInput!) &#123; createReview(episode: $ep, review: $review) &#123; stars commentary &#125;&#125;variables:&#123; &quot;ep&quot;: &quot;JEDI&quot;, &quot;review&quot;: &#123; &quot;stars&quot;: 5, &quot;commentary&quot;: &quot;This is a great movie!&quot; &#125;&#125; 12345678&#123; &quot;data&quot;: &#123; &quot;createReview&quot;: &#123; &quot;stars&quot;: 5, &quot;commentary&quot;: &quot;This is a great movie!&quot; &#125; &#125;&#125; 输入对象类型上的字段本身也可以指代输入对象类型，但是你不能在你的 schema 混淆输入和输出类型。输入对象类型的字段当然也不能拥有参数。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"GraphQL 入门","slug":"GraphQL-入门","permalink":"https://tianxiafeiyu.github.io/tags/GraphQL-%E5%85%A5%E9%97%A8/"}]},{"title":"REST风格理解","slug":"技术开发/grocery/REST风格理解","date":"2022-12-15T23:10:53.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/REST风格理解/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/REST%E9%A3%8E%E6%A0%BC%E7%90%86%E8%A7%A3/","excerpt":"","text":"转载自 https://www.jianshu.com/p/6e8381c9b01d 一、什么是REST一句话来概括RESTful API(具有REST风格的API): 用URL定位资源，用HTTP动词（GET,HEAD,POST,PUT,PATCH,DELETE）描述操作，用响应状态码表示操作结果。 REST是一种软件架构风格，或者说是一种规范，其强调HTTP应当以资源为中心，并且规范了URI的风格；规范了HTTP请求动作（GET&#x2F;PUT&#x2F;POST&#x2F;DELETE&#x2F;HEAD&#x2F;OPTIONS）的使用，具有对应的语义。 核心概念包括： 资源（Resource）：在REST中，资源可以简单的理解为URI，表示一个网络实体。比如，&#x2F;users&#x2F;1&#x2F;name，对应id&#x3D;1的用户的属性name。既然资源是URI，就会具有以下特征：名词，代表一个资源；它对应唯一的一个资源，是资源的地址。 表现（Representation）：资源呈现出来的形式，比如上述URI返回的HTML或JSON，包括HTTP Header等； REST是一个无状态的架构模式，因为在任何时候都可以由客户端发出请求到服务端，最终返回自己想要的数据，当前请求不会受到上次请求的影响。也就是说，服务端将内部资源发布REST服务，客户端通过URL来定位这些资源并通过HTTP协议来访问它们。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"REST风格理解","slug":"REST风格理解","permalink":"https://tianxiafeiyu.github.io/tags/REST%E9%A3%8E%E6%A0%BC%E7%90%86%E8%A7%A3/"}]},{"title":"dalin的服务器配置记录","slug":"技术开发/grocery/dalin的服务器配置记录","date":"2022-12-15T23:10:53.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/dalin的服务器配置记录/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/dalin%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95/","excerpt":"","text":"阿里云上重新买了台穷鬼t5，菜是菜了点，但是该折腾还是要折腾的。。。 设置虚拟内存安装free -m 查看内存状态, Swap 的值都是0，说明还没有安装虚拟内存 在 &#x2F;opt 下创建虚拟内存文件 1dd if=/dev/zero of=/opt/swap bs=2048 count=2048000 将swap文件设置为swap分区文件 12chmod 600 /opt/swap //注意更改swap文件的权限mkswap /opt/swap 激活swap,启用分区交换文件 1swapon /opt/swap 查看结果 1234[root@dalin1 opt]# free -m total used free shared buff/cache availableMem: 1829 1329 169 0 330 357Swap: 3999 429 3570 重启自动启用设置，否则机器重启后分区就失效了 1vim /etc/rc.local 底部添加 1swapon /home/swap 卸载停止swap分区 1swapoff /opt/swap 删除掉swap文件 1rm -rf /opt/swap 查看磁盘情况： 12345678910[root@dalin1 opt]# df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 900M 0 900M 0% /devtmpfs 915M 0 915M 0% /dev/shmtmpfs 915M 612K 915M 1% /runtmpfs 915M 0 915M 0% /sys/fs/cgroup/dev/vda1 40G 9.5G 31G 24% /tmpfs 183M 0 183M 0% /run/user/1000overlay 40G 9.5G 31G 24% /var/lib/docker/overlay2/cb6202d7408b52de4ca486b57263e33e6dbb34d3adf35e86bfdffe62b9d33339/mergedoverlay 40G 9.5G 31G 24% /var/lib/docker/overlay2/25f9d8b78fa8906f7b379efce90fdd90f8e5771399f537988cf15ca450641596/merged mysql 安装上一次鄙人的mysql开启了远程访问，并且没有注意安全防范，被比特币勒索了。。。但是使用远程msql服务的需求还是需要的，毕竟真的是方便，这次注意一下安全方面的配置，应该不至于再没了吧。。。 1. centos8 安装mysql8使用最新的包管理器安装MySQL 1sudo dnf install @mysql 设置开机自启并启动 1sudo systemctl enable --now mysqld 运行mysql_secure_installation脚本，该脚本执行一些与安全性相关的操作并设置MySQL根密码： 1mysql_secure_installation 按提示往下走即可，注意在 Disallow root login remotely?选项中选择 n 2. 更换 mysql 默认端口vim /etc/my.cnf，添加字段 port=6612 systemctl restart mysqld 重启 mysql 防火墙添加6612端口白名单 12firewall-cmd --add-port=6612/tcp --permanentfirewall-cmd --reload centos默认使用的是firewall作为防火墙，一些常用命令： firewall-cmd –list-ports ##查看已开放的端口 firewall-cmd –add-port&#x3D;6612&#x2F;tcp –permanent ##永久开放6612端口 firewall-cmd –remove-port&#x3D;6612&#x2F;tcp –permanent ##永久关闭6612端口 firewall-cmd –reload ##刷新 阿里云控制台安全组开放 6612 端口 3. mysql 允许远程主机访问登录mysql 1mysql -uroot -p&lt;密码&gt; 将 mysql.user 中的 root 的 host 字段设为&#39;%&#39;： 123use mysql;update user set host=&#x27;%&#x27; where user=&#x27;root&#x27;;flush privileges; 4. 使用脚本自动备份数据1234567891011121314151617181920212223242526272829303132333435363738394041#!/bin/bash#数据库服务器dbserver=&#x27;localhost&#x27;#数据库用户名dbuser=&#x27;root&#x27;#数据库用密码dbpasswd=&#x27;********&#x27;#需要备份的数据库，多个数据库用空格分开dbname=&#x27;backdata01 backdata02&#x27;#备份时间backtime=`date +%Y%m%d`#日志备份路径logpath=&#x27;/opt/data/mysqlbak/&#x27;#数据备份路径datapath=&#x27;/opt/data/mysqlbak/&#x27; echo &#x27;##################$backtime##########################&#x27; #日志记录头部echo ‘&quot;备份时间为$&#123;backtime&#125;,备份数据库表 $&#123;dbname&#125; 开始&quot; &gt;&gt; $&#123;logpath&#125;/mysqlback.log#正式备份数据库for table in $dbname; dosource=`mysqldump -h $&#123;dbserver&#125; -u $&#123;dbuser&#125; -p$&#123;dbpasswd&#125; $&#123;table&#125; &gt; $&#123;logpath&#125;/$&#123;backtime&#125;.sql` 2&gt;&gt; $&#123;logpath&#125;/mysqlback.log;#备份成功以下操作if [ &quot;$?&quot; == 0 ];thencd $datapath#为节约硬盘空间，将数据库压缩tar zcf $&#123;table&#125;$&#123;backtime&#125;.tar.gz $&#123;backtime&#125;.sql &gt; /dev/null#删除原始文件，只留压缩后文件rm -f $&#123;datapath&#125;/$&#123;backtime&#125;.sql#删除七天前备份，也就是只保存7天内的备份find $datapath -name &quot;*.tar.gz&quot; -type f -mtime +7 -exec rm -rf &#123;&#125; \\; &gt; /dev/null 2&gt;&amp;1echo &quot;数据库表 $&#123;dbname&#125; 备份成功!!&quot; &gt;&gt; $&#123;logpath&#125;/mysqlback.logelse#备份失败则进行以下操作echo &quot;数据库表 $&#123;dbname&#125; 备份失败!!&quot; &gt;&gt; $&#123;logpath&#125;/mysqlback.logfidone echo &#x27;##################完成############################&#x27; 创建定时任务 12crontab -e59 23 * * * ./opt/mysqldata/mysqlbak.sh ## 每天23:59执行命令 redis 安装5. 安装redis并且设置远程访问和密码配置12[root@dalin1 ~]# yum -y install redis[root@dalin1 ~]# systemctl enable --now redis 修改redis端口、设置密码、允许远程访问 1[root@dalin1 ~]# vim /etc/redis.conf 修改 port 6369 注释掉 bind 127.0.0.1，以便让外网访问 去掉 #requirepass foobared 注释，foobared改为自己的密码 防火墙添加6369端口白名单 12firewall-cmd --add-port=6369/tcp --permanentfirewall-cmd --reload 阿里云控制台安全组开放 6369 端口 6. 创建普通用户，以后尽量使用普通用户操作123[root@dalin1 ~]# adduser dalin #创建普通用户 dalin[root@dalin1 ~]# passwd dalin #修改密码[root@dalin1 ~]# su dalin #切换用户 普通用户只在 /home/&lt;username&gt; 目录下有完整权限 docker 安装docker这么方便的东西怎么能不用呢，但是因为服务器实在太菜了，可能会卡顿，而且要时刻注意内存使用情况 1. 安装依赖包1[root@dalin1 ~]# yum install -y yum-utils device-mapper-persistent-data lvm2 2. 设置Docker源1[root@dalin1 ~]# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 3. 安装Docker CE3.1 docker安装版本查看1[root@dalin1 ~]# yum list docker-ce --showduplicates | sort -r 3.2 安装docker1[root@dalin1 ~]# yum install docker-ce-18.09.6 docker-ce-cli-18.09.6 containerd.io 指定安装的docker版本为18.09.6，由于该版本目前为最新版，故可以直接安装，不用指定版本： 1[root@dalin1 ~]# yum install -y docker-ce docker-ce-cli containerd.io 4. 启动Docker并设置开机自启1[root@dalin1 ~]# systemctl enable --now docker 5. 镜像加速使用阿里云镜像加速地址 123456[root@dalin1 ~]# mkdir -p /etc/docker[root@dalin1 ~]# tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123; &quot;registry-mirrors&quot;: [&quot;https://khv87vsk.mirror.aliyuncs.com&quot;]&#125;EOF docker 下安装Elasticsearch和Kibana服务器太菜，基本跑不动 安装Elasticsearch下载镜像： 1[root@dalin1 ~]# docker pull elasticsearch:7.2.0 启动容器 1[root@dalin1 ~]# docker run --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; -d elasticsearch:7.2.0 大概率启动失败，查看日志： 12345678910111213[root@dalin1 temp]# docker logs elasticsearchException in thread &quot;main&quot; java.lang.RuntimeException: starting java failed with [1]output:## There is insufficient memory for the Java Runtime Environment to continue.# Native memory allocation (mmap) failed to map 1073741824 bytes for committing reserved memory.# An error report file with more information is saved as:# logs/hs_err_pid132.logerror:OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x00000000c0000000, 1073741824, 0) failed; error=&#x27;Not enough space&#x27; (errno=12) at org.elasticsearch.tools.launchers.JvmErgonomics.flagsFinal(JvmErgonomics.java:126) at org.elasticsearch.tools.launchers.JvmErgonomics.finalJvmOptions(JvmErgonomics.java:88) ... jvm内存不足。。。 123[root@dalin1]# find / -name jvm.options/var/lib/docker/overlay2/aa7a9ac9f293452ddf8947e9fdf3af24d602566d54b6278284751239b43e37e5/diff/usr/share/elasticsearch/config/jvm.options[root@dalin1]# vim /var/lib/docker/overlay2/aa7a9ac9f293452ddf8947e9fdf3af24d602566d54b6278284751239b43e37e5/diff/usr/share/elasticsearch/config/jvm.options 1234567891011121314151617181920212223242526## JVM configuration################################################################## IMPORTANT: JVM heap size#################################################################### You should always set the min and max JVM heap## size to the same value. For example, to set## the heap to 4 GB, set:#### -Xms4g## -Xmx4g#### See https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html## for more information################################################################### Xms represents the initial size of total heap space# Xmx represents the maximum size of total heap space-Xms1g #服务器实在太菜了，我改成256m-Xmx1g #服务器实在太菜了，我改成256m################################################################ 重新启动容器 1[root@dalin1 ~]# docker start elasticsearch 检测是否启动成功 12345678910111213141516171819[root@dalin1 ~]# curl http://localhost:9200&#123; &quot;name&quot; : &quot;c19d1882a695&quot;, &quot;cluster_name&quot; : &quot;docker-cluster&quot;, &quot;cluster_uuid&quot; : &quot;-zKpqN7TQMqmPULGgdMz3w&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;7.2.0&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;docker&quot;, &quot;build_hash&quot; : &quot;508c38a&quot;, &quot;build_date&quot; : &quot;2019-06-20T15:54:18.811730Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.0.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 解决跨域访问问题 进入容器，修改elasticsearch.yml文件 12[root@dalin1 ~]# docker exec -it elasticsearch /bin/bashvim /usr/share/elasticsearch/config/elasticsearch.yml 在elasticsearch.yml的文件末尾加上: 12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; es自带的分词器对中文分词不是很友好，所以我们下载开源的IK分词器来解决这个问题。 123456````exit` 退出容器后 `docker restart elasticsearch` 重启容器#### kibana安装下载镜像 [root@dalin1 ~]# docker pull kibana:7.2.0 123启动kibana [root@dalin1 ~]# docker run –name kibana –link&#x3D;elasticsearch:es -e ELASTICSEARCH_URL&#x3D;http://172.17.0.2:9200 -p 5601:5601 -d kibana:7.7.0 123使用--link连接到elasticsearch容器，并添加环境变量，指定安装es的容器地址当然也可以进入容器内部修改配置文件来设置es访问地址 [root@dalin1 ~]# docker exec -it kibana &#x2F;bin&#x2F;bashvi config&#x2F;kibana.yml 12345kibana默认是优先使用环境变量的地址，然后才是配置文件kibana.yml&lt;br&gt;如何查询容器地址？ 获取到容器的元数据信息[root@dalin1 ~]# docker inspect [id&#x2F;name] 12最后，配置安全组和防火墙，开放9200、5601端口 [root@dalin1 ~]# firewall-cmd –add-port&#x3D;5601&#x2F;tcp –permanent[root@dalin1 ~]# firewall-cmd –add-port&#x3D;9200&#x2F;tcp –permanent 12这就结束了吗？是的，网上几乎所有的关于docker下安装kibana教程都是到了这一步就说完事收工、开始体验。。。但是！！！我遇到的情况是访问 `http//:ip:5601`，只会给我冰冷的大字： Kibana server is not ready yet 1`docker logs kibana`打印日志，报错： {“type”:”log”,”@timestamp”:”2020-06-04T08:25:57Z”,”tags”:[“warning”,”elasticsearch”,”admin”],”pid”:6,”message”:”Unable to revive connection: http://172.17.0.2:9200/&quot;}{“type”:”log”,”@timestamp”:”2020-06-04T08:25:57Z”,”tags”:[“warning”,”elasticsearch”,”admin”],”pid”:6,”message”:”No living connections”} 123ip地址是没问题的，es服务也确实起了，为什么呢？？这个问题花了我大半天的时间，找遍了网上的教程都没有相关的介绍，官网上关于docker安装kibana的教程更是少。 进入kibana容器中 [root@dalin1 ~]# docker exec -it kibana &#x2F;bin&#x2F;bashbash-4.2$ ping 172.17.0.2 #没有问题，能ping通bash-4.2$ curl http://120.79.43.44:9200curl: (7) Failed connect to 120.79.43.44:9200; No route to host 123问题就出在这里！应该是防火墙的原因导致容器之间无法进行通信解决方法，依次执行以下命令 [root@dalin1 ~]# nmcli connection modify docker0 connection.zone trusted [root@dalin1 ~]# systemctl stop NetworkManager.service [root@dalin1 ~]# firewall-cmd –permanent –zone&#x3D;trusted –change-interface&#x3D;docker0 [root@dalin1 ~]# systemctl start NetworkManager.service [root@dalin1 ~]# nmcli connection modify docker0 connection.zone trusted [root@dalin1 ~]# systemctl restart docker.service &#96;&#96;&#96;把 docker0 加入防火墙白名单 重新启动容器，访问地址 http://ip:5601 ，总算没有了 Kibana server is not ready yet,显示正在加载的图像，稍作等候即可，部署完成！","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"dalin的服务器配置记录","slug":"dalin的服务器配置记录","permalink":"https://tianxiafeiyu.github.io/tags/dalin%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95/"}]},{"title":"k8s配置文件详解","slug":"技术开发/grocery/k8s配置文件详解","date":"2022-12-15T23:10:53.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/k8s配置文件详解/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/k8s%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"k8s yaml文件yaml基础YAML是专门用来写配置文件的语言，非常简洁和强大，使用比json更方便。它实质上是一种通用的数据串行化格式。 YAML语法规则： 12345大小写敏感使用缩进表示层级关系缩进时不允许使用Tal键，只允许使用空格缩进的空格数目不重要，只要相同层级的元素左侧对齐即可”#” 表示注释，从这个字符一直到行尾，都会被解析器忽略 在Kubernetes中，只需要知道两种结构类型即可：Lists和Maps YAML Maps： Map顾名思义指的是字典，即一个Key:Value 的键值对信息。例如： 123apiVersion: v1kind: Pod 注：---为可选的分隔符 ，当需要在一个文件中定义多个结构的时候需要使用。上述内容表示有两个键apiVersion和kind，分别对应的值为v1和Pod。 Maps的value既能够对应字符串也能够对应一个Maps。例如： 123456apiVersion: v1kind: Podmetadata: name: kube100-site labels: app: web List即列表，说白了就是数组，例如： 12345args -beijing -shanghai -shenzhen -guangzhou 当然Lists的子项也可以是Maps，Maps的子项也可以是List，例如： 123456789101112131415apiVersion: v1kind: Podmetadata: name: kube100-site labels: app: webspec: containers: - name: front-end image: nginx ports: - containerPort: 80 - name: flaskapp-demo image: jcdemo/flaskapp ports: 8080 k8s yaml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172apiVersion: v1 #指定api版本，此值必须在kubectl apiversion中 kind: Pod #指定创建资源的角色/类型 metadata: #资源的元数据/属性 name: web04-pod #资源的名字，在同一个namespace中必须唯一 labels: #设定资源的标签，详情请见http://blog.csdn.net/liyingke112/article/details/77482384 k8s-app: apache version: v1 kubernetes.io/cluster-service: &quot;true&quot; annotations: #自定义注解列表 - name: String #自定义注解名字 spec:#specification of the resource content 指定该资源的内容 restartPolicy: Always #表明该容器一直运行，默认k8s的策略，在此容器退出后，会立即创建一个相同的容器 nodeSelector: #节点选择，先给主机打标签kubectl label nodes kube-node1 zone=node1 zone: node1 containers: - name: web04-pod #容器的名字 image: web:apache #容器使用的镜像地址 imagePullPolicy: Never #三个选择Always、Never、IfNotPresent，每次启动时检查和更新（从registery）images的策略， # Always，每次都检查 # Never，每次都不检查（不管本地是否有） # IfNotPresent，如果本地有就不检查，如果没有就拉取 command: [&#x27;sh&#x27;] #启动容器的运行命令，将覆盖容器中的Entrypoint,对应Dockefile中的ENTRYPOINT args: [&quot;$(str)&quot;] #启动容器的命令参数，对应Dockerfile中CMD参数 env: #指定容器中的环境变量 - name: str #变量的名字 value: &quot;/etc/run.sh&quot; #变量的值 resources: #资源管理，请求请见http://blog.csdn.net/liyingke112/article/details/77452630 requests: #容器运行时，最低资源需求，也就是说最少需要多少资源容器才能正常运行 cpu: 0.1 #CPU资源（核数），两种方式，浮点数或者是整数+m，0.1=100m，最少值为0.001核（1m） memory: 32Mi #内存使用量 limits: #资源限制 cpu: 0.5 memory: 32Mi ports: - containerPort: 80 #容器开放对外的端口 name: httpd #名称 protocol: TCP livenessProbe: #pod内容器健康检查的设置，详情请见http://blog.csdn.net/liyingke112/article/details/77531584 httpGet: #通过httpget检查健康，返回200-399之间，则认为容器正常 path: / #URI地址 port: 80 #host: 127.0.0.1 #主机地址 scheme: HTTP initialDelaySeconds: 180 #表明第一次检测在容器启动后多长时间后开始 timeoutSeconds: 5 #检测的超时时间 periodSeconds: 15 #检查间隔时间 #也可以用这种方法 #exec: 执行命令的方法进行监测，如果其退出码不为0，则认为容器正常 # command: # - cat # - /tmp/health #也可以用这种方法 #tcpSocket: //通过tcpSocket检查健康 # port: number lifecycle: #生命周期管理 postStart: #容器运行之前运行的任务 exec: command: - &#x27;sh&#x27; - &#x27;yum upgrade -y&#x27; preStop: #容器关闭之前运行的任务 exec: command: [&#x27;service httpd stop&#x27;] volumeMounts: #详情请见http://blog.csdn.net/liyingke112/article/details/76577520 - name: volume #挂载设备的名字，与volumes[*].name 需要对应 mountPath: /data #挂载到容器的某个路径下 readOnly: True volumes: #定义一组挂载设备 - name: volume #定义一个挂载设备的名字 #meptyDir: &#123;&#125; hostPath: path: /opt #挂载设备类型为hostPath，路径为宿主机下的/opt,这里设备类型支持很多种 k8s 使用过程笔记如何进入kubernetes的一个pod123456类似于docker进入docker容器 ：docker exec -ti &lt;your-container-name&gt; /bin/sh进入pod：kubectl exec -ti &lt;your-pod-name&gt; -n &lt;your-namespace&gt; -- /bin/sh 关于k8s使用镜像创建pod的坑k8s默认从远程仓库中获取镜像，可以使用镜像获取策略从本地获取： 1234containers: - name: test image: nginx:1.7.9 #必须带上tag imagePullPolicy: Never Always 总是拉取镜像 IfNotPresent 本地有则使用本地镜像,不拉取 Never 只使用本地镜像，从不拉取，即使本地没有 如果省略imagePullPolicy 镜像tag为 :latest 策略为always ，否则 策略为 IfNotPresent","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"k8s配置文件详解","slug":"k8s配置文件详解","permalink":"https://tianxiafeiyu.github.io/tags/k8s%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"}]},{"title":"session，cookie，token学习","slug":"技术开发/grocery/session，cookie，token学习【转】","date":"2022-12-15T23:10:53.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/session，cookie，token学习【转】/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/session%EF%BC%8Ccookie%EF%BC%8Ctoken%E5%AD%A6%E4%B9%A0%E3%80%90%E8%BD%AC%E3%80%91/","excerpt":"","text":"httphttp是一个无状态协议, 也就是说这一次请求和上一次请求是没有任何关系的，互不认识的，没有关联的。这种无状态的的好处是快速。坏处是假如我们想要把 www.zhihu.com/login.html 和 www.zhihu.com/index.html 关联起来，必须使用某些手段和工具。 由于http的无状态性，为了使某个域名下的所有网页能够共享某些数据，session和cookie出现了。客户端访问服务器的流程如下 首先，客户端会发送一个http请求到服务器端。 服务器端接受客户端请求后，建立一个session，并发送一个http响应到客户端，这个响应头，其中就包含Set-Cookie头部。该头部包含了sessionId。Set-Cookie格式如下：Set-Cookie: value[; expires&#x3D;date][; domain&#x3D;domain][; path&#x3D;path][; secure] 在客户端发起的第二次请求，假如服务器给了set-Cookie，浏览器会自动在请求头中添加cookie 服务器接收请求，分解cookie，验证信息，核对成功后返回response给客户端 cookieCookies是服务器在本地机器上存储的小段文本并随每一个请求发送至同一个服务器。IETF RFC 2965 HTTP State Management Mechanism 是通用cookie规范。网络服务器用HTTP头向客户端发送cookies，在客户终端，浏览器解析这些cookies并将它们保存为一个本地文件，它会自动将同一服务器的任何请求缚上这些cookies 。 具体来说cookie机制采用的是在客户端保持状态的方案。它是在用户端的会话状态的存贮机制，他需要用户打开客户端的cookie支持。cookie的作用就是为了解决HTTP协议无状态的缺陷所作的努力。 正统的cookie分发是通过扩展HTTP协议来实现的，服务器通过在HTTP的响应头中加上一行特殊的指示以提示浏览器按照指示生成相应的cookie。然而纯粹的客户端脚本如JavaScript也可以生成cookie。而cookie的使用是由浏览器按照一定的原则在后台自动发送给服务器的。浏览器检查所有存储的cookie，如果某个cookie所声明的作用范围大于等于将要请求的资源所在的位置，则把该cookie附在请求资源的HTTP请求头上发送给服务器。 cookie的内容主要包括：名字，值，过期时间，路径和域。路径与域一起构成cookie的作用范围。若不设置过期时间，则表示这个cookie的生命期为浏览器会话期间，关闭浏览器窗口，cookie就消失。这种生命期为浏览器会话期的cookie被称为会话cookie。会话cookie一般不存储在硬盘上而是保存在内存里，当然这种行为并不是规范规定的。若设置了过期时间，浏览器就会把cookie保存到硬盘上，关闭后再次打开浏览器，这些cookie仍然有效直到超过设定的过期时间。存储在硬盘上的cookie可以在不同的浏览器进程间共享，比如两个IE窗口。而对于保存在内存里的cookie，不同的浏览器有不同的处理方式。 而session机制采用的是一种在服务器端保持状态的解决方案。同时我们也看到，由于采用服务器端保持状态的方案在客户端也需要保存一个标识，所以session机制可能需要借助于cookie机制来达到保存标识的目的。而session提供了方便管理全局变量的方式 。 session是针对每一个用户的，变量的值保存在服务器上，用一个sessionID来区分是哪个用户session变量,这个值是通过用户的浏览器在访问的时候返回给服务器，当客户禁用cookie时，这个值也可能设置为由get来返回给服务器。 就安全性来说：当你访问一个使用session 的站点，同时在自己机子上建立一个cookie，建议在服务器端的session机制更安全些，因为它不会任意读取客户存储的信息。 sessionsession机制是一种服务器端的机制，服务器使用一种类似于散列表的结构（也可能就是使用散列表）来保存信息。 当程序需要为某个客户端的请求创建一个session时，服务器首先检查这个客户端的请求里是否已包含了一个session标识（称为session id），如果已包含则说明以前已经为此客户端创建过session，服务器就按照session id把这个session检索出来使用（检索不到，会新建一个），如果客户端请求不包含session id，则为此客户端创建一个session并且生成一个与此session相关联的session id，session id的值应该是一个既不会重复，又不容易被找到规律以仿造的字符串，这个session id将被在本次响应中返回给客户端保存。 保存这个session id的方式可以采用cookie，这样在交互过程中浏览器可以自动的按照规则把这个标识发挥给服务器。一般这个cookie的名字都是类似于SEEESIONID。但cookie可以被人为的禁止，则必须有其他机制以便在cookie被禁止时仍然能够把session id传递回服务器。 经常被使用的一种技术叫做URL重写，就是把session id直接附加在URL路径的后面。还有一种技术叫做表单隐藏字段。就是服务器会自动修改表单，添加一个隐藏字段，以便在表单提交时能够把session id传递回服务器。 简而言之, session 类似用户信息档案表, 里面包含了用户的认证信息和登录状态等信息. 而 cookie 就是用户通行证。 token概念token 也称作令牌，由uid+time+sign[+固定参数]token 的认证方式类似于临时的证书签名, 并且是一种服务端无状态的认证方式, 非常适合于 REST API 的场景. 所谓无状态就是服务端并不会保存身份认证相关的数据。 组成 uid: 用户唯一身份标识 time: 当前时间的时间戳 sign: 签名, 使用 hash&#x2F;encrypt 压缩成定长的十六进制字符串，以防止第三方恶意拼接 固定参数(可选): 将一些常用的固定参数加入到 token 中是为了避免重复查库 token在客户端一般存放于localStorage，cookie，或sessionStorage中。在服务器一般存于数据库中 token认证流程token 的认证流程与cookie很相似 用户登录，成功后服务器返回Token给客户端。 客户端收到数据后保存在客户端 客户端再次访问服务器，将token放入headers中 服务器端采用filter过滤器校验。校验成功则返回请求数据，校验失败则返回错误码 JWT我们已经知道session时有状态的，一般存于服务器内存或硬盘中，当服务器采用分布式或集群时，session就会面对负载均衡问题。 token是无状态的，token字符串里就保存了所有的用户信息。 客户端登陆传递信息给服务端，服务端收到后把用户信息加密（token）传给客户端，客户端将token存放于localStroage等容器中。客户端每次访问都传递token，服务端解密token，就知道这个用户是谁了。通过cpu加解密，服务端就不需要存储session占用存储空间，就很好的解决负载均衡多服务器的问题了。这个方法叫做JWT(Json Web Token) 区别与联系Cookie与Session都能够进行会话跟踪，但是完成的原理不太一样。普通状况下二者均能够满足需求，但有时分不能够运用Cookie，有时分不能够运用Session。下面经过比较阐明二者的特性以及适用的场所。 1. 存取方式的不同Cookie中只能保管ASCII字符串，假如需求存取Unicode字符或者二进制数据，需求先进行编码。Cookie中也不能直接存取Java对象。若要存储略微复杂的信息，运用Cookie是比较艰难的。 而Session中能够存取任何类型的数据，包括而不限于String、Integer、List、Map等。Session中也能够直接保管Java Bean乃至任何Java类，对象等，运用起来十分便当。能够把Session看做是一个Java容器类。 2. 隐私策略的不同Cookie存储在客户端阅读器中，对客户端是可见的，客户端的一些程序可能会窥探、复制以至修正Cookie中的内容。而Session存储在服务器上，对客户端是透明的，不存在敏感信息泄露的风险。 假如选用Cookie，比较好的方法是，敏感的信息如账号密码等尽量不要写到Cookie中。最好是像Google、Baidu那样将Cookie信息加密，提交到服务器后再进行解密，保证Cookie中的信息只要本人能读得懂。而假如选择Session就省事多了，反正是放在服务器上，Session里任何隐私都能够有效的保护。 3. 有效期上的不同使用过Google的人都晓得，假如登录过Google，则Google的登录信息长期有效。用户不用每次访问都重新登录，Google会持久地记载该用户的登录信息。要到达这种效果，运用Cookie会是比较好的选择。只需要设置Cookie的过期时间属性为一个很大很大的数字。 由于Session依赖于名为JSESSIONID的Cookie，而Cookie JSESSIONID的过期时间默许为–1，只需关闭了阅读器该Session就会失效，因而Session不能完成信息永世有效的效果。运用URL地址重写也不能完成。而且假如设置Session的超时时间过长，服务器累计的Session就会越多，越容易招致内存溢出。 4. 服务器压力的不同Session是保管在服务器端的，每个用户都会产生一个Session。假如并发访问的用户十分多，会产生十分多的Session，耗费大量的内存。因而像Google、Baidu、Sina这样并发访问量极高的网站，是不太可能运用Session来追踪客户会话的。 而Cookie保管在客户端，不占用服务器资源。假如并发阅读的用户十分多，Cookie是很好的选择。关于Google、Baidu、Sina来说，Cookie或许是唯一的选择。 5. 浏览器支持的不同Cookie是需要客户端浏览器支持的。假如客户端禁用了Cookie，或者不支持Cookie，则会话跟踪会失效。关于WAP上的应用，常规的Cookie就派不上用场了。 假如客户端浏览器不支持Cookie，需要运用Session以及URL地址重写。需要注意的是一切的用到Session程序的URL都要进行URL地址重写，否则Session会话跟踪还会失效。关于WAP应用来说，Session+URL地址重写或许是它唯一的选择。 假如客户端支持Cookie，则Cookie既能够设为本浏览器窗口以及子窗口内有效（把过期时间设为–1），也能够设为一切阅读器窗口内有效（把过期时间设为某个大于0的整数）。但Session只能在本阅读器窗口以及其子窗口内有效。假如两个浏览器窗口互不相干，它们将运用两个不同的Session。（IE8下不同窗口Session相干） 6、跨域支持上的不同Cookie支持跨域名访问，例如将domain属性设置为“.biaodianfu.com”，则以“.biaodianfu.com”为后缀的一切域名均能够访问该Cookie。跨域名Cookie如今被普遍用在网络中，例如Google、Baidu、Sina等。而Session则不会支持跨域名访问。Session仅在他所在的域名内有效。 仅运用Cookie或者仅运用Session可能完成不了理想的效果。这时应该尝试一下同时运用Cookie与Session。Cookie与Session的搭配运用在实践项目中会完成很多意想不到的效果。 6. token可以抵抗csrf，cookie+session不行假如用户正在登录银行网页，登录了攻击者的网页，并且银行网页未对csrf攻击进行防护。攻击者就可以在网页放一个表单，该表单提交src为http://www.bank.com/api/transfer，body为count=1000&amp;to=Tom。倘若是session+cookie，用户打开网页的时候就已经转给Tom1000元了.因为form 发起的 POST 请求并不受到浏览器同源策略的限制，因此可以任意地使用其他域的 Cookie 向其他域发送 POST 请求，形成 CSRF 攻击。在post请求的瞬间，cookie会被浏览器自动添加到请求头中。但token不同，token是开发者为了防范csrf而特别设计的令牌，浏览器不会自动添加到headers里，攻击者也无法访问用户的token，所以提交的表单无法通过服务器过滤，也就无法形成攻击。 cookie只是实现session的其中一种方案。虽然是最常用的，但并不是唯一的方法。禁用cookie后还有其他方法存储，比如放在url中 现在大多都是Session + Cookie的方式，但是只用session不用cookie，或是只用cookie不用session，在理论上都可以保持会话状态。可是实际中因为多种原因，一般不会单独使用 用session只需要在客户端保存一个id，实际上大量数据都是保存在服务端。如果全部用cookie，数据量大的时候客户端是没有那么多空间的。 如果只用cookie不用session，那么账户信息全部保存在客户端，一旦被劫持，全部信息都会泄露。并且客户端数据量变大，网络传输的数据量也会变大 总结 session存储于服务器，可以理解为一个状态列表，拥有一个唯一识别符号sessionId，通常存放于cookie中。服务器收到cookie后解析出sessionId，再去session列表中查找，才能找到相应session。依赖cookie cookie类似一个令牌，装有sessionId，存储在客户端，浏览器通常会自动添加。 token也类似一个令牌，无状态，用户信息都被加密到token中，服务器收到token后解密就可知道是哪个用户。需要开发者手动添加。 jwt只是一个跨域认证的方案 参考资料 https://segmentfault.com/a/1190000017831088 https://segmentfault.com/a/1190000015419746","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"session，cookie，token学习","slug":"session，cookie，token学习","permalink":"https://tianxiafeiyu.github.io/tags/session%EF%BC%8Ccookie%EF%BC%8Ctoken%E5%AD%A6%E4%B9%A0/"}]},{"title":"一次完整的HTTP请求过程【转】","slug":"技术开发/grocery/一次完整的HTTP请求过程【转】","date":"2022-12-15T23:10:53.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/一次完整的HTTP请求过程【转】/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/%E4%B8%80%E6%AC%A1%E5%AE%8C%E6%95%B4%E7%9A%84HTTP%E8%AF%B7%E6%B1%82%E8%BF%87%E7%A8%8B%E3%80%90%E8%BD%AC%E3%80%91/","excerpt":"","text":"当我们在浏览器的地址栏输入 www.linux178.com ，然后回车，回车这一瞬间到看到页面到底发生了什么呢？ 域名解析 –&gt; 发起TCP的3次握手 –&gt; 建立TCP连接后发起http请求 –&gt; 服务器响应http请求，浏览器得到html代码 –&gt; 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） –&gt; 浏览器对页面进行渲染呈现给用户 以Chrome浏览器为例： 1.域名解析 首先Chrome浏览器会解析 www.linux178.com 这个域名（准确的叫法应该是主机名）对应的IP地址。怎么解析到对应的IP地址？ ① Chrome浏览器 会首先搜索浏览器自身的DNS缓存（缓存时间比较短，大概只有1分钟，且只能容纳1000条缓存），看自身的缓存中是否有www.linux178.com 对应的条目，而且没有过期，如果有且没有过期则解析到此结束。 注：我们怎么查看Chrome自身的缓存？可以使用 chrome:&#x2F;&#x2F;net-internals&#x2F;#dns 来进行查看 ② 如果浏览器自身的缓存里面没有找到对应的条目，那么Chrome会搜索操作系统自身的DNS缓存,如果找到且没有过期则停止搜索解析到此结束. 注：怎么查看操作系统自身的DNS缓存，以Windows系统为例，可以在命令行下使用 ipconfig &#x2F;displaydns 来进行查看 ③ 如果在Windows系统的DNS缓存也没有找到，那么尝试读取hosts文件（位于C:\\Windows\\System32\\drivers\\etc），看看这里面有没有该域名对应的IP地址，如果有则解析成功。 ④ 如果在hosts文件中也没有找到对应的条目，浏览器就会发起一个DNS的系统调用，就会向本地配置的首选DNS服务器（一般是电信运营商提供的，也可以使用像Google提供的DNS服务器）发起域名解析请求（通过的是UDP协议向DNS的53端口发起请求，这个请求是递归的请求，也就是运营商的DNS服务器必须得提供给我们该域名的IP地址），运营商的DNS服务器首先查找自身的缓存，找到对应的条目，且没有过期，则解析成功。如果没有找到对应的条目，则有运营商的DNS代我们的浏览器发起迭代DNS解析请求，它首先是会找根域的DNS的IP地址（这个DNS服务器都内置13台根域的DNS的IP地址），找到根域的DNS地址，就会向其发起请求（请问www.linux178.com这个域名的IP地址是多少啊？），根域发现这是一个顶级域com域的一个域名，于是就告诉运营商的DNS我不知道这个域名的IP地址，但是我知道com域的IP地址，你去找它去，于是运营商的DNS就得到了com域的IP地址，又向com域的IP地址发起了请求（请问www.linux178.com这个域名的IP地址是多少?）,com域这台服务器告诉运营商的DNS我不知道www.linux178.com这个域名的IP地址，但是我知道linux178.com这个域的DNS地址，你去找它去，于是运营商的DNS又向linux178.com这个域名的DNS地址（这个一般就是由域名注册商提供的，像万网，新网等）发起请求（请问www.linux178.com这个域名的IP地址是多少？），这个时候linux178.com域的DNS服务器一查，诶，果真在我这里，于是就把找到的结果发送给运营商的DNS服务器，这个时候运营商的DNS服务器就拿到了www.linux178.com这个域名对应的IP地址，并返回给Windows系统内核，内核又把结果返回给浏览器，终于浏览器拿到了www.linux178.com对应的IP地址，该进行一步的动作了。 注：一般情况下是不会进行以下步骤的 如果经过以上的4个步骤，还没有解析成功，那么会进行如下步骤（以下是针对Windows操作系统）： ⑤ 操作系统就会查找NetBIOS name Cache（NetBIOS名称缓存，就存在客户端电脑中的），那这个缓存有什么东西呢？凡是最近一段时间内和我成功通讯的计算机的计算机名和Ip地址，就都会存在这个缓存里面。什么情况下该步能解析成功呢？就是该名称正好是几分钟前和我成功通信过，那么这一步就可以成功解析。 ⑥ 如果第⑤步也没有成功，那会查询WINS 服务器（是NETBIOS名称和IP地址对应的服务器） ⑦ 如果第⑥步也没有查询成功，那么客户端就要进行广播查找 ⑧ 如果第⑦步也没有成功，那么客户端就读取LMHOSTS文件（和HOSTS文件同一个目录下，写法也一样） 如果第八步还没有解析成功，那么就宣告这次解析失败，那就无法跟目标计算机进行通信。只要这八步中有一步可以解析成功，那就可以成功和目标计算机进行通信。 2.发起TCP的3次握手拿到域名对应的IP地址之后，User-Agent（一般是指浏览器）会以一个随机端口（1024 &lt; 端口 &lt; 65535）向服务器的WEB程序（常用的有httpd,nginx等）80端口发起TCP的连接请求。这个连接请求（原始的http请求经过TCP&#x2F;IP4层模型的层层封包）到达服务器端后（这中间通过各种路由设备，局域网内除外），进入到网卡，然后是进入到内核的TCP&#x2F;IP协议栈（用于识别该连接请求，解封包，一层一层的剥开），还有可能要经过Netfilter防火墙（属于内核的模块）的过滤，最终到达WEB程序（本文就以Nginx为例），最终建立了TCP&#x2F;IP的连接。 1） Client首先发送一个连接试探，ACK&#x3D;0 表示确认号无效，SYN &#x3D; 1 表示这是一个连接请求或连接接受报文，同时表示这个数据报不能携带数据，seq &#x3D; x 表示Client自己的初始序号（seq &#x3D; 0 就代表这是第0号包），这时候Client进入syn_sent状态，表示客户端等待服务器的回复 2） Server监听到连接请求报文后，如同意建立连接，则向Client发送确认。TCP报文首部中的SYN 和 ACK都置1 ，ack &#x3D; x + 1表示期望收到对方下一个报文段的第一个数据字节序号是x+1，同时表明x为止的所有数据都已正确收到（ack&#x3D;1其实是ack&#x3D;0+1,也就是期望客户端的第1个包），seq &#x3D; y 表示Server 自己的初始序号（seq&#x3D;0就代表这是服务器这边发出的第0号包）。这时服务器进入syn_rcvd，表示服务器已经收到Client的连接请求，等待client的确认。 3） Client收到确认后还需再次发送确认，同时携带要发送给Server的数据。ACK 置1 表示确认号ack&#x3D; y + 1 有效（代表期望收到服务器的第1个包），Client自己的序号seq&#x3D; x + 1（表示这就是我的第1个包，相对于第0个包来说的），一旦收到Client的确认之后，这个TCP连接就进入Established状态，就可以发起http请求了。 TCP 为什么需要3次握手？ 2个计算机通信是靠协议（目前流行的TCP&#x2F;IP协议）来实现,如果2个计算机使用的协议不一样，那是不能进行通信的，所以这个3次握手就相当于试探一下对方是否遵循TCP&#x2F;IP协议，协商完成后就可以进行通信了，当然这样理解不是那么准确。 为什么HTTP协议要基于TCP来实现？ 目前在Internet中所有的传输都是通过TCP&#x2F;IP进行的，HTTP协议作为TCP&#x2F;IP模型中应用层的协议也不例外，TCP是一个端到端的可靠的面向连接的协议，所以HTTP基于传输层TCP协议不用担心数据的传输的各种问题。 3.建立TCP连接后发起http请求一个HTTP请求报文由请求行（request line）、请求头部（header）、空行和请求数据4个部分组成 1) 请求行请求行分为三个部分：请求方法、请求地址和协议版本 请求方法： HTTP&#x2F;1.1 定义的请求方法有8种：GET、POST、PUT、DELETE、PATCH、HEAD、OPTIONS、TRACE。 GET: 完整请求一个资源 （常用） HEAD: 仅请求响应首部 POST：提交表单 （常用） PUT: (webdav) 上传文件（但是浏览器不支持该方法） DELETE：(webdav) 删除 OPTIONS：返回请求的资源所支持的方法的方法 TRACE: 追求一个资源请求中间所经过的代理（该方法不能由浏览器发出） 最常的两种GET和POST，如果是RESTful接口的话一般会用到GET、POST、DELETE、PUT。 请求地址： URL:统一资源定位符，是一种资源位置的抽象唯一识别方法。 组成：&lt;协议&gt;：&#x2F;&#x2F;&lt;主机&gt;：&lt;端口&gt;&#x2F;&lt;路径&gt; 端口和路径有时可以省略（HTTP默认端口号是80），GET请求可能会带参数 什么是URL、URI、URN？URI Uniform Resource Identifier 统一资源标识符。格式： scheme:&#x2F;&#x2F;[username:password@]HOST:port&#x2F;path&#x2F;to&#x2F;source URL Uniform Resource Locator 统一资源定位符格式： http://www.magedu.com/downloads/nginx-1.5.tar.gz URN Uniform Resource Name 统一资源名称 URL和URN 都属于 URI 协议版本： 协议版本的格式为：HTTP&#x2F;主版本号.次版本号 协议有： http&#x2F;0.9: stateless http&#x2F;1.0: MIME, keep-alive (保持连接), 缓存 http&#x2F;1.1: 更多的请求方法，更精细的缓存控制，持久连接(persistent connection) 比较常用 2) 请求头部请求头部为请求报文添加了一些附加信息，如token等，由“名&#x2F;值”对组成，每行一对，名和值之间使用冒号分隔。 请求头部的最后会有一个空行，表示请求头部结束，接下来为请求数据，这一行非常重要，必不可少。 下面是Chrome发起的http请求报文头部信息： Accept 就是告诉服务器端，我接受那些MIME类型 Accept-Encoding 这个看起来是接受那些压缩方式的文件 Accept-Lanague 告诉服务器能够发送哪些语言 Connection 告诉服务器支持keep-alive特性 Cookie 每次请求时都会携带上Cookie以方便服务器端识别是否是同一个客户端 Host 用来标识请求服务器上的那个虚拟主机，比如Nginx里面可以定义很多个虚拟主机，这里就是用来标识要访问那个虚拟主机。 User-Agent 用户代理，一般情况是浏览器，也有其他类型，如：wget curl 搜索引擎的蜘蛛等 条件请求首部： If-Modified-Since 是浏览器向服务器端询问某个资源文件如果自从什么时间修改过，那么重新发给我，这样就保证服务器端资源文件更新时，浏览器再次去请求，而不是使用缓存中的文件 安全请求首部： Authorization: 客户端提供给服务器的认证信息； 什么是MIME？ MIME（Multipurpose Internet Mail Extesions 多用途互联网邮件扩展）是一个互联网标准，它扩展了电子邮件标准，使其能够支持非ASCII字符、二进制格式附件等多种格式的邮件消息，这个标准被定义在RFC 2045、RFC 2046、RFC 2047、RFC 2048、RFC 2049等RFC中。 由RFC 822转变而来的RFC 2822，规定电子邮件标准并不允许在邮件消息中使用7位ASCII字符集以外的字符。正因如此，一些非英语字符消息和二进制文件，图像，声音等非文字消息都不能在电子邮件中传输。MIME规定了用于表示各种各样的数据类型的符号化方法。 此外，在万维网中使用的HTTP协议中也使用了MIME的框架，标准被扩展为互联网媒体类型。 MIME 遵循以下格式：major&#x2F;minor 主类型&#x2F;次类型 例如： 12345image/jpgimage/giftext/htmlvideo/quicktimeappliation/x-httpd-php 3) 请求数据可选部分，比如GET请求就没有请求数据。 下面是一个POST方法的请求报文：123456789101112POST /index.php HTTP/1.1 请求行 Host: localhost User-Agent: Mozilla/5.0 (Windows NT 5.1; rv:10.0.2) Gecko/20100101 Firefox/10.0.2 请求头 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8 Accept-Language: zh-cn,zh;q=0.5 Accept-Encoding: gzip, deflate Connection: keep-alive Referer: http://localhost/ Content-Length：25 Content-Type：application/x-www-form-urlencoded 空行 username=aa&amp;password=1234 请求数据4.服务器端响应http请求，浏览器得到html代码HTTP响应报文主要由状态行、响应头部、空行以及响应数据组成。 1)状态行由3部分组成，分别为：协议版本，状态码，状态码描述。 其中协议版本与请求报文一致，状态码描述是对状态码的简单描述，所以这里就只介绍状态码。 状态码 1xx: 信息性状态码 100, 101 2xx: 成功状态码 200 OK 请求成功。一般用于GET与POST请求 201 Created 已创建。成功请求并创建了新的资源 202 Accepted 已接受。已经接受请求，但未处理完成 3xx: 重定向状态码 301: 永久重定向, Location响应首部的值仍为当前URL，因此为隐藏重定向; 302: 临时重定向，显式重定向, Location响应首部的值为新的URL 304：Not Modified 未修改，比如本地缓存的资源文件和服务器上比较时，发现并没有修改，服务器返回一个304状态码， 告诉浏览器，你不用请求该资源，直接使用本地的资源即可。 4xx: 客户端错误状态码 400：Bad Request 客户端请求的语法错误，服务器无法理解 401：Unauthorized 请求要求用户的身份认证 403：Forbidden 服务器理解请求客户端的请求，但是拒绝执行此请求 404: Not Found 请求的URL资源并不存在 5xx: 服务器端错误状态码 500: Internal Server Error 服务器内部错误 501：Not Implemented 服务器不支持请求的功能，无法完成请求 502: Bad Gateway 前面代理服务器联系不到后端的服务器时出现 504：Gateway Timeout 这个是代理能联系到后端的服务器，但是后端的服务器在规定的时间内没有给代理服务器响应 2.响应头部与请求头部类似，为响应报文添加了一些附加信息 3.响应数据用于存放需要返回给客户端的数据信息。 Connection 使用keep-alive特性 Content-Encoding 使用gzip方式对资源压缩 Content-type MIME类型为html类型，字符集是 UTF-8 Date 响应的日期 Server 使用的WEB服务器 Transfer-Encoding:chunked 分块传输编码 是http中的一种数据传输机制，允许HTTP由网页服务器发送给客户端应用（通常是网页浏览器）的数据可以分成多个部分，分块传输编码只在HTTP协议1.1版本（HTTP&#x2F;1.1）中提供 Vary 这个可以参考（http://blog.csdn.NET/tenfyguo/article/details/5939000） X-Pingback 参考（http://blog.sina.com.cn/s/blog_bb80041c0101fmfz.html） 那到底服务器端接收到http请求后是怎么样生成html文件？ 假设服务器端使用nginx+PHP(fastcgi)架构提供服务 ① nginx读取配置文件 我们在浏览器的地址栏里面输入的是 http://www.linux178.com （http:&#x2F;&#x2F;可以不用输入，浏览器会自动帮我们添加），其实完整的应该是http://www.linux178.com./ 后面还有个点（这个点代表就是根域，一般情况下我们不用输入，也不显示）,后面的&#x2F;也是不用添加，浏览器会自动帮我们添加（且看第3部那个图里面的URL），那么实际请求的URL是http://www.linux178.com/，那么好了Nginx在收到 浏览器 GET &#x2F; 请求时，会读取http请求里面的头部信息，根据Host来匹配 自己的所有的虚拟主机的配置文件的server_name,看看有没有匹配的，有匹配那么就读取该虚拟主机的配置，发现如下配置： 1root /web/echo 通过这个就知道所有网页文件的就在这个目录下 这个目录就是&#x2F; 当我们http://www.linux178.com/时就是访问这个目录下面的文件，例如访问http://www.linux178.com/index.html,那么代表/web/echo下面有个文件叫index.html 1index index.html index.htm index.php 通过这个就能得知网站的首页文件是那个文件，也就是我们在入http://www.linux178.com/ ，nginx就会自动帮我们把index.html（假设首页是index.php 当然是会尝试的去找到该文件，如果没有找到该文件就依次往下找，如果这3个文件都没有找到，那么就抛出一个404错误）加到后面，那么添加之后的URL是&#x2F;index.php,然后根据后面的配置进行处理 1234567location ~ .*\\.php(\\/.*)*$ &#123; root /web/echo; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; astcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params;&#125; 这一段配置指明凡是请求的URL中匹配（这里是启用了正则表达式进行匹配） *.php后缀的（后面跟的参数）都交给后端的fastcgi进程进行处理。 ② 把php文件交给fastcgi进程去处理于是nginx把&#x2F;index.php这个URL交给了后端的fastcgi进程处理，等待fastcgi处理完成后（结合数据库查询出数据，填充模板生成html文件）返回给nginx一个index.html文档，Nginx再把这个index.html返回给浏览器，于是乎浏览器就拿到了首页的html代码，同时nginx写一条访问日志到日志文件中去。 注1：nginx是怎么找index.php文件的？ 当nginx发现需要&#x2F;web&#x2F;echo&#x2F;index.php文件时，就会向内核发起IO系统调用(因为要跟硬件打交道，这里的硬件是指硬盘，通常需要靠内核来操作，而内核提供的这些功能是通过系统调用来实现的)，告诉内核，我需要这个文件,内核从&#x2F;开始找到web目录，再在web目录下找到echo目录，最后在echo目录下找到index.php文件，于是把这个index.php从硬盘上读取到内核自身的内存空间，然后再把这个文件复制到nginx进程所在的内存空间，于是乎nginx就得到了自己想要的文件了。 注2：寻找文件在文件系统层面是怎么操作的？ 比如nginx需要得到&#x2F;web&#x2F;echo&#x2F;index.php这个文件 每个分区（像ext3 ext3等文件系统，block块是文件存储的最小单元 默认是4096字节）都是包含元数据区和数据区，每一个文件在元数据区都有元数据条目（一般是128字节大小），每一个条目都有一个编号，我们称之为inode（index node 索引节点），这个inode里面包含 文件类型、权限、连接次数、属主和数组的ID、时间戳、这个文件占据了那些磁盘块也就是块的编号（block，每个文件可以占用多个block,并且block不一定是连续的，每个block是有编号的），如下图所示： 还有一个要点：目录其实也普通是文件，也需要占用磁盘块，目录不是一个容器。你看默认创建的目录就是4096字节，也就说只需要占用一个磁盘块，但这是不确定的。所以要找到目录也是需要到元数据区里面找到对应的条目，只有找到对应的inode就可找到目录所占用的磁盘块。 那到底目录里面存放着什么，难道不是文件或者其他目录吗？ 其实目录存着这么一张表（姑且这么理解），里面放着 目录或者文件的名称和对应的inode号（暂时称之为映射表）,如 文件名 innode号 test1.txt 100 test2.txt 101 假设 &#x2F; 在数据区占据 1、2号block ，&#x2F;其实也是一个目录 里面有3个目录 web 111 web 占据 5号block 是目录 里面有2个目录 echo data echo 占据 11号 block 是目录 里面有1个文件 index.php index.php 占据 15 16号 block 是文件 其在文件系统中分布如下图所示 那么内核究竟是怎么找到index.php这个文件的呢？ 内核拿到nginx的IO系统调用要获取&#x2F;web&#x2F;echo&#x2F;index.php这个文件请求之后 ① 内核读取元数据区 &#x2F; 的inode，从inode里面读取&#x2F;所对应的数据块的编号，然后在数据区找到其对应的块（1 2号块），读取1号块上的映射表找到web这个名称在元数据区对应的inode号 ② 内核读取web对应的inode（3号），从中得知web在数据区对应的块是5号块，于是到数据区找到5号块，从中读取映射表，知道echo对应的inode是5号，于是到元数据区找到5号inode ③ 内核读取5号inode，得到echo在数据区对应的是11号块，于是到数据区读取11号块得到映射表，得到index.php对应的inode是9号 ④ 内核到元数据区读取9号inode，得到index.php对应的是15和16号数据块，于是就到数据区域找到15 16号块，读取其中的内容，得到index.php的完整内容 5. 浏览器解析html代码，并请求html代码中的资源浏览器拿到index.html文件后，就开始解析其中的html代码，遇到js&#x2F;css&#x2F;image等静态资源时，就向服务器端去请求下载（会使用多线程下载，每个浏览器的线程数不一样），这个时候就用上keep-alive特性了，建立一次HTTP连接，可以请求多个资源，下载资源的顺序就是按照代码里的顺序，但是由于每个资源大小不一样，而浏览器又多线程请求请求资源，所以从下图看出，这里显示的顺序并不一定是代码里面的顺序。 浏览器在请求静态资源时（在未过期的情况下），向服务器端发起一个http请求（询问自从上一次修改时间到现在有没有对资源进行修改），如果服务器端返回304状态码（告诉浏览器服务器端没有修改），那么浏览器会直接读取本地的该资源的缓存文件。 详细的浏览器工作原理请看：http://kb.cnblogs.com/page/129756/ 6.浏览器对页面进行渲染呈现给用户最后，浏览器利用自己内部的工作机制，把请求到的静态资源和html代码进行渲染，渲染之后呈现给用户。 自此一次完整的HTTP事务宣告完成. 本文出自 “雷纳科斯的博客” 博客，转载自http://linux5588.blog.51cto.com/65280/1351007","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"一次完整的HTTP请求过程【转】","slug":"一次完整的HTTP请求过程【转】","permalink":"https://tianxiafeiyu.github.io/tags/%E4%B8%80%E6%AC%A1%E5%AE%8C%E6%95%B4%E7%9A%84HTTP%E8%AF%B7%E6%B1%82%E8%BF%87%E7%A8%8B%E3%80%90%E8%BD%AC%E3%80%91/"}]},{"title":"各种语言版本的 Helloworld","slug":"技术开发/grocery/各种语言版本的 Helloworld","date":"2022-12-15T23:10:53.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/各种语言版本的 Helloworld/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/%E5%90%84%E7%A7%8D%E8%AF%AD%E8%A8%80%E7%89%88%E6%9C%AC%E7%9A%84%20Helloworld/","excerpt":"","text":"接触过C、C++、Java、C#、Python、Go，自认为接触过的编程语言很多了，那么各种语言的经典程序 Hello World 都是什么样的呢？ C1234567#include &lt;stdio.h&gt;void main()&#123; printf(&quot;Hello,World!&quot;); return (0);&#125; C++123456#include &lt;iostream&gt;using namespace std;void main() &#123; cout &lt;&lt; &quot;Hello,World!\\n&quot;;&#125; Java12345public class Helloworld &#123; public static void main(String[] args) &#123; System.out.println(&quot;Hello,World!&quot;); &#125;&#125; C#123456789101112using System;using System.Collections.Generic;using System.Linq;using System.Text;using System.Threading.Tasks;namespace log&#123; class helloworld&#123; static void Main(string[] args)&#123; Console.WriteLine(&quot;Hello,World!&quot;); &#125; &#125;&#125; PythonPython2.x 1print &quot;Hello,World!&quot; Python3.x 1print(&quot;Hello,World!&quot;) Go12345package mainimport &quot;fmt&quot;func main()&#123; fmt.Printf(&quot;Hello,World!\\n&quot;);&#125; Javascript1console.log(&quot;Hello,World!&quot;);","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"各种语言版本的 Helloworld","slug":"各种语言版本的-Helloworld","permalink":"https://tianxiafeiyu.github.io/tags/%E5%90%84%E7%A7%8D%E8%AF%AD%E8%A8%80%E7%89%88%E6%9C%AC%E7%9A%84-Helloworld/"}]},{"title":"服务缓存数据更新","slug":"技术开发/grocery/服务缓存数据更新","date":"2022-12-15T23:10:53.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/服务缓存数据更新/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/%E6%9C%8D%E5%8A%A1%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E6%9B%B4%E6%96%B0/","excerpt":"","text":"内存缓存作为最方便的提升效率的手段，很多程序都有使用到。 缓存痛点： 内存占用 缓存一致性 缓存并发 怎么解决时效性，保证缓存能够及时更新： 更新方法： 定时更新 动态更新","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"服务缓存数据更新","slug":"服务缓存数据更新","permalink":"https://tianxiafeiyu.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E6%9B%B4%E6%96%B0/"}]},{"title":"使用github搭建个人博客","slug":"技术开发/grocery/使用github搭建个人博客","date":"2022-12-15T23:06:36.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/15/技术开发/grocery/使用github搭建个人博客/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/15/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/%E4%BD%BF%E7%94%A8github%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"看到一篇文章 GitHub Pages + Hexo 搭建个人博客，感觉效果不错 想当年，自己也曾用阿里云+spring boot搭建过个人博客，不过后面也是不了了之（甚至服务器到期都懒得去看了~~），现在有这个白嫖的方案怎么能错过呢 今天晚上下班就开整 关于 github pagesGitHub Pages 是一项静态站点托管服务，它直接从 GitHub 上的仓库获取 HTML、CSS 和 JavaScript 文件，然后来解析他们，发布服务。 类型有三种类型的 GitHub Pages 站点：项目、用户和组织。&amp;#x20; 项目站点连接到 GitHub 上托管的特定项目，例如 JavaScript 库或配方集合。 若要发布用户站点，必须创建名为 &lt;username&gt;.github.io 的个人帐户拥有的存储库。 若要发布组织站点，必须创建名为 &lt;organization&gt;.github.io 的组织帐户拥有的存储库。 除非使用的是自定义域，否则用户和组织站点在 http(s)://&lt;username&gt;.github.io 或 http(s)://&lt;organization&gt;.github.io 中可用。 项目站点的源文件与其项目存储在同一个仓库中。 除非使用的是自定义域，否则项目站点在 http(s)://&lt;username&gt;.github.io/&lt;repository&gt; 或 http(s)://&lt;organization&gt;.github.io/&lt;repository&gt; 中可用。 GitHub 上的每个帐户创建一个用户或组织站点。 项目站点（无论是组织还是个人帐户拥有）没有限制。 发布GitHub Pages 会发布您推送到仓库的任何静态文件。 您可以创建自己的静态文件或使用静态站点生成器为您构建站点。 您还可以在本地或其他服务器上自定义自己的构建过程。 如果使用自定义生成过程或 Jekyll 以外的静态站点生成器，可以编写 GitHub Actions 来生成和发布站点。 使用限制GitHub Pages 站点受到以下使用限制的约束： GitHub Pages 源存储库的建议限制为 1 GB。 发布的 GitHub Pages 站点不得超过 1 GB。 GitHub Pages 站点的软带宽限制为每月 100 GB。 GitHub Pages 站点的软限制为每小时 10 次生成。 如果使用自定义 GitHub Actions 工作流生成和发布站点，则此限制不适用 为了为所有 GitHub Pages 站点提供一致的服务质量，可能会实施速率限制。 这些速率限制无意干扰 GitHub Pages 的合法使用。 如果你的请求触发了速率限制，你将收到相应响应，其中包含 HTTP 状态代码 429 以及信息性 HTML 正文。 关于HexoHexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 详细信息可阅读官方文档：https://hexo.io/zh-cn/docs/ 主题我比较喜欢简洁的主题，这里选用我比较心水的一个主题，类wiki风格，非常的简洁和好用 https://github.com/zthxxx/hexo-theme-Wikitten/blob/master/README_zh-CN.md https://github.com/Norcy/wiki/tree/HexoBackup/themes/Wikitten 插件hexo插件推荐：https://blog.csdn.net/qq_43701912/article/details/107310923 一些使用心得如何发布文章 使用github.dev，在仓库页面按下键盘 . 进入，或者仓库地址 .com 改为 .dev 进入 ,是一个在线vscode编辑器 本地修改新增md文件后push &amp;#x20;参考资料 GitHub Pages + Hexo搭建个人博客网站，史上最全教程 GitHub Pages Docs Hexo官方文档 Wikitten","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"使用github搭建个人博客","slug":"使用github搭建个人博客","permalink":"https://tianxiafeiyu.github.io/tags/%E4%BD%BF%E7%94%A8github%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"}]},{"title":"keep","slug":"生活点滴/keep","date":"2022-12-13T23:43:17.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/13/生活点滴/keep/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/13/%E7%94%9F%E6%B4%BB%E7%82%B9%E6%BB%B4/keep/","excerpt":"","text":"","categories":[{"name":"生活点滴","slug":"生活点滴","permalink":"https://tianxiafeiyu.github.io/categories/%E7%94%9F%E6%B4%BB%E7%82%B9%E6%BB%B4/"}],"tags":[{"name":"keep","slug":"keep","permalink":"https://tianxiafeiyu.github.io/tags/keep/"}]},{"title":"为什么bk-cmdb不用go mod管理","slug":"技术开发/golang/为什么bk-cmdb不用go mod管理","date":"2022-12-13T23:43:08.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/13/技术开发/golang/为什么bk-cmdb不用go mod管理/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/13/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/%E4%B8%BA%E4%BB%80%E4%B9%88bk-cmdb%E4%B8%8D%E7%94%A8go%20mod%E7%AE%A1%E7%90%86/","excerpt":"","text":"项目地址 https://github.com/Tencent/bk-cmdb 为什么不用官方推荐的 go mod 管理依赖呢？ bk-cmdb vendor下的一些依赖库都是有修改过的： vendor&#x2F;go.mongodb.org&#x2F;mongo-driver&#x2F;mongo&#x2F;session_exposer.go12345678910111213141516// CmdbPrepareCommitOrAbort set state to InProgress, so that we can commit with other// operation directly. otherwise mongodriver will do a false commitfunc CmdbPrepareCommitOrAbort(sess Session) &#123; i, ok := sess.(*sessionImpl) if !ok &#123; panic(&quot;the session is not type *sessionImpl&quot;) &#125; i.clientSession.SetState(2) i.didCommitAfterStart=false&#125;// CmdbContextWithSession set the session into context if context includes session infofunc CmdbContextWithSession(ctx context.Context, sess Session) SessionContext &#123; return contextWithSession(ctx, sess)&#125; 在mongo driver中添加了CmdbPrepareCommitOrAbort、 CmdbReloadSessio等方法 这些在官方库是没有的，如果切换 go mod,从官方源获取依赖，肯定是不行的 issue：https://github.com/Tencent/bk-cmdb/issues/4748 如果将修改后的官方库上传到github，应该可以解决go mod难切换的问题 会不会有版权问题？ 所以，尽量不要修改官方库","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"golang","slug":"技术开发/golang","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/"}],"tags":[{"name":"为什么bk-cmdb不用go mod管理","slug":"为什么bk-cmdb不用go-mod管理","permalink":"https://tianxiafeiyu.github.io/tags/%E4%B8%BA%E4%BB%80%E4%B9%88bk-cmdb%E4%B8%8D%E7%94%A8go-mod%E7%AE%A1%E7%90%86/"}]},{"title":"Java8新特性","slug":"技术开发/java/Java8新特性","date":"2022-12-13T23:42:27.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/13/技术开发/java/Java8新特性/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/13/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/Java8%E6%96%B0%E7%89%B9%E6%80%A7/","excerpt":"","text":"Java8新特性 （转载自https://www.runoob.com/java/java8-new-features.html，具体内容见链接，非常详细实用） Java 8 (又称为 jdk 1.8) 是 Java 语言开发的一个主要版本。 Oracle 公司于 2014 年 3 月 18 日发布 Java 8 ，它支持函数式编程，新的 JavaScript 引擎，新的日期 API，新的Stream API 等。 Java8 新增了非常多的特性，我们主要讨论以下几个： Lambda 表达式 − Lambda 允许把函数作为一个方法的参数（函数作为参数传递到方法中）。 方法引用 − 方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。 默认方法 − 默认方法就是一个在接口里面有了一个实现的方法。 新工具 − 新的编译工具，如：Nashorn引擎 jjs、 类依赖分析器jdeps。 Stream API −新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。 Date Time API − 加强对日期与时间的处理。 Optional 类 − Optional 类已经成为 Java 8 类库的一部分，用来解决空指针异常。 Nashorn, JavaScript 引擎 − Java 8提供了一个新的Nashorn javascript引擎，它允许我们在JVM上运行特定的javascript应用。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"}],"tags":[{"name":"Java8新特性","slug":"Java8新特性","permalink":"https://tianxiafeiyu.github.io/tags/Java8%E6%96%B0%E7%89%B9%E6%80%A7/"}]},{"title":"进程间通信技术","slug":"技术开发/grocery/进程间通信技术","date":"2022-12-13T23:42:07.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/13/技术开发/grocery/进程间通信技术/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/13/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/","excerpt":"","text":"转自 https://my.oschina.net/taogang/blog/4313908 最早在Unix&#x2F;Linux的编程领域，提供了进程间通信的手段，例如：管道，信号量，消息队列，套接字（Socket）等。如果你的应用是由不同语言编写的，那么这里只能选择Socket通信作为应用之间的API手段。但是Socket通信是一种非常低Level的通信手段，它以底层的数据包作为抽象和通信内容，很难维护和使用。 早期的进程间通信技术包括： DCOM （ Distributed Component Object Model ）分布式组件对象模型，这个是微软的技术，只能用于Windows平台， 通过网络实现远程对象间的通信 RMI （ Remote Method Call) Java的远程方法调用，这个是Java自己的RPC，只能用于Java应用之间的远程调用。 JNI Java的本地接口， 支持Java应用调用本地方法，这个是跨越语言障碍的，但是仅仅局限于Java应用调用其它的本地应用，不具备互操作性，是个单项通道。 CORBA1991年一种名叫CORBA （ Common Object Request Broker Architecture ） 的技术出现。 CORBA和之前提到的DCOM和RMI类似，都提供了远程的对象&#x2F;方法调用，但是CORBA是一种与语言和实现无关的技术 CORBA定了与语言解耦的系统间通信的标准。开发CORAB的过程从IDL的定义开始，用户通过IDL定义了对象，然后在Server端实现该对象的应用逻辑，在Client端调用该对象。 CORBA存在的主要问题： 对象的生命周期管理比较复杂。远程对象的发现，创建和销毁都会带来问题 整个CORAB的架构比较复杂 XML-RPC &#x2F; SOAPXML-RPC发表于1998年，由UserLand Software（UserLand Software）的Dave Winer及Microsoft共同发表。后来在新的功能不断被引入下，这个标准慢慢演变成为今日的SOAP协议。 下面是一个 XML-RPC的请求&#x2F;响应的例子： 123456789101112131415161718&lt;?xml version=&quot;1.0&quot;?&gt;&lt;methodCall&gt; &lt;methodName&gt;examples.getStateName&lt;/methodName&gt; &lt;params&gt; &lt;param&gt; &lt;value&gt;&lt;i4&gt;40&lt;/i4&gt;&lt;/value&gt; &lt;/param&gt; &lt;/params&gt;&lt;/methodCall&gt;&lt;?xml version=&quot;1.0&quot;?&gt;&lt;methodResponse&gt; &lt;params&gt; &lt;param&gt; &lt;value&gt;&lt;string&gt;South Dakota&lt;/string&gt;&lt;/value&gt; &lt;/param&gt; &lt;/params&gt;&lt;/methodResponse&gt; SOAP是 Simple Object Access Protocol 的缩写。SOAP为Web服务提供了Web服务协议栈的Messaging Protocol层。它是一个基于XML的协议，由三部分组成： 一个信封，它定义了消息结构以及如何处理它 一组用于表达应用程序定义的数据类型实例的编码规则 表示过程调用和响应的约定 SOAP具有三个主要特征： 可扩展性（安全性和WS-Addressing在开发中） 中立性（SOAP可以通过HTTP，SMTP，TCP，UDP等任何协议进行操作） 独立性（SOAP允许任何编程语言） 作为SOAP过程可以执行的操作的示例，应用程序可以将SOAP请求发送到启用了带有搜索参数的Web服务的服务器（例如，房地产价格数据库）。然后，服务器返回SOAP响应（包含结果数据的XML格式的文档），例如价格，位置，功能。由于生成的数据采用标准化的机器可解析格式，因此发出请求的应用程序可以直接将其集成。 SOAP体系结构由以下几层规范组成： 讯息格式 邮件交换模式（MEP） 底层传输协议绑定 消息处理模型 协议可扩展性 下面是一个SOAP消息的例子： 12345678910111213141516POST /InStock HTTP/1.1Host: www.example.orgContent-Type: application/soap+xml; charset=utf-8Content-Length: 299SOAPAction: &quot;http://www.w3.org/2003/05/soap-envelope&quot;&lt;?xml version=&quot;1.0&quot;?&gt;&lt;soap:Envelope xmlns:soap=&quot;http://www.w3.org/2003/05/soap-envelope&quot; xmlns:m=&quot;http://www.example.org&quot;&gt; &lt;soap:Header&gt; &lt;/soap:Header&gt; &lt;soap:Body&gt; &lt;m:GetStockPrice&gt; &lt;m:StockName&gt;T&lt;/m:StockName&gt; &lt;/m:GetStockPrice&gt; &lt;/soap:Body&gt;&lt;/soap:Envelope&gt; 相比较XML-RPC，他的功能更多，当然消息结构也更复杂。 SOAP是W3C推荐的Webservice标准，一度也是非常的流行，但是我们看到基于XML的消息比较复杂，消息本身因为XML的原因，有相当多的开销。于是后面又有了基于JSON的RPC格式。但总的来说，SOAP也已经是昨日黄花，当今的应用构建，你选它的概率应该也不大了。 RESTREST是当今最为流行的API。因为大量的Web应用采用REST作为其API的选择。REST是 Representational State Transfer 的缩写。是Roy Thomas Fielding博士于2000年在他的博士论文中提出来的一种万维网软件架构风格，目的是便于不同软件&#x2F;程序在网络（例如互联网）中互相传递信息。表现层状态转换是根基于超文本传输协议（HTTP）之上而确定的一组约束和属性，是一种设计提供万维网络服务的软件构建风格。符合或兼容于这种架构风格（简称为 REST 或 RESTful）的网络服务，允许客户端发出以统一资源标识符访问和操作网络资源的请求，而与预先定义好的无状态操作集一致化。因此表现层状态转换提供了在互联网络的计算系统之间，彼此资源可交互使用的协作性质（interoperability）。相对于其它种类的网络服务，例如SOAP服务，则是以本身所定义的操作集，来访问网络上的资源。目前在三种主流的Web服务实现方案中，因为REST模式与复杂的SOAP和XML-RPC相比更加简洁，越来越多的Web服务开始采用REST风格设计和实现。所以我么可以看到软件的发展，大体是从复杂变得简单，只有简单的东西才会变的更有生命力。 为了使任何应用程序真正实现RESTful，必须遵循六个体系结构约束： 统一接口：意味着必须向Web应用程序中的API使用者提供API接口。 客户端服务器：客户端和服务器必须彼此独立，并且客户端应仅知道资源的URI。 无状态：服务器不得存储与客户端请求相关的任何内容。 客户端负责维护应用程序的状态。 可缓存的：资源必须可缓存。 分层系统：体系结构必须是分层的，这意味着体系结构的组件可以位于多个服务器中。 按需代码：客户端必须能够获取可执行代码作为响应。 这是一个可选约束。 基于REST的Web服务被称为RESTful Web服务。 在这些应用程序中，每个组件都是一种资源，可以使用HTTP标准方法通过公共接口访问这些资源。 以下四种HTTP方法通常用于基于REST的体系结构中： GET-对资源的只读访问。 POST —创建一个新资源。 DELETE—删除资源。 PUT-更新现有资源&#x2F;创建新资源。 RESTFul风格API所有的操作都是一个动词，对应HTTP请求的一种类型。每一个操作都定义了对操作的资源的某种行为。这种抽象，特别适合相当多的Web应用，后台是一个数据库，每一个REST的端点对应了一张数据库的表，很自然的利用REST操作来实现表的增删查改。 当然RESTFul的风格也有它的不足： 不是所有的应用操作都可以用资源的增删查改来对应，在实际的开发中经常会需要把一个操作映射为一个资源这种不伦不类的行为。 REST是同步服务，如果需要可能要引入回调机制。例如Webhook。 REST只提供客户端调用服务器的选项，不支持服务器端发起请求。 GraphQLGraphQL是一个开源的API数据查询和操作语言及实现为了实现上述操作的相应运行环境。 2012年，GraphQL由Facebook内部开发，2015年公开公布。 2018年11月7日，Facebook将GraphQL项目转移到新成立的GraphQL基金会 。 GraphQL规范概述了5条设计原则，这使其成为现代前端开发的精心设计的解决方案: 查询是分层结构的，具有分层和嵌套字段，查询与响应数据一对一匹配。 查询和响应的形状像树，可以查询每个项目的其他嵌套字段。 该结构以产品为中心，着重于前端希望如何接收数据，并构建交付所需的运行时。 这样一来，就可以向后端请求一个所需的所有数据，然后让服务器根据GraphQL的规范从不同的端点获取数据。 它使用特定于应用程序的类型系统，使开发人员能够确保查询使用有效类型，并且在执行之前在语法上正确。 GraphQL查询是在客户端指定的，因此客户端确切知道它将以什么格式接收数据。 带有GraphQL的服务器结构必须是自省的，或者可由GraphQL本身查询。 这将启用功能强大的开发人员工具，例如GraphiQL或GraphQL Playground，这两种工具都将使开发人员能够准确查看哪些查询和字段可供他们在服务器中使用。 像RESTful API一样，GraphQL API旨在处理HTTP请求并提供对这些请求的响应。 但是，相似之处到此结束。 在REST API建立在请求方法和端点之间的连接上的情况下，GraphQL API设计为仅使用一个始终通过POST请求查询的端点，通常使用URL yourdomain.com&#x2F;graphql。 达到GraphQL端点后，客户端请求的负担将完全在请求主体内处理。 该请求主体必须遵守GraphQL规范，并且API必须具有适当的服务器端逻辑来处理这些请求并提供适当的响应。 与RESTful API相比，这提供了更流畅的客户端体验，后者可能要求客户端对多个数据进行多次请求，并在数据返回后进行操作。 GraphQL提供的性能优于REST API，可以为前端开发人员带来回报。 使用GraphQL规范创建服务器可能需要更多设置和编写预测性服务器端逻辑来解析和处理请求。 尽管GraphQL的安装成本可能会高于传统的REST架构，但更具可维护性的代码，强大的开发工具以及简化的客户端查询，这些都是不错的收益。 除了灵活性这个最大的优点外，GraphQL还有以下的优点： 声明性的数据获取，避免了客户端和服务器端的额外交互 优秀的开发体验，不需要版本控制，因为引入新的字段不会影响到API查询。同时客户端和服务器端的团队可以并行的独立工作。 强类型的GraphQL模式使得代码可预测，并及早发现错误。 当然，GraphQL也不是没有缺点： 使用GraphQL，如果您需要查找有关列表或记录集合的信息，则处理起来会很棘手。 例如，如果您想获取包含其地址的用户列表的详细信息，则它将执行n + 1个查询。 一个用于用户列表，然后n查询每个用户的地址。现在它会严重影响性能，因此必须非常小心地处理它。 很难缓存，缓存API响应的目的主要是为了更快地从将来的请求中获取响应。 与GraphQL不同，RESTful API可以利用HTTP规范中内置的缓存。 正如前面提到的，GraphQL查询可以请求资源的任何字段，因此缓存本质上是困难的。 gRPCgRPC是一个开源的远程过程调用框架，用于在服务之间进行高性能的通信。 这是将以不同语言编写的服务与可插拔支持（用于负载平衡，跟踪，运行状况检查和身份验证）相连接的有效方法。 默认情况下，gRPC使用Protobuf（协议缓冲区）序列化结构化数据。 通常，对于微服务体系结构，gRPC被认为是REST协议的更好替代方案。 gRPC中的” g”可以归因于最初开发该技术的Google。 gRPC是对传统RPC框架的改编。 那么，它与现有的RPC框架有何不同？ 最重要的区别是gRPC使用protobuf 协议缓冲区作为接口定义语言进行序列化和通信，而不是JSON &#x2F; XML。 协议缓冲区可以描述数据的结构，并且可以从该描述中生成代码，以生成或解析表示结构化数据的字节流。 这就是为什么gRPC首选多语言（使用不同技术实现）的Web应用程序的原因。 二进制数据格式使通信更轻松。 gRPC也可以与其他数据格式一起使用，但是首选的是protobuf。 同样，gRPC建立在HTTP &#x2F; 2之上，它支持双向通信以及传统的请求&#x2F;响应。 gRPC允许服务器和客户端之间的松散耦合。 在实践中，客户端打开与gRPC服务器的长期连接，并且将为每个RPC调用打开一个新的HTTP &#x2F; 2流。 与使用JSON（主要是JSON）的REST不同，gRPC使用Protobuf，这是编码数据的更好方法。 由于JSON是基于文本的格式，因此它比protobuf格式的压缩数据要重得多。与REST相比，gRPC的另一个显着改进是它使用HTTP 2作为其传输协议。 REST使用的HTTP 1.1基本上是一个请求-响应模型。 gRPC利用HTTP 2的双向通信功能以及传统的响应请求结构。 在HTTP 1.1中，当多个请求来自多个客户端时，它们将被一一处理。 这会降低系统速度。 HTTP 2允许多路复用，因此可以同时处理多个请求和响应。 gRPC的开发模式和之前提到的CORBA有些类似。Protobuf充当了IDL的角色，然后利用工具生成各种语言的代码，最后在生成的代码上实现服务器端和客户端的逻辑。 gRPC的优点是： 出色的性能，因为采用protobuf编码和http&#x2F;2 支持服务器端和客户端的双向通信 易用，相比REST开发，需要更少的代码 缺点： 更陡峭的学习曲线 支持的语言的种类没有REST多，当然它还在发展中 因为需要Protobuf的编译，这带来了服务器和客户端一定的耦合，因为接口变动的时候需要重新编译生成代码。REST的化，基于不同的工具链可能由不同的解决方案 因为其高性能，gRPC更适合被用于系统内部组件的通信选择。比如微服务架构中，对外的服务采用了REST或者GraphQL的API，而内部微服务之间使用的是gRPC。","categories":[{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"}],"tags":[{"name":"进程间通信技术","slug":"进程间通信技术","permalink":"https://tianxiafeiyu.github.io/tags/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/"}]},{"title":"life is strange","slug":"index","date":"2022-12-13T12:38:56.000Z","updated":"2022-12-16T21:36:16.000Z","comments":true,"path":"2022/12/13/index/","link":"","permalink":"https://tianxiafeiyu.github.io/2022/12/13/index/","excerpt":"","text":"","categories":[],"tags":[{"name":"index","slug":"index","permalink":"https://tianxiafeiyu.github.io/tags/index/"}]}],"categories":[{"name":"生活点滴","slug":"生活点滴","permalink":"https://tianxiafeiyu.github.io/categories/%E7%94%9F%E6%B4%BB%E7%82%B9%E6%BB%B4/"},{"name":"技术开发","slug":"技术开发","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/"},{"name":"database","slug":"技术开发/database","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/"},{"name":"grocery","slug":"技术开发/grocery","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/grocery/"},{"name":"es","slug":"技术开发/database/es","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/database/es/"},{"name":"java","slug":"技术开发/java","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/java/"},{"name":"os","slug":"技术开发/os","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/os/"},{"name":"html","slug":"技术开发/html","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/html/"},{"name":"python","slug":"技术开发/python","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/"},{"name":"Script","slug":"技术开发/python/Script","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/python/Script/"},{"name":"golang","slug":"技术开发/golang","permalink":"https://tianxiafeiyu.github.io/categories/%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91/golang/"}],"tags":[{"name":"每日游戏报告（2023-06-15）","slug":"每日游戏报告（2023-06-15）","permalink":"https://tianxiafeiyu.github.io/tags/%E6%AF%8F%E6%97%A5%E6%B8%B8%E6%88%8F%E6%8A%A5%E5%91%8A%EF%BC%882023-06-15%EF%BC%89/"},{"name":"使用Fillder抓包安卓APP","slug":"使用Fillder抓包安卓APP","permalink":"https://tianxiafeiyu.github.io/tags/%E4%BD%BF%E7%94%A8Fillder%E6%8A%93%E5%8C%85%E5%AE%89%E5%8D%93APP/"},{"name":"深入浅出设计模式","slug":"深入浅出设计模式","permalink":"https://tianxiafeiyu.github.io/tags/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"cpu加压脚本","slug":"cpu加压脚本","permalink":"https://tianxiafeiyu.github.io/tags/cpu%E5%8A%A0%E5%8E%8B%E8%84%9A%E6%9C%AC/"},{"name":"Prometheus监控kubernetes方案及实现","slug":"Prometheus监控kubernetes方案及实现","permalink":"https://tianxiafeiyu.github.io/tags/Prometheus%E7%9B%91%E6%8E%A7kubernetes%E6%96%B9%E6%A1%88%E5%8F%8A%E5%AE%9E%E7%8E%B0/"},{"name":"Elasticsearch学习","slug":"Elasticsearch学习","permalink":"https://tianxiafeiyu.github.io/tags/Elasticsearch%E5%AD%A6%E4%B9%A0/"},{"name":"websocket学习","slug":"websocket学习","permalink":"https://tianxiafeiyu.github.io/tags/websocket%E5%AD%A6%E4%B9%A0/"},{"name":"交换机端口标识含义","slug":"交换机端口标识含义","permalink":"https://tianxiafeiyu.github.io/tags/%E4%BA%A4%E6%8D%A2%E6%9C%BA%E7%AB%AF%E5%8F%A3%E6%A0%87%E8%AF%86%E5%90%AB%E4%B9%89/"},{"name":"基于etcd实现的分布式锁","slug":"基于etcd实现的分布式锁","permalink":"https://tianxiafeiyu.github.io/tags/%E5%9F%BA%E4%BA%8Eetcd%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"name":"数据结构与算法---常见算法减治、分治、递归、迭代、回溯、动态规划、贪心的基本思想【转】","slug":"数据结构与算法-常见算法减治、分治、递归、迭代、回溯、动态规划、贪心的基本思想【转】","permalink":"https://tianxiafeiyu.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95%E5%87%8F%E6%B2%BB%E3%80%81%E5%88%86%E6%B2%BB%E3%80%81%E9%80%92%E5%BD%92%E3%80%81%E8%BF%AD%E4%BB%A3%E3%80%81%E5%9B%9E%E6%BA%AF%E3%80%81%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E3%80%81%E8%B4%AA%E5%BF%83%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3%E3%80%90%E8%BD%AC%E3%80%91/"},{"name":"火焰图怎么看","slug":"火焰图怎么看","permalink":"https://tianxiafeiyu.github.io/tags/%E7%81%AB%E7%84%B0%E5%9B%BE%E6%80%8E%E4%B9%88%E7%9C%8B/"},{"name":"PriorityQueue-优先级队列","slug":"PriorityQueue-优先级队列","permalink":"https://tianxiafeiyu.github.io/tags/PriorityQueue-%E4%BC%98%E5%85%88%E7%BA%A7%E9%98%9F%E5%88%97/"},{"name":"实体类中用基本类型还是包装类","slug":"实体类中用基本类型还是包装类","permalink":"https://tianxiafeiyu.github.io/tags/%E5%AE%9E%E4%BD%93%E7%B1%BB%E4%B8%AD%E7%94%A8%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B%E8%BF%98%E6%98%AF%E5%8C%85%E8%A3%85%E7%B1%BB/"},{"name":"混乱的Java版本命名","slug":"混乱的Java版本命名","permalink":"https://tianxiafeiyu.github.io/tags/%E6%B7%B7%E4%B9%B1%E7%9A%84Java%E7%89%88%E6%9C%AC%E5%91%BD%E5%90%8D/"},{"name":"解读阿里巴巴 Java 代码规范","slug":"解读阿里巴巴-Java-代码规范","permalink":"https://tianxiafeiyu.github.io/tags/%E8%A7%A3%E8%AF%BB%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4-Java-%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"},{"name":"TCP 协议灵魂 12 问 【转】","slug":"TCP-协议灵魂-12-问-【转】","permalink":"https://tianxiafeiyu.github.io/tags/TCP-%E5%8D%8F%E8%AE%AE%E7%81%B5%E9%AD%82-12-%E9%97%AE-%E3%80%90%E8%BD%AC%E3%80%91/"},{"name":"NaN代表什么意思","slug":"NaN代表什么意思","permalink":"https://tianxiafeiyu.github.io/tags/NaN%E4%BB%A3%E8%A1%A8%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D/"},{"name":"jsonpath使用心得","slug":"jsonpath使用心得","permalink":"https://tianxiafeiyu.github.io/tags/jsonpath%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/"},{"name":"k8s国际化实现","slug":"k8s国际化实现","permalink":"https://tianxiafeiyu.github.io/tags/k8s%E5%9B%BD%E9%99%85%E5%8C%96%E5%AE%9E%E7%8E%B0/"},{"name":"maven使用本地依赖","slug":"maven使用本地依赖","permalink":"https://tianxiafeiyu.github.io/tags/maven%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0%E4%BE%9D%E8%B5%96/"},{"name":"Spring 注解","slug":"Spring-注解","permalink":"https://tianxiafeiyu.github.io/tags/Spring-%E6%B3%A8%E8%A7%A3/"},{"name":"SkyWalking—Java探针插件开发","slug":"SkyWalking—Java探针插件开发","permalink":"https://tianxiafeiyu.github.io/tags/SkyWalking%E2%80%94Java%E6%8E%A2%E9%92%88%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/"},{"name":"Skywalking数据库插件分析（废稿）","slug":"Skywalking数据库插件分析（废稿）","permalink":"https://tianxiafeiyu.github.io/tags/Skywalking%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8F%92%E4%BB%B6%E5%88%86%E6%9E%90%EF%BC%88%E5%BA%9F%E7%A8%BF%EF%BC%89/"},{"name":"Spring的单例模式与线程安全","slug":"Spring的单例模式与线程安全","permalink":"https://tianxiafeiyu.github.io/tags/Spring%E7%9A%84%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"},{"name":"skywalking Jdbc插件分析","slug":"skywalking-Jdbc插件分析","permalink":"https://tianxiafeiyu.github.io/tags/skywalking-Jdbc%E6%8F%92%E4%BB%B6%E5%88%86%E6%9E%90/"},{"name":"RESTful API格式规范","slug":"RESTful-API格式规范","permalink":"https://tianxiafeiyu.github.io/tags/RESTful-API%E6%A0%BC%E5%BC%8F%E8%A7%84%E8%8C%83/"},{"name":"mysql常用函数汇总","slug":"mysql常用函数汇总","permalink":"https://tianxiafeiyu.github.io/tags/mysql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E6%B1%87%E6%80%BB/"},{"name":"mysql联合索引","slug":"mysql联合索引","permalink":"https://tianxiafeiyu.github.io/tags/mysql%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95/"},{"name":"Linux shell 各种符号的意义","slug":"Linux-shell-各种符号的意义","permalink":"https://tianxiafeiyu.github.io/tags/Linux-shell-%E5%90%84%E7%A7%8D%E7%AC%A6%E5%8F%B7%E7%9A%84%E6%84%8F%E4%B9%89/"},{"name":"Linux常用命令","slug":"Linux常用命令","permalink":"https://tianxiafeiyu.github.io/tags/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"name":"Java中无处不在的坑","slug":"Java中无处不在的坑","permalink":"https://tianxiafeiyu.github.io/tags/Java%E4%B8%AD%E6%97%A0%E5%A4%84%E4%B8%8D%E5%9C%A8%E7%9A%84%E5%9D%91/"},{"name":"Java优雅的关闭连接资源","slug":"Java优雅的关闭连接资源","permalink":"https://tianxiafeiyu.github.io/tags/Java%E4%BC%98%E9%9B%85%E7%9A%84%E5%85%B3%E9%97%AD%E8%BF%9E%E6%8E%A5%E8%B5%84%E6%BA%90/"},{"name":"Java保留小数点后几位","slug":"Java保留小数点后几位","permalink":"https://tianxiafeiyu.github.io/tags/Java%E4%BF%9D%E7%95%99%E5%B0%8F%E6%95%B0%E7%82%B9%E5%90%8E%E5%87%A0%E4%BD%8D/"},{"name":"Java对象循环引用解法","slug":"Java对象循环引用解法","permalink":"https://tianxiafeiyu.github.io/tags/Java%E5%AF%B9%E8%B1%A1%E5%BE%AA%E7%8E%AF%E5%BC%95%E7%94%A8%E8%A7%A3%E6%B3%95/"},{"name":"Jpa还是Mybatis？","slug":"Jpa还是Mybatis？","permalink":"https://tianxiafeiyu.github.io/tags/Jpa%E8%BF%98%E6%98%AFMybatis%EF%BC%9F/"},{"name":"java多线程核心技术梳理【转】","slug":"java多线程核心技术梳理【转】","permalink":"https://tianxiafeiyu.github.io/tags/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E6%A2%B3%E7%90%86%E3%80%90%E8%BD%AC%E3%80%91/"},{"name":"AI视频处理软件","slug":"AI视频处理软件","permalink":"https://tianxiafeiyu.github.io/tags/AI%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86%E8%BD%AF%E4%BB%B6/"},{"name":"FTP、FTPS和SFTP都是啥","slug":"FTP、FTPS和SFTP都是啥","permalink":"https://tianxiafeiyu.github.io/tags/FTP%E3%80%81FTPS%E5%92%8CSFTP%E9%83%BD%E6%98%AF%E5%95%A5/"},{"name":"github添加ssh方法","slug":"github添加ssh方法","permalink":"https://tianxiafeiyu.github.io/tags/github%E6%B7%BB%E5%8A%A0ssh%E6%96%B9%E6%B3%95/"},{"name":"git—合并不同仓库的项目代码","slug":"git—合并不同仓库的项目代码","permalink":"https://tianxiafeiyu.github.io/tags/git%E2%80%94%E5%90%88%E5%B9%B6%E4%B8%8D%E5%90%8C%E4%BB%93%E5%BA%93%E7%9A%84%E9%A1%B9%E7%9B%AE%E4%BB%A3%E7%A0%81/"},{"name":"git仓库第一次提交时失败问题记录","slug":"git仓库第一次提交时失败问题记录","permalink":"https://tianxiafeiyu.github.io/tags/git%E4%BB%93%E5%BA%93%E7%AC%AC%E4%B8%80%E6%AC%A1%E6%8F%90%E4%BA%A4%E6%97%B6%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"name":"数据库之脏读、幻读、不可重复读","slug":"数据库之脏读、幻读、不可重复读","permalink":"https://tianxiafeiyu.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8B%E8%84%8F%E8%AF%BB%E3%80%81%E5%B9%BB%E8%AF%BB%E3%80%81%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB/"},{"name":"一次apisix问题排查过程","slug":"一次apisix问题排查过程","permalink":"https://tianxiafeiyu.github.io/tags/%E4%B8%80%E6%AC%A1apisix%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E8%BF%87%E7%A8%8B/"},{"name":"一次python代码混淆问题排查","slug":"一次python代码混淆问题排查","permalink":"https://tianxiafeiyu.github.io/tags/%E4%B8%80%E6%AC%A1python%E4%BB%A3%E7%A0%81%E6%B7%B7%E6%B7%86%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"},{"name":"一种将文本转换为图表的现代图表脚本语言","slug":"一种将文本转换为图表的现代图表脚本语言","permalink":"https://tianxiafeiyu.github.io/tags/%E4%B8%80%E7%A7%8D%E5%B0%86%E6%96%87%E6%9C%AC%E8%BD%AC%E6%8D%A2%E4%B8%BA%E5%9B%BE%E8%A1%A8%E7%9A%84%E7%8E%B0%E4%BB%A3%E5%9B%BE%E8%A1%A8%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/"},{"name":"为什么好的开源软件多是基础架构层","slug":"为什么好的开源软件多是基础架构层","permalink":"https://tianxiafeiyu.github.io/tags/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A5%BD%E7%9A%84%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%A4%9A%E6%98%AF%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E5%B1%82/"},{"name":"延时、丢包、抖动——术语解释","slug":"延时、丢包、抖动——术语解释","permalink":"https://tianxiafeiyu.github.io/tags/%E5%BB%B6%E6%97%B6%E3%80%81%E4%B8%A2%E5%8C%85%E3%80%81%E6%8A%96%E5%8A%A8%E2%80%94%E2%80%94%E6%9C%AF%E8%AF%AD%E8%A7%A3%E9%87%8A/"},{"name":"css知识点","slug":"css知识点","permalink":"https://tianxiafeiyu.github.io/tags/css%E7%9F%A5%E8%AF%86%E7%82%B9/"},{"name":"tops","slug":"tops","permalink":"https://tianxiafeiyu.github.io/tags/tops/"},{"name":"Python高级编程技巧","slug":"Python高级编程技巧","permalink":"https://tianxiafeiyu.github.io/tags/Python%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"},{"name":"python list()和[],dict()和{}","slug":"python-list-和-dict-和","permalink":"https://tianxiafeiyu.github.io/tags/python-list-%E5%92%8C-dict-%E5%92%8C/"},{"name":"python入门","slug":"python入门","permalink":"https://tianxiafeiyu.github.io/tags/python%E5%85%A5%E9%97%A8/"},{"name":"python单例模式实现","slug":"python单例模式实现","permalink":"https://tianxiafeiyu.github.io/tags/python%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%AE%9E%E7%8E%B0/"},{"name":"python多进程与多线程","slug":"python多进程与多线程","permalink":"https://tianxiafeiyu.github.io/tags/python%E5%A4%9A%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"python知识点","slug":"python知识点","permalink":"https://tianxiafeiyu.github.io/tags/python%E7%9F%A5%E8%AF%86%E7%82%B9/"},{"name":"python编程技巧","slug":"python编程技巧","permalink":"https://tianxiafeiyu.github.io/tags/python%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"},{"name":"python脚本接收参数的几种实现方式","slug":"python脚本接收参数的几种实现方式","permalink":"https://tianxiafeiyu.github.io/tags/python%E8%84%9A%E6%9C%AC%E6%8E%A5%E6%94%B6%E5%8F%82%E6%95%B0%E7%9A%84%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/"},{"name":"变量及方法前后下划线的含义","slug":"变量及方法前后下划线的含义","permalink":"https://tianxiafeiyu.github.io/tags/%E5%8F%98%E9%87%8F%E5%8F%8A%E6%96%B9%E6%B3%95%E5%89%8D%E5%90%8E%E4%B8%8B%E5%88%92%E7%BA%BF%E7%9A%84%E5%90%AB%E4%B9%89/"},{"name":"cmdb_mock","slug":"cmdb-mock","permalink":"https://tianxiafeiyu.github.io/tags/cmdb-mock/"},{"name":"push_cmdb_data","slug":"push-cmdb-data","permalink":"https://tianxiafeiyu.github.io/tags/push-cmdb-data/"},{"name":"Golang与Java","slug":"Golang与Java","permalink":"https://tianxiafeiyu.github.io/tags/Golang%E4%B8%8EJava/"},{"name":"golang学习大纲","slug":"golang学习大纲","permalink":"https://tianxiafeiyu.github.io/tags/golang%E5%AD%A6%E4%B9%A0%E5%A4%A7%E7%BA%B2/"},{"name":"go流程控制","slug":"go流程控制","permalink":"https://tianxiafeiyu.github.io/tags/go%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/"},{"name":"go项目标准布局","slug":"go项目标准布局","permalink":"https://tianxiafeiyu.github.io/tags/go%E9%A1%B9%E7%9B%AE%E6%A0%87%E5%87%86%E5%B8%83%E5%B1%80/"},{"name":"http client最优配置","slug":"http-client最优配置","permalink":"https://tianxiafeiyu.github.io/tags/http-client%E6%9C%80%E4%BC%98%E9%85%8D%E7%BD%AE/"},{"name":"优秀golang开源项目","slug":"优秀golang开源项目","permalink":"https://tianxiafeiyu.github.io/tags/%E4%BC%98%E7%A7%80golang%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"},{"name":"go ast","slug":"go-ast","permalink":"https://tianxiafeiyu.github.io/tags/go-ast/"},{"name":"go csp并发模型","slug":"go-csp并发模型","permalink":"https://tianxiafeiyu.github.io/tags/go-csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"},{"name":"go gc","slug":"go-gc","permalink":"https://tianxiafeiyu.github.io/tags/go-gc/"},{"name":"xorm使用","slug":"xorm使用","permalink":"https://tianxiafeiyu.github.io/tags/xorm%E4%BD%BF%E7%94%A8/"},{"name":"go checklist","slug":"go-checklist","permalink":"https://tianxiafeiyu.github.io/tags/go-checklist/"},{"name":"JTW详解","slug":"JTW详解","permalink":"https://tianxiafeiyu.github.io/tags/JTW%E8%AF%A6%E8%A7%A3/"},{"name":"JVM与Java程序","slug":"JVM与Java程序","permalink":"https://tianxiafeiyu.github.io/tags/JVM%E4%B8%8EJava%E7%A8%8B%E5%BA%8F/"},{"name":"Java创建线程的4种方式","slug":"Java创建线程的4种方式","permalink":"https://tianxiafeiyu.github.io/tags/Java%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E7%9A%844%E7%A7%8D%E6%96%B9%E5%BC%8F/"},{"name":"Java序列化与反序列化","slug":"Java序列化与反序列化","permalink":"https://tianxiafeiyu.github.io/tags/Java%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/"},{"name":"Java异常处理原则","slug":"Java异常处理原则","permalink":"https://tianxiafeiyu.github.io/tags/Java%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E5%8E%9F%E5%88%99/"},{"name":"Java构造函数细节","slug":"Java构造函数细节","permalink":"https://tianxiafeiyu.github.io/tags/Java%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E7%BB%86%E8%8A%82/"},{"name":"Java正则表达式","slug":"Java正则表达式","permalink":"https://tianxiafeiyu.github.io/tags/Java%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"Java获取时间工具类","slug":"Java获取时间工具类","permalink":"https://tianxiafeiyu.github.io/tags/Java%E8%8E%B7%E5%8F%96%E6%97%B6%E9%97%B4%E5%B7%A5%E5%85%B7%E7%B1%BB/"},{"name":"Jenkins遇到的坑","slug":"Jenkins遇到的坑","permalink":"https://tianxiafeiyu.github.io/tags/Jenkins%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/"},{"name":"Skywalking使用graphql查询","slug":"Skywalking使用graphql查询","permalink":"https://tianxiafeiyu.github.io/tags/Skywalking%E4%BD%BF%E7%94%A8graphql%E6%9F%A5%E8%AF%A2/"},{"name":"Skywalking学习","slug":"Skywalking学习","permalink":"https://tianxiafeiyu.github.io/tags/Skywalking%E5%AD%A6%E4%B9%A0/"},{"name":"Spring boot单元测试","slug":"Spring-boot单元测试","permalink":"https://tianxiafeiyu.github.io/tags/Spring-boot%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"},{"name":"Spring boot读取配置文件问题","slug":"Spring-boot读取配置文件问题","permalink":"https://tianxiafeiyu.github.io/tags/Spring-boot%E8%AF%BB%E5%8F%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E9%97%AE%E9%A2%98/"},{"name":"Spring security实现权限认证","slug":"Spring-security实现权限认证","permalink":"https://tianxiafeiyu.github.io/tags/Spring-security%E5%AE%9E%E7%8E%B0%E6%9D%83%E9%99%90%E8%AE%A4%E8%AF%81/"},{"name":"lombok","slug":"lombok","permalink":"https://tianxiafeiyu.github.io/tags/lombok/"},{"name":"null==obj or obj==null ？","slug":"null-obj-or-obj-null-？","permalink":"https://tianxiafeiyu.github.io/tags/null-obj-or-obj-null-%EF%BC%9F/"},{"name":"spring boot + jasypt实现配置文件信息加密","slug":"spring-boot-jasypt实现配置文件信息加密","permalink":"https://tianxiafeiyu.github.io/tags/spring-boot-jasypt%E5%AE%9E%E7%8E%B0%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%BF%A1%E6%81%AF%E5%8A%A0%E5%AF%86/"},{"name":"spring boot中代码修改配置文件","slug":"spring-boot中代码修改配置文件","permalink":"https://tianxiafeiyu.github.io/tags/spring-boot%E4%B8%AD%E4%BB%A3%E7%A0%81%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"name":"spring boot使用单例模式的痛","slug":"spring-boot使用单例模式的痛","permalink":"https://tianxiafeiyu.github.io/tags/spring-boot%E4%BD%BF%E7%94%A8%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E7%97%9B/"},{"name":"spring boot使用多线程","slug":"spring-boot使用多线程","permalink":"https://tianxiafeiyu.github.io/tags/spring-boot%E4%BD%BF%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"spring security学习【转】","slug":"spring-security学习【转】","permalink":"https://tianxiafeiyu.github.io/tags/spring-security%E5%AD%A6%E4%B9%A0%E3%80%90%E8%BD%AC%E3%80%91/"},{"name":"关于线程安全","slug":"关于线程安全","permalink":"https://tianxiafeiyu.github.io/tags/%E5%85%B3%E4%BA%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"},{"name":"2020 学习计划（成长之路）","slug":"2020-学习计划（成长之路）","permalink":"https://tianxiafeiyu.github.io/tags/2020-%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92%EF%BC%88%E6%88%90%E9%95%BF%E4%B9%8B%E8%B7%AF%EF%BC%89/"},{"name":"Java 归并排序【转】","slug":"Java-归并排序【转】","permalink":"https://tianxiafeiyu.github.io/tags/Java-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E3%80%90%E8%BD%AC%E3%80%91/"},{"name":"acmp开发记录","slug":"acmp开发记录","permalink":"https://tianxiafeiyu.github.io/tags/acmp%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"},{"name":"idea+maven+git 开发环境安装","slug":"idea-maven-git-开发环境安装","permalink":"https://tianxiafeiyu.github.io/tags/idea-maven-git-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"},{"name":"idea使用心得","slug":"idea使用心得","permalink":"https://tianxiafeiyu.github.io/tags/idea%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/"},{"name":"《On Java 8》读书笔记","slug":"《On-Java-8》读书笔记","permalink":"https://tianxiafeiyu.github.io/tags/%E3%80%8AOn-Java-8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"git 笔记","slug":"git-笔记","permalink":"https://tianxiafeiyu.github.io/tags/git-%E7%AC%94%E8%AE%B0/"},{"name":"mysql、redis开启远程访问","slug":"mysql、redis开启远程访问","permalink":"https://tianxiafeiyu.github.io/tags/mysql%E3%80%81redis%E5%BC%80%E5%90%AF%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/"},{"name":"Elasticsearch Java Rest Client","slug":"Elasticsearch-Java-Rest-Client","permalink":"https://tianxiafeiyu.github.io/tags/Elasticsearch-Java-Rest-Client/"},{"name":"Elasticsearch版本特性","slug":"Elasticsearch版本特性","permalink":"https://tianxiafeiyu.github.io/tags/Elasticsearch%E7%89%88%E6%9C%AC%E7%89%B9%E6%80%A7/"},{"name":"Apdex 应用性能指数","slug":"Apdex-应用性能指数","permalink":"https://tianxiafeiyu.github.io/tags/Apdex-%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD%E6%8C%87%E6%95%B0/"},{"name":"GraphQL 入门","slug":"GraphQL-入门","permalink":"https://tianxiafeiyu.github.io/tags/GraphQL-%E5%85%A5%E9%97%A8/"},{"name":"REST风格理解","slug":"REST风格理解","permalink":"https://tianxiafeiyu.github.io/tags/REST%E9%A3%8E%E6%A0%BC%E7%90%86%E8%A7%A3/"},{"name":"dalin的服务器配置记录","slug":"dalin的服务器配置记录","permalink":"https://tianxiafeiyu.github.io/tags/dalin%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95/"},{"name":"k8s配置文件详解","slug":"k8s配置文件详解","permalink":"https://tianxiafeiyu.github.io/tags/k8s%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"name":"session，cookie，token学习","slug":"session，cookie，token学习","permalink":"https://tianxiafeiyu.github.io/tags/session%EF%BC%8Ccookie%EF%BC%8Ctoken%E5%AD%A6%E4%B9%A0/"},{"name":"一次完整的HTTP请求过程【转】","slug":"一次完整的HTTP请求过程【转】","permalink":"https://tianxiafeiyu.github.io/tags/%E4%B8%80%E6%AC%A1%E5%AE%8C%E6%95%B4%E7%9A%84HTTP%E8%AF%B7%E6%B1%82%E8%BF%87%E7%A8%8B%E3%80%90%E8%BD%AC%E3%80%91/"},{"name":"各种语言版本的 Helloworld","slug":"各种语言版本的-Helloworld","permalink":"https://tianxiafeiyu.github.io/tags/%E5%90%84%E7%A7%8D%E8%AF%AD%E8%A8%80%E7%89%88%E6%9C%AC%E7%9A%84-Helloworld/"},{"name":"服务缓存数据更新","slug":"服务缓存数据更新","permalink":"https://tianxiafeiyu.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E6%9B%B4%E6%96%B0/"},{"name":"使用github搭建个人博客","slug":"使用github搭建个人博客","permalink":"https://tianxiafeiyu.github.io/tags/%E4%BD%BF%E7%94%A8github%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"name":"keep","slug":"keep","permalink":"https://tianxiafeiyu.github.io/tags/keep/"},{"name":"为什么bk-cmdb不用go mod管理","slug":"为什么bk-cmdb不用go-mod管理","permalink":"https://tianxiafeiyu.github.io/tags/%E4%B8%BA%E4%BB%80%E4%B9%88bk-cmdb%E4%B8%8D%E7%94%A8go-mod%E7%AE%A1%E7%90%86/"},{"name":"Java8新特性","slug":"Java8新特性","permalink":"https://tianxiafeiyu.github.io/tags/Java8%E6%96%B0%E7%89%B9%E6%80%A7/"},{"name":"进程间通信技术","slug":"进程间通信技术","permalink":"https://tianxiafeiyu.github.io/tags/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/"},{"name":"index","slug":"index","permalink":"https://tianxiafeiyu.github.io/tags/index/"}]}
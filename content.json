{"meta":{"title":"Dalin blog","subtitle":"","description":"","author":"Dalin","url":"http://example.com"},"pages":[{"title":"Categories","date":"2022-12-13T04:38:23.541Z","updated":"2022-12-13T04:38:23.541Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"About","date":"2022-12-13T04:38:23.541Z","updated":"2022-12-13T04:38:23.541Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""},{"title":"Tags","date":"2022-12-13T04:38:23.541Z","updated":"2022-12-13T04:38:23.541Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"开发笔记/Apdex 应用性能指数","date":"2022-12-13T04:38:23.541Z","updated":"2022-12-13T04:38:23.541Z","comments":true,"path":"2022/12/13/开发笔记/Apdex 应用性能指数/","link":"","permalink":"http://example.com/2022/12/13/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/Apdex%20%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD%E6%8C%87%E6%95%B0/","excerpt":"","text":"Apdex 应用性能指数是站在用户角度衡量用户对应用满意度的数值。 假设用户对于服务的响应容忍度权值为 T 满意（1分） 容忍（0.5分） 失望（0分） 0~T T~4T 4T~ Apdex指数 &#x3D; (满意样本 x 1 + 容忍样本 x 0.5)&#x2F; 样本总数","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"","slug":"开发笔记/dalin的服务器配置记录","date":"2022-12-13T04:38:23.541Z","updated":"2022-12-13T04:38:23.541Z","comments":true,"path":"2022/12/13/开发笔记/dalin的服务器配置记录/","link":"","permalink":"http://example.com/2022/12/13/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/dalin%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95/","excerpt":"","text":"阿里云上重新买了台穷鬼t5，菜是菜了点，但是该折腾还是要折腾的。。。 设置虚拟内存安装free -m 查看内存状态, Swap 的值都是0，说明还没有安装虚拟内存 在 &#x2F;opt 下创建虚拟内存文件 1dd if=/dev/zero of=/opt/swap bs=2048 count=2048000 将swap文件设置为swap分区文件 12chmod 600 /opt/swap //注意更改swap文件的权限mkswap /opt/swap 激活swap,启用分区交换文件 1swapon /opt/swap 查看结果 1234[root@dalin1 opt]# free -m total used free shared buff/cache availableMem: 1829 1329 169 0 330 357Swap: 3999 429 3570 重启自动启用设置，否则机器重启后分区就失效了 1vim /etc/rc.local 底部添加 1swapon /home/swap 卸载停止swap分区 1swapoff /opt/swap 删除掉swap文件 1rm -rf /opt/swap 查看磁盘情况： 12345678910[root@dalin1 opt]# df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 900M 0 900M 0% /devtmpfs 915M 0 915M 0% /dev/shmtmpfs 915M 612K 915M 1% /runtmpfs 915M 0 915M 0% /sys/fs/cgroup/dev/vda1 40G 9.5G 31G 24% /tmpfs 183M 0 183M 0% /run/user/1000overlay 40G 9.5G 31G 24% /var/lib/docker/overlay2/cb6202d7408b52de4ca486b57263e33e6dbb34d3adf35e86bfdffe62b9d33339/mergedoverlay 40G 9.5G 31G 24% /var/lib/docker/overlay2/25f9d8b78fa8906f7b379efce90fdd90f8e5771399f537988cf15ca450641596/merged mysql 安装上一次鄙人的mysql开启了远程访问，并且没有注意安全防范，被比特币勒索了。。。但是使用远程msql服务的需求还是需要的，毕竟真的是方便，这次注意一下安全方面的配置，应该不至于再没了吧。。。 1. centos8 安装mysql8使用最新的包管理器安装MySQL 1sudo dnf install @mysql 设置开机自启并启动 1sudo systemctl enable --now mysqld 运行mysql_secure_installation脚本，该脚本执行一些与安全性相关的操作并设置MySQL根密码： 1mysql_secure_installation 按提示往下走即可，注意在 Disallow root login remotely?选项中选择 n 2. 更换 mysql 默认端口vim /etc/my.cnf，添加字段 port=6612 systemctl restart mysqld 重启 mysql 防火墙添加6612端口白名单 12firewall-cmd --add-port=6612/tcp --permanentfirewall-cmd --reload centos默认使用的是firewall作为防火墙，一些常用命令： firewall-cmd –list-ports ##查看已开放的端口 firewall-cmd –add-port&#x3D;6612&#x2F;tcp –permanent ##永久开放6612端口 firewall-cmd –remove-port&#x3D;6612&#x2F;tcp –permanent ##永久关闭6612端口 firewall-cmd –reload ##刷新 阿里云控制台安全组开放 6612 端口 3. mysql 允许远程主机访问登录mysql 1mysql -uroot -p&lt;密码&gt; 将 mysql.user 中的 root 的 host 字段设为&#39;%&#39;： 123use mysql;update user set host=&#x27;%&#x27; where user=&#x27;root&#x27;;flush privileges; 4. 使用脚本自动备份数据1234567891011121314151617181920212223242526272829303132333435363738394041#!/bin/bash#数据库服务器dbserver=&#x27;localhost&#x27;#数据库用户名dbuser=&#x27;root&#x27;#数据库用密码dbpasswd=&#x27;********&#x27;#需要备份的数据库，多个数据库用空格分开dbname=&#x27;backdata01 backdata02&#x27;#备份时间backtime=`date +%Y%m%d`#日志备份路径logpath=&#x27;/opt/data/mysqlbak/&#x27;#数据备份路径datapath=&#x27;/opt/data/mysqlbak/&#x27; echo &#x27;##################$backtime##########################&#x27; #日志记录头部echo ‘&quot;备份时间为$&#123;backtime&#125;,备份数据库表 $&#123;dbname&#125; 开始&quot; &gt;&gt; $&#123;logpath&#125;/mysqlback.log#正式备份数据库for table in $dbname; dosource=`mysqldump -h $&#123;dbserver&#125; -u $&#123;dbuser&#125; -p$&#123;dbpasswd&#125; $&#123;table&#125; &gt; $&#123;logpath&#125;/$&#123;backtime&#125;.sql` 2&gt;&gt; $&#123;logpath&#125;/mysqlback.log;#备份成功以下操作if [ &quot;$?&quot; == 0 ];thencd $datapath#为节约硬盘空间，将数据库压缩tar zcf $&#123;table&#125;$&#123;backtime&#125;.tar.gz $&#123;backtime&#125;.sql &gt; /dev/null#删除原始文件，只留压缩后文件rm -f $&#123;datapath&#125;/$&#123;backtime&#125;.sql#删除七天前备份，也就是只保存7天内的备份find $datapath -name &quot;*.tar.gz&quot; -type f -mtime +7 -exec rm -rf &#123;&#125; \\; &gt; /dev/null 2&gt;&amp;1echo &quot;数据库表 $&#123;dbname&#125; 备份成功!!&quot; &gt;&gt; $&#123;logpath&#125;/mysqlback.logelse#备份失败则进行以下操作echo &quot;数据库表 $&#123;dbname&#125; 备份失败!!&quot; &gt;&gt; $&#123;logpath&#125;/mysqlback.logfidone echo &#x27;##################完成############################&#x27; 创建定时任务 12crontab -e59 23 * * * ./opt/mysqldata/mysqlbak.sh ## 每天23:59执行命令 redis 安装5. 安装redis并且设置远程访问和密码配置12[root@dalin1 ~]# yum -y install redis[root@dalin1 ~]# systemctl enable --now redis 修改redis端口、设置密码、允许远程访问 1[root@dalin1 ~]# vim /etc/redis.conf 修改 port 6369 注释掉 bind 127.0.0.1，以便让外网访问 去掉 #requirepass foobared 注释，foobared改为自己的密码 防火墙添加6369端口白名单 12firewall-cmd --add-port=6369/tcp --permanentfirewall-cmd --reload 阿里云控制台安全组开放 6369 端口 6. 创建普通用户，以后尽量使用普通用户操作123[root@dalin1 ~]# adduser dalin #创建普通用户 dalin[root@dalin1 ~]# passwd dalin #修改密码[root@dalin1 ~]# su dalin #切换用户 普通用户只在 /home/&lt;username&gt; 目录下有完整权限 docker 安装docker这么方便的东西怎么能不用呢，但是因为服务器实在太菜了，可能会卡顿，而且要时刻注意内存使用情况 1. 安装依赖包1[root@dalin1 ~]# yum install -y yum-utils device-mapper-persistent-data lvm2 2. 设置Docker源1[root@dalin1 ~]# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 3. 安装Docker CE3.1 docker安装版本查看1[root@dalin1 ~]# yum list docker-ce --showduplicates | sort -r 3.2 安装docker1[root@dalin1 ~]# yum install docker-ce-18.09.6 docker-ce-cli-18.09.6 containerd.io 指定安装的docker版本为18.09.6，由于该版本目前为最新版，故可以直接安装，不用指定版本： 1[root@dalin1 ~]# yum install -y docker-ce docker-ce-cli containerd.io 4. 启动Docker并设置开机自启1[root@dalin1 ~]# systemctl enable --now docker 5. 镜像加速使用阿里云镜像加速地址 123456[root@dalin1 ~]# mkdir -p /etc/docker[root@dalin1 ~]# tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123; &quot;registry-mirrors&quot;: [&quot;https://khv87vsk.mirror.aliyuncs.com&quot;]&#125;EOF docker 下安装Elasticsearch和Kibana服务器太菜，基本跑不动 安装Elasticsearch下载镜像： 1[root@dalin1 ~]# docker pull elasticsearch:7.2.0 启动容器 1[root@dalin1 ~]# docker run --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; -d elasticsearch:7.2.0 大概率启动失败，查看日志： 12345678910111213[root@dalin1 temp]# docker logs elasticsearchException in thread &quot;main&quot; java.lang.RuntimeException: starting java failed with [1]output:## There is insufficient memory for the Java Runtime Environment to continue.# Native memory allocation (mmap) failed to map 1073741824 bytes for committing reserved memory.# An error report file with more information is saved as:# logs/hs_err_pid132.logerror:OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x00000000c0000000, 1073741824, 0) failed; error=&#x27;Not enough space&#x27; (errno=12) at org.elasticsearch.tools.launchers.JvmErgonomics.flagsFinal(JvmErgonomics.java:126) at org.elasticsearch.tools.launchers.JvmErgonomics.finalJvmOptions(JvmErgonomics.java:88) ... jvm内存不足。。。 123[root@dalin1]# find / -name jvm.options/var/lib/docker/overlay2/aa7a9ac9f293452ddf8947e9fdf3af24d602566d54b6278284751239b43e37e5/diff/usr/share/elasticsearch/config/jvm.options[root@dalin1]# vim /var/lib/docker/overlay2/aa7a9ac9f293452ddf8947e9fdf3af24d602566d54b6278284751239b43e37e5/diff/usr/share/elasticsearch/config/jvm.options 1234567891011121314151617181920212223242526## JVM configuration################################################################## IMPORTANT: JVM heap size#################################################################### You should always set the min and max JVM heap## size to the same value. For example, to set## the heap to 4 GB, set:#### -Xms4g## -Xmx4g#### See https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html## for more information################################################################### Xms represents the initial size of total heap space# Xmx represents the maximum size of total heap space-Xms1g #服务器实在太菜了，我改成256m-Xmx1g #服务器实在太菜了，我改成256m################################################################ 重新启动容器 1[root@dalin1 ~]# docker start elasticsearch 检测是否启动成功 12345678910111213141516171819[root@dalin1 ~]# curl http://localhost:9200&#123; &quot;name&quot; : &quot;c19d1882a695&quot;, &quot;cluster_name&quot; : &quot;docker-cluster&quot;, &quot;cluster_uuid&quot; : &quot;-zKpqN7TQMqmPULGgdMz3w&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;7.2.0&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;docker&quot;, &quot;build_hash&quot; : &quot;508c38a&quot;, &quot;build_date&quot; : &quot;2019-06-20T15:54:18.811730Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.0.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 解决跨域访问问题 进入容器，修改elasticsearch.yml文件 12[root@dalin1 ~]# docker exec -it elasticsearch /bin/bashvim /usr/share/elasticsearch/config/elasticsearch.yml 在elasticsearch.yml的文件末尾加上: 12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; es自带的分词器对中文分词不是很友好，所以我们下载开源的IK分词器来解决这个问题。 123456````exit` 退出容器后 `docker restart elasticsearch` 重启容器#### kibana安装下载镜像 [root@dalin1 ~]# docker pull kibana:7.2.0 123启动kibana [root@dalin1 ~]# docker run –name kibana –link&#x3D;elasticsearch:es -e ELASTICSEARCH_URL&#x3D;http://172.17.0.2:9200 -p 5601:5601 -d kibana:7.7.0 123使用--link连接到elasticsearch容器，并添加环境变量，指定安装es的容器地址当然也可以进入容器内部修改配置文件来设置es访问地址 [root@dalin1 ~]# docker exec -it kibana &#x2F;bin&#x2F;bashvi config&#x2F;kibana.yml 12345kibana默认是优先使用环境变量的地址，然后才是配置文件kibana.yml&lt;br&gt;如何查询容器地址？ 获取到容器的元数据信息[root@dalin1 ~]# docker inspect [id&#x2F;name] 12最后，配置安全组和防火墙，开放9200、5601端口 [root@dalin1 ~]# firewall-cmd –add-port&#x3D;5601&#x2F;tcp –permanent[root@dalin1 ~]# firewall-cmd –add-port&#x3D;9200&#x2F;tcp –permanent 12这就结束了吗？是的，网上几乎所有的关于docker下安装kibana教程都是到了这一步就说完事收工、开始体验。。。但是！！！我遇到的情况是访问 `http//:ip:5601`，只会给我冰冷的大字： Kibana server is not ready yet 1`docker logs kibana`打印日志，报错： {“type”:”log”,”@timestamp”:”2020-06-04T08:25:57Z”,”tags”:[“warning”,”elasticsearch”,”admin”],”pid”:6,”message”:”Unable to revive connection: http://172.17.0.2:9200/&quot;}{“type”:”log”,”@timestamp”:”2020-06-04T08:25:57Z”,”tags”:[“warning”,”elasticsearch”,”admin”],”pid”:6,”message”:”No living connections”} 123ip地址是没问题的，es服务也确实起了，为什么呢？？这个问题花了我大半天的时间，找遍了网上的教程都没有相关的介绍，官网上关于docker安装kibana的教程更是少。 进入kibana容器中 [root@dalin1 ~]# docker exec -it kibana &#x2F;bin&#x2F;bashbash-4.2$ ping 172.17.0.2 #没有问题，能ping通bash-4.2$ curl http://120.79.43.44:9200curl: (7) Failed connect to 120.79.43.44:9200; No route to host 123问题就出在这里！应该是防火墙的原因导致容器之间无法进行通信解决方法，依次执行以下命令 [root@dalin1 ~]# nmcli connection modify docker0 connection.zone trusted [root@dalin1 ~]# systemctl stop NetworkManager.service [root@dalin1 ~]# firewall-cmd –permanent –zone&#x3D;trusted –change-interface&#x3D;docker0 [root@dalin1 ~]# systemctl start NetworkManager.service [root@dalin1 ~]# nmcli connection modify docker0 connection.zone trusted [root@dalin1 ~]# systemctl restart docker.service &#96;&#96;&#96;把 docker0 加入防火墙白名单 重新启动容器，访问地址 http://ip:5601 ，总算没有了 Kibana server is not ready yet,显示正在加载的图像，稍作等候即可，部署完成！","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"","slug":"开发笔记/golang/学习大纲","date":"2022-12-13T04:38:23.541Z","updated":"2022-12-13T04:38:23.541Z","comments":true,"path":"2022/12/13/开发笔记/golang/学习大纲/","link":"","permalink":"http://example.com/2022/12/13/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/golang/%E5%AD%A6%E4%B9%A0%E5%A4%A7%E7%BA%B2/","excerpt":"","text":"todo…","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"golang","slug":"开发笔记/golang","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/golang/"}],"tags":[]},{"title":"","slug":"开发笔记/java/关于线程安全","date":"2022-12-13T04:38:23.541Z","updated":"2022-12-13T04:38:23.541Z","comments":true,"path":"2022/12/13/开发笔记/java/关于线程安全/","link":"","permalink":"http://example.com/2022/12/13/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/%E5%85%B3%E4%BA%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/","excerpt":"","text":"关于线程安全（摘自https://www.cnblogs.com/nizuimeiabc1/p/4254127.html） 1）常量始终是线程安全的，因为只存在读操作。 2）每次调用方法前都新建一个实例是线程安全的，因为不会访问共享的资源。 3）局部变量是线程安全的。因为每执行一个方法，都会在独立的空间创建局部变量，它不是共享的资源。局部变量包括方法的参数变量和方法内变量。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"开发笔记/java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/java/"}],"tags":[]},{"title":"","slug":"开发笔记/工具/git 笔记","date":"2022-12-13T04:38:23.541Z","updated":"2022-12-13T04:38:23.541Z","comments":true,"path":"2022/12/13/开发笔记/工具/git 笔记/","link":"","permalink":"http://example.com/2022/12/13/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E5%B7%A5%E5%85%B7/git%20%E7%AC%94%E8%AE%B0/","excerpt":"","text":"删除本地文件后从远程仓库获取问题在本地删除文件后，git pull从远程仓库获取，但是一直提示 up-to-date，无法获取被删除的文件。 原因：当前本地库处于另一个分支中，需将本分支发Head重置至master。 将本分支发Head重置至master: 12$ git checkout master $ git reset --hard 强行pull并覆盖本地文件 123$ git fetch --all $ git reset --hard origin/master $ git pull","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"工具","slug":"开发笔记/工具","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E5%B7%A5%E5%85%B7/"}],"tags":[]},{"title":"","slug":"开发笔记/数据库/mysql、redis开启远程访问","date":"2022-12-13T04:38:23.541Z","updated":"2022-12-13T04:38:23.541Z","comments":true,"path":"2022/12/13/开发笔记/数据库/mysql、redis开启远程访问/","link":"","permalink":"http://example.com/2022/12/13/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql%E3%80%81redis%E5%BC%80%E5%90%AF%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/","excerpt":"","text":"要在本地使用云服务器中的mysql、redis服务，需要开启远程访问，阿里云还需要在控制台中开放3306、6379访问端口。 1、mysql开启远程访问默认情况下，mysql帐号不允许从远程登陆，只能在localhost登录。 在localhost登入mysql后，更改 “mysql” 数据库里的 “user” 表里的 “host” 项，将”localhost”改为”%” 12345678$ mysql -u root -p Enter password: …… mysql&gt; mysql&gt;update user set host = &#x27;%&#x27; where user = &#x27;root&#x27;; mysql&gt;select host, user from user; 2、redis开启远程访问防火墙开放6379端口： 123vim /etc/sysconfig/iptables添加字段：-A RH-Firewall-1-INPUT -m state NEW -m tcp -dport 8080 -j ACCEPT 修改redis配置文件vim &#x2F;etc&#x2F;redis.conf bind127.0.0.1 这一行注释掉 protected-mode yes 改为 protected-mode no 保存后重启：sysremctl restart redis 2020-6-1：由于鄙人暴露了mysql到公网上，不加约束、放荡不羁，如今数据库已遭到比特币勒索，血与泪的教训，以后要多加规范，防火防盗防小人","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"数据库","slug":"开发笔记/数据库","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"","slug":"开发笔记/数据库/es/Elasticsearch版本特性","date":"2022-12-13T04:38:23.541Z","updated":"2022-12-13T04:38:23.541Z","comments":true,"path":"2022/12/13/开发笔记/数据库/es/Elasticsearch版本特性/","link":"","permalink":"http://example.com/2022/12/13/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/es/Elasticsearch%E7%89%88%E6%9C%AC%E7%89%B9%E6%80%A7/","excerpt":"","text":"elasticsearch 各版本特性5.0支持Lucene 6.x Instant Aggregations，在Shard层面提供了Aggregation缓存 新增 Sliced Scroll类型，现在Scroll接口可以并发来进行数据遍历了。每个Scroll请求，可以分成多个Slice请求，可以理解为切片，各Slice独立并行，利用Scroll重建或者遍历要快很多倍。 新增了Profile API 同时支持search和aggregation的profile 有一个新的 Search After 机制，其实和 scroll 类似，也是游标的机制，它的原理是对文档按照多个字段进行排序，然后利用上一个结果的最后一个文档作为起始值，拿 size 个文档，一般我们建议使用 _uid 这个字段，它的值是唯一的 id 新增Shrink API 新增了Rollover API 新增Reindex 提供了第一个Java原生的REST客户端SDK 基于HTTP协议的客户端对Elasticsearch的依赖解耦，没有jar包冲突，提供了集群节点自动发现、日志处理、节点请求失败自动进行请求轮询，充分发挥Elasticsearch的高可用能力 新增Wait for refresh，提供了文档级别的Refresh 新增Ingest Node 新增Painless Scripting 新增Task Manager 新增Depreated logging 新增Cluster allocation explain API 新增 half_float 类型 新增 :Matrix Stats Aggregation 为索引写操作添加顺序号 引入新的字段类型 Text&#x2F;Keyword 来替换 String 关于 Index Settings 现在，配置验证更加严格和保证原子性，如果其中一项失败，那个整个都会更新请求都会失败，不会一半成功一半失败。下面主要说两点： 1.设置可以重设会默认值，只需要设置为 null即可 2.获取设置接口新增参数include_defaults,可以直接返回所有设置和默认值 集群管理方面，新增Deleted Index Tombstones Cluster state 的修改现在会和所有节点进行 ack 确认。 Shard 的一个副本如果失败了， Primary 标记失败的时候会和 Master 节点确认完毕再返回。 使用 UUID 来作为索引的物理的路径名，有很多好处，避免命名的冲突。 _timestamp 和 _ttl 已经移除，需要在 Ingest 或者程序端处理。 ES 可直接用 HDFS 来进行备份还原（ Snapshot&#x2F;Restore ）了 Delete-by-query 和 Update-by-query 重新回到 core ，以前是插件，现在可以直接使用了，也是构建在 Reindex 机制之上。(es1.x版本是直接支持，在es2.x中提取为插件，5.x继续回归直接支持) HTTP 请求默认支持压缩，当然 http 调用端需要在 header 信息里面传对应的支持信息。 创建索引不会再让集群变红了，不会因为这个卡死集群了。 默认使用 BM25 评分算法，效果更佳，之前是 TF&#x2F;IDF。 快照 Snapshots 添加 UUID 解决冲突 限制索引请求大小，避免大量并发请求压垮 ES 限制单个请求的 shards 数量，默认 1000 个 移除 site plugins ，就是说 head 、 bigdesk 都不能直接装 es 里面了，不过可以部署独立站点（反正都是静态文件）或开发 kibana 插件 允许现有 parent 类型新增 child 类型 这个功能对于使用parent-child特性的人应该非常有用。 支持分号（；）来分割 url 参数，与符号（ &amp; ）一样 6.0无宕机升级 使之能够从 5 的最后一个版本滚动升级到 6 的最后一个版本，不需要集群的完整重启。无宕机在线升级，无缝滚动升级 跨多个 Elasticsearch 群集搜索 和以前一样，Elasticsearch 6.0 能够读取在 5.x 中创建的 Indices ，但不能读取在 2.x 中创建的 Indices 。不同的是，现在不必重新索引所有的旧 Indices ，你可以选择将其保留在 5.x 群集中，并使用跨群集搜索同时在 6.x 和 5.x 群集上进行搜索 迁移助手 Kibana X-Pack 插件提供了一个简单的用户界面，可帮助重新索引旧 Indices ，以及将 Kibana、Security 和 Watcher 索引升级到 6.0 。 群集检查助手在现有群集上运行一系列检查，以帮助在升级之前更正任何问题。 你还应该查阅弃用日志，以确保您没有使用 6.0 版中已删除的功能 使用序列号更快地重启和还原 6.0 版本中最大的一个新特性就是序列 ID，它允许基于操作的分片恢复。 以前，如果由于网络问题或节点重启而从集群断开连接的节点，则节点上的每个分区都必须通过将分段文件与主分片进行比较并复制任何不同的分段来重新同步。 这可能是一个漫长而昂贵的过程，甚至使节点的滚动重新启动非常缓慢。 使用序列 ID，每个分片将只能重放该分片中缺少的操作，使恢复过程更加高效 使用排序索引更快查询 通过索引排序，只要收集到足够的命中，搜索就可以终止。它对通常用作过滤器的低基数字段（例如 age, gender, is_published）进行排序时可以更高效的搜索，因为所有潜在的匹配文档都被分组在一起。 稀疏区域改进 以前，每个列中的每个字段都预留了一个存储空间。如果只有少数文档出现很多字段，则可能会导致磁盘空间的巨大浪费。现在，你付出你使用的东西。密集字段将使用与以前相同的空间量，但稀疏字段将显着减小。这不仅可以减少磁盘空间使用量，还可以减少合并时间并提高查询吞吐量，因为可以更好地利用文件系统缓存 7.x集群连接变化：TransportClient被废弃 以至于，es7的java代码，只能使用restclient。然后，个人综合了一下，对于java编程，建议采用 High-level-rest-client 的方式操作ES集群 ES数据存储结构变化：去除了Type es6时，官方就提到了es7会删除type，并且es6时已经规定每一个index只能有一个type。在es7中使用默认的_doc作为type，官方说在8.x版本会彻底移除type。 api请求方式也发送变化，如获得某索引的某ID的文档：GET index&#x2F;_doc&#x2F;id其中index和id为具体的值 High-level REST client 改变 已删除接受Header参数的API方法；Cluster Health API默认为集群级别； ES程序包默认打包jdk：以至于7.x版本的程序包大小突然边300MB+ 对比6.x发现，包大了200MB+， 正是JDK的大小 默认配置变化：默认节点名称为主机名，默认分片数改为1，不再是5。 查询相关性速度优化：Weak-AND算法 啥是weak-and算法？ 核心原理：取TOP N结果集，估算命中记录数。 简单来说，一般我们在计算文本相关性的时候，会通过倒排索引的方式进行查询，通过倒排索引已经要比全量遍历节约大量时间，但是有时候仍然很慢。 原因是很多时候我们其实只是想要top n个结果，一些结果明显较差的也进行了复杂的相关性计算， 而weak-and算法通过计算每个词的贡献上限来估计文档的相关性上限，从而建立一个阈值对倒排中的结果进行减枝，从而得到提速的效果。 间隔查询(Intervals queries)： 某些搜索用例（例如，法律和专利搜索）引入了查找单词或短语彼此相距一定距离的记录的需要。 Elasticsearch 7.0中的间隔查询引入了一种构建此类查询的全新方式，与之前的方法（跨度查询span queries）相比，使用和定义更加简单。 与跨度查询相比，间隔查询对边缘情况的适应性更强。 引入新的集群协调子系统 移除 minimum_master_nodes 参数，让 Elasticsearch 自己选择可以形成仲裁的节点。 典型的主节点选举现在只需要很短的时间就可以完成。 集群的伸缩变得更安全、更容易，并且可能造成丢失数据的系统配置选项更少了。 节点更清楚地记录它们的状态，有助于诊断为什么它们不能加入集群或为什么无法选举出主节点。 时间戳纳秒级支持，提升数据精度 加粗样式 不再内存溢出 新的 Circuit Breaker 在JVM 堆栈层面监测内存使用，Elasticsearch 比之前更加健壮。 设置indices.breaker.fielddata.limit的默认值已从JVM堆大小的60％降低到40％。 ES7与旧版本的区别1. 关于 type（类型）使用 kibana 开发工具查询时候，指定类型查询会出现下面的提示： Deprecation: [types removal] Specifying types in document get requests is deprecated, use the &#x2F;{index}&#x2F;_doc&#x2F;{id} endpoint instead. es6时，官方就提到了es7会删除type，并且es6时已经规定每一个index只能有一个type。在es7中使用默认的_doc作为type，官方说在8.x版本会彻底移除type。 api请求方式也发送变化，如获得某索引的某ID的文档： 1GET index/_doc/id 其中index和id为具体的值 2. 弃用 “string”, 使用 “text” 域指定映射的时候使用 String 的话将会报错： 1No handler for type [string] declared on field xxx 使用 text 替代 string","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"数据库","slug":"开发笔记/数据库","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"es","slug":"开发笔记/数据库/es","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/es/"}],"tags":[]}]}